<!DOCTYPE html>
<!-- saved from url=(0078)https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-poster-papers -->
<html class="no-js"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>ICLR 2018 Conference | OpenReview</title>
  <meta name="description" content="">

      <meta name="twitter:card" content="summary">
      <meta name="twitter:site" content="@openreviewnet">
      <meta name="og:title" content="ICLR 2018 Conference">
      <meta name="og:description" content="">
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png">

  <link rel="stylesheet" href="./ICLR 2018 Conference _ OpenReview_files/css">

  <link rel="stylesheet" href="./ICLR 2018 Conference _ OpenReview_files/bootstrap.min.css">
  <link rel="stylesheet" href="./ICLR 2018 Conference _ OpenReview_files/jquery-ui.min.css">
  <link rel="stylesheet" href="./ICLR 2018 Conference _ OpenReview_files/main.min.css">
</head>

<body class="group"><div id="StayFocusd-infobar" style="display: none; top: 0px;">
    <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
    <span id="StayFocusd-infobar-msg"></span>
    <span id="StayFocusd-infobar-links">
        <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
        <a id="StayFocusd-infobar-hide">hide once</a>
    </span>
</div>
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="https://openreview.net/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search OpenReview..." autocomplete="off">
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="all">
          <input id="search_content" type="hidden" value="all">
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="https://openreview.net/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
          <span class="tagline">Open Peer Review. Open Publishing. Open Access. <span class="hidden-xs">Open Discussion. Open Recommendations.</span> <span class="hidden-xs hidden-sm">Open Directory. Open API. Open Source.</span></span>
      </div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix pre-rendered legacy-styles">
        <div id="group-container"><div id="header" class="venue-header" style="display: block;"><h1>ICLR 2018 Conference Track</h1>
<h3>6th International Conference on Learning Representations</h3>

  <h4>
      <span class="venue-location">
        <span class="glyphicon glyphicon-globe" aria-hidden="true"></span> Vancouver Convention Center, Vancouver, BC, Canada
      </span>
      <span class="venue-date">
        <span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> April 30 - May 3, 2018
      </span>
      <span class="venue-website">
        <span class="glyphicon glyphicon-new-window" aria-hidden="true"></span> <a href="http://www.iclr.cc/" title="ICLR 2018 Conference Track Homepage" target="_blank">http://www.iclr.cc</a>
      </span>
  </h4>

<div class="description">
    <p class="no-margin">Please see the venue website for more information.</p>
  <p></p>
</div>
</div><div id="invitation"></div><div id="notes">
<div class="tabs-container" style=""><ul class="nav nav-tabs" role="tablist">
    <li role="presentation" class="">
      <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-oral-papers" aria-controls="accepted-oral-papers" role="tab" data-toggle="tab" data-tab-index="0" aria-expanded="false">
        Oral Papers
      </a>
    </li>
    <li role="presentation" class="active">
      <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-poster-papers" aria-controls="accepted-poster-papers" role="tab" data-toggle="tab" data-tab-index="1" aria-expanded="true">
        Poster Papers
      </a>
    </li>
    <li role="presentation">
      <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#workshop-papers" aria-controls="workshop-papers" role="tab" data-toggle="tab" data-tab-index="2">
        Invited to submit to Workshop
      </a>
    </li>
    <li role="presentation">
      <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rejected-papers" aria-controls="rejected-papers" role="tab" data-toggle="tab" data-tab-index="3">
        Rejected Papers
      </a>
    </li>
    <li role="presentation">
      <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#withdrawn-papers" aria-controls="withdrawn-papers" role="tab" data-toggle="tab" data-tab-index="4">
        Withdrawn Papers
      </a>
    </li>
</ul>

<div class="tab-content">
    <div role="tabpanel" class="tab-pane fade" id="accepted-oral-papers">
      
    <ul class="list-unstyled submissions-list">
    <li class="note " data-id="ryQu7f-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryQu7f-RZ">
          On the Convergence of Adam and Beyond
        </a>
        
          <a href="https://openreview.net/pdf?id=ryQu7f-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sashank%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sashank@google.com">Sashank J. Reddi</a>, <a href="https://openreview.net/profile?email=satyenkale%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="satyenkale@google.com">Satyen Kale</a>, <a href="https://openreview.net/profile?email=sanjivk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjivk@google.com">Sanjiv Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>27 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryQu7f-RZ-details-418" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryQu7f-RZ-details-418"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> Several recently proposed stochastic optimization methods that have been successfully used in training deep networks such as RMSProp, Adam, Adadelta, Nadam are based on using gradient updates scaled by square roots of exponential moving averages of squared past gradients. In many applications, e.g. learning with large output spaces, it has been empirically observed that these algorithms fail to converge to an optimal solution (or a critical point in nonconvex settings). We show that one cause for such failures is the exponential moving average used in the algorithms. We provide an explicit example of a simple convex optimization setting where Adam does not converge to the optimal solution, and describe the precise problems with the previous analysis of Adam algorithm. Our analysis suggests that the convergence issues can be fixed by endowing such algorithms with ``long-term memory'' of past gradients, and propose new variants of the Adam algorithm which not only fix the convergence issues but often also lead to improved empirical performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate the convergence of popular optimization algorithms like Adam , RMSProp and propose new variants of these methods which provably converge to optimal solution in convex  settings. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimization, deep learning, adam, rmsprop</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ8vJebC-">
      <h4>
        <a href="https://openreview.net/forum?id=BJ8vJebC-">
          Synthetic and Natural Noise Both Break Neural Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ8vJebC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=belinkov%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="belinkov@mit.edu">Yonatan Belinkov</a>, <a href="https://openreview.net/profile?email=ybisk%40yonatanbisk.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ybisk@yonatanbisk.com">Yonatan Bisk</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ8vJebC--details-994" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ8vJebC--details-994"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems.  Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">CharNMT is brittle</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural machine translation, characters, noise, adversarial examples, robust training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk2aImxAb">
      <h4>
        <a href="https://openreview.net/forum?id=Hk2aImxAb">
          Multi-Scale Dense Networks for Resource Efficient Image Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk2aImxAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gh349%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gh349@cornell.edu">Gao Huang</a>, <a href="https://openreview.net/profile?email=taineleau%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taineleau@gmail.com">Danlu Chen</a>, <a href="https://openreview.net/profile?email=lth14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lth14@mails.tsinghua.edu.cn">Tianhong Li</a>, <a href="https://openreview.net/profile?email=fw245%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fw245@cornell.edu">Felix Wu</a>, <a href="https://openreview.net/profile?email=lvdmaaten%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lvdmaaten@fb.com">Laurens van der Maaten</a>, <a href="https://openreview.net/profile?email=kqw4%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kqw4@cornell.edu">Kilian Weinberger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk2aImxAb-details-568" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk2aImxAb-details-568"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network’s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across “easier” and “harder” inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">efficient learning, budgeted learning, deep learning, image classification, convolutional networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJGXzmspb">
      <h4>
        <a href="https://openreview.net/forum?id=HJGXzmspb">
          Training and Inference with Integers in Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJGXzmspb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wus15%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wus15@mails.tsinghua.edu.cn">Shuang Wu</a>, <a href="https://openreview.net/profile?email=liguoqi%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liguoqi@mail.tsinghua.edu.cn">Guoqi Li</a>, <a href="https://openreview.net/profile?email=chenfeng%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenfeng@mail.tsinghua.edu.cn">Feng Chen</a>, <a href="https://openreview.net/profile?email=lpshi%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lpshi@mail.tsinghua.edu.cn">Luping Shi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJGXzmspb-details-301" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJGXzmspb-details-301"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Researches on deep neural networks with discrete parameters and their deployment in embedded systems have been active and promising topics. Although previous works have successfully reduced precision in inference, transferring both training and inference processes to low-bitwidth integers has not been demonstrated simultaneously. In this work, we develop a new method termed as ``"WAGE" to discretize both training and inference, where weights (W), activations (A), gradients (G) and errors (E) among layers are shifted and linearly constrained to low-bitwidth integers. To perform pure discrete dataflow for fixed-point devices, we further replace batch normalization by a constant scaling layer and simplify other components that are arduous for integer implementation. Improved accuracies can be obtained on multiple datasets, which indicates that WAGE somehow acts as a type of regularization. Empirically, we demonstrate the potential to deploy training in hardware systems such as integer-based deep learning accelerators and neuromorphic chips with comparable accuracy and higher energy efficiency, which is crucial to future AI applications in variable scenarios with transfer and continual learning demands.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We apply training and inference with only low-bitwidth integers in DNNs</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">quantization, training, bitwidth, ternary weights</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJGv1Z-AW">
      <h4>
        <a href="https://openreview.net/forum?id=HJGv1Z-AW">
          Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input
        </a>
        
          <a href="https://openreview.net/pdf?id=HJGv1Z-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=angeliki%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="angeliki@google.com">Angeliki Lazaridou</a>, <a href="https://openreview.net/profile?email=kmh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kmh@google.com">Karl Moritz Hermann</a>, <a href="https://openreview.net/profile?email=karltuyls%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karltuyls@google.com">Karl Tuyls</a>, <a href="https://openreview.net/profile?email=clarkstephen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="clarkstephen@google.com">Stephen Clark</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJGv1Z-AW-details-475" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJGv1Z-AW-details-475"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The ability of algorithms to evolve or learn (compositional) communication protocols has traditionally been studied in the language evolution literature through the use of emergent communication tasks. Here we scale up this research by using contemporary deep learning methods and by training reinforcement-learning neural network agents on referential communication games. We extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A controlled study of the role of environments with respect to properties in emergent communication protocols.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">disentanglement, communication, emergent language, compositionality, multi-agent</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkbd5xZRb">
      <h4>
        <a href="https://openreview.net/forum?id=Hkbd5xZRb">
          Spherical CNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=Hkbd5xZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=taco.cohen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taco.cohen@gmail.com">Taco S. Cohen</a>, <a href="https://openreview.net/profile?email=geiger.mario%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="geiger.mario@gmail.com">Mario Geiger</a>, <a href="https://openreview.net/profile?email=jonas.koehler.ks%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonas.koehler.ks@gmail.com">Jonas Köhler</a>, <a href="https://openreview.net/profile?email=m.welling%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.welling@uva.nl">Max Welling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hkbd5xZRb-details-21" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkbd5xZRb-details-21"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional Neural Networks (CNNs) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective.
      
      In this paper we introduce the building blocks for constructing spherical CNNs. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical CNNs applied to 3D model recognition and atomization energy regression.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce Spherical CNNs, a convolutional network for spherical signals, and apply it to 3D model recognition and molecular energy regression.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, equivariance, convolution, group convolution, 3D, vision, omnidirectional, shape recognition, molecular energy regression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1CChZ-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=S1CChZ-CZ">
          Ask the Right Questions: Active Question Reformulation with Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=S1CChZ-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cbuck%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbuck@google.com">Christian Buck</a>, <a href="https://openreview.net/profile?email=jbulian%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbulian@google.com">Jannis Bulian</a>, <a href="https://openreview.net/profile?email=massi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="massi@google.com">Massimiliano Ciaramita</a>, <a href="https://openreview.net/profile?email=wgaj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wgaj@google.com">Wojciech Gajewski</a>, <a href="https://openreview.net/profile?email=agesmundo%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="agesmundo@google.com">Andrea Gesmundo</a>, <a href="https://openreview.net/profile?email=neilhoulsby%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="neilhoulsby@google.com">Neil Houlsby</a>, <a href="https://openreview.net/profile?email=wangwe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangwe@google.com">Wei Wang.</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1CChZ-CZ-details-112" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1CChZ-CZ-details-112"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We frame Question Answering (QA) as a Reinforcement Learning task, an approach that we call Active Question Answering. 
      
      We propose an agent that sits between the user and a black box QA system and learns to reformulate questions to elicit the best possible answers. The agent probes the system with, potentially many, natural language reformulations of an initial question and aggregates the returned evidence to yield the best answer. 
      
      The reformulation system is trained end-to-end to maximize answer quality using policy gradient. We evaluate on SearchQA, a dataset of complex questions extracted from Jeopardy!. The agent outperforms a state-of-the-art base model, playing the role of the environment, and other benchmarks.
      
      We also analyze the language that the agent has learned while interacting with the question answering system. We find that successful question reformulations look quite different from natural language paraphrases. The agent is able to discover non-trivial reformulation strategies that resemble classic information retrieval techniques such as term re-weighting (tf-idf) and stemming.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an agent that sits between the user and a black box question-answering system and which learns to reformulate questions to elicit the best possible answers</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine translation, paraphrasing, question answering, reinforcement learning, agents</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJTutzbA-">
      <h4>
        <a href="https://openreview.net/forum?id=rJTutzbA-">
          On the insufficiency of existing momentum schemes for Stochastic Optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=rJTutzbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rkidambi%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rkidambi@uw.edu">Rahul Kidambi</a>, <a href="https://openreview.net/profile?email=praneeth%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="praneeth@microsoft.com">Praneeth Netrapalli</a>, <a href="https://openreview.net/profile?email=prajain%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="prajain@microsoft.com">Prateek Jain</a>, <a href="https://openreview.net/profile?email=sham%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sham@cs.washington.edu">Sham M. Kakade</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJTutzbA--details-240" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJTutzbA--details-240"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Momentum based stochastic gradient methods such as heavy ball (HB) and Nesterov's accelerated gradient descent (NAG) method are widely used in practice for training deep networks and other supervised learning models, as they often provide significant improvements over stochastic gradient descent (SGD). Rigorously speaking, fast gradient methods have provable improvements over gradient descent only for the deterministic case, where the gradients are exact. In the stochastic case, the popular explanations for their wide applicability is that when these fast gradient methods are applied in the stochastic case, they partially mimic their exact gradient counterparts, resulting in some practical gain. This work provides a counterpoint to this belief by proving that there exist simple problem instances where these methods cannot outperform SGD despite the best setting of its parameters. These negative problem instances are, in an informal sense, generic; they do not look like carefully constructed pathological instances. These results suggest (along with empirical evidence) that HB or NAG's practical performance gains are a by-product of minibatching.
      
      Furthermore, this work provides a viable (and provable) alternative, which, on the same set of problem instances, significantly improves over HB, NAG, and SGD's performance. This algorithm, referred to as Accelerated Stochastic Gradient Descent (ASGD), is a simple to implement stochastic algorithm, based on a relatively less popular variant of Nesterov's Acceleration. Extensive empirical results in this paper show that ASGD has performance gains over HB, NAG, and SGD. The code for implementing the ASGD Algorithm can be found at https://github.com/rahulkidambi/AccSGD.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Existing momentum/acceleration schemes such as heavy ball method and Nesterov's acceleration employed with stochastic gradients do not improve over vanilla stochastic gradient descent, especially when employed with small batch sizes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Stochastic Gradient Descent, Deep Learning, Momentum, Acceleration, Heavy Ball, Nesterov Acceleration, Stochastic Optimization, SGD, Accelerated Stochastic Gradient Descent</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk6kPgZA-">
      <h4>
        <a href="https://openreview.net/forum?id=Hk6kPgZA-">
          Certifying Some Distributional Robustness with Principled Adversarial Training
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk6kPgZA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amans%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amans@stanford.edu">Aman Sinha</a>, <a href="https://openreview.net/profile?email=hnamk%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hnamk@stanford.edu">Hongseok Namkoong</a>, <a href="https://openreview.net/profile?email=jduchi%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jduchi@stanford.edu">John Duchi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 04 Jan 2019)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk6kPgZA--details-568" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk6kPgZA--details-568"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks are vulnerable to adversarial examples and researchers have proposed many heuristic attack and defense mechanisms. We address this problem through the principled lens of distributionally robust optimization, which guarantees performance under adversarial input perturbations.  By considering a Lagrangian penalty formulation of perturbing the underlying data distribution in a Wasserstein ball, we provide a training procedure that augments model parameter updates with worst-case perturbations of training data. For smooth losses, our procedure provably achieves moderate levels of robustness with little computational or statistical cost relative to empirical risk minimization. Furthermore, our statistical guarantees allow us to efficiently certify robustness for the population loss. For imperceptible perturbations, our method matches or outperforms heuristic approaches.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We provide a fast, principled adversarial training procedure with computational and statistical performance guarantees.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial training, distributionally robust optimization, deep learning, optimization, learning theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HktK4BeCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HktK4BeCZ">
          Learning Deep Mean Field Games for Modeling Large Population Behavior
        </a>
        
          <a href="https://openreview.net/pdf?id=HktK4BeCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yjiachen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yjiachen@gmail.com">Jiachen Yang</a>, <a href="https://openreview.net/profile?email=xye%40gsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xye@gsu.edu">Xiaojing Ye</a>, <a href="https://openreview.net/profile?email=rstrivedi%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rstrivedi@gatech.edu">Rakshit Trivedi</a>, <a href="https://openreview.net/profile?email=huan.xu%40isye.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huan.xu@isye.gatech.edu">Huan Xu</a>, <a href="https://openreview.net/profile?email=zha%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zha@cc.gatech.edu">Hongyuan Zha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HktK4BeCZ-details-53" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HktK4BeCZ-details-53"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of representing collective behavior of large populations and predicting the evolution of a population distribution over a discrete state space. A discrete time mean field game (MFG) is motivated as an interpretable model founded on game theory for understanding the aggregate effect of individual actions and predicting the temporal evolution of population distributions. We achieve a synthesis of MFG and Markov decision processes (MDP) by showing that a special MFG is reducible to an MDP. This enables us to broaden the scope of mean field game theory and infer MFG models of large real-world systems via deep inverse reinforcement learning. Our method learns both the reward function and forward dynamics of an MFG from real data, and we report the first empirical test of a mean field game model of a real-world social media population.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Inference of a mean field game (MFG) model of large population behavior via a synthesis of MFG and Markov decision processes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">mean field games, reinforcement learning, Markov decision processes, inverse reinforcement learning, deep learning, inverse optimal control, computational social science, population modeling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkL7n1-0b">
      <h4>
        <a href="https://openreview.net/forum?id=HkL7n1-0b">
          Wasserstein Auto-Encoders
        </a>
        
          <a href="https://openreview.net/pdf?id=HkL7n1-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=iliya.tolstikhin%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iliya.tolstikhin@gmail.com">Ilya Tolstikhin</a>, <a href="https://openreview.net/profile?email=obousquet%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="obousquet@gmail.com">Olivier Bousquet</a>, <a href="https://openreview.net/profile?email=sylvain.gelly%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sylvain.gelly@gmail.com">Sylvain Gelly</a>, <a href="https://openreview.net/profile?email=bs%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tuebingen.mpg.de">Bernhard Schoelkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkL7n1-0b-details-682" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkL7n1-0b-details-682"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE).
      This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE). Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new auto-encoder based on the Wasserstein distance, which improves on the sampling properties of VAE.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">auto-encoder, generative models, GAN, VAE, unsupervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1QRgziT-">
      <h4>
        <a href="https://openreview.net/forum?id=B1QRgziT-">
          Spectral Normalization for Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1QRgziT-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=miyato%40preferred.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="miyato@preferred.jp">Takeru Miyato</a>, <a href="https://openreview.net/profile?email=kataoka%40preferred.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="kataoka@preferred.jp">Toshiki Kataoka</a>, <a href="https://openreview.net/profile?email=koyama.masanori%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="koyama.masanori@gmail.com">Masanori Koyama</a>, <a href="https://openreview.net/profile?email=yyoshida%40nii.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyoshida@nii.ac.jp">Yuichi Yoshida</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>31 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1QRgziT--details-524" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1QRgziT--details-524"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the challenges in the study of generative adversarial networks is the instability of its training. 
      In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator.
      Our new normalization technique is computationally light and easy to incorporate into existing implementations. 
      We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator of GANs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, Deep Generative Models, Unsupervised Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJOFETxR-">
      <h4>
        <a href="https://openreview.net/forum?id=BJOFETxR-">
          Learning to Represent Programs with Graphs
        </a>
        
          <a href="https://openreview.net/pdf?id=BJOFETxR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=miallama%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="miallama@microsoft.com">Miltiadis Allamanis</a>, <a href="https://openreview.net/profile?email=mabrocks%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mabrocks@microsoft.com">Marc Brockschmidt</a>, <a href="https://openreview.net/profile?email=mkhademi%40sfu.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkhademi@sfu.ca">Mahmoud Khademi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 05 May 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJOFETxR--details-495" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJOFETxR--details-495"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.
      
      In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">programs, source code, graph neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gJ1L2aW">
      <h4>
        <a href="https://openreview.net/forum?id=B1gJ1L2aW">
          Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality
        </a>
        
          <a href="https://openreview.net/pdf?id=B1gJ1L2aW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xingjunm%40student.unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="xingjunm@student.unimelb.edu.au">Xingjun Ma</a>, <a href="https://openreview.net/profile?email=crystalboli%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="crystalboli@berkeley.edu">Bo Li</a>, <a href="https://openreview.net/profile?email=wangys14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangys14@mails.tsinghua.edu.cn">Yisen Wang</a>, <a href="https://openreview.net/profile?email=sarah.erfani%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="sarah.erfani@unimelb.edu.au">Sarah M. Erfani</a>, <a href="https://openreview.net/profile?email=sudanthi.wijewickrema%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="sudanthi.wijewickrema@unimelb.edu.au">Sudanthi Wijewickrema</a>, <a href="https://openreview.net/profile?email=schoeneb%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="schoeneb@umich.edu">Grant Schoenebeck</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>, <a href="https://openreview.net/profile?email=meh%40nii.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="meh@nii.ac.jp">Michael E. Houle</a>, <a href="https://openreview.net/profile?email=baileyj%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="baileyj@unimelb.edu.au">James Bailey</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1gJ1L2aW-details-201" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gJ1L2aW-details-201"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep Neural Networks (DNNs) have recently been shown to be vulnerable against adversarial examples, which are carefully crafted instances that can mislead DNNs to make errors during prediction. To better understand such attacks, a characterization is needed of the properties of regions (the so-called `adversarial subspaces') in which adversarial examples lie. We tackle this challenge by characterizing the dimensional properties of adversarial regions, via the use of Local Intrinsic Dimensionality (LID). LID assesses the space-filling capability of the region surrounding a reference example, based on the distance distribution of the example to its neighbors. We first provide explanations about how adversarial perturbation can affect the LID characteristic of adversarial regions, and then show empirically that LID characteristics can facilitate the distinction of adversarial examples generated using state-of-the-art attacks. As a proof-of-concept, we show that a potential application of LID is to distinguish adversarial examples, and the preliminary results show that it can outperform several state-of-the-art detection measures by large margins for five attack strategies considered in this paper across three benchmark datasets. Our analysis of the LID characteristic for adversarial regions not only motivates new directions of effective adversarial defense, but also opens up more challenges for developing new attacks to better understand the vulnerabilities of DNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We characterize the dimensional properties of adversarial subspaces in the neighborhood of adversarial examples via the use of Local Intrinsic Dimensionality (LID).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Subspace, Local Intrinsic Dimensionality, Deep Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkwZSG-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=HkwZSG-CZ">
          Breaking the Softmax Bottleneck: A High-Rank RNN Language Model
        </a>
        
          <a href="https://openreview.net/pdf?id=HkwZSG-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhiliny%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhiliny@cs.cmu.edu">Zhilin Yang</a>, <a href="https://openreview.net/profile?email=zander.dai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zander.dai@gmail.com">Zihang Dai</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>, <a href="https://openreview.net/profile?email=wcohen%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wcohen@cs.cmu.edu">William W. Cohen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 03 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>23 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkwZSG-CZ-details-752" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkwZSG-CZ-details-752"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck. Given that natural language is highly context-dependent, this further implies that in practice Softmax with distributed word embeddings does not have enough capacity to model natural language. We propose a simple and effective method to address this issue, and improve the state-of-the-art perplexities on Penn Treebank and WikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on the large-scale 1B Word dataset, outperforming the baseline by over 5.6 points in perplexity.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk2u1g-0-">
      <h4>
        <a href="https://openreview.net/forum?id=Sk2u1g-0-">
          Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk2u1g-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alshedivat%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alshedivat@cs.cmu.edu">Maruan Al-Shedivat</a>, <a href="https://openreview.net/profile?email=tbansal%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tbansal@cs.umass.edu">Trapit Bansal</a>, <a href="https://openreview.net/profile?email=yburda%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yburda@openai.com">Yura Burda</a>, <a href="https://openreview.net/profile?email=ilyasu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilyasu@openai.com">Ilya Sutskever</a>, <a href="https://openreview.net/profile?email=mordatch%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mordatch@openai.com">Igor Mordatch</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk2u1g-0--details-160" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk2u1g-0--details-160"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Ability to continuously learn and adapt from limited experience in nonstationary environments is an important milestone on the path towards general intelligence. In this paper, we cast the problem of continuous adaptation into the learning-to-learn framework. We develop a simple gradient-based meta-learning algorithm suitable for adaptation in dynamically changing and adversarial scenarios. Additionally, we design a new multi-agent competitive environment, RoboSumo, and define iterated adaptation games for testing various aspects of continuous adaptation. We demonstrate that meta-learning enables significantly more efficient adaptation than reactive baselines in the few-shot regime. Our experiments with a population of agents that learn and compete suggest that meta-learners are the fittest.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, nonstationarity, meta-learning, transfer learning, multi-agent</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1JHhv6TW">
      <h4>
        <a href="https://openreview.net/forum?id=S1JHhv6TW">
          Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions
        </a>
        
          <a href="https://openreview.net/pdf?id=S1JHhv6TW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cohennadav%40ias.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cohennadav@ias.edu">Nadav Cohen</a>, <a href="https://openreview.net/profile?email=ronent%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronent@cs.huji.ac.il">Ronen Tamari</a>, <a href="https://openreview.net/profile?email=shashua%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shashua@cs.huji.ac.il">Amnon Shashua</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1JHhv6TW-details-200" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1JHhv6TW-details-200"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The driving force behind deep networks is their ability to compactly represent rich classes of functions. The primary notion for formally reasoning about this phenomenon is expressive efficiency, which refers to a situation where one network must grow unfeasibly large in order to replicate functions of another. To date, expressive efficiency analyses focused on the architectural feature of depth, showing that deep networks are representationally superior to shallow ones. In this paper we study the expressive efficiency brought forth by connectivity, motivated by the observation that modern networks interconnect their layers in elaborate ways. We focus on dilated convolutional networks, a family of deep models delivering state of the art performance in sequence processing tasks. By introducing and analyzing the concept of mixed tensor decompositions, we prove that interconnecting dilated convolutional networks can lead to expressive efficiency. In particular, we show that even a single connection between intermediate layers can already lead to an almost quadratic gap, which in large-scale settings typically makes the difference between a model that is practical and one that is not. Empirical evaluation demonstrates how the expressive efficiency of connectivity, similarly to that of depth, translates into gains in accuracy. This leads us to believe that expressive efficiency may serve a key role in developing new tools for deep network design.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the notion of mixed tensor decompositions, and use it to prove that interconnecting dilated convolutional networks boosts their expressive power.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Expressive Efficiency, Dilated Convolutions, Tensor Decompositions</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkfXMz-Ab">
      <h4>
        <a href="https://openreview.net/forum?id=HkfXMz-Ab">
          Neural Sketch Learning for Conditional Program Generation
        </a>
        
          <a href="https://openreview.net/pdf?id=HkfXMz-Ab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vijay%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vijay@rice.edu">Vijayaraghavan Murali</a>, <a href="https://openreview.net/profile?email=letao.qi%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="letao.qi@rice.edu">Letao Qi</a>, <a href="https://openreview.net/profile?email=swarat%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="swarat@rice.edu">Swarat Chaudhuri</a>, <a href="https://openreview.net/profile?email=cmj4%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cmj4@rice.edu">Chris Jermaine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkfXMz-Ab-details-667" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkfXMz-Ab-details-667"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the problem of generating source code in a strongly typed,
      Java-like programming language, given a label (for example a set of
      API calls or types) carrying a small amount of information about the
      code that is desired. The generated programs are expected to respect a
      `"realistic" relationship between programs and labels, as exemplified
      by a corpus of labeled programs available during training.
      
      Two challenges in such *conditional program generation* are that
      the generated programs must satisfy a rich set of syntactic and
      semantic constraints, and that source code contains many low-level
      features that impede learning.  We address these problems by training
      a neural generator not on code but on *program sketches*, or
      models of program syntax that abstract out names and operations that
      do not generalize across programs. During generation, we infer a
      posterior distribution over sketches, then concretize samples from
      this distribution into type-safe programs using combinatorial
      techniques.  We implement our ideas in a system for generating
      API-heavy Java code, and show that it can often predict the entire
      body of a method given just a few API calls or data types that appear
      in the method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We give a method for generating type-safe programs in a Java-like language, given a small amount of syntactic information about the desired code.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Program generation, Source code, Program synthesis, Deep generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk99zCeAb">
      <h4>
        <a href="https://openreview.net/forum?id=Hk99zCeAb">
          Progressive Growing of GANs for Improved Quality, Stability, and Variation
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk99zCeAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tkarras%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tkarras@nvidia.com">Tero Karras</a>, <a href="https://openreview.net/profile?email=taila%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taila@nvidia.com">Timo Aila</a>, <a href="https://openreview.net/profile?email=slaine%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slaine@nvidia.com">Samuli Laine</a>, <a href="https://openreview.net/profile?email=jlehtinen%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jlehtinen@nvidia.com">Jaakko Lehtinen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk99zCeAb-details-189" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk99zCeAb-details-189"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, unsupervised learning, hierarchical methods</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1tSsb-AW">
      <h4>
        <a href="https://openreview.net/forum?id=H1tSsb-AW">
          Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines
        </a>
        
          <a href="https://openreview.net/pdf?id=H1tSsb-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cathywu%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cathywu@eecs.berkeley.edu">Cathy Wu</a>, <a href="https://openreview.net/profile?email=aravraj%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aravraj@cs.washington.edu">Aravind Rajeswaran</a>, <a href="https://openreview.net/profile?email=rockyduan%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rockyduan@eecs.berkeley.edu">Yan Duan</a>, <a href="https://openreview.net/profile?email=vikash%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vikash@cs.washington.edu">Vikash Kumar</a>, <a href="https://openreview.net/profile?email=bayen%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bayen@berkeley.edu">Alexandre M Bayen</a>, <a href="https://openreview.net/profile?email=sham%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sham@cs.washington.edu">Sham Kakade</a>, <a href="https://openreview.net/profile?email=igor.mordatch%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="igor.mordatch@gmail.com">Igor Mordatch</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1tSsb-AW-details-118" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1tSsb-AW-details-118"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Policy gradient methods have enjoyed great success in deep reinforcement learning but suffer from high variance of gradient estimates. The high variance problem is particularly exasperated in problems with long horizons or high-dimensional action spaces. To mitigate this issue, we derive a bias-free action-dependent baseline for variance reduction which fully exploits the structural form of the stochastic policy itself and does not make any additional assumptions about the MDP. We demonstrate and quantify the benefit of the action-dependent baseline through both theoretical analysis as well as numerical results, including an analysis of the suboptimality of the optimal state-dependent baseline. The result is a computationally efficient policy gradient algorithm, which scales to high-dimensional control problems, as demonstrated by a synthetic 2000-dimensional target matching task. Our experimental results indicate that action-dependent baselines allow for faster learning on standard reinforcement learning benchmarks and high-dimensional hand manipulation and synthetic tasks. Finally, we show that the general idea of including additional information in baselines for improved variance reduction can be extended to partially observed and multi-agent tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Action-dependent baselines can be bias-free and yield greater variance reduction than state-only dependent baselines for policy gradient methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, policy gradient, variance reduction, baseline, control variates</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkisuzWRW">
      <h4>
        <a href="https://openreview.net/forum?id=BkisuzWRW">
          Zero-Shot Visual Imitation
        </a>
        
          <a href="https://openreview.net/pdf?id=BkisuzWRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pathak%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pathak@berkeley.edu">Deepak Pathak</a>, <a href="https://openreview.net/profile?email=parsa.m%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="parsa.m@berkeley.edu">Parsa Mahmoudieh</a>, <a href="https://openreview.net/profile?email=michaelluo%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="michaelluo@berkeley.edu">Guanghao Luo</a>, <a href="https://openreview.net/profile?email=pulkitag%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pulkitag@berkeley.edu">Pulkit Agrawal</a>, <a href="https://openreview.net/profile?email=dianchen%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dianchen@berkeley.edu">Dian Chen</a>, <a href="https://openreview.net/profile?email=fredshentu%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fredshentu@berkeley.edu">Yide Shentu</a>, <a href="https://openreview.net/profile?email=shelhamer%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shelhamer@cs.berkeley.edu">Evan Shelhamer</a>, <a href="https://openreview.net/profile?email=malik%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="malik@eecs.berkeley.edu">Jitendra Malik</a>, <a href="https://openreview.net/profile?email=efros%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="efros@eecs.berkeley.edu">Alexei A. Efros</a>, <a href="https://openreview.net/profile?email=trevor%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="trevor@eecs.berkeley.edu">Trevor Darrell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkisuzWRW-details-91" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkisuzWRW-details-91"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both 'what' and 'how' to imitate. We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss. In our framework, the role of the expert is only to communicate the goals (i.e., what to imitate) during inference. The learned policy is then employed to mimic the expert (i.e., how to imitate) after seeing just a sequence of images demonstrating the desired task. Our method is 'zero-shot' in the sense that the agent never has access to expert actions during training or for the task demonstration at inference. We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot. Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance. Videos, models, and more details are available at https://pathak22.github.io/zeroshot-imitation/.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Agents can learn to imitate solely visual demonstrations (without actions) at test time after learning from their own experience without any form of supervision at training time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">imitation, zero-shot, self-supervised, robotics, skills, navigation, manipulation, vizdoom, reinforcement</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkRwGg-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rkRwGg-0Z">
          Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs
        </a>
        
          <a href="https://openreview.net/pdf?id=rkRwGg-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jmurdoch%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmurdoch@berkeley.edu">W. James Murdoch</a>, <a href="https://openreview.net/profile?email=peterjliu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peterjliu@google.com">Peter J. Liu</a>, <a href="https://openreview.net/profile?email=binyu%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="binyu@berkeley.edu">Bin Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkRwGg-0Z-details-40" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkRwGg-0Z-details-40"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Consequently, our inability to describe these relationships has led to LSTMs being characterized as black boxes. To this end, we introduce contextual decomposition (CD), an interpretation algorithm for analysing individual predictions made by standard LSTMs, without any changes to the underlying model. By decomposing the output of a LSTM, CD captures the contributions of combinations of words or variables to the final prediction of an LSTM. On the task of sentiment analysis with the Yelp and SST data sets, we show that CD is able to reliably identify words and phrases of contrasting sentiment, and how they are combined to yield the LSTM's final prediction. Using the phrase-level labels in SST, we also demonstrate that CD is able to successfully extract positive and negative negations from an LSTM, something which has not previously been done.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce contextual decompositions, an interpretation algorithm for LSTMs capable of extracting word, phrase and interaction-level importance score</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">interpretability, LSTM, natural language processing, sentiment analysis, interactions</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy7fDog0b">
      <h4>
        <a href="https://openreview.net/forum?id=Hy7fDog0b">
          AmbientGAN: Generative models from lossy measurements
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy7fDog0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ashish.bora%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashish.bora@utexas.edu">Ashish Bora</a>, <a href="https://openreview.net/profile?email=ecprice%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ecprice@cs.utexas.edu">Eric Price</a>, <a href="https://openreview.net/profile?email=dimakis%40austin.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimakis@austin.utexas.edu">Alexandros G. Dimakis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy7fDog0b-details-253" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy7fDog0b-details-253"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative models provide a way to model structure in complex distributions and have been shown to be useful for many tasks of practical interest. However, current techniques for training generative models require access to fully-observed samples. In many settings, it is expensive or even impossible to obtain fully-observed samples, but economical to obtain partial, noisy observations. We consider the task of learning an implicit generative model given only lossy measurements of samples from the distribution of interest. We show that the true underlying distribution can be provably recovered even in the presence of per-sample information loss for a class of measurement models. Based on this, we propose a new method of training Generative Adversarial Networks (GANs) which we call AmbientGAN. On three benchmark datasets, and for various measurement models, we demonstrate substantial qualitative and quantitative improvements. Generative models trained with our method can obtain $2$-$4$x higher inception scores than the baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">How to learn GANs from noisy, distorted, partial observations</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative models, Adversarial networks, Lossy measurements</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
</ul>
</div>
    <div role="tabpanel" class="tab-pane fade   active in" id="accepted-poster-papers">
      
    <ul class="list-unstyled submissions-list">
    <li class="note " data-id="rJWechg0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rJWechg0Z">
          Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=rJWechg0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pietro.morerio%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="pietro.morerio@iit.it">Pietro Morerio</a>, <a href="https://openreview.net/profile?email=jacopo.cavazza%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="jacopo.cavazza@iit.it">Jacopo Cavazza</a>, <a href="https://openreview.net/profile?email=vittorio.murino%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="vittorio.murino@iit.it">Vittorio Murino</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 19 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJWechg0Z-details-318" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJWechg0Z-details-318"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work, we face the problem of unsupervised domain adaptation with a novel deep learning approach which leverages our finding that entropy minimization is induced by the optimal alignment of second order statistics between source and target domains. We formally demonstrate this hypothesis and, aiming at achieving an optimal alignment in practical cases, we adopt a more principled strategy which, differently from the current Euclidean approaches, deploys alignment along geodesics. Our pipeline can be implemented by adding to the standard classification loss (on the labeled source domain), a source-to-target regularizer that is weighted in an unsupervised and data-driven fashion. We provide extensive experiments to assess the superiority of our framework on standard domain and modality adaptation benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new unsupervised deep domain adaptation technique which efficiently unifies correlation alignment and entropy minimization</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised domain adaptation, entropy minimization, image classification, deep transfer learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1zlp1bRW">
      <h4>
        <a href="https://openreview.net/forum?id=B1zlp1bRW">
          Large Scale Optimal Transport and Mapping Estimation
        </a>
        
          <a href="https://openreview.net/pdf?id=B1zlp1bRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vivienseguy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vivienseguy@gmail.com">Vivien Seguy</a>, <a href="https://openreview.net/profile?email=bharath-bhushan.damodaran%40irisa.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="bharath-bhushan.damodaran@irisa.fr">Bharath Bhushan Damodaran</a>, <a href="https://openreview.net/profile?email=remi.flamary%40unice.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="remi.flamary@unice.fr">Remi Flamary</a>, <a href="https://openreview.net/profile?email=courty%40univ-ubs.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="courty@univ-ubs.fr">Nicolas Courty</a>, <a href="https://openreview.net/profile?email=antoine.rolet%40iip.ist.i.kyoto-u.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoine.rolet@iip.ist.i.kyoto-u.ac.jp">Antoine Rolet</a>, <a href="https://openreview.net/profile?email=mblondel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mblondel@gmail.com">Mathieu Blondel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1zlp1bRW-details-265" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1zlp1bRW-details-265"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper presents a novel two-step approach for the fundamental problem of learning an optimal map from one distribution to another. First, we learn an optimal transport (OT) plan, which can be thought as a one-to-many map between the two distributions. To that end, we propose a stochastic dual approach of regularized OT, and show empirically that it scales better than a recent related approach when the amount of samples is very large. Second, we estimate a Monge map as a deep neural network learned by approximating the barycentric projection of the previously-obtained OT plan. This parameterization allows generalization of the mapping outside the support of the input measure. We prove two theoretical stability results of regularized OT which show that our estimations converge to the OT and Monge map between the underlying continuous measures. We showcase our proposed approach on two applications: domain adaptation and generative modeling.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learning optimal mapping with deepNN between distributions along with theoretical guarantees.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimal transport, Wasserstein, domain adaptation, generative models, Monge map, optimal mapping</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryUlhzWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryUlhzWCZ">
          TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING &amp; IMITATION LEARNING
        </a>
        
          <a href="https://openreview.net/pdf?id=ryUlhzWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wensun%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wensun@cs.cmu.edu">Wen Sun</a>, <a href="https://openreview.net/profile?email=dbagnell%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbagnell@cs.cmu.edu">J. Andrew Bagnell</a>, <a href="https://openreview.net/profile?email=bboots%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bboots@cc.gatech.edu">Byron Boots</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryUlhzWCZ-details-965" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryUlhzWCZ-details-965"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose to combine imitation and reinforcement learning via the idea of reward shaping using an oracle. We study the effectiveness of the near- optimal cost-to-go oracle on the planning horizon and demonstrate that the cost- to-go oracle shortens the learner’s planning horizon as function of its accuracy: a globally optimal oracle can shorten the planning horizon to one, leading to a one- step greedy Markov Decision Process which is much easier to optimize, while an oracle that is far away from the optimality requires planning over a longer horizon to achieve near-optimal performance. Hence our new insight bridges the gap and interpolates between imitation learning and reinforcement learning. Motivated by the above mentioned insights, we propose Truncated HORizon Policy Search (THOR), a method that focuses on searching for policies that maximize the total reshaped reward over a finite planning horizon when the oracle is sub-optimal. We experimentally demonstrate that a gradient-based implementation of THOR can achieve superior performance compared to RL baselines and IL baselines even when the oracle is sub-optimal.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Combining Imitation Learning and Reinforcement Learning to learn to outperform the expert</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Imitation Learning, Reinforcement Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJJinbWRZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJJinbWRZ">
          Model-Ensemble Trust-Region Policy Optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=SJJinbWRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thanard.kurutach%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="thanard.kurutach@berkeley.edu">Thanard Kurutach</a>, <a href="https://openreview.net/profile?email=iclavera%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="iclavera@berkeley.edu">Ignasi Clavera</a>, <a href="https://openreview.net/profile?email=rockyduan%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rockyduan@eecs.berkeley.edu">Yan Duan</a>, <a href="https://openreview.net/profile?email=avivt%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="avivt@berkeley.edu">Aviv Tamar</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 28 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJJinbWRZ-details-252" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJJinbWRZ-details-252"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning.  However, they tend to suffer from high sample complexity, which hinders their use in real-world domains.  Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Deep Model-Based RL that works well.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">model-based reinforcement learning, model ensemble, reinforcement learning, model bias</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy6GHpkCW">
      <h4>
        <a href="https://openreview.net/forum?id=Hy6GHpkCW">
          A Neural Representation of Sketch Drawings
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy6GHpkCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hadavid%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hadavid@google.com">David Ha</a>, <a href="https://openreview.net/profile?email=deck%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="deck@google.com">Douglas Eck</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 06 Jul 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy6GHpkCW-details-342" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy6GHpkCW-details-342"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present sketch-rnn, a recurrent neural network able to construct stroke-based drawings of common objects. The model is trained on a dataset of human-drawn images representing many different classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate alternative to traditional pixel image modelling approaches, and propose a generative model for vector images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">applications, image modelling, computer-assisted, drawing, art, creativity, dataset</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJaP_-xAb">
      <h4>
        <a href="https://openreview.net/forum?id=SJaP_-xAb">
          Deep Learning with Logged Bandit Feedback
        </a>
        
          <a href="https://openreview.net/pdf?id=SJaP_-xAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tj%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tj@cs.cornell.edu">Thorsten Joachims</a>, <a href="https://openreview.net/profile?email=adswamin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adswamin@microsoft.com">Adith Swaminathan</a>, <a href="https://openreview.net/profile?email=derijke%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="derijke@uva.nl">Maarten de Rijke</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJaP_-xAb-details-294" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJaP_-xAb-details-294"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a new output layer for deep neural networks that permits the use of logged contextual bandit feedback for training. Such contextual bandit feedback can be available in huge quantities (e.g., logs of search engines, recommender systems) at little cost, opening up a path for training deep networks on orders of magnitude more data. To this effect, we propose a Counterfactual Risk Minimization (CRM) approach for training deep networks using an equivariant empirical risk estimator with variance regularization, BanditNet, and show how the resulting objective can be decomposed in a way that allows Stochastic Gradient Descent (SGD) training. We empirically demonstrate the effectiveness of the method by showing how deep networks -- ResNets in particular -- can be trained for object recognition without conventionally labeled images. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper proposes a new output layer for deep networks that permits the use of logged contextual bandit feedback for training. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Batch Learning from Bandit Feedback, Counterfactual Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byt3oJ-0W">
      <h4>
        <a href="https://openreview.net/forum?id=Byt3oJ-0W">
          Learning Latent Permutations with Gumbel-Sinkhorn Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Byt3oJ-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gem2131%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gem2131@columbia.edu">Gonzalo Mena</a>, <a href="https://openreview.net/profile?email=dbelanger%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbelanger@google.com">David Belanger</a>, <a href="https://openreview.net/profile?email=scott.linderman%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="scott.linderman@gmail.com">Scott Linderman</a>, <a href="https://openreview.net/profile?email=jsnoek%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsnoek@google.com">Jasper Snoek</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Byt3oJ-0W-details-494" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byt3oJ-0W-details-494"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Permutations and matchings are core building blocks in a variety of latent variable models, as they allow us to align, canonicalize, and sort data. Learning in such models is difficult, however, because exact marginalization over these combinatorial objects is intractable. In response, this paper introduces a collection of new methods for end-to-end learning in such models that approximate discrete maximum-weight matching using the continuous Sinkhorn operator.  Sinkhorn iteration is attractive because it functions as a simple, easy-to-implement analog of the softmax operator. With this, we can define the Gumbel-Sinkhorn method, an extension of the Gumbel-Softmax method (Jang et al. 2016, Maddison2016 et al. 2016) to distributions over latent matchings. We demonstrate the effectiveness of our method by outperforming competitive baselines on a range of qualitatively different tasks: sorting numbers, solving jigsaw puzzles, and identifying neural signals in worms. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new method for gradient-descent inference of permutations, with applications to latent matching inference and supervised learning of permutations with neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Permutation, Latent, Sinkhorn, Inference, Optimal Transport, Gumbel, Softmax, Sorting</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk07ZXZRb">
      <h4>
        <a href="https://openreview.net/forum?id=rk07ZXZRb">
          Learning an Embedding Space for Transferable Robot Skills
        </a>
        
          <a href="https://openreview.net/pdf?id=rk07ZXZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hausmankarol%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hausmankarol@gmail.com">Karol Hausman</a>, <a href="https://openreview.net/profile?email=springenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="springenberg@google.com">Jost Tobias Springenberg</a>, <a href="https://openreview.net/profile?email=ziyu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziyu@google.com">Ziyu Wang</a>, <a href="https://openreview.net/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Nicolas Heess</a>, <a href="https://openreview.net/profile?email=riedmiller%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="riedmiller@google.com">Martin Riedmiller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk07ZXZRb-details-670" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk07ZXZRb-details-670"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a method for reinforcement learning of closely related skills that are parameterized via a skill embedding space. We learn such skills by taking advantage of latent variables and exploiting a connection between reinforcement learning and variational inference. The main contribution of our work is an entropy-regularized policy gradient formulation for hierarchical policies, and an associated, data-efficient and robust off-policy gradient algorithm based on stochastic value gradients. We demonstrate the effectiveness of our method on several simulated robotic manipulation tasks. We find that our method allows for discovery of multiple solutions and is capable of learning the minimum number of distinct skills that are necessary to solve a given set of tasks. In addition, our results indicate that the hereby proposed technique can interpolate and/or sequence previously learned skills in order to accomplish more complex tasks, even in the presence of sparse rewards.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning, Variational Inference, Control, Robotics</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1DWPP1A-">
      <h4>
        <a href="https://openreview.net/forum?id=S1DWPP1A-">
          Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration
        </a>
        
          <a href="https://openreview.net/pdf?id=S1DWPP1A-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alexandre.pere%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexandre.pere@inria.fr">Alexandre Péré</a>, <a href="https://openreview.net/profile?email=sebastien.forestier%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastien.forestier@inria.fr">Sébastien Forestier</a>, <a href="https://openreview.net/profile?email=olivier.sigaud%40upmc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="olivier.sigaud@upmc.fr">Olivier Sigaud</a>, <a href="https://openreview.net/profile?email=pierre-yves.oudeyer%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="pierre-yves.oudeyer@inria.fr">Pierre-Yves Oudeyer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1DWPP1A--details-878" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1DWPP1A--details-878"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Intrinsically motivated goal exploration algorithms enable machines to discover repertoires of policies that produce a diversity of effects in complex environments. These exploration algorithms have been shown to allow real world robots to acquire skills such as tool use in high-dimensional continuous state and action spaces. However, they have so far assumed that self-generated goals are sampled in a specifically engineered feature space, limiting their autonomy. In this work, we propose an approach using deep representation learning algorithms to learn an adequate goal space. This is a developmental 2-stage approach: first, in a perceptual learning stage, deep learning algorithms use passive raw sensor observations of world changes to learn a corresponding latent space; then goal exploration happens in a second stage by sampling goals in this latent space. We present experiments with a simulated robot arm interacting with an object, and we show that exploration algorithms using such learned representations can closely match, and even sometimes improve, the performance obtained using engineered representations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel Intrinsically Motivated Goal Exploration architecture with unsupervised learning of goal space representations, and evaluate how various implementations enable the discovery of a diversity of policies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">exploration; autonomous goal setting; diversity; unsupervised learning; deep neural network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryRh0bb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=ryRh0bb0Z">
          Multi-View Data Generation Without View Supervision
        </a>
        
          <a href="https://openreview.net/pdf?id=ryRh0bb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mickael.chen%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="mickael.chen@lip6.fr">Mickael Chen</a>, <a href="https://openreview.net/profile?email=ludovic.denoyer%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludovic.denoyer@lip6.fr">Ludovic Denoyer</a>, <a href="https://openreview.net/profile?email=thierry.artieres%40lif.univ-mrs.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="thierry.artieres@lif.univ-mrs.fr">Thierry Artières</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 07 Jun 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryRh0bb0Z-details-230" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryRh0bb0Z-details-230"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The development of high-dimensional generative models has recently gained a great surge of interest with the introduction of variational auto-encoders and generative adversarial neural networks. Different variants have been proposed where the underlying latent space is structured, for example, based on attributes describing the data to generate. We focus on a particular problem where one aims at generating samples corresponding to a number of objects under various views. We assume that the distribution of the data is driven by two independent latent factors: the content, which represents the intrinsic features of an object, and the view, which stands for the settings of a particular observation of that object. Therefore, we propose a generative model and a conditional variant built on such a disentangled latent space. This approach allows us to generate realistic samples corresponding to various objects in a high variety of views. Unlike many multi-view approaches, our model doesn't need any supervision on the views but only on the content. Compared to other conditional generation approaches that are mostly based on binary or categorical attributes, we make no such assumption about the factors of variations. Our model can be used on problems with a huge, potentially infinite, number of categories. We experiment it on four images datasets on which we demonstrate the effectiveness of the model and its ability to generalize. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe a novel multi-view generative model that can generate multiple views of the same object, or multiple objects in the same view with no need of label on views.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-view, adversarial learning, generative model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyYe6k-CW">
      <h4>
        <a href="https://openreview.net/forum?id=SyYe6k-CW">
          Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling
        </a>
        
          <a href="https://openreview.net/pdf?id=SyYe6k-CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rikel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rikel@google.com">Carlos Riquelme</a>, <a href="https://openreview.net/profile?email=gjt%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gjt@google.com">George Tucker</a>, <a href="https://openreview.net/profile?email=jsnoek%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsnoek@google.com">Jasper Snoek</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyYe6k-CW-details-332" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyYe6k-CW-details-332"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent advances in deep reinforcement learning have made significant strides in performance on applications such as Go and Atari games. However, developing practical methods to balance exploration and exploitation in complex domains remains largely unsolved. Thompson Sampling and its extension to reinforcement learning provide an elegant approach to exploration that only requires access to posterior samples of the model. At the same time, advances in approximate Bayesian methods have made posterior approximation for flexible neural network models practical. Thus, it is attractive to consider approximate Bayesian neural networks in a Thompson Sampling framework. To understand the impact of using an approximate posterior on Thompson Sampling, we benchmark well-established and recently developed methods for approximate posterior sampling combined with Thompson Sampling over a series of contextual bandit problems. We found that many approaches that have been successful in the supervised learning setting underperformed in the sequential decision-making scenario. In particular, we highlight the challenge of adapting slowly converging uncertainty estimates to the online setting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">exploration, Thompson Sampling, Bayesian neural networks, bandits, reinforcement learning, variational inference, Monte Carlo</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H15odZ-C-">
      <h4>
        <a href="https://openreview.net/forum?id=H15odZ-C-">
          Semantic Interpolation in Implicit Models
        </a>
        
          <a href="https://openreview.net/pdf?id=H15odZ-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yannic.kilcher%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="yannic.kilcher@inf.ethz.ch">Yannic Kilcher</a>, <a href="https://openreview.net/profile?email=aurelien.lucchi%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aurelien.lucchi@inf.ethz.ch">Aurelien Lucchi</a>, <a href="https://openreview.net/profile?email=thomas.hofmann%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.hofmann@inf.ethz.ch">Thomas Hofmann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H15odZ-C--details-871" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H15odZ-C--details-871"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In implicit models, one often interpolates between sampled points in latent space. As we show in this paper, care needs to be taken to match-up the distributional assumptions on code vectors with the geometry of the interpolating paths.  Otherwise, typical assumptions about the quality and semantics of in-between points may not be justified. Based on our analysis we propose to modify the prior code distribution to put significantly more probability mass closer to the origin. As a result, linear interpolation paths are not only shortest paths, but they are also guaranteed to pass through high-density regions, irrespective of the dimensionality of the latent space. Experiments on standard benchmark image datasets demonstrate clear visual improvements in the quality of the generated samples and exhibit more meaningful interpolation paths.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Generative Models, GANs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1X0mzZCW">
      <h4>
        <a href="https://openreview.net/forum?id=B1X0mzZCW">
          Fidelity-Weighted Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B1X0mzZCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dehghani%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="dehghani@uva.nl">Mostafa Dehghani</a>, <a href="https://openreview.net/profile?email=amehrjou%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="amehrjou@tuebingen.mpg.de">Arash Mehrjou</a>, <a href="https://openreview.net/profile?email=sgouws%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgouws@google.com">Stephan Gouws</a>, <a href="https://openreview.net/profile?email=kamps%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="kamps@uva.nl">Jaap Kamps</a>, <a href="https://openreview.net/profile?email=bs%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tuebingen.mpg.de">Bernhard Schölkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1X0mzZCW-details-732" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1X0mzZCW-details-732"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Training deep neural networks requires many training samples, but in practice training labels are expensive to obtain and may be of varying quality, as some may be from trusted expert labelers while others might be from heuristics or other sources of weak supervision such as crowd-sourcing. This creates a fundamental quality- versus-quantity trade-off in the learning process. Do we learn from the small amount of high-quality data or the potentially large amount of weakly-labeled data? We argue that if the learner could somehow know and take the label-quality into account when learning the data representation, we could get the best of both worlds. To this end, we propose “fidelity-weighted learning” (FWL), a semi-supervised student- teacher approach for training deep neural networks using weakly-labeled data. FWL modulates the parameter updates to a student network (trained on the task we care about) on a per-sample basis according to the posterior confidence of its label-quality estimated by a teacher (who has access to the high-quality labels). Both student and teacher are learned from the data. We evaluate FWL on two tasks in information retrieval and natural language processing where we outperform state-of-the-art alternative semi-supervised methods, indicating that our approach makes better use of strong and weak labels, and leads to better task-dependent data representations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose Fidelity-weighted Learning, a semi-supervised teacher-student approach for training neural networks using weakly-labeled data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">fidelity-weighted learning, semisupervised learning, weakly-labeled data, teacher-student</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJzRZ-WCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJzRZ-WCZ">
          Latent Space Oddity: on the Curvature of Deep Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SJzRZ-WCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gear%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="gear@dtu.dk">Georgios Arvanitidis</a>, <a href="https://openreview.net/profile?email=lkai%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="lkai@dtu.dk">Lars Kai Hansen</a>, <a href="https://openreview.net/profile?email=sohau%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sohau@dtu.dk">Søren Hauberg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJzRZ-WCZ-details-399" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJzRZ-WCZ-details-399"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep generative models provide a systematic way to learn nonlinear data distributions through a set of latent variables and a nonlinear "generator" function that maps latent points into the input space. The nonlinearity of the generator implies that the latent space gives a distorted view of the input space. Under mild conditions, we show that this distortion can be characterized by a stochastic Riemannian metric, and we demonstrate that distances and interpolants are significantly improved under this metric. This in turn improves probability distributions, sampling algorithms and clustering in the latent space. Our geometric analysis further reveals that current generators provide poor variance estimates and we propose a new generator architecture with vastly improved variance estimates. Results are demonstrated on convolutional and fully connected variational autoencoders, but the formalism easily generalizes to other deep generative models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative models, Riemannian Geometry, Latent Space</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk3ddfWRW">
      <h4>
        <a href="https://openreview.net/forum?id=Hk3ddfWRW">
          Imitation Learning from Visual Data with Multiple Intentions
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk3ddfWRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=avivt%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="avivt@berkeley.edu">Aviv Tamar</a>, <a href="https://openreview.net/profile?email=khash%40osaro.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="khash@osaro.com">Khashayar Rohanimanesh</a>, <a href="https://openreview.net/profile?email=yldick.chow%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yldick.chow@gmail.com">Yinlam Chow</a>, <a href="https://openreview.net/profile?email=chris%40osaro.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chris@osaro.com">Chris Vigorito</a>, <a href="https://openreview.net/profile?email=ben%40osaro.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ben@osaro.com">Ben Goodrich</a>, <a href="https://openreview.net/profile?email=mk%40osaro.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mk@osaro.com">Michael Kahane</a>, <a href="https://openreview.net/profile?email=derik%40osaro.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="derik@osaro.com">Derik Pridmore</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 18 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk3ddfWRW-details-660" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk3ddfWRW-details-660"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent advances in learning from demonstrations (LfD) with deep neural networks have enabled learning complex robot skills that involve high dimensional perception such as raw image inputs. 
      LfD algorithms generally assume learning from single task demonstrations. In practice, however, it is more efficient for a teacher to demonstrate a multitude of tasks without careful task set up, labeling, and engineering. Unfortunately in such cases, traditional imitation learning techniques fail to represent the multi-modal nature of the data, and often result in sub-optimal behavior. In this paper we present an LfD approach for learning multiple modes of behavior from visual data. Our approach is based on a stochastic deep neural network (SNN), which represents the underlying intention in the demonstration as a stochastic activation in the network. We present an efficient algorithm for training SNNs, and for learning with vision inputs, we also propose an architecture that associates the intention with a stochastic attention module.
      We demonstrate our method on real robot visual object reaching tasks, and show that
      it can reliably learn the multiple behavior modes in the demonstration data. Video results are available at https://vimeo.com/240212286/fd401241b9.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">multi-modal imitation learning from unstructured demonstrations using stochastic neural network modeling intention. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-modal imitation learning, deep learning, generative models, stochastic neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1zriGeCZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1zriGeCZ">
          Hyperparameter optimization: a spectral approach
        </a>
        
          <a href="https://openreview.net/pdf?id=H1zriGeCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ehazan%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ehazan@cs.princeton.edu">Elad Hazan</a>, <a href="https://openreview.net/profile?email=klivans%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="klivans@cs.utexas.edu">Adam Klivans</a>, <a href="https://openreview.net/profile?email=yangyuan%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangyuan@cs.cornell.edu">Yang Yuan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1zriGeCZ-details-260" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1zriGeCZ-details-260"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We give a simple, fast algorithm for hyperparameter optimization inspired by techniques from the analysis of Boolean functions.  We focus on the high-dimensional regime where the canonical example is training a neural network with a large number of hyperparameters. The algorithm --- an iterative application of compressed sensing techniques for orthogonal polynomials --- requires only uniform sampling of the hyperparameters and is thus easily parallelizable.
       
      Experiments for training deep neural networks on Cifar-10 show that compared to state-of-the-art tools (e.g., Hyperband and Spearmint), our algorithm finds significantly improved solutions, in some cases better than what is attainable by hand-tuning.  In terms of overall running time (i.e., time required to sample various settings of hyperparameters plus additional computation time), we are at least an order of magnitude faster than Hyperband and Bayesian Optimization.  We also outperform Random Search $8\times$.
         
      Our method is inspired by provably-efficient algorithms for learning decision trees using the discrete Fourier transform.  We obtain improved sample-complexty bounds for learning decision trees while matching state-of-the-art bounds on running time (polynomial and quasipolynomial, respectively). </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A hyperparameter tuning algorithm using discrete Fourier analysis and compressed sensing</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Hyperparameter Optimization, Fourier Analysis, Decision Tree, Compressed Sensing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1Xw62kRZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1Xw62kRZ">
          Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis
        </a>
        
          <a href="https://openreview.net/pdf?id=H1Xw62kRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rudy%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="rudy@robots.ox.ac.uk">Rudy Bunel</a>, <a href="https://openreview.net/profile?email=mahauskn%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mahauskn@microsoft.com">Matthew Hausknecht</a>, <a href="https://openreview.net/profile?email=jacobdevlin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jacobdevlin@google.com">Jacob Devlin</a>, <a href="https://openreview.net/profile?email=risin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="risin@microsoft.com">Rishabh Singh</a>, <a href="https://openreview.net/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1Xw62kRZ-details-951" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1Xw62kRZ-details-951"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Program synthesis is the task of automatically generating a program consistent with
      a specification. Recent years have seen proposal of a number of neural approaches
      for program synthesis, many of which adopt a sequence generation paradigm similar
      to neural machine translation, in which sequence-to-sequence models are trained to
      maximize the likelihood of known reference programs. While achieving impressive
      results, this strategy has two key limitations. First, it ignores Program Aliasing: the
      fact that many different programs may satisfy a given specification (especially with
      incomplete specifications such as a few input-output examples). By maximizing
      the likelihood of only a single reference program, it penalizes many semantically
      correct programs, which can adversely affect the synthesizer performance. Second,
      this strategy overlooks the fact that programs have a strict syntax that can be
      efficiently checked. To address the first limitation, we perform reinforcement
      learning on top of a supervised model with an objective that explicitly maximizes
      the likelihood of generating semantically correct programs. For addressing the
      second limitation, we introduce a training procedure that directly maximizes the
      probability of generating syntactically correct programs that fulfill the specification.
      We show that our contributions lead to improved accuracy of the models, especially
      in cases where the training data is limited.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Program Synthesis, Reinforcement Learning, Language Model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJzgZ3JCW">
      <h4>
        <a href="https://openreview.net/forum?id=HJzgZ3JCW">
          Efficient Sparse-Winograd Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJzgZ3JCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xyl%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xyl@stanford.edu">Xingyu Liu</a>, <a href="https://openreview.net/profile?email=jpool%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpool@nvidia.com">Jeff Pool</a>, <a href="https://openreview.net/profile?email=songhan%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="songhan@stanford.edu">Song Han</a>, <a href="https://openreview.net/profile?email=dally%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dally@stanford.edu">William J. Dally</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 19 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJzgZ3JCW-details-891" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJzgZ3JCW-details-891"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional Neural Networks (CNNs) are computationally intensive, which limits their application on mobile devices. Their energy is dominated by the number of multiplies needed to perform the convolutions. Winograd’s minimal filtering algorithm (Lavin, 2015) and network pruning (Han et al., 2015) can reduce the operation count, but these two methods cannot be straightforwardly combined — applying the Winograd transform fills in the sparsity in both the weights and the activations. We propose two modifications to Winograd-based CNNs to enable these methods to exploit sparsity. First, we move the ReLU operation into the Winograd domain to increase the sparsity of the transformed activations. Second, we prune the weights in the Winograd domain to exploit static weight sparsity. For models on CIFAR-10, CIFAR-100 and ImageNet datasets, our method reduces the number of multiplications by 10.4x, 6.8x and 10.8x respectively with loss of accuracy less than 0.1%, outperforming previous baselines by 2.0x-3.0x. We also show that moving ReLU to the Winograd domain allows more aggressive pruning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Prune and ReLU in Winograd domain for efficient convolutional neural network</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, convolutional neural network, pruning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk6fD5yCb">
      <h4>
        <a href="https://openreview.net/forum?id=Sk6fD5yCb">
          Espresso: Efficient Forward Propagation for Binary Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk6fD5yCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=fpeder%40uvic.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="fpeder@uvic.ca">Fabrizio Pedersoli</a>, <a href="https://openreview.net/profile?email=gtzan%40uvic.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gtzan@uvic.ca">George Tzanetakis</a>, <a href="https://openreview.net/profile?email=ataiya%40uvic.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ataiya@uvic.ca">Andrea Tagliasacchi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk6fD5yCb-details-968" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk6fD5yCb-details-968"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">  There are many applications scenarios for which the computational
        performance and memory footprint of the prediction phase of Deep
        Neural Networks (DNNs) need to be optimized. Binary Deep Neural
        Networks (BDNNs) have been shown to be an effective way of achieving
        this objective. In this paper, we show how Convolutional Neural
        Networks (CNNs) can be implemented using binary
        representations. Espresso is a compact, yet powerful
        library written in C/CUDA that features all the functionalities
        required for the forward propagation of CNNs, in a binary file less
        than 400KB, without any external dependencies. Although it is mainly
        designed to take advantage of massive GPU parallelism, Espresso also
        provides an equivalent CPU implementation for CNNs. Espresso
        provides special convolutional and dense layers for BCNNs,
        leveraging bit-packing and bit-wise computations
        for efficient execution. These techniques provide a speed-up of
        matrix-multiplication routines, and at the same time, reduce memory
        usage when storing parameters and activations. We experimentally
        show that Espresso is significantly faster than existing
        implementations of optimized binary neural networks (~ 2
        orders of magnitude). Espresso is released under the Apache 2.0
        license and is available at http://github.com/organization/project.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">state-of-the-art computational performance implementation of binary neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">binary deep neural networks, optimized implementation, bitwise computations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r11Q2SlRW">
      <h4>
        <a href="https://openreview.net/forum?id=r11Q2SlRW">
          Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis
        </a>
        
          <a href="https://openreview.net/pdf?id=r11Q2SlRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhou859%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhou859@usc.edu">Yi Zhou</a>, <a href="https://openreview.net/profile?email=zimoli%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zimoli@usc.edu">Zimo Li</a>, <a href="https://openreview.net/profile?email=xsjiu99%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xsjiu99@sjtu.edu.cn">Shuangjiu Xiao</a>, <a href="https://openreview.net/profile?email=sal%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="sal@sjtu.edu.cn">Chong He</a>, <a href="https://openreview.net/profile?email=zenghuang%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zenghuang@usc.edu">Zeng Huang</a>, <a href="https://openreview.net/profile?email=hao%40hao-li.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hao@hao-li.com">Hao Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r11Q2SlRW-details-646" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r11Q2SlRW-details-646"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a real-time method for synthesizing highly complex human motions using a novel training regime we call the auto-conditioned Recurrent Neural Network (acRNN). Recently, researchers have attempted to synthesize new motion by using autoregressive techniques, but existing methods tend to freeze or diverge after a couple of seconds due to an accumulation of errors that are fed back into the network. Furthermore, such methods have only been shown to be reliable for relatively simple human motions, such as walking or running. In contrast, our approach can synthesize arbitrary motions with highly complex styles, including dances or martial arts in addition to locomotion. The acRNN is able to accomplish this by explicitly accommodating for autoregressive noise accumulation during training. Our work is the first to our knowledge that demonstrates the ability to generate over 18,000 continuous frames (300 seconds) of new complex human motion w.r.t. different styles. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Synthesize complex and extended human motions using an auto-conditioned LSTM network</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">motion synthesis, motion prediction, human pose, human motion, recurrent networks, lstm</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyMvJrdaW">
      <h4>
        <a href="https://openreview.net/forum?id=SyMvJrdaW">
          Decoupling the Layers in Residual Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SyMvJrdaW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ricky.fok3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ricky.fok3@gmail.com">Ricky Fok</a>, <a href="https://openreview.net/profile?email=aan%40cse.yorku.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="aan@cse.yorku.ca">Aijun An</a>, <a href="https://openreview.net/profile?email=rashidi.zana%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rashidi.zana@gmail.com">Zana Rashidi</a>, <a href="https://openreview.net/profile?email=stevenw%40mathstat.yorku.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="stevenw@mathstat.yorku.ca">Xiaogang Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>26 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyMvJrdaW-details-251" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyMvJrdaW-details-251"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a Warped Residual Network (WarpNet) using a parallelizable warp operator for forward and backward propagation to distant layers that trains faster than the original residual neural network. We apply a perturbation theory on residual networks and decouple the interactions between residual units. The resulting warp operator is a first order approximation of the output over multiple layers. The first order perturbation theory exhibits properties such as binomial path lengths and exponential gradient scaling found experimentally by Veit et al (2016). 
      We demonstrate through an extensive performance study that the proposed network achieves comparable predictive performance to the original residual network with the same number of parameters, while achieving a significant speed-up on the total training time. As WarpNet performs model parallelism in residual network training in which weights are distributed over different GPUs, it offers speed-up and capability to train larger networks compared to original residual networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose the Warped Residual Network using a parallelizable warp operator for forward and backward propagation to distant layers that trains faster than the original residual neural network. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Warped residual networks, residual networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HktRlUlAZ">
      <h4>
        <a href="https://openreview.net/forum?id=HktRlUlAZ">
          Polar Transformer Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HktRlUlAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=machc%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="machc@seas.upenn.edu">Carlos Esteves</a>, <a href="https://openreview.net/profile?email=allec%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="allec@seas.upenn.edu">Christine Allen-Blanchette</a>, <a href="https://openreview.net/profile?email=xiaowz%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaowz@seas.upenn.edu">Xiaowei Zhou</a>, <a href="https://openreview.net/profile?email=kostas%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kostas@seas.upenn.edu">Kostas Daniilidis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HktRlUlAZ-details-496" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HktRlUlAZ-details-496"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks (CNNs) are inherently equivariant to translation. Efforts to embed other forms of equivariance have concentrated solely on rotation. We expand the notion of equivariance in CNNs through the Polar Transformer Network (PTN). PTN combines ideas from the Spatial Transformer Network (STN) and canonical coordinate representations. The result is a network invariant to translation and equivariant to both rotation and scale. PTN is trained end-to-end and composed of three distinct stages: a polar origin predictor, the newly introduced polar transformer module and a classifier. PTN achieves state-of-the-art on rotated MNIST and the newly introduced SIM2MNIST dataset, an MNIST variation obtained by adding clutter and perturbing digits with translation, rotation and scaling. The ideas of PTN are extensible to 3D which we demonstrate through the Cylindrical Transformer Network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We learn feature maps invariant to translation, and equivariant to rotation and scale.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">equivariance, invariance, canonical coordinates</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1VGkIxRZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1VGkIxRZ">
          Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H1VGkIxRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sliang26%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sliang26@illinois.edu">Shiyu Liang</a>, <a href="https://openreview.net/profile?email=yli%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yli@cs.cornell.edu">Yixuan Li</a>, <a href="https://openreview.net/profile?email=rsrikant%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsrikant@illinois.edu">R. Srikant</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1VGkIxRZ-details-633" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1VGkIxRZ-details-633"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of detecting  out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can  separate the softmax score distributions of in- and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7% to 4.3% on the DenseNet (applied to CIFAR-10 and Tiny-ImageNet) when the true positive rate is 95%.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural networks, out-of-distribution detection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skj8Kag0Z">
      <h4>
        <a href="https://openreview.net/forum?id=Skj8Kag0Z">
          Stabilizing Adversarial Nets with Prediction Methods
        </a>
        
          <a href="https://openreview.net/pdf?id=Skj8Kag0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jaiabhay%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaiabhay@cs.umd.edu">Abhay Yadav</a>, <a href="https://openreview.net/profile?email=sohilas%40umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sohilas@umd.edu">Sohil Shah</a>, <a href="https://openreview.net/profile?email=xuzh%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuzh@cs.umd.edu">Zheng Xu</a>, <a href="https://openreview.net/profile?email=djacobs%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="djacobs@umiacs.umd.edu">David Jacobs</a>, <a href="https://openreview.net/profile?email=tomg%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomg@cs.umd.edu">Tom Goldstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skj8Kag0Z-details-517" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skj8Kag0Z-details-517"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Adversarial neural networks solve many important problems in data science, but are notoriously difficult to train. These difficulties come from the fact that optimal weights for adversarial nets correspond to saddle points, and not minimizers, of the loss function. The alternating stochastic gradient methods typically used for such problems do not reliably converge to saddle points, and when convergence does happen it is often highly sensitive to learning rates. We propose a simple modification of stochastic gradient descent that stabilizes adversarial networks. We show, both in theory and practice, that the proposed method reliably converges to saddle points. This makes adversarial networks less likely to "collapse," and enables faster training with larger learning rates.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a simple modification to the alternating SGD method, called a prediction step, that improves the stability of adversarial networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial networks, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJXMpikCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJXMpikCZ">
          Graph Attention Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJXMpikCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=petar.velickovic%40cst.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="petar.velickovic@cst.cam.ac.uk">Petar Veličković</a>, <a href="https://openreview.net/profile?email=gcucurull%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gcucurull@gmail.com">Guillem Cucurull</a>, <a href="https://openreview.net/profile?email=ar.casanova.8%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ar.casanova.8@gmail.com">Arantxa Casanova</a>, <a href="https://openreview.net/profile?email=adriana.romsor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adriana.romsor@gmail.com">Adriana Romero</a>, <a href="https://openreview.net/profile?email=pietro.lio%40cst.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="pietro.lio@cst.cam.ac.uk">Pietro Liò</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJXMpikCZ-details-586" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJXMpikCZ-details-586"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of computationally intensive matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel approach to processing graph-structured data by neural networks, leveraging attention over a node's neighborhood. Achieves state-of-the-art results on transductive citation network tasks and an inductive protein-protein interaction task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Graph Convolutions, Attention, Self-Attention</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BywyFQlAW">
      <h4>
        <a href="https://openreview.net/forum?id=BywyFQlAW">
          Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity
        </a>
        
          <a href="https://openreview.net/pdf?id=BywyFQlAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tianyi.david.zhou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianyi.david.zhou@gmail.com">Tianyi Zhou</a>, <a href="https://openreview.net/profile?email=bilmes%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bilmes@uw.edu">Jeff Bilmes</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 08 Jun 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BywyFQlAW-details-540" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BywyFQlAW-details-540"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce and study minimax curriculum learning (MCL), a new method for adaptively selecting a sequence of training subsets for a succession of stages in machine learning. The subsets are encouraged to be small and diverse early on, and then larger, harder, and allowably more homogeneous in later stages. At each stage, model weights and training sets are chosen by solving a joint continuous-discrete minimax optimization, whose objective is composed of a continuous loss (reflecting training set hardness) and a discrete submodular promoter of diversity for the chosen subset. MCL repeatedly solves a sequence of such optimizations with a schedule of increasing training set size and decreasing pressure on diversity encouragement. We reduce MCL to the minimization of a surrogate function handled by submodular maximization and continuous gradient methods. We show that MCL achieves better performance and, with a clustering trick, uses fewer labeled samples for both shallow and deep models while achieving the same performance. Our method involves repeatedly solving constrained submodular maximization of an only slowly varying function on the same ground set. Therefore, we develop a heuristic method that utilizes the previous submodular maximization solution as a warm start for the current submodular maximization process to reduce computation while still yielding a guarantee.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Minimax Curriculum Learning is a machine teaching method involving increasing desirable hardness and scheduled reducing diversity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine teaching, deep learning, minimax, curriculum learning, submodular, diversity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1n8LexRZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1n8LexRZ">
          Generalizing Hamiltonian Monte Carlo with Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1n8LexRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=danilevy%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danilevy@cs.stanford.edu">Daniel Levy</a>, <a href="https://openreview.net/profile?email=mhoffman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhoffman@google.com">Matt D. Hoffman</a>, <a href="https://openreview.net/profile?email=jaschasd%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaschasd@google.com">Jascha Sohl-Dickstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1n8LexRZ-details-46" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1n8LexRZ-details-46"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a general-purpose method to train Markov chain Monte Carlo kernels, parameterized by deep neural networks, that converge and mix quickly to their target distribution. Our method generalizes Hamiltonian Monte Carlo and is trained to maximize expected squared jumped distance, a proxy for mixing speed. We demonstrate large empirical gains on a collection of simple but challenging distributions, for instance achieving a 106x improvement in effective sample size in one case, and mixing when standard HMC makes no measurable progress in a second. Finally, we show quantitative and qualitative gains on a real-world task: latent-variable generative modeling. Python source code will be open-sourced with the camera-ready paper.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">General method to train expressive MCMC kernels parameterized with deep neural networks. Given a target distribution p, our method provides a fast-mixing sampler, able to efficiently explore the state space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">markov, chain, monte, carlo, sampling, posterior, deep, learning, hamiltonian, mcmc</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1Yp-j1Cb">
      <h4>
        <a href="https://openreview.net/forum?id=H1Yp-j1Cb">
          An Online Learning Approach to Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H1Yp-j1Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=paulina.grnarova%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="paulina.grnarova@inf.ethz.ch">Paulina Grnarova</a>, <a href="https://openreview.net/profile?email=yehuda.levy%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="yehuda.levy@inf.ethz.ch">Kfir Y Levy</a>, <a href="https://openreview.net/profile?email=aurelien.lucchi%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aurelien.lucchi@inf.ethz.ch">Aurelien Lucchi</a>, <a href="https://openreview.net/profile?email=thomas.hofmann%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.hofmann@inf.ethz.ch">Thomas Hofmann</a>, <a href="https://openreview.net/profile?email=krausea%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="krausea@ethz.ch">Andreas Krause</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1Yp-j1Cb-details-752" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1Yp-j1Cb-details-752"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of training generative models with a Generative Adversarial Network (GAN). Although GANs can accurately model complex distributions, they are known to be difficult to train due to instabilities caused by a difficult minimax optimization problem. In this paper, we view the problem of training GANs as finding a mixed strategy in a zero-sum game. Building on ideas from online learning we propose a novel training method named Chekhov GAN. On the theory side, we show that our method provably converges to an equilibrium for semi-shallow GAN architectures, i.e. architectures where the discriminator is a one-layer network and the generator is arbitrary. On the practical side, we develop an efficient heuristic guided by our theoretical results, which we apply to commonly used deep GAN architectures.
      On several real-world tasks our approach exhibits improved stability and performance compared to standard GAN training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, GANs, online learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkQkBnJAb">
      <h4>
        <a href="https://openreview.net/forum?id=rkQkBnJAb">
          Improving GANs Using Optimal Transport
        </a>
        
          <a href="https://openreview.net/pdf?id=rkQkBnJAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tim%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tim@openai.com">Tim Salimans</a>, <a href="https://openreview.net/profile?email=han.zhang%40cs.rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="han.zhang@cs.rutgers.edu">Han Zhang</a>, <a href="https://openreview.net/profile?email=alec%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alec@openai.com">Alec Radford</a>, <a href="https://openreview.net/profile?email=dnm%40cs.rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dnm@cs.rutgers.edu">Dimitris Metaxas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkQkBnJAb-details-428" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkQkBnJAb-details-428"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Optimal Transport GAN (OT-GAN), a variant of generative adversarial nets minimizing a new metric measuring the distance between the generator distribution and the data distribution. This metric, which we call mini-batch energy distance, combines optimal transport in primal form with an energy distance defined in an adversarially learned feature space, resulting in a highly discriminative distance function with unbiased mini-batch gradients. Experimentally we show OT-GAN to be highly stable when trained with large mini-batches, and we present state-of-the-art results on several popular benchmark problems for image generation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An extension of GANs combining optimal transport in primal form with an energy distance defined in an adversarially learned feature space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, generative modeling, adversarial, optimal transport</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1HlA-ZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=S1HlA-ZAZ">
          The Kanerva Machine: A Generative Distributed Memory
        </a>
        
          <a href="https://openreview.net/pdf?id=S1HlA-ZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yanwu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanwu@google.com">Yan Wu</a>, <a href="https://openreview.net/profile?email=gregwayne%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gregwayne@google.com">Greg Wayne</a>, <a href="https://openreview.net/profile?email=gravesa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gravesa@google.com">Alex Graves</a>, <a href="https://openreview.net/profile?email=countzero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="countzero@google.com">Timothy Lillicrap</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 18 Jun 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1HlA-ZAZ-details-716" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1HlA-ZAZ-details-716"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present an end-to-end trained memory system that quickly adapts to new data and generates samples like them. Inspired by Kanerva's sparse distributed memory, it has a robust  distributed reading and writing mechanism. The memory is analytically tractable, which enables optimal on-line compression via a Bayesian update-rule. We formulate it as a hierarchical conditional generative model, where memory provides a rich data-dependent prior distribution. Consequently, the top-down memory and bottom-up perception are combined to produce the code representing an observation. Empirically, we demonstrate that the adaptive memory significantly improves generative models trained on both the Omniglot and CIFAR datasets. Compared with the Differentiable Neural Computer (DNC) and its variants, our memory model has greater capacity and is significantly easier to train.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A generative memory model that combines slow-learning neural networks and a fast-adapting linear Gaussian model as memory.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">memory, generative model, inference, neural network, hierarchical model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1gs9JgRZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1gs9JgRZ">
          Mixed Precision Training
        </a>
        
          <a href="https://openreview.net/pdf?id=r1gs9JgRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pauliusm%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pauliusm@nvidia.com">Paulius Micikevicius</a>, <a href="https://openreview.net/profile?email=sharan%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sharan@baidu.com">Sharan Narang</a>, <a href="https://openreview.net/profile?email=alben%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alben@nvidia.com">Jonah Alben</a>, <a href="https://openreview.net/profile?email=gdiamos%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdiamos@baidu.com">Gregory Diamos</a>, <a href="https://openreview.net/profile?email=eriche%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eriche@google.com">Erich Elsen</a>, <a href="https://openreview.net/profile?email=dagarcia%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dagarcia@nvidia.com">David Garcia</a>, <a href="https://openreview.net/profile?email=bginsburg%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bginsburg@nvidia.com">Boris Ginsburg</a>, <a href="https://openreview.net/profile?email=mhouston%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhouston@nvidia.com">Michael Houston</a>, <a href="https://openreview.net/profile?email=okuchaiev%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="okuchaiev@nvidia.com">Oleksii Kuchaiev</a>, <a href="https://openreview.net/profile?email=gavenkatesh%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gavenkatesh@nvidia.com">Ganesh Venkatesh</a>, <a href="https://openreview.net/profile?email=skyw%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skyw@nvidia.com">Hao Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1gs9JgRZ-details-662" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1gs9JgRZ-details-662"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Increasing the size of a neural network typically improves accuracy but also increases the memory and compute requirements for training the model. We introduce methodology for training deep neural networks using half-precision floating point numbers, without losing model accuracy or having to modify hyper-parameters. This nearly halves memory requirements and, on recent GPUs, speeds up arithmetic. Weights, activations, and gradients are stored in IEEE half-precision format. Since this format has a narrower range than single-precision we propose three techniques for preventing the loss of critical information. Firstly, we recommend maintaining a single-precision copy of weights that accumulates the gradients after each optimizer step (this copy is rounded to half-precision for the forward- and back-propagation). Secondly, we propose loss-scaling to preserve gradient values with small magnitudes. Thirdly, we use half-precision arithmetic that accumulates into single-precision outputs, which are converted to half-precision before storing to memory. We demonstrate that the proposed methodology works across a wide variety of tasks and modern large scale (exceeding 100 million parameters) model architectures, trained on large datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Half precision, float16, Convolutional neural networks, Recurrent neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy8XvGb0-">
      <h4>
        <a href="https://openreview.net/forum?id=Sy8XvGb0-">
          Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy8XvGb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jesseengel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jesseengel@google.com">Jesse Engel</a>, <a href="https://openreview.net/profile?email=mhoffman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhoffman@google.com">Matthew Hoffman</a>, <a href="https://openreview.net/profile?email=adarob%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adarob@google.com">Adam Roberts</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy8XvGb0--details-680" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy8XvGb0--details-680"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep generative neural networks have proven effective at both conditional and unconditional modeling of complex data distributions. Conditional generation enables interactive control, but creating new controls often requires expensive retraining. In this paper, we develop a method to condition generation without retraining the model. By post-hoc learning latent constraints, value functions identify regions in latent space that generate outputs with desired attributes, we can conditionally sample from these regions with gradient-based optimization or amortized actor functions. Combining attribute constraints with a universal “realism” constraint, which enforces similarity to the data distribution, we generate realistic conditional images from an unconditional variational autoencoder. Further, using gradient-based optimization, we demonstrate identity-preserving transformations that make the minimal adjustment in latent space to modify the attributes of an image. Finally, with discrete sequences of musical notes, we demonstrate zero-shot conditional generation, learning latent constraints in the absence of labeled data or a differentiable reward function.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new approach to conditional generation by constraining the latent space of an unconditional generative model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">VAE, GAN, generative networks, conditional generation, latent-variable models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByOExmWAb">
      <h4>
        <a href="https://openreview.net/forum?id=ByOExmWAb">
          MaskGAN: Better Text Generation via Filling in the _______
        </a>
        
          <a href="https://openreview.net/pdf?id=ByOExmWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=liam.fedus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liam.fedus@gmail.com">William Fedus</a>, <a href="https://openreview.net/profile?email=goodfellow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goodfellow@google.com">Ian Goodfellow</a>, <a href="https://openreview.net/profile?email=adai%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adai@google.com">Andrew M. Dai</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 01 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByOExmWAb-details-176" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByOExmWAb-details-176"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural text generation models are often autoregressive language models or seq2seq models. Neural autoregressive and seq2seq models that generate text by sampling words sequentially, with each word conditioned on the previous model, are state-of-the-art for several machine translation and summarization benchmarks. These benchmarks are often defined by validation perplexity even though this is not a direct measure of sample quality. Language models are typically trained via maximum likelihood and most often with teacher forcing. Teacher forcing is well-suited to optimizing perplexity but can result in poor sample quality because generating text requires conditioning on sequences of words that were never observed at training time. We propose to improve sample quality using Generative Adversarial Network (GANs), which explicitly train the generator to produce high quality samples and have shown a lot of success in image generation. GANs were originally to designed to output differentiable values, so discrete language generation is challenging for them. We introduce an actor-critic conditional GAN that fills in missing text conditioned on the surrounding context. We show qualitatively and quantitatively, evidence that this produces more realistic text samples compared to a maximum likelihood trained model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Natural language GAN for filling in the blank</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, GAN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1jscMbAW">
      <h4>
        <a href="https://openreview.net/forum?id=B1jscMbAW">
          Divide and Conquer Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1jscMbAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alexnowakvila%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexnowakvila@gmail.com">Alex Nowak</a>, <a href="https://openreview.net/profile?email=david.folque%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.folque@gmail.com">David Folqué</a>, <a href="https://openreview.net/profile?email=bruna%40cims.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bruna@cims.nyu.edu">Joan Bruna</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1jscMbAW-details-968" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1jscMbAW-details-968"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the learning of algorithmic tasks by mere observation of input-output
      pairs. Rather than studying this as a black-box discrete regression problem with
      no assumption whatsoever on the input-output mapping, we concentrate on tasks
      that are amenable to the principle of divide and conquer, and study what are its
      implications in terms of learning.
      This principle creates a powerful inductive bias that we leverage with neural
      architectures that are defined recursively and dynamically, by learning two scale-
      invariant atomic operations: how to split a given input into smaller sets, and how
      to merge two partially solved tasks into a larger partial solution. Our model can be
      trained in weakly supervised environments, namely by just observing input-output
      pairs, and in even weaker environments, using a non-differentiable reward signal.
      Moreover, thanks to the dynamic aspect of our architecture, we can incorporate
      the computational complexity as a regularization term that can be optimized by
      backpropagation. We demonstrate the flexibility and efficiency of the Divide-
      and-Conquer Network on several combinatorial and geometric tasks: convex hull,
      clustering, knapsack and euclidean TSP. Thanks to the dynamic programming
      nature of our model, we show significant improvements in terms of generalization
      error and computational complexity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Dynamic model that learns divide and conquer strategies by weak supervision.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Networks, Combinatorial Optimization, Algorithms</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyjC5yWCW">
      <h4>
        <a href="https://openreview.net/forum?id=HyjC5yWCW">
          Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm
        </a>
        
          <a href="https://openreview.net/pdf?id=HyjC5yWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cbfinn%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbfinn@eecs.berkeley.edu">Chelsea Finn</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyjC5yWCW-details-71" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyjC5yWCW-details-71"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Deep representations combined with gradient descent can approximate any learning algorithm.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meta-learning, learning to learn, universal function approximation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1ANxQW0b">
      <h4>
        <a href="https://openreview.net/forum?id=S1ANxQW0b">
          Maximum a Posteriori Policy Optimisation
        </a>
        
          <a href="https://openreview.net/pdf?id=S1ANxQW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=abbas.abdolmaleky%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abbas.abdolmaleky@gmail.com">Abbas Abdolmaleki</a>, <a href="https://openreview.net/profile?email=springenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="springenberg@google.com">Jost Tobias Springenberg</a>, <a href="https://openreview.net/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Yuval Tassa</a>, <a href="https://openreview.net/profile?email=tassa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tassa@google.com">Remi Munos</a>, <a href="https://openreview.net/profile?email=munos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="munos@google.com">Nicolas Heess</a>, Martin Riedmiller
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1ANxQW0b-details-363" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1ANxQW0b-details-363"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a new algorithm for reinforcement learning called Maximum a-posteriori Policy Optimisation (MPO) based on coordinate ascent on a relative-entropy objective. We show that several existing methods can directly be related to our derivation. We develop two off-policy algorithms and demonstrate that they are competitive with the state-of-the-art in deep reinforcement learning. In particular, for continuous control, our method outperforms existing methods with respect to sample efficiency, premature convergence and robustness to hyperparameter settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Variational Inference, Control</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyX0IeWAW">
      <h4>
        <a href="https://openreview.net/forum?id=SyX0IeWAW">
          META LEARNING SHARED HIERARCHIES
        </a>
        
          <a href="https://openreview.net/pdf?id=SyX0IeWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kevinfrans2%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevinfrans2@gmail.com">Kevin Frans</a>, <a href="https://openreview.net/profile?email=jonathanho%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonathanho@berkeley.edu">Jonathan Ho</a>, <a href="https://openreview.net/profile?email=c.xi%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="c.xi@eecs.berkeley.edu">Xi Chen</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>, <a href="https://openreview.net/profile?email=joschu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joschu@openai.com">John Schulman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyX0IeWAW-details-276" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyX0IeWAW-details-276"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We develop a metalearning approach for learning hierarchically structured poli- cies, improving sample efficiency on unseen tasks through the use of shared primitives—policies that are executed for large numbers of timesteps. Specifi- cally, a set of primitives are shared within a distribution of tasks, and are switched between by task-specific policies. We provide a concrete metric for measuring the strength of such hierarchies, leading to an optimization problem for quickly reaching high reward on unseen tasks. We then present an algorithm to solve this problem end-to-end through the use of any off-the-shelf reinforcement learning method, by repeatedly sampling new tasks and resetting task-specific policies. We successfully discover meaningful motor primitives for the directional movement of four-legged robots, solely by interacting with distributions of mazes. We also demonstrate the transferability of primitives to solve long-timescale sparse-reward obstacle courses, and we enable 3D humanoid robots to robustly walk and crawl with the same policy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">learn hierarchal sub-policies through end-to-end training over a distribution of tasks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hierarchal reinforcement learning, meta-learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1EA-M-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=B1EA-M-0Z">
          Deep Neural Networks as Gaussian Processes
        </a>
        
          <a href="https://openreview.net/pdf?id=B1EA-M-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jaehlee%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaehlee@google.com">Jaehoon Lee</a>, <a href="https://openreview.net/profile?email=yasamanb%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yasamanb@google.com">Yasaman Bahri</a>, <a href="https://openreview.net/profile?email=romann%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="romann@google.com">Roman Novak</a>, <a href="https://openreview.net/profile?email=schsam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schsam@google.com">Samuel S. Schoenholz</a>, <a href="https://openreview.net/profile?email=jpennin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpennin@google.com">Jeffrey Pennington</a>, <a href="https://openreview.net/profile?email=jaschasd%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaschasd@google.com">Jascha Sohl-Dickstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1EA-M-0Z-details-276" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1EA-M-0Z-details-276"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It has long been known that a single-layer fully-connected neural network with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP), in the limit of infinite network width.  This correspondence enables exact Bayesian inference for infinite width neural networks on regression tasks by means of evaluating the corresponding GP. Recently, kernel functions which mimic multi-layer random neural networks have been developed, but only outside of a Bayesian framework. As such, previous work has not identified that these kernels can be used as covariance functions for GPs and allow fully Bayesian prediction with a deep neural network.
      
      In this work, we derive the exact equivalence between infinitely wide, deep, networks and GPs with a particular covariance function. We further develop a computationally efficient pipeline to compute this covariance function. We then use the resulting GP to perform Bayesian inference for deep neural networks on MNIST and CIFAR-10.  We observe that the trained neural network accuracy approaches that of the corresponding GP with increasing layer width, and that the GP uncertainty is strongly correlated with trained network prediction error. We further find that test performance increases as finite-width trained networks are made wider and  more  similar  to  a  GP,  and  that  the  GP-based  predictions  typically  outperform  those  of  finite-width  networks. Finally  we  connect  the  prior  distribution over weights and variances in our GP formulation to the recent development of signal propagation in random neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how to make predictions using deep networks, without training deep networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Gaussian process, Bayesian regression, deep networks, kernel methods</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyqShMZRb">
      <h4>
        <a href="https://openreview.net/forum?id=SyqShMZRb">
          Syntax-Directed Variational Autoencoder for Structured Data
        </a>
        
          <a href="https://openreview.net/pdf?id=SyqShMZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hanjundai%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanjundai@gatech.edu">Hanjun Dai</a>, <a href="https://openreview.net/profile?email=yittian%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yittian@cs.stonybrook.edu">Yingtao Tian</a>, <a href="https://openreview.net/profile?email=bohr.dai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bohr.dai@gmail.com">Bo Dai</a>, <a href="https://openreview.net/profile?email=skiena%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="skiena@cs.stonybrook.edu">Steven Skiena</a>, <a href="https://openreview.net/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyqShMZRb-details-240" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyqShMZRb-details-240"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep generative models have been enjoying success in modeling continuous data. However it remains challenging to capture the representations for discrete structures with formal grammars and semantics, e.g., computer programs and molecular structures. How to generate both syntactically and semantically correct data still remains largely an open problem. Inspired by the theory of compiler where syntax and semantics check is done via syntax-directed translation (SDT), we propose a novel syntax-directed variational autoencoder (SD-VAE) by introducing stochastic lazy attributes. This approach converts the offline SDT check into on-the-fly generated guidance for constraining the decoder. Comparing to the state-of-the-art methods, our approach enforces constraints on the output space so that the output will be not only syntactically valid, but also semantically reasonable. We evaluate the proposed model with applications in programming language and molecules, including reconstruction and program/molecule optimization. The results demonstrate the effectiveness in incorporating syntactic and semantic constraints in discrete generative models, which is significantly better than current state-of-the-art approaches.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new generative model for discrete structured data. The proposed stochastic lazy attribute converts the offline semantic check into online guidance for stochastic decoding, which effectively addresses the constraints in syntax and semantics, and also achieves superior performance</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative model for structured data, syntax-directed generation, molecule and program optimization, variational autoencoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rywDjg-RW">
      <h4>
        <a href="https://openreview.net/forum?id=rywDjg-RW">
          Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=rywDjg-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ashwinkv%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashwinkv@gatech.edu">Ashwin Kalyan</a>, <a href="https://openreview.net/profile?email=t-abmoht%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="t-abmoht@microsoft.com">Abhishek Mohta</a>, <a href="https://openreview.net/profile?email=polozov%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="polozov@microsoft.com">Oleksandr Polozov</a>, <a href="https://openreview.net/profile?email=dbatra%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbatra@gatech.edu">Dhruv Batra</a>, <a href="https://openreview.net/profile?email=prajain%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="prajain@microsoft.com">Prateek Jain</a>, <a href="https://openreview.net/profile?email=sumitg%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sumitg@microsoft.com">Sumit Gulwani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rywDjg-RW-details-299" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rywDjg-RW-details-299"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Synthesizing user-intended programs from a small number of input-output exam-
      ples is a challenging problem with several important applications like spreadsheet
      manipulation, data wrangling and code refactoring. Existing synthesis systems
      either completely rely on deductive logic techniques that are extensively hand-
      engineered or on purely statistical models that need massive amounts of data, and in
      general fail to provide real-time synthesis on challenging benchmarks. In this work,
      we propose Neural Guided Deductive Search (NGDS), a hybrid synthesis technique
      that combines the best of both symbolic logic techniques and statistical models.
      Thus, it produces programs that satisfy the provided specifications by construction
      and generalize well on unseen examples, similar to data-driven systems. Our
      technique effectively utilizes the deductive search framework to reduce the learning
      problem of the neural component to a simple supervised learning setup. Further,
      this allows us to both train on sparingly available real-world data and still leverage
      powerful recurrent neural network encoders. We demonstrate the effectiveness
      of our method by evaluating on real-world customer scenarios by synthesizing
      accurate programs with up to 12× speed-up compared to state-of-the-art systems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We integrate symbolic (deductive) and statistical (neural-based) methods to enable real-time program synthesis with almost perfect generalization from 1 input-output example.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Program synthesis, deductive search, deep learning, program induction, recurrent neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJl3yM-Ab">
      <h4>
        <a href="https://openreview.net/forum?id=rJl3yM-Ab">
          Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering
        </a>
        
          <a href="https://openreview.net/pdf?id=rJl3yM-Ab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shwang.2014%40phdis.smu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="shwang.2014@phdis.smu.edu.sg">Shuohang Wang</a>, <a href="https://openreview.net/profile?email=yum%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yum@us.ibm.com">Mo Yu</a>, <a href="https://openreview.net/profile?email=jingjiang%40smu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="jingjiang@smu.edu.sg">Jing Jiang</a>, <a href="https://openreview.net/profile?email=zhangwei%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangwei@us.ibm.com">Wei Zhang</a>, <a href="https://openreview.net/profile?email=xiaoxiao.guo%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoxiao.guo@ibm.com">Xiaoxiao Guo</a>, <a href="https://openreview.net/profile?email=shiyu.chang%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiyu.chang@ibm.com">Shiyu Chang</a>, <a href="https://openreview.net/profile?email=zhigwang%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhigwang@us.ibm.com">Zhiguo Wang</a>, <a href="https://openreview.net/profile?email=tklinger%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tklinger@us.ibm.com">Tim Klinger</a>, <a href="https://openreview.net/profile?email=gtesauro%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gtesauro@us.ibm.com">Gerald Tesauro</a>, <a href="https://openreview.net/profile?email=mcam%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcam@us.ibm.com">Murray Campbell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJl3yM-Ab-details-394" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJl3yM-Ab-details-394"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Very recently, it comes to be a popular approach for answering open-domain questions by first searching question-related passages, then applying reading comprehension models to extract answers. Existing works usually extract answers from single passages independently, thus not fully make use of the multiple searched passages, especially for the some questions requiring several evidences, which can appear in different passages, to be answered. The above observations raise the problem of evidence aggregation from multiple passages. In this paper, we deal with this problem as answer re-ranking. Specifically, based on the answer candidates generated from the existing state-of-the-art QA model, we propose two different re-ranking methods, strength-based and coverage-based re-rankers, which make use of the aggregated evidences from different passages to help entail the ground-truth answer for the question. Our model achieved state-of-the-arts on three public open-domain QA datasets, Quasar-T, SearchQA and the open-domain version of TriviaQA, with about 8\% improvement on the former two datasets. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a method that can make use of the multiple passages information for open-domain QA.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Question Answering, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1ZvaaeAZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1ZvaaeAZ">
          WRPN: Wide Reduced-Precision Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1ZvaaeAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=asit.k.mishra%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="asit.k.mishra@intel.com">Asit Mishra</a>, <a href="https://openreview.net/profile?email=eriko.nurvitadhi%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eriko.nurvitadhi@intel.com">Eriko Nurvitadhi</a>, <a href="https://openreview.net/profile?email=jeffrey.j.cook%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeffrey.j.cook@intel.com">Jeffrey J Cook</a>, <a href="https://openreview.net/profile?email=debbie.marr%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="debbie.marr@intel.com">Debbie Marr</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1ZvaaeAZ-details-856" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1ZvaaeAZ-details-856"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">For computer vision applications, prior works have shown the efficacy of reducing numeric precision of model parameters (network weights) in deep neural networks. Activation maps, however, occupy a large memory footprint during both the training and inference step when using mini-batches of inputs. One way to reduce this large memory footprint is to reduce the precision of activations. However, past works have shown that reducing the precision of activations hurts model accuracy. We study schemes to train networks from scratch using reduced-precision activations without hurting accuracy. We reduce the precision of activation maps (along with model parameters) and increase the number of filter maps in a layer, and find that this scheme matches or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly improve the execution efficiency (e.g. reduce dynamic memory footprint, memory band- width and computational energy) and speed up the training and inference process with appropriate hardware support. We call our scheme WRPN -- wide reduced-precision networks. We report results and show that WRPN scheme is better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Lowering precision (to 4-bits, 2-bits and even binary) and widening the filter banks gives as accurate network as those obtained with FP32 weights and activations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Low precision, binary, ternary, 4-bits networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkmu5b0a-">
      <h4>
        <a href="https://openreview.net/forum?id=rkmu5b0a-">
          MGAN: Training Generative Adversarial Nets with Multiple Generators
        </a>
        
          <a href="https://openreview.net/pdf?id=rkmu5b0a-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=qhoang%40umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qhoang@umass.edu">Quan Hoang</a>, <a href="https://openreview.net/profile?email=tu.nguyen%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="tu.nguyen@deakin.edu.au">Tu Dinh Nguyen</a>, <a href="https://openreview.net/profile?email=trung.l%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="trung.l@deakin.edu.au">Trung Le</a>, <a href="https://openreview.net/profile?email=dinh.phung%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="dinh.phung@deakin.edu.au">Dinh Phung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>29 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkmu5b0a--details-471" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkmu5b0a--details-471"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose in this paper a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. The idea is simple, yet proven to be extremely effective at covering diverse data modes, easily overcoming the mode collapsing problem and delivering state-of-the-art results. A minimax formulation was able to establish among a classifier, a discriminator, and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data, whilst the discriminator determines whether samples are true data or generated by generators, and the classifier specifies which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators, and then one of them will be randomly selected as final output similar to the mechanism of a probabilistic mixture model. We term our method Mixture Generative Adversarial Nets (MGAN). We develop theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon divergence (JSD) between the mixture of generators’ distributions and the empirical data distribution is minimal, whilst the JSD among generators’ distributions is maximal, hence effectively avoiding the mode collapsing problem. By utilizing parameter sharing, our proposed model adds minimal computational cost to the standard GAN, and thus can also efficiently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines, generating diverse and appealing recognizable objects at different resolutions, and specializing in capturing different types of objects by the generators.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new approach to train GANs with a mixture of generators to overcome the mode collapsing problem.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GANs, Mode Collapse, Mixture, Jensen-Shannon Divergence, Inception Score, Generator, Discriminator, CIFAR-10, STL-10, ImageNet</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkHVZWZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkHVZWZAZ">
          The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rkHVZWZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=audrunas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="audrunas@google.com">Audrunas Gruslys</a>, <a href="https://openreview.net/profile?email=wdabney%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wdabney@google.com">Will Dabney</a>, <a href="https://openreview.net/profile?email=mazar%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mazar@google.com">Mohammad Gheshlaghi Azar</a>, <a href="https://openreview.net/profile?email=piot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="piot@google.com">Bilal Piot</a>, <a href="https://openreview.net/profile?email=bellemare%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bellemare@google.com">Marc Bellemare</a>, <a href="https://openreview.net/profile?email=munos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="munos@google.com">Remi Munos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkHVZWZAZ-details-911" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkHVZWZAZ-details-911"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work we present a new agent architecture, called Reactor, which combines multiple algorithmic and architectural contributions to produce an agent with higher sample-efficiency than Prioritized Dueling DQN (Wang et al., 2016) and Categorical DQN (Bellemare et al., 2017), while giving better run-time performance than A3C (Mnih et al., 2016). Our first contribution is a new policy evaluation algorithm called Distributional Retrace, which brings multi-step off-policy updates to the distributional reinforcement learning setting. The same approach can be used to convert several classes of multi-step policy evaluation algorithms designed for expected value evaluation into distributional ones. Next, we introduce the β-leaveone-out policy gradient algorithm which improves the trade-off between variance and bias by using action values as a baseline. Our final algorithmic contribution is a new prioritized replay algorithm for sequences, which exploits the temporal locality of neighboring observations for more efficient replay prioritization. Using the Atari 2600 benchmarks, we show that each of these innovations contribute to both the sample efficiency and final agent performance. Finally, we demonstrate that Reactor reaches state-of-the-art performance after 200 million frames and less than a day of training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Reactor combines multiple algorithmic and architectural contributions to produce an agent with higher sample-efficiency than Prioritized Dueling DQN while giving better run-time performance than A3C.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, policy gradient, distributional reinforcement learning, distributed computing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkUR_y-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=HkUR_y-RZ">
          SEARNN: Training RNNs with global-local losses
        </a>
        
          <a href="https://openreview.net/pdf?id=HkUR_y-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=remi.leblond%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="remi.leblond@inria.fr">Rémi Leblond</a>, <a href="https://openreview.net/profile?email=jean-baptiste.alayrac%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jean-baptiste.alayrac@inria.fr">Jean-Baptiste Alayrac</a>, <a href="https://openreview.net/profile?email=aosokin%40hse.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="aosokin@hse.ru">Anton Osokin</a>, <a href="https://openreview.net/profile?email=slacoste%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="slacoste@iro.umontreal.ca">Simon Lacoste-Julien</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkUR_y-RZ-details-879" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkUR_y-RZ-details-879"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose SEARNN, a novel training algorithm for recurrent neural networks (RNNs) inspired by the "learning to search" (L2S) approach to structured prediction. RNNs have been widely successful in structured prediction applications such as machine translation or parsing, and are commonly trained using maximum likelihood estimation (MLE). Unfortunately, this training loss is not always an appropriate surrogate for the test error: by only maximizing the ground truth probability, it fails to exploit the wealth of information offered by structured losses. Further, it introduces discrepancies between training and predicting (such as exposure bias) that may hurt test performance. Instead, SEARNN leverages test-alike search space exploration to introduce global-local losses that are closer to the test error. We first demonstrate improved performance over MLE on two different tasks: OCR and spelling correction. Then, we propose a subsampling strategy to enable SEARNN to scale to large vocabulary sizes. This allows us to validate the benefits of our approach on a machine translation task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce SeaRNN, a novel algorithm for RNN training, inspired by the learning to search approach to structured prediction, in order to avoid the limitations of MLE training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Structured prediction, RNNs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyZipzbCb">
      <h4>
        <a href="https://openreview.net/forum?id=SyZipzbCb">
          Distributed Distributional Deterministic Policy Gradients
        </a>
        
          <a href="https://openreview.net/pdf?id=SyZipzbCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gabrielbm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gabrielbm@google.com">Gabriel Barth-Maron</a>, <a href="https://openreview.net/profile?email=mwhoffman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mwhoffman@google.com">Matthew W. Hoffman</a>, <a href="https://openreview.net/profile?email=budden%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="budden@google.com">David Budden</a>, <a href="https://openreview.net/profile?email=wdabney%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wdabney@google.com">Will Dabney</a>, <a href="https://openreview.net/profile?email=horgan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="horgan@google.com">Dan Horgan</a>, <a href="https://openreview.net/profile?email=dhruvat%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhruvat@google.com">Dhruva TB</a>, <a href="https://openreview.net/profile?email=alimuldal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alimuldal@google.com">Alistair Muldal</a>, <a href="https://openreview.net/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Nicolas Heess</a>, <a href="https://openreview.net/profile?email=countzero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="countzero@google.com">Timothy Lillicrap</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyZipzbCb-details-949" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyZipzbCb-details-949"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This work adopts the very successful distributional perspective on reinforcement learning and adapts it to the continuous control setting. We combine this within a distributed framework for off-policy learning in order to develop what we call the Distributed Distributional Deep Deterministic Policy Gradient algorithm, D4PG. We also combine this technique with a number of additional, simple improvements such as the use of N-step returns and prioritized experience replay. Experimentally we examine the contribution of each of these individual components, and show how they interact, as well as their combined contributions. Our results show that across a wide variety of simple control tasks, difficult manipulation tasks, and a set of hard obstacle-based locomotion tasks the D4PG algorithm achieves state of the art performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We develop an agent that we call the Distributional Deterministic Deep Policy Gradient algorithm, which achieves state of the art performance on a number of challenging continuous control problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">policy gradient, continuous control, actor critic, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry80wMW0W">
      <h4>
        <a href="https://openreview.net/forum?id=ry80wMW0W">
          Hierarchical Subtask Discovery with Non-Negative Matrix Factorization
        </a>
        
          <a href="https://openreview.net/pdf?id=ry80wMW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=adam.earle%40ymail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.earle@ymail.com">Adam C. Earle</a>, <a href="https://openreview.net/profile?email=asaxe%40fas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asaxe@fas.harvard.edu">Andrew M. Saxe</a>, <a href="https://openreview.net/profile?email=benjros%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="benjros@gmail.com">Benjamin Rosman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry80wMW0W-details-407" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry80wMW0W-details-407"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Hierarchical reinforcement learning methods offer a powerful means of planning flexible behavior in complicated domains. However, learning an appropriate hierarchical decomposition of a domain into subtasks remains a substantial challenge. We present a novel algorithm for subtask discovery, based on the recently introduced multitask linearly-solvable Markov decision process (MLMDP) framework. The MLMDP can perform never-before-seen tasks by representing them as a linear combination of a previously learned basis set of tasks. In this setting, the subtask discovery problem can naturally be posed as finding an optimal low-rank approximation of the set of tasks the agent will face in a domain. We use non-negative matrix factorization to discover this minimal basis set of tasks, and show that the technique learns intuitive decompositions in a variety of domains. Our method has several qualitatively desirable features: it is not limited to learning subtasks with single goal states, instead learning distributed patterns of preferred states; it learns qualitatively different hierarchical decompositions in the same domain depending on the ensemble of tasks the agent will face; and it may be straightforwardly iterated to obtain deeper hierarchical decompositions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a novel algorithm for hierarchical subtask discovery which leverages the multitask linear Markov decision process framework.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Hierarchy, Subtask Discovery, Linear Markov Decision Process</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJl63fZRb">
      <h4>
        <a href="https://openreview.net/forum?id=rJl63fZRb">
          Parametrized Hierarchical Procedures for Neural Programming
        </a>
        
          <a href="https://openreview.net/pdf?id=rJl63fZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=roy.d.fox%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="roy.d.fox@gmail.com">Roy Fox</a>, <a href="https://openreview.net/profile?email=shin.richard%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shin.richard@gmail.com">Richard Shin</a>, <a href="https://openreview.net/profile?email=sanjay%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjay@eecs.berkeley.edu">Sanjay Krishnan</a>, <a href="https://openreview.net/profile?email=goldberg%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="goldberg@berkeley.edu">Ken Goldberg</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>, <a href="https://openreview.net/profile?email=istoica%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="istoica@cs.berkeley.edu">Ion Stoica</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJl63fZRb-details-213" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJl63fZRb-details-213"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural programs are highly accurate and structured policies that perform algorithmic tasks by controlling the behavior of a computation mechanism. Despite the potential to increase the interpretability and the compositionality of the behavior of artificial agents, it remains difficult to learn from demonstrations neural networks that represent computer programs. The main challenges that set algorithmic domains apart from other imitation learning domains are the need for high accuracy, the involvement of specific structures of data, and the extremely limited observability. To address these challenges, we propose to model programs as Parametrized Hierarchical Procedures (PHPs). A PHP is a sequence of conditional operations, using a program counter along with the observation to select between taking an elementary action, invoking another PHP as a sub-procedure, and returning to the caller. We develop an algorithm for training PHPs from a set of supervisor demonstrations, only some of which are annotated with the internal call structure, and apply it to efficient level-wise training of multi-level PHPs. We show in two benchmarks, NanoCraft and long-hand addition, that PHPs can learn neural programs more accurately from smaller amounts of both annotated and unannotated demonstrations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the PHP model for hierarchical representation of neural programs, and an algorithm for learning PHPs from a mixture of strong and weak supervision.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural programming, Hierarchical Control</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1D8MPxA-">
      <h4>
        <a href="https://openreview.net/forum?id=S1D8MPxA-">
          Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio
        </a>
        
          <a href="https://openreview.net/pdf?id=S1D8MPxA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dslee3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dslee3@gmail.com">Dongsoo Lee</a>, <a href="https://openreview.net/profile?email=daehyun.ahn%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="daehyun.ahn@postech.ac.kr">Daehyun Ahn</a>, <a href="https://openreview.net/profile?email=taesukim%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="taesukim@postech.ac.kr">Taesu Kim</a>, <a href="https://openreview.net/profile?email=pchuang%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pchuang@us.ibm.com">Pierce I. Chuang</a>, <a href="https://openreview.net/profile?email=jaejoon%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaejoon@postech.ac.kr">Jae-Joon Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1D8MPxA--details-274" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1D8MPxA--details-274"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Weight pruning has proven to be an effective method in reducing the model size and computation cost while not sacrificing the model accuracy. Conventional sparse matrix formats, however, involve irregular index structures with large storage requirement and sequential reconstruction process, resulting in inefficient use of highly parallel computing resources. Hence, pruning is usually restricted to inference with a batch size of one, for which an efficient parallel matrix-vector multiplication method exists. In this paper, a new class of sparse matrix representation utilizing Viterbi algorithm that has a high, and more importantly, fixed index compression ratio regardless of the pruning rate, is proposed. In this approach, numerous sparse matrix candidates are first generated by the Viterbi encoder, and then the one that aims to minimize the model accuracy degradation is selected by the Viterbi algorithm. The model pruning process based on the proposed Viterbi encoder and Viterbi algorithm is highly parallelizable, and can be implemented efficiently in hardware to achieve low-energy, high-performance index decoding process. Compared with the existing magnitude-based pruning methods, index data storage requirement can be further compressed by 85.2% in MNIST and 83.9% in AlexNet while achieving similar pruning rate. Even compared with the relative index compression technique, our method can still reduce the index storage requirement by 52.7% in MNIST and 35.5% in AlexNet.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a new pruning method and sparse matrix format to enable high index compression ratio and parallel index decoding process.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">pruning, sparse matrix, memory footprint, model size, model compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByS1VpgRZ">
      <h4>
        <a href="https://openreview.net/forum?id=ByS1VpgRZ">
          cGANs with Projection Discriminator
        </a>
        
          <a href="https://openreview.net/pdf?id=ByS1VpgRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=miyato%40preferred.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="miyato@preferred.jp">Takeru Miyato</a>, <a href="https://openreview.net/profile?email=koyama.masanori%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="koyama.masanori@gmail.com">Masanori Koyama</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByS1VpgRZ-details-119" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByS1VpgRZ-details-119"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. 
      This approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. 
      With this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. 
      We were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. 
      This new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, GANs, conditional GANs, Generative models, Projection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1v4N2l0-">
      <h4>
        <a href="https://openreview.net/forum?id=S1v4N2l0-">
          Unsupervised Representation Learning by Predicting Image Rotations
        </a>
        
          <a href="https://openreview.net/pdf?id=S1v4N2l0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=spyros.gidaris%40enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="spyros.gidaris@enpc.fr">Spyros Gidaris</a>, <a href="https://openreview.net/profile?email=praveer.singh%40enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="praveer.singh@enpc.fr">Praveer Singh</a>, <a href="https://openreview.net/profile?email=nikos.komodakis%40enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikos.komodakis@enpc.fr">Nikos Komodakis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1v4N2l0--details-128" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1v4N2l0--details-128"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their  unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input.  We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning.  We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4%$that is only 2.4 points lower from the supervised case.  We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on:
      https://github.com/gidariss/FeatureLearningRotNet</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Unsupervised representation learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJGZq6g0-">
      <h4>
        <a href="https://openreview.net/forum?id=rJGZq6g0-">
          Emergent Communication in a Multi-Modal, Multi-Step Referential Game
        </a>
        
          <a href="https://openreview.net/pdf?id=rJGZq6g0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kve216%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kve216@nyu.edu">Katrina Evtimova</a>, <a href="https://openreview.net/profile?email=apd283%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="apd283@nyu.edu">Andrew Drozdov</a>, <a href="https://openreview.net/profile?email=dkiela%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkiela@fb.com">Douwe Kiela</a>, <a href="https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 17 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJGZq6g0--details-584" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJGZq6g0--details-584"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Inspired by previous work on emergent communication in referential games, we propose a novel multi-modal, multi-step referential game, where the sender and receiver have access to distinct modalities of an object, and their information exchange is bidirectional and of arbitrary duration.  The multi-modal multi-step setting allows agents to develop an internal communication significantly closer to natural language, in that they share a single set of messages, and that the length of the conversation may vary according to the difficulty of the task. We examine these properties empirically using a dataset consisting of images and textual descriptions of mammals, where the agents are tasked with identifying the correct object. Our experiments indicate that a robust and efficient communication protocol emerges, where gradual information exchange informs better predictions and higher communication bandwidth improves generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">emergent communication, multi-agent systems, multi-modal</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rytstxWAW">
      <h4>
        <a href="https://openreview.net/forum?id=rytstxWAW">
          FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling
        </a>
        
          <a href="https://openreview.net/pdf?id=rytstxWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chenjie%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenjie@us.ibm.com">Jie Chen</a>, <a href="https://openreview.net/profile?email=tengfei.ma1%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tengfei.ma1@ibm.com">Tengfei Ma</a>, <a href="https://openreview.net/profile?email=cxiao%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiao@us.ibm.com">Cao Xiao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>28 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rytstxWAW-details-897" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rytstxWAW-details-897"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. Such a model, however, is transductive in nature because parameters are learned through convolutions with both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work---FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude more efficient while predictions remain comparably accurate.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Graph convolutional networks, importance sampling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1vEXaxA-">
      <h4>
        <a href="https://openreview.net/forum?id=H1vEXaxA-">
          Emergent Translation in Multi-Agent Communication
        </a>
        
          <a href="https://openreview.net/pdf?id=H1vEXaxA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jason%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jason@cs.nyu.edu">Jason Lee</a>, <a href="https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>, <a href="https://openreview.net/profile?email=jase%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jase@fb.com">Jason Weston</a>, <a href="https://openreview.net/profile?email=dkiela%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkiela@fb.com">Douwe Kiela</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1vEXaxA--details-736" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1vEXaxA--details-736"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While most machine translation systems to date are trained on large parallel corpora, humans learn language in a different way: by being grounded in an environment and interacting with other humans. In this work, we propose a communication game where two agents, native speakers of their own respective languages, jointly learn to solve a visual referential task. We find that the ability to understand and translate a foreign language emerges as a means to achieve shared goals. The emergent translation is interactive and multimodal, and crucially does not require parallel corpora, but only monolingual, independent text and corresponding images. Our proposed translation model achieves this by grounding the source and target languages into a shared visual modality, and outperforms several baselines on both word-level and sentence-level translation tasks. Furthermore, we show that agents in a multilingual community learn to translate better and faster than in a bilingual communication setting.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJvJXZb0W">
      <h4>
        <a href="https://openreview.net/forum?id=rJvJXZb0W">
          An efficient framework for learning sentence representations
        </a>
        
          <a href="https://openreview.net/pdf?id=rJvJXZb0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=llajan%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="llajan@umich.edu">Lajanugen Logeswaran</a>, <a href="https://openreview.net/profile?email=honglak%40eecs.umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@eecs.umich.edu">Honglak Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJvJXZb0W-details-101" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJvJXZb0W-details-101"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and the context in which it appears, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A framework for learning high-quality sentence representations efficiently.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sentence, embeddings, unsupervised, representations, learning, efficient</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1sqHMZCb">
      <h4>
        <a href="https://openreview.net/forum?id=S1sqHMZCb">
          NerveNet: Learning Structured Policy with Graph Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S1sqHMZCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tingwuwang%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tingwuwang@cs.toronto.edu">Tingwu Wang</a>, <a href="https://openreview.net/profile?email=rjliao%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rjliao@cs.toronto.edu">Renjie Liao</a>, <a href="https://openreview.net/profile?email=jimmy%40psi.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jimmy@psi.toronto.edu">Jimmy Ba</a>, <a href="https://openreview.net/profile?email=fidler%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fidler@cs.toronto.edu">Sanja Fidler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 11 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1sqHMZCb-details-510" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1sqHMZCb-details-510"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We address the problem of learning structured policies for continuous control. In traditional reinforcement learning, policies of agents are learned by MLPs which take the concatenation of all observations from the environment as input for predicting actions. In this work, we propose NerveNet to explicitly model the structure of an agent, which naturally takes the form of a graph. Specifically, serving as the agent's policy network, NerveNet first propagates information over the structure of the agent and then predict actions for different parts of the agent. In the experiments, we first show that our NerveNet is comparable to state-of-the-art methods on standard MuJoCo environments. We further propose our customized reinforcement learning environments for benchmarking two types of structure transfer learning tasks, i.e., size and disability transfer. We demonstrate that policies learned by NerveNet are significantly better than policies learned by other models and are able to transfer even in a zero-shot setting.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">using graph neural network to model structural information of the agents to improve policy and transferability </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, transfer learning, graph neural network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkMvEOlAb">
      <h4>
        <a href="https://openreview.net/forum?id=HkMvEOlAb">
          Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=HkMvEOlAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ozsel%40mail.usf.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ozsel@mail.usf.edu">Ozsel Kilinc</a>, <a href="https://openreview.net/profile?email=iuysal%40usf.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="iuysal@usf.edu">Ismail Uysal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkMvEOlAb-details-816" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkMvEOlAb-details-816"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a novel unsupervised clustering approach exploiting the hidden information that is indirectly introduced through a pseudo classification objective. Specifically, we randomly assign a pseudo parent-class label to each observation which is then modified by applying the domain specific transformation associated with the assigned label. Generated pseudo observation-label pairs are subsequently used to train a neural network with Auto-clustering Output Layer (ACOL) that introduces multiple softmax nodes for each pseudo parent-class. Due to the unsupervised objective based on Graph-based Activity Regularization (GAR) terms, softmax duplicates of each parent-class are specialized as the hidden information captured through the help of domain specific transformations is propagated during training. Ultimately we obtain a k-means friendly latent representation. Furthermore, we demonstrate how the chosen transformation type impacts performance and helps propagate the latent information that is useful in revealing unknown clusters. Our results show state-of-the-art performance for unsupervised clustering tasks on MNIST, SVHN and USPS datasets, with the highest accuracies reported to date in the literature.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, unsupervised clustering, pseudo supervision, graph-based activity regularization, auto-clustering output layer</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJIoJWZCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJIoJWZCZ">
          Adversarial Dropout Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=HJIoJWZCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=k-saito%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="k-saito@mi.t.u-tokyo.ac.jp">Kuniaki Saito</a>, <a href="https://openreview.net/profile?email=ushiku%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="ushiku@mi.t.u-tokyo.ac.jp">Yoshitaka Ushiku</a>, <a href="https://openreview.net/profile?email=harada%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="harada@mi.t.u-tokyo.ac.jp">Tatsuya Harada</a>, <a href="https://openreview.net/profile?email=saenko%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saenko@bu.edu">Kate Saenko</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJIoJWZCZ-details-518" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJIoJWZCZ-details-518"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a domain adaptation method for transferring neural representations from label-rich source domains to unlabeled target domains. Recent adversarial methods proposed for this task learn to align features across domains by ``fooling'' a special domain classifier network. However, a drawback of this approach is that the domain classifier simply labels the generated features as in-domain or not, without considering the boundaries between classes. This means that ambiguous target features can be generated near class boundaries, reducing target classification accuracy. We propose a novel approach, Adversarial Dropout Regularization (ADR), which encourages the generator to output more discriminative features for the target domain. Our key idea is to replace the traditional domain critic with a critic that detects non-discriminative features by using dropout on the classifier network. The generator then learns to avoid these areas of the feature space and thus creates better features. We apply our ADR approach to the problem of unsupervised domain adaptation for image classification and semantic segmentation tasks, and demonstrate significant improvements over the state of the art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a new adversarial method for adapting neural representations based on a critic that detects non-discriminative features.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">domain adaptation, computer vision, generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lUOzWCW">
      <h4>
        <a href="https://openreview.net/forum?id=r1lUOzWCW">
          Demystifying MMD GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=r1lUOzWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mikbinkowski%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mikbinkowski@gmail.com">Mikołaj Bińkowski</a>, <a href="https://openreview.net/profile?email=dougal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dougal@gmail.com">Dougal J. Sutherland</a>, <a href="https://openreview.net/profile?email=michael.n.arbel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.n.arbel@gmail.com">Michael Arbel</a>, <a href="https://openreview.net/profile?email=arthur.gretton%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arthur.gretton@gmail.com">Arthur Gretton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1lUOzWCW-details-577" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lUOzWCW-details-577"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs. As our main theoretical contribution, we clarify the situation with bias in GAN loss functions raised by recent work: we show that gradient estimators used in the optimization process for both MMD GANs and Wasserstein GANs are unbiased, but learning a discriminator based on samples leads to biased gradients for the generator parameters. We also discuss the issue of kernel choice for the MMD critic, and characterize the kernel corresponding to the energy distance used for the Cramér GAN critic. Being an integral probability metric, the MMD benefits from training strategies recently developed for Wasserstein GANs. In experiments, the MMD GAN is able to employ a smaller critic network than the Wasserstein GAN, resulting in a simpler and faster-training algorithm with matching performance. We also propose an improved measure of GAN convergence, the Kernel Inception Distance, and show how to use it to dynamically adapt learning rates during GAN training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Explain bias situation with MMD GANs; MMD GANs work with smaller critic networks than WGAN-GPs; new GAN evaluation metric.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">gans, mmd, ipms, wgan, gradient penalty, unbiased gradients</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk5elxbRW">
      <h4>
        <a href="https://openreview.net/forum?id=Hk5elxbRW">
          Smooth Loss Functions for Deep Top-k Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk5elxbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lberrada%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="lberrada@robots.ox.ac.uk">Leonard Berrada</a>, <a href="https://openreview.net/profile?email=az%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="az@robots.ox.ac.uk">Andrew Zisserman</a>, <a href="https://openreview.net/profile?email=pawan%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="pawan@robots.ox.ac.uk">M. Pawan Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk5elxbRW-details-126" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk5elxbRW-details-126"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The top-$k$ error is a common measure of performance in machine learning and computer vision. In practice, top-$k$ classification is typically performed with deep neural networks trained with the cross-entropy loss. Theoretical results indeed suggest that cross-entropy is an optimal learning objective for such a task in the limit of infinite data. In the context of limited and noisy data however, the use of a loss function that is specifically designed for top-$k$ classification can bring significant improvements.
      Our empirical evidence suggests that the loss function must be smooth and have non-sparse gradients in order to work well with deep neural networks. Consequently, we introduce a family of smoothed loss functions that are suited to top-$k$ optimization via deep learning. The widely used cross-entropy is a special case of our family. Evaluating our smooth loss functions is computationally challenging: a na{\"i}ve algorithm would require $\mathcal{O}(\binom{n}{k})$ operations, where $n$ is the number of classes. Thanks to a connection to polynomial algebra and a divide-and-conquer approach, we provide an algorithm with a time complexity of $\mathcal{O}(k n)$. Furthermore, we present a novel approximation to obtain fast and stable algorithms on GPUs with single floating point precision. We compare the performance of the cross-entropy loss and our margin-based losses in various regimes of noise and data size, for the predominant use case of $k=5$. Our investigation reveals that our loss is more robust to noise and overfitting than cross-entropy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Smooth Loss Function for Top-k Error Minimization</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1Lc-Gb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=B1Lc-Gb0Z">
          Deep Learning as a Mixed Convex-Combinatorial Optimization Problem
        </a>
        
          <a href="https://openreview.net/pdf?id=B1Lc-Gb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=afriesen%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="afriesen@cs.washington.edu">Abram L. Friesen</a>, <a href="https://openreview.net/profile?email=pedrod%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pedrod@cs.washington.edu">Pedro Domingos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1Lc-Gb0Z-details-920" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1Lc-Gb0Z-details-920"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">As neural networks grow deeper and wider, learning networks with hard-threshold activations is becoming increasingly important, both for network quantization, which can drastically reduce time and energy requirements, and for creating large integrated systems of deep networks, which may have non-differentiable components and must avoid vanishing and exploding gradients for effective learning. However, since gradient descent is not applicable to hard-threshold functions, it is not clear how to learn them in a principled way. We address this problem by observing that setting targets for hard-threshold hidden units in order to minimize loss is a discrete optimization problem, and can be solved as such. The discrete optimization goal is to find a set of targets such that each unit, including the output, has a linearly separable problem to solve. Given these targets, the network decomposes into individual perceptrons, which can then be learned with standard convex approaches. Based on this, we develop a recursive mini-batch algorithm for learning deep hard-threshold networks that includes the popular but poorly justified straight-through estimator as a special case. Empirically, we show that our algorithm improves classification accuracy in a number of settings, including for AlexNet and ResNet-18 on ImageNet, when compared to the straight-through estimator.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We learn deep networks of hard-threshold units by setting hidden-unit targets using combinatorial optimization and weights by convex optimization, resulting in improved performance on ImageNet.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hard-threshold units, combinatorial optimization, target propagation, straight-through estimation, quantization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1WgVz-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1WgVz-AZ">
          Learning Approximate Inference Networks for Structured Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=H1WgVz-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lifu%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lifu@ttic.edu">Lifu Tu</a>, <a href="https://openreview.net/profile?email=kgimpel%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kgimpel@ttic.edu">Kevin Gimpel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1WgVz-AZ-details-472" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1WgVz-AZ-details-472"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Structured prediction energy networks (SPENs; Belanger &amp; McCallum 2016) use neural network architectures to define energy functions that can capture arbitrary dependencies among parts of structured outputs. Prior work used gradient descent for inference, relaxing the structured output to a set of continuous variables and then optimizing the energy with respect to them. We replace this use of gradient descent with a neural network trained to approximate structured argmax inference. This
      “inference network” outputs continuous values that we treat as the output structure. We develop large-margin training criteria for joint training of the structured energy function and inference network. On multi-label classification we report speed-ups
      of 10-60x compared to (Belanger et al., 2017) while also improving accuracy. For sequence labeling with simple structured energies, our approach performs comparably to exact inference while being much faster at test time. We then demonstrate improved accuracy by augmenting the energy with a “label language model” that scores entire output label sequences, showing it can improve handling of long-distance dependencies in part-of-speech tagging. Finally, we show how inference networks can replace dynamic programming for test-time inference in conditional random fields, suggestive for their general use for fast inference in structured settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Approximate Inference Networks, Structured Prediction, Multi-Label Classification, Sequence Labeling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rypT3fb0b">
      <h4>
        <a href="https://openreview.net/forum?id=rypT3fb0b">
          LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING
        </a>
        
          <a href="https://openreview.net/pdf?id=rypT3fb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dejiao%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dejiao@umich.edu">Dejiao Zhang</a>, <a href="https://openreview.net/profile?email=hzwang%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hzwang@umich.edu">Haozhu Wang</a>, <a href="https://openreview.net/profile?email=mario.figueiredo%40lx.it.pt" class="profile-link" data-toggle="tooltip" data-placement="top" title="mario.figueiredo@lx.it.pt">Mario Figueiredo</a>, <a href="https://openreview.net/profile?email=girasole%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="girasole@umich.edu">Laura Balzano</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rypT3fb0b-details-474" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rypT3fb0b-details-474"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks (DNNs) usually contain millions, maybe billions, of parameters/weights, making both storage and computation very expensive. This has motivated a large body of work to reduce the complexity of the neural network by using sparsity-inducing regularizers.  Another well-known approach for controlling the complexity of DNNs is parameter sharing/tying, where certain sets of weights are forced to share a common value. Some forms of weight sharing are hard-wired to express certain in- variances, with a notable example being the shift-invariance of convolutional layers. However, there may be other groups of weights that may be tied together during the learning process, thus further re- ducing the complexity of the network. In this paper, we adopt a recently proposed sparsity-inducing regularizer, named GrOWL (group ordered weighted l1), which encourages sparsity and, simulta- neously, learns which groups of parameters should share a common value. GrOWL has been proven effective in linear regression, being able to identify and cope with strongly correlated covariates. Unlike standard sparsity-inducing regularizers (e.g., l1 a.k.a. Lasso), GrOWL not only eliminates unimportant neurons by setting all the corresponding weights to zero, but also explicitly identifies strongly correlated neurons by tying the corresponding weights to a common value. This ability of GrOWL motivates the following two-stage procedure: (i) use GrOWL regularization in the training process to simultaneously identify significant neurons and groups of parameter that should be tied together; (ii) retrain the network, enforcing the structure that was unveiled in the previous phase, i.e., keeping only the significant neurons and enforcing the learned tying structure. We evaluate the proposed approach on several benchmark datasets, showing that it can dramatically compress the network with slight or even no loss on generalization performance.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We have proposed using the recent GrOWL regularizer for simultaneous parameter sparsity and tying in DNN learning. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Compressing neural network, simultaneously parameter tying and sparsification, group ordered l1 regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1XolQbRW">
      <h4>
        <a href="https://openreview.net/forum?id=S1XolQbRW">
          Model compression via distillation and quantization
        </a>
        
          <a href="https://openreview.net/pdf?id=S1XolQbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=antonio.polino1%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="antonio.polino1@gmail.com">Antonio Polino</a>, <a href="https://openreview.net/profile?email=razp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="razp@google.com">Razvan Pascanu</a>, <a href="https://openreview.net/profile?email=d.alistarh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.alistarh@gmail.com">Dan Alistarh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1XolQbRW-details-897" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1XolQbRW-details-897"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks (DNNs) continue to make significant advances, solving tasks from image classification to translation or reinforcement learning. One aspect of the field receiving considerable attention is efficiently executing deep models in resource-constrained environments, such as mobile or embedded devices. This paper focuses on this problem, and proposes two new compression methods, which jointly leverage weight quantization and distillation of larger teacher networks into smaller student networks. The first method we propose is called quantized distillation and leverages distillation during the training process, by incorporating distillation loss, expressed with respect to the teacher, into the training of a student network whose weights are quantized to a limited set of levels. The second method,  differentiable quantization, optimizes the location of quantization points through stochastic gradient descent, to better fit the behavior of the teacher model.  We validate both methods through experiments on convolutional and recurrent architectures. We show that quantized shallow students can reach similar accuracy levels to full-precision teacher models, while providing order of magnitude compression, and inference speedup that is linear in the depth reduction. In sum, our results enable DNNs for resource-constrained environments to leverage architecture and accuracy advances developed on more powerful devices.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Obtains state-of-the-art accuracy for quantized, shallow nets by leveraging distillation. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">quantization, distillation, model compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyH9lbZAW">
      <h4>
        <a href="https://openreview.net/forum?id=HyH9lbZAW">
          Variational Message Passing with Structured Inference Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyH9lbZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wlin2018%40cs.ubc.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="wlin2018@cs.ubc.ca">Wu Lin</a>, <a href="https://openreview.net/profile?email=nicolas.hubacher%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicolas.hubacher@outlook.com">Nicolas Hubacher</a>, <a href="https://openreview.net/profile?email=emtiyaz%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="emtiyaz@gmail.com">Mohammad Emtiyaz Khan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyH9lbZAW-details-951" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyH9lbZAW-details-951"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent efforts on combining deep models with probabilistic graphical models are promising in providing flexible models that are also easy to interpret. We propose a variational message-passing algorithm for variational inference in such models. We make three contributions. First, we propose structured inference networks that incorporate the structure of the graphical model in the inference network of variational auto-encoders (VAE). Second, we establish conditions under which such inference networks enable fast amortized inference similar to VAE. Finally, we derive a variational message passing algorithm to perform efficient natural-gradient inference while retaining the efficiency of the amortized inference. By simultaneously enabling structured, amortized, and natural-gradient inference for deep structured models, our method simplifies and generalizes existing methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a variational message-passing algorithm for models that contain both the deep model and probabilistic graphical model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Variational Inference, Variational Message Passing, Variational Auto-Encoder, Graphical Models, Structured Models, Natural Gradients</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1mCp-ZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1mCp-ZRZ">
          Action-dependent Control Variates for Policy Optimization via Stein Identity
        </a>
        
          <a href="https://openreview.net/pdf?id=H1mCp-ZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=uestcliuhao%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="uestcliuhao@gmail.com">Hao Liu*</a>, <a href="https://openreview.net/profile?email=yihao%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yihao@cs.utexas.edu">Yihao Feng*</a>, <a href="https://openreview.net/profile?email=maoyi%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maoyi@microsoft.com">Yi Mao</a>, <a href="https://openreview.net/profile?email=dennyzhou%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dennyzhou@google.com">Dengyong Zhou</a>, <a href="https://openreview.net/profile?email=jianpeng%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianpeng@illinois.edu">Jian Peng</a>, <a href="https://openreview.net/profile?email=lqiang%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lqiang@cs.utexas.edu">Qiang Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1mCp-ZRZ-details-190" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1mCp-ZRZ-details-190"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Policy gradient methods have achieved remarkable successes in solving challenging reinforcement learning problems. However, it still often suffers from the large variance issue on policy gradient estimation, which leads to poor sample efficiency during training. In this work, we propose a control variate method to effectively reduce variance for policy gradient methods. Motivated by the Stein’s identity, our method extends the previous control variate methods used in REINFORCE and advantage actor-critic by introducing more flexible and general action-dependent baseline functions. Empirical studies show that our method essentially improves the sample efficiency of the state-of-the-art policy gradient approaches.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, control variates, sample efficiency, variance reduction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkcQFMZRb">
      <h4>
        <a href="https://openreview.net/forum?id=rkcQFMZRb">
          Variational image compression with a scale hyperprior
        </a>
        
          <a href="https://openreview.net/pdf?id=rkcQFMZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jballe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jballe@google.com">Johannes Ballé</a>, <a href="https://openreview.net/profile?email=dminnen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dminnen@google.com">David Minnen</a>, <a href="https://openreview.net/profile?email=saurabhsingh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saurabhsingh@google.com">Saurabh Singh</a>, <a href="https://openreview.net/profile?email=sjhwang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang@google.com">Sung Jin Hwang</a>, <a href="https://openreview.net/profile?email=nickj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nickj@google.com">Nick Johnston</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 30 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkcQFMZRb-details-765" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkcQFMZRb-details-765"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We describe an end-to-end trainable model for image compression based on variational autoencoders. The model incorporates a hyperprior to effectively capture spatial dependencies in the latent representation. This hyperprior relates to side information, a concept universal to virtually all modern image codecs, but largely unexplored in image compression using artificial neural networks (ANNs). Unlike existing autoencoder compression methods, our model trains a complex prior jointly with the underlying autoencoder. We demonstrate that this model leads to state-of-the-art image compression when measuring visual quality using the popular MS-SSIM index, and yields rate--distortion performance surpassing published ANN-based methods when evaluated using a more traditional metric based on squared error (PSNR). Furthermore, we provide a qualitative comparison of models trained for different distortion metrics.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1kG7GZAW">
      <h4>
        <a href="https://openreview.net/forum?id=H1kG7GZAW">
          Variational Inference of Disentangled Latent Concepts from Unlabeled Observations
        </a>
        
          <a href="https://openreview.net/pdf?id=H1kG7GZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=abhishk%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhishk@us.ibm.com">Abhishek Kumar</a>, <a href="https://openreview.net/profile?email=psattig%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="psattig@us.ibm.com">Prasanna Sattigeri</a>, <a href="https://openreview.net/profile?email=avinash.bala%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avinash.bala@us.ibm.com">Avinash Balakrishnan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1kG7GZAW-details-507" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1kG7GZAW-details-507"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Disentangled representations, where the higher level data generative factors are reflected in disjoint latent dimensions, offer several benefits such as ease of deriving invariant representations, transferability to other tasks, interpretability, etc. We consider the problem of unsupervised learning of disentangled representations from large pool of unlabeled observations, and propose a variational inference based approach to infer disentangled latent factors. We introduce a regularizer on the expectation of the approximate posterior over observed data that encourages the disentanglement. We also propose a new disentanglement metric which is better aligned with the qualitative disentanglement observed in the decoder's output. We empirically observe significant improvement over existing methods in terms of both disentanglement and data likelihood (reconstruction quality). 
      
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a variational inference based approach for encouraging the inference of disentangled latents. We also propose a new metric for quantifying disentanglement. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">disentangled representations, variational inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJNpifWAb">
      <h4>
        <a href="https://openreview.net/forum?id=rJNpifWAb">
          Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches
        </a>
        
          <a href="https://openreview.net/pdf?id=rJNpifWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wenyemin%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenyemin@cs.toronto.edu">Yeming Wen</a>, <a href="https://openreview.net/profile?email=pvicol%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pvicol@cs.toronto.edu">Paul Vicol</a>, <a href="https://openreview.net/profile?email=jimmy%40psi.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jimmy@psi.toronto.edu">Jimmy Ba</a>, <a href="https://openreview.net/profile?email=trandustin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="trandustin@google.com">Dustin Tran</a>, <a href="https://openreview.net/profile?email=rgrosse%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgrosse@cs.toronto.edu">Roger Grosse</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJNpifWAb-details-68" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJNpifWAb-details-68"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Stochastic neural net weights are used in a variety of contexts, including regularization, Bayesian neural nets, exploration in reinforcement learning, and evolution strategies. Unfortunately, due to the large number of weights, all the examples in a mini-batch typically share the same weight perturbation, thereby limiting the variance reduction effect of large mini-batches. We introduce flipout, an efficient method for decorrelating the gradients within a mini-batch by implicitly sampling pseudo-independent weight perturbations for each example. Empirically, flipout achieves the ideal linear variance reduction for fully connected networks, convolutional networks, and RNNs. We find significant speedups in training neural networks with multiplicative Gaussian perturbations. We show that flipout is effective at regularizing LSTMs, and outperforms previous methods. Flipout also enables us to vectorize evolution strategies: in our experiments, a single GPU with flipout can handle the same throughput as at least 40 CPU cores using existing methods, equivalent to a factor-of-4 cost reduction on Amazon Web Services.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce flipout, an efficient method for decorrelating the gradients computed by stochastic neural net weights within a mini-batch by implicitly sampling pseudo-independent weight perturbations for each example.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">weight perturbation, reparameterization gradient, gradient variance reduction, evolution strategies, LSTM, regularization, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1l4eQW0Z">
      <h4>
        <a href="https://openreview.net/forum?id=r1l4eQW0Z">
          Kernel Implicit Variational Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=r1l4eQW0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shijx15%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="shijx15@mails.tsinghua.edu.cn">Jiaxin Shi</a>, <a href="https://openreview.net/profile?email=ssy%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ssy@cs.toronto.edu">Shengyang Sun</a>, <a href="https://openreview.net/profile?email=dcszj%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@tsinghua.edu.cn">Jun Zhu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1l4eQW0Z-details-945" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1l4eQW0Z-details-945"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent progress in variational inference has paid much attention to the flexibility of variational posteriors. One promising direction is to use implicit distributions, i.e., distributions without tractable densities as the variational posterior. However, existing methods on implicit posteriors still face challenges of noisy estimation and computational infeasibility when applied to models with high-dimensional latent variables. In this paper, we present a new approach named Kernel Implicit Variational Inference that addresses these challenges. As far as we know, for the first time implicit variational inference is successfully applied to Bayesian neural networks, which shows promising results on both regression and classification tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Variational inference, Bayesian neural networks, Implicit distribution</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skdvd2xAZ">
      <h4>
        <a href="https://openreview.net/forum?id=Skdvd2xAZ">
          A Scalable Laplace Approximation for Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Skdvd2xAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=j.ritter%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.ritter@cs.ucl.ac.uk">Hippolyt Ritter</a>, <a href="https://openreview.net/profile?email=botevmg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botevmg@gmail.com">Aleksandar Botev</a>, <a href="https://openreview.net/profile?email=d.barber%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.barber@cs.ucl.ac.uk">David Barber</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skdvd2xAZ-details-145" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skdvd2xAZ-details-145"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We leverage recent insights from second-order optimisation for neural networks to construct a Kronecker factored Laplace approximation to the posterior over the weights of a trained network. Our approximation requires no modification of the training procedure, enabling practitioners to estimate the uncertainty of their models currently used in production without having to retrain them. We extensively compare our method to using Dropout and a diagonal Laplace approximation for estimating the uncertainty of a network. We demonstrate that our Kronecker factored method leads to better uncertainty estimates on out-of-distribution data and is more robust to simple adversarial attacks. Our approach only requires calculating two square curvature factor matrices for each layer. Their size is equal to the respective square of the input and output size of the layer, making the method efficient both computationally and in terms of memory usage. We illustrate its scalability by applying it to a state-of-the-art convolutional network architecture.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We construct a Kronecker factored Laplace approximation for neural networks that leads to an efficient matrix normal distribution over the weights.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, neural networks, laplace approximation, bayesian deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1IDRdeCW">
      <h4>
        <a href="https://openreview.net/forum?id=B1IDRdeCW">
          The High-Dimensional Geometry of Binary Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1IDRdeCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aga%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aga@berkeley.edu">Alexander G. Anderson</a>, <a href="https://openreview.net/profile?email=cberg500%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cberg500@berkeley.edu">Cory P. Berg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1IDRdeCW-details-326" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1IDRdeCW-details-326"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent research has shown that one can train a neural network with binary weights and activations at train time by augmenting the weights with a high-precision continuous latent variable that accumulates small changes from stochastic gradient descent. However, there is a dearth of work to explain why one can effectively capture the features in data with binary weights and activations. Our main result is that the neural networks with binary weights and activations trained using the method of Courbariaux, Hubara et al. (2016) work because of the high-dimensional geometry of binary vectors. In particular, the ideal continuous vectors that extract out features in the intermediate representations of these BNNs are well-approximated by binary vectors in the sense that dot products are approximately preserved. Compared to previous research that demonstrated good classification performance with BNNs, our work explains why these BNNs work in terms of HD geometry.  Furthermore, the results and analysis used on BNNs are shown to generalize to neural networks with ternary weights and activations. Our theory serves as a foundation for understanding not only BNNs but a variety of methods that seek to compress traditional neural networks. Furthermore, a better understanding of multilayer binary neural networks serves as a starting point for generalizing BNNs to other neural network architectures such as recurrent neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Recent successes of Binary Neural Networks can be understood based on the geometry of high-dimensional binary vectors</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Binary Neural Networks, Neural Network Visualization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1ae1lZRb">
      <h4>
        <a href="https://openreview.net/forum?id=B1ae1lZRb">
          Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy
        </a>
        
          <a href="https://openreview.net/pdf?id=B1ae1lZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=asit.k.mishra%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="asit.k.mishra@intel.com">Asit Mishra</a>, <a href="https://openreview.net/profile?email=debbie.marr%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="debbie.marr@intel.com">Debbie Marr</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 28 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1ae1lZRb-details-582" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1ae1lZRb-details-582"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning networks have achieved state-of-the-art accuracies on computer vision workloads like image classification and object detection. The performant systems, however, typically involve big models with numerous parameters. Once trained, a challenging aspect for such top performing models is deployment on resource constrained inference systems -- the models (often deep networks or wide networks or both) are compute and memory intensive. Low precision numerics and model compression using knowledge distillation are popular techniques to lower both the compute requirements and memory footprint of these deployed models. In this paper, we study the combination of these two techniques and show that the performance of low precision networks can be significantly improved by using knowledge distillation techniques. We call our approach Apprentice and show state-of-the-art accuracies using ternary precision and 4-bit precision for many variants of ResNet architecture on ImageNet dataset. We study three schemes in which one can apply knowledge distillation techniques to various stages of the train-and-deploy pipeline.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that knowledge transfer techniques can improve the accuracy of low precision networks and set new state-of-the-art accuracy for ternary and 4-bits precision. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Ternary, 4-bits, low precision, knowledge distillation, knowledge transfer, model compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1Dy---0Z">
      <h4>
        <a href="https://openreview.net/forum?id=H1Dy---0Z">
          Distributed Prioritized Experience Replay
        </a>
        
          <a href="https://openreview.net/pdf?id=H1Dy---0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=horgan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="horgan@google.com">Dan Horgan</a>, <a href="https://openreview.net/profile?email=johnquan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="johnquan@google.com">John Quan</a>, <a href="https://openreview.net/profile?email=budden%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="budden@google.com">David Budden</a>, <a href="https://openreview.net/profile?email=gabrielbm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gabrielbm@google.com">Gabriel Barth-Maron</a>, <a href="https://openreview.net/profile?email=mtthss%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mtthss@google.com">Matteo Hessel</a>, <a href="https://openreview.net/profile?email=hado%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hado@google.com">Hado van Hasselt</a>, <a href="https://openreview.net/profile?email=davidsilver%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidsilver@google.com">David Silver</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1Dy---0Z-details-306" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1Dy---0Z-details-306"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible. The algorithm decouples acting from learning: the actors interact with their own instances of the environment by selecting actions according to a shared neural network, and accumulate the resulting experience in a shared experience replay memory; the learner replays samples of experience and updates the neural network. The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors. Our architecture substantially improves the state of the art on the Arcade Learning Environment, achieving better final performance in a fraction of the wall-clock training time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A distributed architecture for deep reinforcement learning at scale, using parallel data-generation to improve the state of the art on the Arcade Learning Environment benchmark in a fraction of the wall-clock training time of previous approaches.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, reinforcement learning, distributed systems</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1Gi6LeRZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1Gi6LeRZ">
          Learning from Between-class Examples for Deep Sound Recognition
        </a>
        
          <a href="https://openreview.net/pdf?id=B1Gi6LeRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tokozume%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="tokozume@mi.t.u-tokyo.ac.jp">Yuji Tokozume</a>, <a href="https://openreview.net/profile?email=ushiku%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="ushiku@mi.t.u-tokyo.ac.jp">Yoshitaka Ushiku</a>, <a href="https://openreview.net/profile?email=harada%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="harada@mi.t.u-tokyo.ac.jp">Tatsuya Harada</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1Gi6LeRZ-details-121" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1Gi6LeRZ-details-121"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning methods have achieved high performance in sound recognition tasks. Deciding how to feed the training data is important for further performance improvement. We propose a novel learning method for deep sound recognition: Between-Class learning (BC learning). Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds. We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio. We then input the mixed sound to the model and train the model to output the mixing ratio. The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fisher’s criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes. The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial. Furthermore, we construct a new deep sound recognition network (EnvNet-v2) and train it with BC learning. As a result, we achieved a performance surpasses the human level.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an novel learning method for deep sound recognition named BC learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sound recognition, supervised learning, feature learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryiAv2xAZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryiAv2xAZ">
          Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples
        </a>
        
          <a href="https://openreview.net/pdf?id=ryiAv2xAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kiminlee%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kiminlee@kaist.ac.kr">Kimin Lee</a>, <a href="https://openreview.net/profile?email=honglak%40eecs.umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@eecs.umich.edu">Honglak Lee</a>, <a href="https://openreview.net/profile?email=kibok%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kibok@umich.edu">Kibok Lee</a>, <a href="https://openreview.net/profile?email=jinwoos%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinwoos@kaist.ac.kr">Jinwoo Shin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryiAv2xAZ-details-270" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryiAv2xAZ-details-270"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The problem of detecting whether a test sample is from in-distribution (i.e., training distribution by a classifier) or out-of-distribution sufficiently different from it arises in many real-world machine learning applications. However, the state-of-art deep neural networks are known to be highly overconfident in their predictions, i.e., do not distinguish in- and out-of-distributions. Recently, to handle this issue, several threshold-based detectors have been proposed given pre-trained neural classifiers. However, the performance of prior works highly depends on how to train the classifiers since they only focus on improving inference procedures. In this paper, we develop a novel training method for classifiers so that such inference algorithms can work better. In particular, we suggest two additional terms added to the original loss (e.g., cross entropy). The first one forces samples from out-of-distribution less confident by the classifier and the second one is for (implicitly) generating most effective training samples for the first one. In essence, our method jointly trains both classification and generative neural networks for out-of-distribution. We demonstrate its effectiveness using deep convolutional neural networks on various popular image datasets.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkFAWax0-">
      <h4>
        <a href="https://openreview.net/forum?id=SkFAWax0-">
          VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop
        </a>
        
          <a href="https://openreview.net/pdf?id=SkFAWax0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yaniv%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaniv@fb.com">Yaniv Taigman</a>, <a href="https://openreview.net/profile?email=wolf%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wolf@fb.com">Lior Wolf</a>, <a href="https://openreview.net/profile?email=adampolyak%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adampolyak@fb.com">Adam Polyak</a>, <a href="https://openreview.net/profile?email=enk100%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="enk100@gmail.com">Eliya Nachmani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkFAWax0--details-921" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkFAWax0--details-921"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a new neural text to speech (TTS) method that is able to transform text to speech in voices that are sampled in the wild. Unlike other systems, our solution is able to deal with unconstrained voice samples and without requiring aligned phonemes or linguistic features. The network architecture is simpler than those in the existing literature and is based on a novel shifting buffer working memory. The same buffer is used for estimating the attention, computing the output audio, and for updating the buffer itself. The input sentence is encoded using a context-free lookup table that contains one entry per character or phoneme. The speakers are similarly represented by a short vector that can also be fitted to new identities, even with only a few samples. Variability in the generated speech is achieved by priming the buffer prior to generating the audio. Experimental results on several datasets demonstrate convincing capabilities, making TTS accessible to a wider range of applications. In order to promote reproducibility, we release our source code and models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Voice Synthesis, Multi-Speaker, Differentiable Memory, Text-to-Speech</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkr1UDeC-">
      <h4>
        <a href="https://openreview.net/forum?id=rkr1UDeC-">
          Large scale distributed neural network training through online distillation
        </a>
        
          <a href="https://openreview.net/pdf?id=rkr1UDeC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rohananil%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rohananil@google.com">Rohan Anil</a>, <a href="https://openreview.net/profile?email=pereyra%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pereyra@google.com">Gabriel Pereyra</a>, <a href="https://openreview.net/profile?email=apassos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="apassos@google.com">Alexandre Passos</a>, <a href="https://openreview.net/profile?email=ormandi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ormandi@google.com">Robert Ormandi</a>, <a href="https://openreview.net/profile?email=gdahl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdahl@google.com">George E. Dahl</a>, <a href="https://openreview.net/profile?email=geoffhinton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="geoffhinton@google.com">Geoffrey E. Hinton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkr1UDeC--details-732" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkr1UDeC--details-732"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Techniques such as ensembling and distillation promise model quality improvements when paired with almost any base model. However, due to increased test-time cost (for ensembles) and increased complexity of the training pipeline (for distillation), these techniques are challenging to use in industrial settings. In this paper we explore a variant of distillation which is relatively straightforward to use as it does not require a complicated multi-stage setup or many new hyperparameters. Our first claim is that online distillation enables us to use extra parallelism to fit very large datasets about twice as fast. Crucially, we can still speed up training even after we have already reached the point at which additional parallelism provides no benefit for synchronous or asynchronous stochastic gradient descent. Two neural networks trained on disjoint subsets of the data can share knowledge by encouraging each model to agree with the predictions the other model would have made. These predictions can come from a stale version of the other model so they can be safely computed using weights that only rarely get transmitted. Our second claim is that online distillation is a cost-effective way to make the exact predictions of a model dramatically more reproducible. We support our claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet, and the largest to-date dataset used for neural language modeling, containing $6\times 10^{11}$ tokens and based on the Common Crawl repository of web data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We perform large scale experiments to show that a simple online variant of distillation can help us scale distributed neural network training to more machines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distillation, distributed training, neural networks, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ0hF1Z0b">
      <h4>
        <a href="https://openreview.net/forum?id=BJ0hF1Z0b">
          Learning Differentially Private Recurrent Language Models
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ0hF1Z0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mcmahan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcmahan@google.com">H. Brendan McMahan</a>, <a href="https://openreview.net/profile?email=dramage%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dramage@google.com">Daniel Ramage</a>, <a href="https://openreview.net/profile?email=kunal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunal@google.com">Kunal Talwar</a>, <a href="https://openreview.net/profile?email=liqzhang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liqzhang@google.com">Li Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ0hF1Z0b-details-573" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ0hF1Z0b-details-573"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We demonstrate that it is possible to train large recurrent language models with user-level differential privacy guarantees with only a negligible cost in predictive accuracy.  Our work builds on recent advances in the training of deep networks on user-partitioned data and privacy accounting for stochastic gradient descent. In particular, we add user-level privacy protection to the federated averaging algorithm, which makes large step updates from user-level data. Our work demonstrates that given a dataset with a sufficiently large number of users (a requirement easily met by even small internet-scale datasets), achieving differential privacy comes at the cost of increased computation, rather than in decreased utility as in most prior work. We find that our private LSTM language models are quantitatively and qualitatively similar to un-noised models when trained on a large dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">User-level differential privacy for recurrent neural network language models is possible with a sufficiently large dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">differential privacy, LSTMs, language models, privacy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ-C6JbRW">
      <h4>
        <a href="https://openreview.net/forum?id=SJ-C6JbRW">
          Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ-C6JbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhiliny%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhiliny@cs.cmu.edu">Zhilin Yang</a>, <a href="https://openreview.net/profile?email=saizheng.zhang%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="saizheng.zhang@umontreal.ca">Saizheng Zhang</a>, <a href="https://openreview.net/profile?email=jju%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jju@fb.com">Jack Urbanek</a>, <a href="https://openreview.net/profile?email=willfeng%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="willfeng@fb.com">Will Feng</a>, <a href="https://openreview.net/profile?email=ahm%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahm@fb.com">Alexander Miller</a>, <a href="https://openreview.net/profile?email=aszlam%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aszlam@fb.com">Arthur Szlam</a>, <a href="https://openreview.net/profile?email=dkiela%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkiela@fb.com">Douwe Kiela</a>, <a href="https://openreview.net/profile?email=jase%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jase@fb.com">Jason Weston</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ-C6JbRW-details-592" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ-C6JbRW-details-592"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Contrary to most natural language processing research, which makes use of static datasets,  humans learn language interactively, grounded in an environment. In this work we propose an interactive learning procedure called Mechanical Turker Descent (MTD) that trains agents to execute natural language commands grounded in a fantasy text adventure game. In MTD, Turkers compete to train better agents in the short term, and collaborate by sharing their agents' skills in the long term. This results in a gamified, engaging experience for the Turkers and a better quality teaching signal for the agents compared to static datasets, as the Turkers naturally adapt the training data to the agent's abilities.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyg0vbWC-">
      <h4>
        <a href="https://openreview.net/forum?id=Hyg0vbWC-">
          Generating Wikipedia by Summarizing Long Sequences
        </a>
        
          <a href="https://openreview.net/pdf?id=Hyg0vbWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=peterjliu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peterjliu@google.com">Peter J. Liu*</a>, <a href="https://openreview.net/profile?email=msaleh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="msaleh@google.com">Mohammad Saleh*</a>, <a href="https://openreview.net/profile?email=epot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="epot@google.com">Etienne Pot</a>, <a href="https://openreview.net/profile?email=bgoodrich%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bgoodrich@google.com">Ben Goodrich</a>, <a href="https://openreview.net/profile?email=rsepassi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsepassi@google.com">Ryan Sepassi</a>, <a href="https://openreview.net/profile?email=lukaszkaiser%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukaszkaiser@google.com">Lukasz Kaiser</a>, <a href="https://openreview.net/profile?email=noam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="noam@google.com">Noam Shazeer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 01 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hyg0vbWC--details-121" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyg0vbWC--details-121"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We show that generating English Wikipedia articles can be approached as a multi-
      document summarization of source documents. We use extractive summarization
      to coarsely identify salient information and a neural abstractive model to generate
      the article. For the abstractive model, we introduce a decoder-only architecture
      that can scalably attend to very long sequences, much longer than typical encoder-
      decoder architectures used in sequence transduction. We show that this model can
      generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia
      articles. When given reference documents, we show it can extract relevant factual
      information as reflected in perplexity, ROUGE scores and human evaluations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We generate Wikipedia articles abstractively conditioned on source document text.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">abstractive summarization, Transformer, long sequences, natural language processing, sequence transduction, Wikipedia, extractive summarization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkYTTf-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkYTTf-AZ">
          Unsupervised Machine Translation Using Monolingual Corpora Only
        </a>
        
          <a href="https://openreview.net/pdf?id=rkYTTf-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=glample%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="glample@fb.com">Guillaume Lample</a>, <a href="https://openreview.net/profile?email=aconneau%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aconneau@fb.com">Alexis Conneau</a>, <a href="https://openreview.net/profile?email=ludovic.denoyer%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludovic.denoyer@lip6.fr">Ludovic Denoyer</a>, <a href="https://openreview.net/profile?email=ranzato%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ranzato@fb.com">Marc'Aurelio Ranzato</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkYTTf-AZ-details-120" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkYTTf-AZ-details-120"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Machine translation has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale parallel corpora. There have been numerous attempts to extend these successes to low-resource language pairs, yet requiring tens of thousands of parallel sentences. In this work, we take this research direction to the extreme and investigate whether it is possible to learn to translate even without any parallel data. We propose a model that takes sentences from monolingual corpora in two different languages and maps them into the same latent space. By learning to reconstruct in both languages from this shared feature space, the model effectively learns to translate without using any labeled data. We demonstrate our model on two widely used datasets and two language pairs, reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-French datasets, without using even a single parallel sentence at training time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new unsupervised machine translation model that can learn without using parallel corpora; experimental results show impressive performance on multiple corpora and pairs of languages.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised, machine translation, adversarial</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkAClQgA-">
      <h4>
        <a href="https://openreview.net/forum?id=HkAClQgA-">
          A Deep Reinforced Model for Abstractive Summarization
        </a>
        
          <a href="https://openreview.net/pdf?id=HkAClQgA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rpaulus%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rpaulus@salesforce.com">Romain Paulus</a>, <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkAClQgA--details-814" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkAClQgA--details-814"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. For longer documents and summaries however these models often include repetitive and incoherent phrases. We introduce a neural network model with a novel intra-attention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL). 
      Models trained only with supervised learning often exhibit "exposure bias" - they assume ground truth is provided at each step during training.
      However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable.
      We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models. Human evaluation also shows that our model produces higher quality summaries.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A summarization model combining a new intra-attention and reinforcement learning method to increase summary ROUGE scores and quality for long sequences.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, natural language processing, reinforcement learning, text summarization, sequence generation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJRZzFlRb">
      <h4>
        <a href="https://openreview.net/forum?id=BJRZzFlRb">
          Compressing Word Embeddings via Deep Compositional Code Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BJRZzFlRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shu%40nlab.ci.i.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="shu@nlab.ci.i.u-tokyo.ac.jp">Raphael Shu</a>, <a href="https://openreview.net/profile?email=nakayama%40ci.i.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="nakayama@ci.i.u-tokyo.ac.jp">Hideki Nakayama</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJRZzFlRb-details-692" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJRZzFlRb-details-692"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Natural language processing (NLP) models often require a massive number of parameters for word embeddings, resulting in a large storage or memory footprint. Deploying neural NLP models to mobile devices requires compressing the word embeddings without any significant sacrifices in performance. For this purpose, we propose to construct the embeddings with few basis vectors. For each word, the composition of basis vectors is determined by a hash code. To maximize the compression rate, we adopt the multi-codebook quantization approach instead of binary coding scheme. Each code is composed of multiple discrete numbers, such as (3, 2, 1, 8), where the value of each component is limited to a fixed range. We propose to directly learn the discrete codes in an end-to-end neural network by applying the Gumbel-softmax trick. Experiments show the compression rate achieves 98% in a sentiment analysis task and 94% ~ 99% in machine translation tasks without performance loss. In both tasks, the proposed method can improve the model performance by slightly lowering the compression rate. Compared to other approaches such as character-level segmentation, the proposed method is language-independent and does not require modifications to the network architecture.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Compressing the word embeddings over 94% without hurting the performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural language processing, word embedding, compression, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkhQHMW0W">
      <h4>
        <a href="https://openreview.net/forum?id=SkhQHMW0W">
          Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training
        </a>
        
          <a href="https://openreview.net/pdf?id=SkhQHMW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yujunlin%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yujunlin@stanford.edu">Yujun Lin</a>, <a href="https://openreview.net/profile?email=songhan%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="songhan@stanford.edu">Song Han</a>, <a href="https://openreview.net/profile?email=huizi%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huizi@stanford.edu">Huizi Mao</a>, <a href="https://openreview.net/profile?email=yu-wang%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yu-wang@mail.tsinghua.edu.cn">Yu Wang</a>, <a href="https://openreview.net/profile?email=dally%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dally@stanford.edu">Bill Dally</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>39 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkhQHMW0W-details-882" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkhQHMW0W-details-882"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training, and requires expensive high-bandwidth network infrastructure. The situation gets even worse with distributed training on mobile devices (federated learning), which suffers from higher latency, lower throughput, and intermittent poor connections. In this paper, we find 99.9% of the gradient exchange in distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to greatly reduce the communication bandwidth. To preserve accuracy during compression, DGC employs four methods: momentum correction, local gradient clipping, momentum factor masking, and warm-up training. We have applied Deep Gradient Compression to image classification, speech recognition, and language modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and Librispeech Corpus. On these scenarios, Deep Gradient Compression achieves a gradient compression ratio from 270x to 600x without losing accuracy, cutting the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from 488MB to 0.74MB. Deep gradient compression enables large-scale distributed training on inexpensive commodity 1Gbps Ethernet and facilitates distributed training on mobile.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">we find 99.9% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B14TlG-RW">
      <h4>
        <a href="https://openreview.net/forum?id=B14TlG-RW">
          QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension
        </a>
        
          <a href="https://openreview.net/pdf?id=B14TlG-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=weiyu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="weiyu@cs.cmu.edu">Adams Wei Yu</a>, <a href="https://openreview.net/profile?email=ddohan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddohan@google.com">David Dohan</a>, <a href="https://openreview.net/profile?email=thangluong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thangluong@google.com">Minh-Thang Luong</a>, <a href="https://openreview.net/profile?email=rzhao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rzhao@google.com">Rui Zhao</a>, <a href="https://openreview.net/profile?email=kaichen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaichen@google.com">Kai Chen</a>, <a href="https://openreview.net/profile?email=mnorouzi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mnorouzi@google.com">Mohammad Norouzi</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B14TlG-RW-details-496" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B14TlG-RW-details-496"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> Current end-to-end machine reading and question answering (Q\&amp;A) models are primarily based on recurrent neural networks (RNNs) with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\&amp;A architecture called QANet, which does not require recurrent networks:  Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models. The speed-up gain allows us to train the model with much more data. We hence combine our model with data generated by backtranslation from a neural machine translation model. 
      On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score on the test set, which is significantly better than the best published F1 score of 81.8.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simple architecture consisting of convolutions and attention achieves results on par with the best documented recurrent models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">squad, stanford question answering dataset, reading comprehension, attention, text convolutions, question answering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy2ogebAW">
      <h4>
        <a href="https://openreview.net/forum?id=Sy2ogebAW">
          Unsupervised Neural Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy2ogebAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mikel.artetxe%40ehu.eus" class="profile-link" data-toggle="tooltip" data-placement="top" title="mikel.artetxe@ehu.eus">Mikel Artetxe</a>, <a href="https://openreview.net/profile?email=gorka.labaka%40ehu.eus" class="profile-link" data-toggle="tooltip" data-placement="top" title="gorka.labaka@ehu.eus">Gorka Labaka</a>, <a href="https://openreview.net/profile?email=e.agirre%40ehu.eus" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.agirre@ehu.eus">Eneko Agirre</a>, <a href="https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy2ogebAW-details-763" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy2ogebAW-details-763"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French-to-English and German-to-English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our implementation is released as an open source project.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the first successful method to train neural machine translation in an unsupervised manner, using nothing but monolingual corpora</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural machine translation, unsupervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkwHObbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=BkwHObbRZ">
          Learning One-hidden-layer Neural Networks with Landscape Design
        </a>
        
          <a href="https://openreview.net/pdf?id=BkwHObbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rongge%40cs.duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rongge@cs.duke.edu">Rong Ge</a>, <a href="https://openreview.net/profile?email=jasondlee88%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jasondlee88@gmail.com">Jason D. Lee</a>, <a href="https://openreview.net/profile?email=tengyuma%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tengyuma@cs.stanford.edu">Tengyu Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkwHObbRZ-details-383" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkwHObbRZ-details-383"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of learning a one-hidden-layer neural network: we assume the input x is from Gaussian distribution and the label $y = a \sigma(Bx) + \xi$, where a is a nonnegative vector and  $B$ is a full-rank weight matrix, and $\xi$ is a noise vector. We first give an analytic formula for the population risk of the standard squared loss and demonstrate that it implicitly attempts to decompose a sequence of low-rank tensors simultaneously. 
      	
      Inspired by the formula, we design a non-convex objective function $G$ whose landscape is guaranteed to have the following properties:	
      
      1. All local minima of $G$ are also global minima.
      2. All global minima of $G$ correspond to the ground truth parameters.
      3. The value and gradient of $G$ can be estimated using samples.
      	
      With these properties, stochastic gradient descent on $G$ provably converges to the global minimum and learn the ground-truth parameters. We also prove finite sample complexity results and validate the results by simulations. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper analyzes the optimization landscape of one-hidden-layer neural nets and designs a new objective that provably has no spurious local minimum. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">theory, non-convex optimization, loss surface</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SysEexbRb">
      <h4>
        <a href="https://openreview.net/forum?id=SysEexbRb">
          Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties
        </a>
        
          <a href="https://openreview.net/pdf?id=SysEexbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhou.1172%40osu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhou.1172@osu.edu">Yi Zhou</a>, <a href="https://openreview.net/profile?email=liang.889%40osu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liang.889@osu.edu">Yingbin Liang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SysEexbRb-details-187" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SysEexbRb-details-187"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks. We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We provide necessary and sufficient analytical forms for the critical points of the square loss functions for various neural networks, and exploit the analytical forms to characterize the landscape properties for the loss functions of these neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural networks, critical points, analytical form, landscape</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJm7VfZA-">
      <h4>
        <a href="https://openreview.net/forum?id=rJm7VfZA-">
          Learning Parametric Closed-Loop Policies for Markov Potential Games
        </a>
        
          <a href="https://openreview.net/pdf?id=rJm7VfZA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sergio%40prowler.io" class="profile-link" data-toggle="tooltip" data-placement="top" title="sergio@prowler.io">Sergio Valcarcel Macua</a>, <a href="https://openreview.net/profile?email=javier.zazo.ruiz%40upm.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="javier.zazo.ruiz@upm.es">Javier Zazo</a>, <a href="https://openreview.net/profile?email=santiago%40gaps.ssr.upm.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="santiago@gaps.ssr.upm.es">Santiago Zazo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJm7VfZA--details-18" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJm7VfZA--details-18"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Multiagent systems where the agents interact among themselves and with an stochastic environment can be formalized as stochastic games. We study a subclass of these games, named Markov potential games (MPGs), that appear often in economic and engineering applications when the agents share some common resource. We consider MPGs with continuous state-action variables, coupled constraints and nonconvex rewards. Previous analysis followed a variational approach that is only valid for very simple cases (convex rewards, invertible dynamics, and no coupled constraints); or considered deterministic dynamics and provided open-loop (OL) analysis, studying strategies that consist in predefined action sequences, which are not optimal for stochastic environments. We present a closed-loop (CL) analysis for MPGs and consider parametric policies that depend on the current state and where agents adapt to stochastic transitions. We provide easily verifiable, sufficient and necessary conditions for a stochastic game to be an MPG, even for complex parametric functions (e.g., deep neural networks); and show that a closed-loop Nash equilibrium (NE) can be found (or at least approximated) by solving a related optimal control problem (OCP). This is useful since solving an OCP---which is a single-objective problem---is usually much simpler than solving the original set of coupled OCPs that form the game---which is a multiobjective control problem. This is a considerable improvement over the previously standard approach for the CL analysis of MPGs, which gives no approximate solution if no NE belongs to the chosen parametric family, and which is practical only for simple parametric forms. We illustrate the theoretical contributions with an example by applying our approach to a noncooperative communications engineering game. We then solve the game with a deep reinforcement learning algorithm that learns policies that closely approximates an exact variational NE of the game.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present general closed loop analysis for Markov potential games and show that deep reinforcement learning can be used for learning approximate closed-loop Nash equilibrium.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Stochastic games, potential games, closed loop, reinforcement learning, multiagent systems</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyProzZAW">
      <h4>
        <a href="https://openreview.net/forum?id=SyProzZAW">
          The power of deeper networks for expressing natural functions
        </a>
        
          <a href="https://openreview.net/pdf?id=SyProzZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=drolnick%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="drolnick@mit.edu">David Rolnick</a>, <a href="https://openreview.net/profile?email=tegmark%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tegmark@mit.edu">Max Tegmark</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyProzZAW-details-785" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyProzZAW-details-785"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is well-known that neural networks are universal approximators, but that deeper networks tend in practice to be more powerful than shallower ones. We shed light on this by proving that the total number of neurons m required to approximate natural classes of multivariate polynomials of n variables grows only linearly with n for deep neural networks, but grows exponentially when merely a single hidden layer is allowed. We also provide evidence that when the number of hidden layers is increased from 1 to k, the neuron requirement grows exponentially not with n but with n^{1/k}, suggesting that the minimum number of layers required for practical expressibility grows only logarithmically with n.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove that deep neural networks are exponentially more efficient than shallow ones at approximating sparse multivariate polynomials.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">expressivity of neural networks, depth of neural networks, universal approximators, function approximation, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1QgVti6Z">
      <h4>
        <a href="https://openreview.net/forum?id=B1QgVti6Z">
          Empirical Risk Landscape Analysis for Understanding Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1QgVti6Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pzhou%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pzhou@u.nus.edu">Pan Zhou</a>, <a href="https://openreview.net/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1QgVti6Z-details-650" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1QgVti6Z-details-650"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This work aims to provide  comprehensive landscape analysis of empirical risk in deep neural networks (DNNs), including the convergence behavior of its gradient, its stationary points and the empirical risk itself to their corresponding population counterparts, which reveals how various network parameters determine the convergence performance. In particular, for an $l$-layer linear neural network consisting of $\dm_i$ neurons in the $i$-th layer, we prove the gradient of its empirical risk  uniformly converges to the one of its population risk, at the rate of $\mathcal{O}(r^{2l} \sqrt{l\sqrt{\max_i \dm_i} s\log(d/l)/n})$. Here $d$ is the total weight dimension, $s$ is the number of nonzero entries  of all the  weights and the magnitude  of weights per layer is upper bounded by $r$. Moreover, we prove the one-to-one correspondence of the non-degenerate stationary points between the empirical and population risks and provide convergence guarantee for each pair. We also establish the uniform convergence of the empirical risk to its population counterpart and further derive the stability and  generalization bounds for the empirical risk. In addition, we  analyze these properties for deep \emph{nonlinear} neural networks with sigmoid activation functions. We prove  similar results for convergence behavior of their empirical risk gradients, non-degenerate stationary points as well as the empirical risk itself.
      
      To our best knowledge, this work is the first one theoretically characterizing the uniform convergence of the gradient and stationary points of the empirical risk of DNN models, which benefits the theoretical understanding on  how  the neural network depth $l$, the layer width $\dm_i$, the network size $d$, the sparsity in weight and the parameter magnitude $r$ determine the neural network landscape.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning Analysis, Deep Learning Theory, Empirical Risk, Landscape Analysis, Nonconvex Optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk9Xc_lR-">
      <h4>
        <a href="https://openreview.net/forum?id=Hk9Xc_lR-">
          On the Discrimination-Generalization Tradeoff in GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk9Xc_lR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=penzhan%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="penzhan@microsoft.com">Pengchuan Zhang</a>, <a href="https://openreview.net/profile?email=qiang.liu%40dartmouth.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiang.liu@dartmouth.edu">Qiang Liu</a>, <a href="https://openreview.net/profile?email=dennyzhou%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dennyzhou@google.com">Dengyong Zhou</a>, <a href="https://openreview.net/profile?email=tax313%40lehigh.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tax313@lehigh.edu">Tao Xu</a>, <a href="https://openreview.net/profile?email=xiaohe%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaohe@microsoft.com">Xiaodong He</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk9Xc_lR--details-758" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk9Xc_lR--details-758"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial training can be generally understood as minimizing certain moment matching loss defined by a set of discriminator functions, typically  neural networks. The discriminator set should be large enough to be able to uniquely identify the true distribution (discriminative), and also be small enough to go beyond memorizing samples (generalizable). In this paper, we show that a discriminator set is guaranteed to be discriminative whenever its linear span is dense in the set of bounded continuous functions. This is a very mild condition satisfied even by neural networks with a single neuron. Further, we develop generalization bounds between the learned distribution and true distribution under different evaluation metrics. When evaluated with neural distance, our bounds show that generalization is guaranteed as long as the discriminator set is small enough, regardless of the size of the generator or hypothesis set. When evaluated with KL divergence, our bound provides an explanation on the counter-intuitive behaviors of testing likelihood in GAN training. Our analysis sheds lights on understanding the practical performance of GANs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial network, discrimination, generalization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyZI0GWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyZI0GWCZ">
          Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SyZI0GWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wieland.brendel%40bethgelab.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="wieland.brendel@bethgelab.org">Wieland Brendel *</a>, <a href="https://openreview.net/profile?email=jonas.rauber%40bethgelab.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonas.rauber@bethgelab.org">Jonas Rauber *</a>, <a href="https://openreview.net/profile?email=matthias.bethge%40bethgelab.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthias.bethge@bethgelab.org">Matthias Bethge</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyZI0GWCZ-details-0" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyZI0GWCZ-details-0"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox (https://github.com/bethgelab/foolbox).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel adversarial attack that can directly attack real-world black-box machine learning models without transfer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial attacks, adversarial examples, adversarials, robustness, security</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJQDjk-0b">
      <h4>
        <a href="https://openreview.net/forum?id=rJQDjk-0b">
          Unbiased Online Recurrent Optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=rJQDjk-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=corentin.tallec%40polytechnique.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="corentin.tallec@polytechnique.edu">Corentin Tallec</a>, <a href="https://openreview.net/profile?email=yann%40yann-ollivier.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann@yann-ollivier.org">Yann Ollivier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJQDjk-0b-details-647" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJQDjk-0b-details-647"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The novel \emph{Unbiased Online Recurrent Optimization} (UORO) algorithm allows for online learning of general recurrent computational graphs such as recurrent network models. It works in a streaming fashion and avoids backtracking through past activations and inputs. UORO is computationally as costly as \emph{Truncated Backpropagation Through Time} (truncated BPTT), a widespread algorithm for online learning of recurrent networks \cite{jaeger2002tutorial}.  UORO is a modification of \emph{NoBackTrack} \cite{DBLP:journals/corr/OllivierC15} that bypasses the need for model sparsity and makes implementation easy in current deep learning frameworks, even for complex models.  Like NoBackTrack, UORO provides unbiased gradient estimates; unbiasedness is the core hypothesis in stochastic gradient descent theory, without which convergence to a local optimum is not guaranteed. On the contrary, truncated BPTT does not provide this property, leading to possible divergence.  On synthetic tasks where truncated BPTT is shown to diverge, UORO converges. For instance, when a parameter has a positive short-term but negative long-term influence, truncated BPTT diverges unless the truncation span is very significantly longer than the intrinsic temporal range of the interactions, while UORO performs well thanks to the unbiasedness of its gradients.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Introduces an online, unbiased and easily implementable gradient estimate for recurrent models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryup8-WCW">
      <h4>
        <a href="https://openreview.net/forum?id=ryup8-WCW">
          Measuring the Intrinsic Dimension of Objective Landscapes
        </a>
        
          <a href="https://openreview.net/pdf?id=ryup8-WCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chunyuan.li%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chunyuan.li@duke.edu">Chunyuan Li</a>, <a href="https://openreview.net/profile?email=heerad%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heerad@uber.com">Heerad Farkhoor</a>, <a href="https://openreview.net/profile?email=rosanne%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rosanne@uber.com">Rosanne Liu</a>, <a href="https://openreview.net/profile?email=jason%40yosinski.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jason@yosinski.com">Jason Yosinski</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryup8-WCW-details-227" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryup8-WCW-details-227"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many recently trained neural networks employ large numbers of parameters to achieve good performance. One may intuitively use the number of parameters required as a rough gauge of the difficulty of a problem. But how accurate are such notions? How many parameters are really needed? In this paper we attempt to answer this question by training networks not in their native parameter space, but instead in a smaller, randomly oriented subspace. We slowly increase the dimension of this subspace, note at which dimension solutions first appear, and define this to be the intrinsic dimension of the objective landscape. The approach is simple to implement, computationally tractable, and produces several suggestive conclusions. Many problems have smaller intrinsic dimensions than one might suspect, and the intrinsic dimension for a given dataset varies little across a family of models with vastly different sizes. This latter result has the profound implication that once a parameter space is large enough to solve a problem, extra parameters serve directly to increase the dimensionality of the solution manifold. Intrinsic dimension allows some quantitative comparison of problem difficulty across supervised, reinforcement, and other types of learning where we conclude, for example, that solving the inverted pendulum problem is 100 times easier than classifying digits from MNIST, and playing Atari Pong from pixels is about as hard as classifying CIFAR-10. In addition to providing new cartography of the objective landscapes wandered by parameterized models, the method is a simple technique for constructively obtaining an upper bound on the minimum description length of a solution. A byproduct of this construction is a simple approach for compressing networks, in some cases by more than 100 times.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train in random subspaces of parameter space to measure how many dimensions are really needed to find a solution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine learning, neural networks, intrinsic dimension, random subspace, model understanding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkO3uTkAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkO3uTkAZ">
          Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rkO3uTkAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=youngjin.kim%40vision.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="youngjin.kim@vision.snu.ac.kr">Youngjin Kim</a>, <a href="https://openreview.net/profile?email=minjung.kim1994%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="minjung.kim1994@gmail.com">Minjung Kim</a>, <a href="https://openreview.net/profile?email=gunhee%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="gunhee@snu.ac.kr">Gunhee Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 05 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkO3uTkAZ-details-286" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkO3uTkAZ-details-286"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose an approach to address two issues that commonly occur during training of unsupervised GANs. First, since GANs use only a continuous latent distribution to embed multiple classes or clusters of data, they often do not correctly handle the structural discontinuity between disparate classes in a latent space. Second, discriminators of GANs easily forget about past generated samples by generators, incurring instability during adversarial training. We argue that these two infamous problems of unsupervised GAN training can be largely alleviated by a learnable memory network to which both generators and discriminators can access. Generators can effectively learn representation of training samples to understand underlying cluster distributions of data, which ease the structure discontinuity problem. At the same time, discriminators can better memorize clusters of previously generated samples, which mitigate the forgetting problem. We propose a novel end-to-end GAN model named memoryGAN, which involves a memory network that is unsupervisedly trainable and integrable to many existing GAN models. With evaluations on multiple datasets such as Fashion-MNIST, CelebA, CIFAR10, and Chairs, we show that our model is probabilistically interpretable, and generates realistic image samples of high visual fidelity. The memoryGAN also achieves the state-of-the-art inception scores over unsupervised GAN models on the CIFAR10 dataset, without any optimization tricks and weaker divergences.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, Memory Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1uR4GZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1uR4GZRZ">
          Stochastic Activation Pruning for Robust Adversarial Defense
        </a>
        
          <a href="https://openreview.net/pdf?id=H1uR4GZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=guneetdhillon%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guneetdhillon@utexas.edu">Guneet S. Dhillon</a>, <a href="https://openreview.net/profile?email=kazizzad%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kazizzad@uci.edu">Kamyar Azizzadenesheli</a>, <a href="https://openreview.net/profile?email=zlipton%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlipton@cmu.edu">Zachary C. Lipton</a>, <a href="https://openreview.net/profile?email=bernstein%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bernstein@caltech.edu">Jeremy D. Bernstein</a>, <a href="https://openreview.net/profile?email=jean.kossaifi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jean.kossaifi@gmail.com">Jean Kossaifi</a>, <a href="https://openreview.net/profile?email=arankhan%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arankhan@amazon.com">Aran Khanna</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Animashree Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1uR4GZRZ-details-386" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1uR4GZRZ-details-386"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks are known to be vulnerable to adversarial examples. Carefully chosen perturbations to real images, while imperceptible to humans, induce misclassification and threaten the reliability of deep learning systems in the wild. To guard against adversarial examples, we take inspiration from game theory and cast the problem as a minimax zero-sum game between the adversary and the model. In general, for such games, the optimal strategy for both players requires a stochastic policy, also known as a mixed strategy. In this light, we propose Stochastic Activation Pruning (SAP), a mixed strategy for adversarial defense. SAP prunes a random subset of activations (preferentially pruning those with smaller magnitude) and scales up the survivors to compensate. We can apply SAP to pretrained networks, including adversarially trained models, without fine-tuning, providing robustness against adversarial examples. Experiments demonstrate that SAP confers robustness against attacks, increasing accuracy and preserving calibration.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkxF5RgC-">
      <h4>
        <a href="https://openreview.net/forum?id=HkxF5RgC-">
          Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip
        </a>
        
          <a href="https://openreview.net/pdf?id=HkxF5RgC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mzhu%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mzhu@nvidia.com">Feiwen Zhu</a>, <a href="https://openreview.net/profile?email=jpool%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpool@nvidia.com">Jeff Pool</a>, <a href="https://openreview.net/profile?email=mandersch%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mandersch@nvidia.com">Michael Andersch</a>, <a href="https://openreview.net/profile?email=jappleyard%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jappleyard@nvidia.com">Jeremy Appleyard</a>, <a href="https://openreview.net/profile?email=ftse%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ftse@nvidia.com">Fung Xie</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkxF5RgC--details-351" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkxF5RgC--details-351"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent Neural Networks (RNNs) are powerful tools for solving sequence-based problems, but their efficacy and execution time are dependent on the size of the network.  Following recent work in simplifying these networks with model pruning and a novel mapping of work onto GPUs, we design an efficient implementation for sparse RNNs.  We investigate several optimizations and tradeoffs: Lamport timestamps, wide memory loads, and a bank-aware weight layout.  With these optimizations, we achieve speedups of over 6x over the next best algorithm for a hidden layer of size 2304, batch size of 4, and a density of 30%.  Further, our technique allows for models of over 5x the size to fit on a GPU for a speedup of 2x, enabling larger networks to help advance the state-of-the-art.  We perform case studies on NMT and speech recognition tasks in the appendix, accelerating their recurrent layers by up to 3x.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Combining network pruning and persistent kernels into a practical, fast, and accurate network implementation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Sparsity, Pruning, Compression, RNN, LSTM, Persistent, RF-Resident, GPU</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByKWUeWA-">
      <h4>
        <a href="https://openreview.net/forum?id=ByKWUeWA-">
          GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=ByKWUeWA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jsyoon0823%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsyoon0823@gmail.com">Jinsung Yoon</a>, <a href="https://openreview.net/profile?email=james.jordon%40hertford.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.jordon@hertford.ox.ac.uk">James Jordon</a>, <a href="https://openreview.net/profile?email=mihaela.vanderschaar%40oxford-man.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mihaela.vanderschaar@oxford-man.ox.ac.uk">Mihaela van der Schaar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByKWUeWA--details-715" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByKWUeWA--details-715"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Estimating individualized treatment effects (ITE) is a challenging task due to the need for an individual's potential outcomes to be learned from biased data and without having access to the counterfactuals. We propose a novel method for inferring ITE based on the Generative Adversarial Nets (GANs) framework. Our method, termed Generative Adversarial Nets for inference of Individualized Treatment Effects (GANITE), is motivated by the possibility that we can capture the uncertainty in the counterfactual distributions by attempting to learn them using a GAN. We generate proxies of the counterfactual outcomes using a counterfactual generator, G, and then pass these proxies to an ITE generator, I, in order to train it. By modeling both of these using the GAN framework, we are able to infer based on the factual data, while still accounting for the unseen counterfactuals. We test our method on three real-world datasets (with both binary and multiple treatments) and show that GANITE outperforms state-of-the-art methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Individualized Treatment Effects, Counterfactual Estimation, Generative Adversarial Nets</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S18Su--CW">
      <h4>
        <a href="https://openreview.net/forum?id=S18Su--CW">
          Thermometer Encoding: One Hot Way To Resist Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=S18Su--CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=buckman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="buckman@google.com">Jacob Buckman</a>, <a href="https://openreview.net/profile?email=aurkor%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aurkor@google.com">Aurko Roy</a>, <a href="https://openreview.net/profile?email=craffel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="craffel@google.com">Colin Raffel</a>, <a href="https://openreview.net/profile?email=goodfellow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goodfellow@google.com">Ian Goodfellow</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S18Su--CW-details-677" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S18Su--CW-details-677"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is well known that it is possible to construct "adversarial examples"
      for neural networks: inputs which are misclassified by the network
      yet indistinguishable from true data. We propose a simple
      modification to standard neural network architectures, thermometer
      encoding, which significantly increases the robustness of the network to
      adversarial examples. We demonstrate this robustness with experiments
      on the MNIST, CIFAR-10, CIFAR-100, and SVHN datasets, and show that
      models with thermometer-encoded inputs consistently have higher accuracy
      on adversarial examples, without decreasing generalization.
      State-of-the-art accuracy under the strongest known white-box attack was 
      increased from 93.20% to 94.30% on MNIST and 50.00% to 79.16% on CIFAR-10.
      We explore the properties of these networks, providing evidence
      that thermometer encodings help neural networks to
      find more-non-linear decision boundaries.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Input discretization leads to robustness against adversarial examples</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial examples, robust neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyrCWeWCb">
      <h4>
        <a href="https://openreview.net/forum?id=HyrCWeWCb">
          Trust-PCL: An Off-Policy Trust Region Method for Continuous Control
        </a>
        
          <a href="https://openreview.net/pdf?id=HyrCWeWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ofirnachum%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ofirnachum@google.com">Ofir Nachum</a>, <a href="https://openreview.net/profile?email=mnorouzi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mnorouzi@google.com">Mohammad Norouzi</a>, <a href="https://openreview.net/profile?email=iamkelvinxu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iamkelvinxu@gmail.com">Kelvin Xu</a>, <a href="https://openreview.net/profile?email=schuurmans%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schuurmans@google.com">Dale Schuurmans</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyrCWeWCb-details-664" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyrCWeWCb-details-664"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Trust region methods, such as TRPO, are often used to stabilize policy optimization algorithms in reinforcement learning (RL). While current trust region strategies are effective for continuous control, they typically require a large amount of on-policy interaction with the environment. To address this problem, we propose an off-policy trust region method, Trust-PCL, which exploits an observation that the optimal policy and state values of a maximum reward objective with a relative-entropy regularizer satisfy a set of multi-step pathwise consistencies along any path. The introduction of relative entropy regularization allows Trust-PCL to maintain optimization stability while exploiting off-policy data to improve sample efficiency. When evaluated on a number of continuous control tasks, Trust-PCL significantly improves the solution quality and sample efficiency of TRPO.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We extend recent insights related to softmax consistency to achieve state-of-the-art results in continuous control.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk49Mg-CW">
      <h4>
        <a href="https://openreview.net/forum?id=rk49Mg-CW">
          Stochastic Variational Video Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=rk49Mg-CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mb2%40uiuc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mb2@uiuc.edu">Mohammad Babaeizadeh</a>, <a href="https://openreview.net/profile?email=cbfinn%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbfinn@eecs.berkeley.edu">Chelsea Finn</a>, <a href="https://openreview.net/profile?email=dumitru%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dumitru@google.com">Dumitru Erhan</a>, <a href="https://openreview.net/profile?email=rhc%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rhc@illinois.edu">Roy H. Campbell</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk49Mg-CW-details-202" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk49Mg-CW-details-202"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Predicting the future in real-world settings, particularly from raw sensory observations such as images, is exceptionally challenging. Real-world events can be stochastic and unpredictable, and the high dimensionality and complexity of natural images requires the predictive model to build an intricate understanding of the natural world. Many existing methods tackle this problem by making simplifying assumptions about the environment. One common assumption is that the outcome is deterministic and there is only one plausible future. This can lead to low-quality predictions in real-world settings with stochastic dynamics. In this paper, we develop a stochastic variational video prediction (SV2P) method that predicts a different possible future for each sample of its latent variables. To the best of our knowledge, our model is the first to provide effective stochastic multi-frame prediction for real-world video. We demonstrate the capability of the proposed method in predicting detailed future frames of videos on multiple real-world datasets, both action-free and action-conditioned. We find that our proposed method produces substantially improved video predictions when compared to the same model without stochasticity, and to other stochastic video prediction methods. Our SV2P implementation will be open sourced upon publication.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Stochastic variational video prediction in real-world settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">video prediction, stochastic prediction, variational inference, unsupervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkXWCMbRW">
      <h4>
        <a href="https://openreview.net/forum?id=HkXWCMbRW">
          Towards Image Understanding from Deep Compression Without Decoding
        </a>
        
          <a href="https://openreview.net/pdf?id=HkXWCMbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=robertto%40student.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="robertto@student.ethz.ch">Robert Torfason</a>, <a href="https://openreview.net/profile?email=mentzerf%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="mentzerf@vision.ee.ethz.ch">Fabian Mentzer</a>, <a href="https://openreview.net/profile?email=aeirikur%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aeirikur@vision.ee.ethz.ch">Eirikur Agustsson</a>, <a href="https://openreview.net/profile?email=michaelt%40nari.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="michaelt@nari.ee.ethz.ch">Michael Tschannen</a>, <a href="https://openreview.net/profile?email=radu.timofte%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="radu.timofte@vision.ee.ethz.ch">Radu Timofte</a>, <a href="https://openreview.net/profile?email=vangool%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="vangool@vision.ee.ethz.ch">Luc Van Gool</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkXWCMbRW-details-884" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkXWCMbRW-details-884"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Motivated by recent work on deep neural network (DNN)-based image compression methods showing potential improvements in image quality, savings in storage, and bandwidth reduction, we propose to perform image understanding tasks such as classification and segmentation directly on the compressed representations produced by these compression methods. Since the encoders and decoders in DNN-based compression methods are neural networks with feature-maps as internal representations of the images, we directly integrate these with architectures for image understanding. This bypasses decoding of the compressed representation into RGB space and reduces computational cost. Our study shows that accuracies comparable to networks that operate on compressed RGB images can be achieved while reducing the computational complexity up to $2\times$. Furthermore, we show that synergies are obtained by jointly training compression networks with classification networks on the compressed representations, improving image quality, classification accuracy, and segmentation performance. We find that inference from compressed representations is particularly advantageous compared to inference from compressed RGB images for aggressive compression rates.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByJIWUnpW">
      <h4>
        <a href="https://openreview.net/forum?id=ByJIWUnpW">
          Automatically Inferring Data Quality for Spatiotemporal Forecasting
        </a>
        
          <a href="https://openreview.net/pdf?id=ByJIWUnpW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sungyons%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sungyons@usc.edu">Sungyong Seo</a>, <a href="https://openreview.net/profile?email=mohegh%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohegh@usc.edu">Arash Mohegh</a>, <a href="https://openreview.net/profile?email=banweiss%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="banweiss@usc.edu">George Ban-Weiss</a>, <a href="https://openreview.net/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByJIWUnpW-details-108" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByJIWUnpW-details-108"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Spatiotemporal forecasting has become an increasingly important prediction task in machine learning and statistics due to its vast applications, such as climate modeling, traffic prediction, video caching predictions, and so on. While numerous studies have been conducted, most existing works assume that the data from different sources or across different locations are equally reliable. Due to cost, accessibility, or other factors, it is inevitable that the data quality could vary, which introduces significant biases into the model and leads to unreliable prediction results. The problem could be exacerbated in black-box prediction models, such as deep neural networks. In this paper, we propose a novel solution that can automatically infer data quality levels of different sources through local variations of spatiotemporal signals without explicit labels. Furthermore, we integrate the estimate of data quality level with graph convolutional networks to exploit their efficient structures. We evaluate our proposed method on forecasting temperatures in Los Angeles.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a method that infers the time-varying data quality level for spatiotemporal forecasting without explicitly assigned labels.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">spatiotemporal data, graph convolutional network, data quality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy21R9JAW">
      <h4>
        <a href="https://openreview.net/forum?id=Sy21R9JAW">
          Towards better understanding of gradient-based attribution methods for Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy21R9JAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=marco.ancona%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="marco.ancona@inf.ethz.ch">Marco Ancona</a>, <a href="https://openreview.net/profile?email=enea.ceolini%40ini.uzh.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="enea.ceolini@ini.uzh.ch">Enea Ceolini</a>, <a href="https://openreview.net/profile?email=cengizo%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="cengizo@inf.ethz.ch">Cengiz Öztireli</a>, <a href="https://openreview.net/profile?email=grossm%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="grossm@inf.ethz.ch">Markus Gross</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 07 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy21R9JAW-details-765" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy21R9JAW-details-765"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Understanding the flow of information in Deep Neural Networks (DNNs) is a challenging problem that has gain increasing attention over the last few years. While several methods have been proposed to explain network predictions, there have been only a few attempts to compare them from a theoretical perspective. What is more, no exhaustive empirical comparison has been performed in the past. In this work we analyze four gradient-based attribution methods and formally prove conditions of equivalence and approximation between them. By reformulating two of these methods, we construct a unified framework which enables a direct comparison, as well as an easier implementation. Finally, we propose a novel evaluation metric, called Sensitivity-n and test the gradient-based attribution methods alongside with a simple perturbation-based attribution method on several datasets in the domains of image and text classification, using various network architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Four existing backpropagation-based attribution methods are fundamentally similar. How to assess it?</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Neural Networks, Attribution methods, Theory of deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyJ7ClWCb">
      <h4>
        <a href="https://openreview.net/forum?id=SyJ7ClWCb">
          Countering Adversarial Images using Input Transformations
        </a>
        
          <a href="https://openreview.net/pdf?id=SyJ7ClWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cg563%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cg563@cornell.edu">Chuan Guo</a>, <a href="https://openreview.net/profile?email=mayankrana%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mayankrana@fb.com">Mayank Rana</a>, <a href="https://openreview.net/profile?email=moustaphacisse%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="moustaphacisse@fb.com">Moustapha Cisse</a>, <a href="https://openreview.net/profile?email=lvdmaaten%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lvdmaaten@gmail.com">Laurens van der Maaten</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Jul 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>32 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyJ7ClWCb-details-483" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyJ7ClWCb-details-483"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper investigates strategies that defend against adversarial-example attacks on image-classification systems by transforming the inputs before feeding them to the system. Specifically, we study applying image transformations such as bit-depth reduction, JPEG compression, total variance minimization, and image quilting before feeding the image to a convolutional network classifier. Our experiments on ImageNet show that total variance minimization and image quilting are very effective defenses in practice, in particular, when the network is trained on transformed images. The strength of those defenses lies in their non-differentiable nature and their inherent randomness, which makes it difficult for an adversary to circumvent the defenses. Our best defense eliminates 60% of strong gray-box and 90% of strong black-box attacks by a variety of major attack methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We apply a model-agnostic defense strategy against adversarial examples and achieve 60% white-box accuracy and 90% black-box accuracy against major attack algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial example, machine learning security, computer vision, image classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkwVAXyCW">
      <h4>
        <a href="https://openreview.net/forum?id=HkwVAXyCW">
          Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HkwVAXyCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=victor.campos%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="victor.campos@bsc.es">Víctor Campos</a>, <a href="https://openreview.net/profile?email=bjou%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bjou@google.com">Brendan Jou</a>, <a href="https://openreview.net/profile?email=xavier.giro%40upc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xavier.giro@upc.edu">Xavier Giró-i-Nieto</a>, <a href="https://openreview.net/profile?email=jordi.torres%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="jordi.torres@bsc.es">Jordi Torres</a>, <a href="https://openreview.net/profile?email=shih.fu.chang%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shih.fu.chang@columbia.edu">Shih-Fu Chang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkwVAXyCW-details-921" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkwVAXyCW-details-921"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent Neural Networks (RNNs) continue to show  outstanding performance in sequence modeling tasks. However, training RNNs on long sequences often face challenges like slow inference, vanishing gradients and difficulty in capturing long term dependencies. In backpropagation through time settings, these issues are tightly coupled with the large, sequential computational graph resulting from unfolding the RNN in time. We introduce the Skip RNN model which extends existing RNN models by learning to skip state updates and shortens the effective size of the computational graph. This model can also be encouraged to perform fewer state updates through a budget constraint. We evaluate the proposed model on various tasks and show how it can reduce the number of required RNN updates while preserving, and sometimes even improving, the performance of the baseline RNN models. Source code is publicly available at https://imatge-upc.github.io/skiprnn-2017-telecombcn/.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A modification for existing RNN architectures which allows them to skip state updates while preserving the performance of the original architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, dynamic learning, conditional computation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkPLzgZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkPLzgZAZ">
          Modular Continual Learning in a Unified Visual Environment
        </a>
        
          <a href="https://openreview.net/pdf?id=rkPLzgZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=feigelis%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="feigelis@stanford.edu">Kevin T. Feigelis</a>, <a href="https://openreview.net/profile?email=bsheffer%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bsheffer@stanford.edu">Blue Sheffer</a>, <a href="https://openreview.net/profile?email=yamins%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yamins@stanford.edu">Daniel L. K. Yamins</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkPLzgZAZ-details-513" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkPLzgZAZ-details-513"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> A core aspect of human intelligence is the ability to learn new tasks quickly and switch between them flexibly. Here, we describe a modular continual reinforcement learning paradigm inspired by these abilities. We first introduce a visual interaction environment that allows many types of tasks to be unified in a single framework. We then describe a reward map prediction scheme that learns new tasks robustly in the very large state and action spaces required by such an environment. We investigate how properties of module architecture influence efficiency of task learning, showing that a module motif incorporating specific design principles (e.g. early bottlenecks, low-order polynomial nonlinearities, and symmetry) significantly outperforms more standard neural network motifs, needing fewer training examples and fewer neurons to achieve high levels of performance. Finally, we present a meta-controller architecture for task switching based on a dynamic neural voting scheme, which allows new modules to use information learned from previously-seen tasks to substantially improve their own learning efficiency. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a neural module approach to continual learning using a unified visual environment with a large action space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Continual Learning, Neural Modules, Interface Learning, Task Switching, Reinforcement Learning, Visual Decision Making</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BydLzGb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=BydLzGb0Z">
          Twin Networks: Matching the Future for Sequence Generation
        </a>
        
          <a href="https://openreview.net/pdf?id=BydLzGb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=serdyuk.dmitriy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="serdyuk.dmitriy@gmail.com">Dmitriy Serdyuk</a>, <a href="https://openreview.net/profile?email=rosemary.nan.ke%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rosemary.nan.ke@gmail.com">Nan Rosemary Ke</a>, <a href="https://openreview.net/profile?email=alessandro.sordoni%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alessandro.sordoni@gmail.com">Alessandro Sordoni</a>, <a href="https://openreview.net/profile?email=adam.trischler%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.trischler@microsoft.com">Adam Trischler</a>, <a href="https://openreview.net/profile?email=chris.j.pal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chris.j.pal@gmail.com">Chris Pal</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BydLzGb0Z-details-638" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BydLzGb0Z-details-638"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a simple technique for encouraging generative RNNs to plan ahead. We train a ``backward'' recurrent network to generate a given sequence in reverse order, and we encourage states of the forward model to predict cotemporal states of the backward model. The backward network is used only during training, and plays no role during sampling or inference. We hypothesize that our approach eases modeling of long-term dependencies by implicitly forcing the forward states to hold information about the longer-term future (as contained in the backward states). We show empirically that our approach achieves 9% relative improvement for a speech recognition task, and achieves significant improvement on a COCO caption generation task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper introduces a method of training generative recurrent networks that helps to plan ahead. We run a second RNN in a reverse direction and make a soft constraint between cotemporal forward and backward states.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative rnns, long term dependencies, speech recognition, image captioning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1J2ZyZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=S1J2ZyZ0Z">
          Interpretable Counting for Visual Question Answering
        </a>
        
          <a href="https://openreview.net/pdf?id=S1J2ZyZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=atrott%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="atrott@salesforce.com">Alexander Trott</a>, <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=rsocher%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsocher@salesforce.com">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1J2ZyZ0Z-details-235" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1J2ZyZ0Z-details-235"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Questions that require counting a variety of objects in images remain a major challenge in visual question answering (VQA). The most common approaches to VQA involve either classifying answers based on fixed length representations of both the image and question or summing fractional counts estimated from each section of the image. In contrast, we treat counting as a sequential decision process and force our model to make discrete choices of what to count. Specifically, the model sequentially selects from detected objects and learns interactions between objects that influence subsequent selections. A distinction of our approach is its intuitive and interpretable output, as discrete counts are automatically grounded in the image. Furthermore, our method outperforms the state of the art architecture for VQA on multiple metrics that evaluate counting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We perform counting for visual question answering; our model produces interpretable outputs by counting directly from detected objects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Counting, VQA, Object detection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1UOm4gA-">
      <h4>
        <a href="https://openreview.net/forum?id=H1UOm4gA-">
          Interactive Grounded Language Acquisition and Generalization in a 2D World
        </a>
        
          <a href="https://openreview.net/pdf?id=H1UOm4gA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=haonanyu%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haonanyu@baidu.com">Haonan Yu</a>, <a href="https://openreview.net/profile?email=zhanghaichao%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanghaichao@baidu.com">Haichao Zhang</a>, <a href="https://openreview.net/profile?email=wei.xu%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wei.xu@baidu.com">Wei Xu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 14 Aug 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1UOm4gA--details-9" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1UOm4gA--details-9"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We build a virtual agent for learning language in a 2D maze-like world. The agent sees images of the surrounding environment, listens to a virtual teacher, and takes actions to receive rewards. It interactively learns the teacher’s language from scratch based on two language use cases: sentence-directed navigation and question answering. It learns simultaneously the visual representations of the world, the language, and the action control. By disentangling language grounding from other computational routines and sharing a concept detection function between language grounding and prediction, the agent reliably interpolates and extrapolates to interpret sentences that contain new word combinations or new words missing from training sentences. The new words are transferred from the answers of language prediction. Such a language ability is trained and evaluated on a population of over 1.6 million distinct sentences consisting of 119 object words, 8 color words, 9 spatial-relation words, and 50 grammatical words. The proposed model significantly outperforms five comparison methods for interpreting zero-shot sentences. In addition, we demonstrate human-interpretable intermediate outputs of the model in the appendix.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Training an agent in a 2D virtual world for grounded language acquisition and generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">grounded language learning and generalization, zero-shot language learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy0GnUxCb">
      <h4>
        <a href="https://openreview.net/forum?id=Sy0GnUxCb">
          Emergent Complexity via Multi-Agent Competition
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy0GnUxCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tbansal%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tbansal@cs.umass.edu">Trapit Bansal</a>, <a href="https://openreview.net/profile?email=jakub%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jakub@openai.com">Jakub Pachocki</a>, <a href="https://openreview.net/profile?email=szymon%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="szymon@openai.com">Szymon Sidor</a>, <a href="https://openreview.net/profile?email=ilyasu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilyasu@openai.com">Ilya Sutskever</a>, <a href="https://openreview.net/profile?email=mordatch%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mordatch@openai.com">Igor Mordatch</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy0GnUxCb-details-830" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy0GnUxCb-details-830"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement learning algorithms can train agents that solve problems in complex, interesting environments. Normally, the complexity of the trained agent is closely related to the complexity of the environment.  This suggests that a highly capable agent requires a complex environment for training.  In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself.  We also point out that such environments come with a natural curriculum, because for any skill level, an environment full of agents of this level will have the right level of difficulty.
      This work introduces several competitive multi-agent environments where agents compete in a 3D world with simulated physics. The trained agents learn a wide variety of complex and interesting skills, even though the environment themselves are relatively simple. The skills include behaviors such as running, blocking, ducking, tackling, fooling opponents, kicking, and defending using both arms and legs. A highlight of the learned behaviors can be found here: https://goo.gl/eR7fbX</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-agent systems, multi-agent competition, self-play, deep reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1mvVm-C-">
      <h4>
        <a href="https://openreview.net/forum?id=B1mvVm-C-">
          Universal Agent for Disentangling Environments and Tasks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1mvVm-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mjy14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjy14@mails.tsinghua.edu.cn">Jiayuan Mao</a>, <a href="https://openreview.net/profile?email=dhh14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhh14@mails.tsinghua.edu.cn">Honghua Dong</a>, <a href="https://openreview.net/profile?email=limjj%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="limjj@usc.edu">Joseph J. Lim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 03 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1mvVm-C--details-726" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1mvVm-C--details-726"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent state-of-the-art reinforcement learning algorithms are trained under the goal of excelling in one specific task. Hence, both environment and task specific knowledge are entangled into one framework. However, there are often scenarios where the environment (e.g. the physical world) is fixed while only the target task changes. Hence, borrowing the idea from hierarchical reinforcement learning, we propose a framework that disentangles task and environment specific knowledge by separating them into two units. The environment-specific unit handles how to move from one state to the target state; and the task-specific unit plans for the next target state given a specific task. The extensive results in simulators indicate that our method can efficiently separate and learn two independent units, and also adapt to a new task more efficiently than the state-of-the-art methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a DRL framework that disentangles task and environment specific knowledge.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, transfer learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJa9iHgAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJa9iHgAZ">
          Residual Connections Encourage Iterative Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=SJa9iHgAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=staszek.jastrzebski%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="staszek.jastrzebski@gmail.com">Stanisław Jastrzebski</a>, <a href="https://openreview.net/profile?email=devansharpit%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="devansharpit@gmail.com">Devansh Arpit</a>, <a href="https://openreview.net/profile?email=ballas.n%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ballas.n@gmail.com">Nicolas Ballas</a>, <a href="https://openreview.net/profile?email=vikasverma.iitm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vikasverma.iitm@gmail.com">Vikas Verma</a>, <a href="https://openreview.net/profile?email=tongcheprivate%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tongcheprivate@gmail.com">Tong Che</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJa9iHgAZ-details-577" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJa9iHgAZ-details-577"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Residual networks (Resnets) have become a prominent architecture in deep learning. However, a comprehensive understanding of Resnets is still a topic of ongoing research. A recent view argues that Resnets perform iterative refinement of features. We attempt to further expose properties of this aspect. To this end, we study Resnets both analytically and empirically. We formalize the notion of iterative refinement in Resnets by showing that residual architectures naturally encourage features to move along the negative gradient of loss during the feedforward phase. In addition, our empirical analysis suggests that Resnets are able to perform both representation learning and iterative refinement. In general, a Resnet block tends to concentrate representation learning behavior in the first few layers while higher layers perform iterative refinement of features. Finally we observe that sharing residual layers naively leads to representation explosion and hurts generalization performance, and show that simple existing strategies can help alleviating this problem.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Residual connections really perform iterative inference</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">residual network, iterative inference, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk6WhagRW">
      <h4>
        <a href="https://openreview.net/forum?id=Hk6WhagRW">
          Emergent Communication through Negotiation
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk6WhagRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kc391%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="kc391@cam.ac.uk">Kris Cao</a>, <a href="https://openreview.net/profile?email=angeliki%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="angeliki@google.com">Angeliki Lazaridou</a>, <a href="https://openreview.net/profile?email=lanctot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lanctot@google.com">Marc Lanctot</a>, <a href="https://openreview.net/profile?email=jzl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzl@google.com">Joel Z Leibo</a>, <a href="https://openreview.net/profile?email=karltuyls%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karltuyls@google.com">Karl Tuyls</a>, <a href="https://openreview.net/profile?email=clarkstephen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="clarkstephen@google.com">Stephen Clark</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk6WhagRW-details-902" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk6WhagRW-details-902"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Multi-agent reinforcement learning offers a way to study how communication could emerge in communities of agents needing to solve specific problems. In this paper, we study the emergence of communication in the negotiation environment, a semi-cooperative model of agent interaction. We introduce two communication protocols - one grounded in the semantics of the game, and one which is a priori ungrounded.  We show that self-interested agents can use the pre-grounded communication channel to negotiate fairly, but are unable to effectively use the ungrounded, cheap talk channel to do the same.  However, prosocial agents do learn to use cheap talk to find an optimal negotiating strategy, suggesting that cooperation is necessary for language to emerge. We also study communication behaviour in a setting where one agent interacts with agents in a community with different levels of prosociality and show how agent identifiability can aid negotiation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We teach agents to negotiate using only reinforcement learning; selfish agents can do so, but only using a trustworthy communication channel, and prosocial agents can negotiate using cheap talk.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-agent learning, reinforcement learning, game theory, emergent communication</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygwwGbRW">
      <h4>
        <a href="https://openreview.net/forum?id=SygwwGbRW">
          Semi-parametric topological memory for navigation
        </a>
        
          <a href="https://openreview.net/pdf?id=SygwwGbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nikolay.savinov%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikolay.savinov@inf.ethz.ch">Nikolay Savinov</a>, <a href="https://openreview.net/profile?email=adosovitskiy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adosovitskiy@gmail.com">Alexey Dosovitskiy</a>, <a href="https://openreview.net/profile?email=vkoltun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkoltun@gmail.com">Vladlen Koltun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SygwwGbRW-details-839" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygwwGbRW-details-839"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals. The proposed semi-parametric topological memory (SPTM) consists of a (non-parametric) graph with nodes corresponding to locations in the environment and a (parametric) deep network capable of retrieving nodes from the graph based on observations. The graph stores no metric information, only connectivity of locations corresponding to the nodes. We use SPTM as a planning module in a navigation system. Given only 5 minutes of footage of a previously unseen maze, an SPTM-based navigation agent can build a topological map of the environment and use it to confidently navigate towards goals. The average success rate of the SPTM agent in goal-directed navigation across test environments is higher than the best-performing baseline by a factor of three.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, navigation, memory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B12Js_yRb">
      <h4>
        <a href="https://openreview.net/forum?id=B12Js_yRb">
          Learning to Count Objects in Natural Images for Visual Question Answering
        </a>
        
          <a href="https://openreview.net/pdf?id=B12Js_yRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yz5n12%40ecs.soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yz5n12@ecs.soton.ac.uk">Yan Zhang</a>, <a href="https://openreview.net/profile?email=jsh2%40ecs.soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsh2@ecs.soton.ac.uk">Jonathon Hare</a>, <a href="https://openreview.net/profile?email=apb%40ecs.soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="apb@ecs.soton.ac.uk">Adam Prügel-Bennett</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B12Js_yRb-details-386" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B12Js_yRb-details-386"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Visual Question Answering (VQA) models have struggled with counting objects in natural images so far. We identify a fundamental problem due to soft attention in these models as a cause. To circumvent this problem, we propose a neural network component that allows robust counting from object proposals. Experiments on a toy task show the effectiveness of this component and we obtain state-of-the-art accuracy on the number category of the VQA v2 dataset without negatively affecting other categories, even outperforming ensemble models with our single model. On a difficult balanced pair metric, the component gives a substantial improvement in counting over a strong baseline by 6.6%.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Enabling Visual Question Answering models to count by handling overlapping object proposals.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">visual question answering, vqa, counting</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJsjkMb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=HJsjkMb0Z">
          i-RevNet: Deep Invertible Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJsjkMb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joern.jacobsen%40bethgelab.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="joern.jacobsen@bethgelab.org">Jörn-Henrik Jacobsen</a>, <a href="https://openreview.net/profile?email=a.w.m.smeulders%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.w.m.smeulders@uva.nl">Arnold W.M. Smeulders</a>, <a href="https://openreview.net/profile?email=edouard.oyallon%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="edouard.oyallon@ens.fr">Edouard Oyallon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJsjkMb0Z-details-139" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJsjkMb0Z-details-139"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is widely believed that the success of deep convolutional networks is based on progressively discarding uninformative variability about the input with respect to the problem at hand. This is supported empirically by the difficulty of recovering images from their hidden representations, in most commonly used network architectures. In this paper we show via a one-to-one mapping that this loss of information is not a necessary condition to learn representations that generalize well on complicated problems, such as ImageNet. Via a cascade of homeomorphic layers, we build the $i$-RevNet, a network that can be fully inverted up to the final projection onto the classes, i.e. no information is discarded. Building an invertible architecture is difficult, for one, because the local inversion is ill-conditioned, we overcome this by providing an explicit inverse. 
      An analysis of i-RevNet’s learned representations suggests an alternative explanation for the success of deep networks by a progressive contraction and linear separation with depth. To shed light on the nature of the model learned by the $i$-RevNet we reconstruct linear interpolations between natural image representations.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkUHlMZ0b">
      <h4>
        <a href="https://openreview.net/forum?id=BkUHlMZ0b">
          Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach
        </a>
        
          <a href="https://openreview.net/pdf?id=BkUHlMZ0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=twweng%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="twweng@mit.edu">Tsui-Wei Weng*</a>, <a href="https://openreview.net/profile?email=ecezhang%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ecezhang@ucdavis.edu">Huan Zhang*</a>, <a href="https://openreview.net/profile?email=pin-yu.chen%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pin-yu.chen@ibm.com">Pin-Yu Chen</a>, <a href="https://openreview.net/profile?email=jinfengyi.ustc%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinfengyi.ustc@gmail.com">Jinfeng Yi</a>, <a href="https://openreview.net/profile?email=dong.su%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dong.su@ibm.com">Dong Su</a>, <a href="https://openreview.net/profile?email=yupeng.gao%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yupeng.gao@ibm.com">Yupeng Gao</a>, <a href="https://openreview.net/profile?email=chohsieh%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@ucdavis.edu">Cho-Jui Hsieh</a>, <a href="https://openreview.net/profile?email=dluca%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dluca@mit.edu">Luca Daniel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkUHlMZ0b-details-863" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkUHlMZ0b-details-863"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The robustness of neural networks to adversarial examples has received great attention due to security implications. Despite various attack approaches to crafting visually imperceptible adversarial examples, little has been developed towards a comprehensive measure of robustness. In this paper, we provide theoretical justification for converting robustness analysis into a local Lipschitz constant estimation problem, and propose to use the Extreme Value Theory for efficient evaluation. Our analysis yields a novel robustness metric called CLEVER, which is short for Cross Lipschitz Extreme Value for nEtwork Robustness. The proposed CLEVER score is attack-agnostic and is computationally feasible for large neural networks. Experimental results on various networks, including ResNet, Inception-v3 and MobileNet, show that (i) CLEVER is aligned with the robustness indication measured by the $\ell_2$ and $\ell_\infty$ norms of adversarial examples from powerful attacks, and (ii) defended networks using defensive distillation or bounded ReLU indeed give better CLEVER scores. To the best of our knowledge, CLEVER is the first attack-independent robustness metric that can be applied to any neural network classifiers.
      
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose the first attack-independent robustness metric, a.k.a CLEVER, that can be applied to any neural network classifier.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">robustness, adversarial machine learning, neural network, extreme value theory, adversarial example, adversarial perturbation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1vuQG-CW">
      <h4>
        <a href="https://openreview.net/forum?id=r1vuQG-CW">
          HexaConv
        </a>
        
          <a href="https://openreview.net/pdf?id=r1vuQG-CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=e.hoogeboom%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.hoogeboom@gmail.com">Emiel Hoogeboom</a>, <a href="https://openreview.net/profile?email=jornpeters%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jornpeters@gmail.com">Jorn W.T. Peters</a>, <a href="https://openreview.net/profile?email=taco.cohen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taco.cohen@gmail.com">Taco S. Cohen</a>, <a href="https://openreview.net/profile?email=welling.max%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="welling.max@gmail.com">Max Welling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1vuQG-CW-details-966" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1vuQG-CW-details-966"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The effectiveness of Convolutional Neural Networks stems in large part from their ability to exploit the translation invariance that is inherent in many learning problems. Recently, it was shown that CNNs can exploit other invariances, such as rotation invariance, by using group convolutions instead of planar convolutions. However, for reasons of performance and ease of implementation, it has been necessary to limit the group convolution to transformations that can be applied to the filters without interpolation. Thus, for images with square pixels, only integer translations, rotations by multiples of 90 degrees, and reflections are admissible.
      
      Whereas the square tiling provides a 4-fold rotational symmetry, a hexagonal tiling of the plane has a 6-fold rotational symmetry. In this paper we show how one can efficiently implement planar convolution and group convolution over hexagonal lattices, by re-using existing highly optimized convolution routines. We find that, due to the reduced anisotropy of hexagonal filters, planar HexaConv provides better accuracy than planar convolution with square filters, given a fixed parameter budget. Furthermore, we find that the increased degree of symmetry of the hexagonal grid increases the effectiveness of group convolutions, by allowing for more parameter sharing. We show that our method significantly outperforms conventional CNNs on the AID aerial scene classification dataset, even outperforming ImageNet pre-trained models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce G-HexaConv, a group equivariant convolutional neural network on hexagonal lattices.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hexagonal, group, symmetry, representation learning, rotation, equivariance, invariance</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJzIBfZAb">
      <h4>
        <a href="https://openreview.net/forum?id=rJzIBfZAb">
          Towards Deep Learning Models Resistant to Adversarial Attacks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJzIBfZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=madry%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="madry@mit.edu">Aleksander Madry</a>, <a href="https://openreview.net/profile?email=amakelov%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amakelov@mit.edu">Aleksandar Makelov</a>, <a href="https://openreview.net/profile?email=ludwigs%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludwigs@mit.edu">Ludwig Schmidt</a>, <a href="https://openreview.net/profile?email=tsipras%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsipras@mit.edu">Dimitris Tsipras</a>, <a href="https://openreview.net/profile?email=avladu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="avladu@mit.edu">Adrian Vladu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJzIBfZAb-details-2" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJzIBfZAb-details-2"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against a well-defined class of adversaries. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest robustness against a first-order adversary as a natural security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We provide a principled, optimization-based re-look at the notion of adversarial examples, and develop methods that produce models that are adversarially robust against a wide range of adversaries.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, robust optimization, ML security</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By4HsfWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=By4HsfWAZ">
          Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge
        </a>
        
          <a href="https://openreview.net/pdf?id=By4HsfWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=emmanuel.de_bezenac%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="emmanuel.de_bezenac@lip6.fr">Emmanuel de Bezenac</a>, <a href="https://openreview.net/profile?email=arthur.pajot%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="arthur.pajot@lip6.fr">Arthur Pajot</a>, <a href="https://openreview.net/profile?email=patrick.gallinari%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="patrick.gallinari@lip6.fr">Patrick Gallinari</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By4HsfWAZ-details-694" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By4HsfWAZ-details-694"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider  the use of Deep Learning methods for modeling complex phenomena like those occurring in natural physical processes. With the large amount of data gathered on these phenomena the data intensive paradigm could begin to challenge more traditional approaches elaborated over the years in fields like maths or physics. However, despite considerable successes in a variety of application domains, the machine learning field is not yet ready to handle the level of complexity required by such problems. Using an example application, namely Sea Surface Temperature Prediction, we show how general background knowledge gained from the physics could be used as a guideline for designing efficient Deep Learning models. In order to motivate the approach and to assess its generality we demonstrate a formal link between the solution of a class of differential equations underlying a large family of physical phenomena and the proposed model. Experiments and comparison with series of baselines including a state of the art numerical approach is then provided.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, physical processes, forecasting, spatio-temporal</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryazCMbR-">
      <h4>
        <a href="https://openreview.net/forum?id=ryazCMbR-">
          Communication Algorithms via Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=ryazCMbR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hyejikim%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyejikim@illinois.edu">Hyeji Kim</a>, <a href="https://openreview.net/profile?email=yihanrogerjiang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yihanrogerjiang@gmail.com">Yihan Jiang</a>, <a href="https://openreview.net/profile?email=rbrana2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rbrana2@illinois.edu">Ranvir B. Rana</a>, <a href="https://openreview.net/profile?email=ksreeram%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ksreeram@uw.edu">Sreeram Kannan</a>, <a href="https://openreview.net/profile?email=sewoong79%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sewoong79@gmail.com">Sewoong Oh</a>, <a href="https://openreview.net/profile?email=pramodv%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pramodv@illinois.edu">Pramod Viswanath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>31 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryazCMbR--details-795" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryazCMbR--details-795"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Coding theory is a central discipline underpinning wireline and wireless modems that are the workhorses of the information age. Progress in coding theory is largely driven by individual human ingenuity with sporadic breakthroughs over the past century. In this paper we study whether it is possible to automate the discovery of decoding algorithms via deep learning. We study a family of sequential codes parametrized by recurrent neural network (RNN) architectures. We show that cre- atively designed and trained RNN architectures can decode well known sequential codes such as the convolutional and turbo codes with close to optimal performance on the additive white Gaussian noise (AWGN) channel, which itself is achieved by breakthrough algorithms of our times (Viterbi and BCJR decoders, representing dynamic programing and forward-backward algorithms). We show strong gen- eralizations, i.e., we train at a specific signal to noise ratio and block length but test at a wide range of these quantities, as well as robustness and adaptivity to deviations from the AWGN setting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that creatively designed and trained RNN architectures can decode well known sequential codes and achieve close to optimal performances.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">coding theory, recurrent neural network, communication</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJYFzMZC-">
      <h4>
        <a href="https://openreview.net/forum?id=rJYFzMZC-">
          Simulating Action Dynamics with Neural Process Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJYFzMZC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=antoineb%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoineb@cs.washington.edu">Antoine Bosselut</a>, <a href="https://openreview.net/profile?email=omerlevy%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="omerlevy@cs.washington.edu">Omer Levy</a>, <a href="https://openreview.net/profile?email=ahai%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahai@cs.washington.edu">Ari Holtzman</a>, <a href="https://openreview.net/profile?email=corin123%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="corin123@uw.edu">Corin Ennis</a>, <a href="https://openreview.net/profile?email=fox%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fox@cs.washington.edu">Dieter Fox</a>, <a href="https://openreview.net/profile?email=yejin%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yejin@cs.washington.edu">Yejin Choi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 29 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJYFzMZC--details-101" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJYFzMZC--details-101"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Understanding procedural language requires anticipating the causal effects of actions, even when they are not explicitly stated. In this work, we introduce Neural Process Networks to understand procedural text through (neural) simulation of action dynamics.   Our model complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers. The model updates the states of the entities by executing learned action operators. Empirical results demonstrate that our proposed model can reason about the unstated causal effects of actions, allowing it to provide more accurate contextual information for understanding and generating procedural text, all while offering more interpretable internal representations than existing alternatives.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new recurrent memory architecture that can track common sense state changes of entities by simulating the causal effects of actions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, memory networks, state tracking</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkeqO7x0-">
      <h4>
        <a href="https://openreview.net/forum?id=BkeqO7x0-">
          Unsupervised Cipher Cracking Using Discrete GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=BkeqO7x0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aidan.n.gomez%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aidan.n.gomez@gmail.com">Aidan N. Gomez</a>, <a href="https://openreview.net/profile?email=huang%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huang@cs.toronto.edu">Sicong Huang</a>, <a href="https://openreview.net/profile?email=ivan%40for.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="ivan@for.ai">Ivan Zhang</a>, <a href="https://openreview.net/profile?email=bryan%40for.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="bryan@for.ai">Bryan M. Li</a>, <a href="https://openreview.net/profile?email=osama%40for.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="osama@for.ai">Muhammad Osama</a>, <a href="https://openreview.net/profile?email=lukaszkaiser%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukaszkaiser@google.com">Lukasz Kaiser</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkeqO7x0--details-468" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkeqO7x0--details-468"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This work details CipherGAN, an architecture inspired by CycleGAN used for inferring the underlying cipher mapping given banks of unpaired ciphertext and plaintext. We demonstrate that CipherGAN is capable of cracking language data enciphered using shift and Vigenere ciphers to a high degree of fidelity and for vocabularies much larger than previously achieved. We present how CycleGAN can be made compatible with discrete data and train in a stable way. We then prove that the technique used in CipherGAN avoids the common problem of uninformative discrimination associated with GANs applied to discrete data.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy-dQG-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=Sy-dQG-Rb">
          Neural Speed Reading via Skim-RNN
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy-dQG-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=minjoon%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="minjoon@cs.washington.edu">Minjoon Seo</a>, <a href="https://openreview.net/profile?email=shmsw25%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="shmsw25@snu.ac.kr">Sewon Min</a>, <a href="https://openreview.net/profile?email=ali%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ali@cs.washington.edu">Ali Farhadi</a>, <a href="https://openreview.net/profile?email=hannaneh%40washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hannaneh@washington.edu">Hannaneh Hajishirzi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy-dQG-Rb-details-853" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy-dQG-Rb-details-853"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Inspired by the principles of speed reading, we introduce Skim-RNN, a recurrent neural network (RNN) that dynamically decides to update only a small fraction of the hidden state for relatively unimportant input tokens. Skim-RNN gives a significant computational advantage over an RNN that always updates the entire hidden state. Skim-RNN uses the same input and output interfaces as a standard RNN and can be easily used instead of RNNs in existing models.  In our experiments, we show that Skim-RNN can achieve significantly reduced computational cost without losing accuracy compared to standard RNNs across five different natural language tasks. In addition, we demonstrate that the trade-off between accuracy and speed of Skim-RNN can be dynamically controlled during inference time in a stable manner. Our analysis also shows that Skim-RNN running on a single CPU offers lower latency compared to standard RNNs on GPUs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Natural Language Processing, RNN, Inference Speed</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyJS-OgR-">
      <h4>
        <a href="https://openreview.net/forum?id=SyJS-OgR-">
          Multi-level Residual Networks from Dynamical Systems View
        </a>
        
          <a href="https://openreview.net/pdf?id=SyJS-OgR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bchang%40stat.ubc.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="bchang@stat.ubc.ca">Bo Chang</a>, <a href="https://openreview.net/profile?email=lilimeng1103%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lilimeng1103@gmail.com">Lili Meng</a>, <a href="https://openreview.net/profile?email=haber%40math.ubc.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="haber@math.ubc.ca">Eldad Haber</a>, <a href="https://openreview.net/profile?email=ftung%40sfu.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ftung@sfu.ca">Frederick Tung</a>, <a href="https://openreview.net/profile?email=david%40xtract.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="david@xtract.ai">David Begert</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyJS-OgR--details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyJS-OgR--details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep residual networks (ResNets) and their variants are widely used in many computer vision applications and natural language processing tasks.  However, the theoretical principles for designing and training ResNets are still not fully understood. Recently, several points of view have emerged to try to interpret ResNet theoretically, such as unraveled view, unrolled iterative estimation and dynamical systems view. In this paper, we adopt the dynamical systems point of view, and analyze the lesioning properties of ResNet both theoretically and experimentally.  Based on these analyses, we additionally propose a novel method for accelerating ResNet training. We apply the proposed method to train ResNets and Wide ResNets for three image classification benchmarks, reducing training time by more than 40\% with superior or on-par accuracy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">residual networks, dynamical systems</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HktJec1RZ">
      <h4>
        <a href="https://openreview.net/forum?id=HktJec1RZ">
          Towards Neural Phrase-based Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=HktJec1RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=huang.person%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huang.person@gmail.com">Po-Sen Huang</a>, <a href="https://openreview.net/profile?email=chongw%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongw@google.com">Chong Wang</a>, <a href="https://openreview.net/profile?email=shuang91%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shuang91@illinois.edu">Sitao Huang</a>, <a href="https://openreview.net/profile?email=dennyzhou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dennyzhou@gmail.com">Dengyong Zhou</a>, <a href="https://openreview.net/profile?email=l.deng%40ieee.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="l.deng@ieee.org">Li Deng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Sep 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HktJec1RZ-details-482" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HktJec1RZ-details-482"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we present Neural Phrase-based Machine Translation (NPMT). Our method explicitly models the phrase structures in output sequences using Sleep-WAke Networks (SWAN), a recently proposed segmentation-based sequence modeling method. To mitigate the monotonic alignment requirement of SWAN, we introduce a new layer to perform (soft) local reordering of input sequences. Different from existing neural machine translation (NMT) approaches, NPMT does not use attention-based decoding mechanisms.  Instead, it directly outputs phrases in a sequential order and can decode in linear time. Our experiments show that NPMT achieves superior performances on IWSLT 2014 German-English/English-German and IWSLT 2015 English-Vietnamese machine translation tasks compared with strong NMT baselines. We also observe that our method produces meaningful phrases in output languages.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Neural phrase-based machine translation with linear decoding time</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Machine Translation, Sequence to Sequence, Sequence Modeling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByJHuTgA-">
      <h4>
        <a href="https://openreview.net/forum?id=ByJHuTgA-">
          On the State of the Art of Evaluation in Neural Language Models
        </a>
        
          <a href="https://openreview.net/pdf?id=ByJHuTgA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=melisgl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="melisgl@google.com">Gábor Melis</a>, <a href="https://openreview.net/profile?email=cdyer%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdyer@cs.cmu.edu">Chris Dyer</a>, <a href="https://openreview.net/profile?email=phil.blunsom%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="phil.blunsom@cs.ox.ac.uk">Phil Blunsom</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByJHuTgA--details-154" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByJHuTgA--details-154"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Ongoing innovations in recurrent neural network architectures have provided a steady influx of apparently state-of-the-art results on language modelling benchmarks. However, these have been evaluated using differing codebases and limited computational resources, which represent uncontrolled sources of experimental variation. We reevaluate several popular architectures and regularisation methods with large-scale automatic black-box hyperparameter tuning and arrive at the somewhat surprising conclusion that standard LSTM architectures, when properly regularised, outperform more recent models. We establish a new state of the art on the Penn Treebank and Wikitext-2 corpora, as well as strong baselines on the Hutter Prize dataset.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Show that LSTMs are as good or better than recent innovations for LM and that model evaluation is often unreliable.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">rnn, language modelling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkfOvGbCW">
      <h4>
        <a href="https://openreview.net/forum?id=rkfOvGbCW">
          Memory-based Parameter Adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=rkfOvGbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=psprechmann%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="psprechmann@google.com">Pablo Sprechmann</a>, <a href="https://openreview.net/profile?email=sidmj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sidmj@google.com">Siddhant M. Jayakumar</a>, <a href="https://openreview.net/profile?email=jwrae%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwrae@google.com">Jack W. Rae</a>, <a href="https://openreview.net/profile?email=apritzel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="apritzel@google.com">Alexander Pritzel</a>, <a href="https://openreview.net/profile?email=adriap%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adriap@google.com">Adria Puigdomenech Badia</a>, <a href="https://openreview.net/profile?email=buria%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="buria@google.com">Benigno Uria</a>, <a href="https://openreview.net/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>, <a href="https://openreview.net/profile?email=dhcontact%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhcontact@google.com">Demis Hassabis</a>, <a href="https://openreview.net/profile?email=razp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="razp@google.com">Razvan Pascanu</a>, <a href="https://openreview.net/profile?email=cblundell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cblundell@google.com">Charles Blundell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkfOvGbCW-details-441" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkfOvGbCW-details-441"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> Deep neural networks have excelled on a wide range of problems, from vision to language and game playing. Neural networks very gradually incorporate information into weights as they process data, requiring very low learning rates. If the training distribution shifts, the network is slow to adapt, and when it does adapt, it typically performs badly on the training distribution before the shift. Our method, Memory-based Parameter Adaptation, stores examples in memory and then uses a context-based lookup to directly modify the weights of a neural network. Much higher learning rates can be used for this local adaptation, reneging the need for many iterations over similar data before good predictions can be made. As our method is memory-based, it alleviates several shortcomings of neural networks, such as catastrophic forgetting, fast, stable acquisition of new knowledge, learning with an imbalanced class labels, and fast learning during evaluation. We demonstrate this on a range of supervised tasks: large-scale image classification and language modelling.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJJ23bW0b">
      <h4>
        <a href="https://openreview.net/forum?id=HJJ23bW0b">
          Initialization matters: Orthogonal Predictive State Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJJ23bW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kchoro%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kchoro@google.com">Krzysztof Choromanski</a>, <a href="https://openreview.net/profile?email=cmdowney%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cmdowney@cs.cmu.edu">Carlton Downey</a>, <a href="https://openreview.net/profile?email=bboots%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bboots@cc.gatech.edu">Byron Boots</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJJ23bW0b-details-186" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJJ23bW0b-details-186"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning to predict complex time-series data is a fundamental challenge in a range of disciplines including Machine Learning, Robotics, and Natural Language Processing. Predictive State Recurrent Neural Networks (PSRNNs) (Downey et al.) are a state-of-the-art approach for modeling time-series data which combine the benefits of probabilistic filters and Recurrent Neural Networks into a single model. PSRNNs leverage the concept of Hilbert Space Embeddings of distributions (Smola et al.) to embed predictive states into a Reproducing Kernel Hilbert Space, then estimate, predict, and update these embedded states using Kernel Bayes Rule. Practical implementations of PSRNNs are made possible by the machinery of Random Features, where input features are mapped into a new space where dot products approximate the kernel well. Unfortunately PSRNNs often require a large number of RFs to obtain good results, resulting in large models which are slow to execute and slow to train. Orthogonal Random Features (ORFs) (Choromanski et al.) is an improvement on RFs which has been shown to decrease the number of RFs required for pointwise kernel approximation. Unfortunately, it is not clear that ORFs can be applied to PSRNNs, as PSRNNs rely on Kernel Ridge Regression as a core component of their learning algorithm, and the theoretical guarantees of ORF do not apply in this setting. In this paper, we extend the theory of ORFs to Kernel Ridge Regression and show that ORFs can be used to obtain Orthogonal PSRNNs (OPSRNNs), which are smaller and faster than PSRNNs. In particular, we show that OPSRNN models clearly outperform LSTMs and furthermore, can achieve accuracy similar to PSRNNs with an order of magnitude smaller number of features needed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Improving Predictive State Recurrent Neural Networks via Orthogonal Random Features</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, orthogonal random features, predictive state representations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJUYGxbCW">
      <h4>
        <a href="https://openreview.net/forum?id=rJUYGxbCW">
          PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=rJUYGxbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yangsong%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangsong@cs.stanford.edu">Yang Song</a>, <a href="https://openreview.net/profile?email=taesup.kim%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="taesup.kim@umontreal.ca">Taesup Kim</a>, <a href="https://openreview.net/profile?email=sebastian.nowozin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.nowozin@microsoft.com">Sebastian Nowozin</a>, <a href="https://openreview.net/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>, <a href="https://openreview.net/profile?email=nkushman%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nkushman@microsoft.com">Nate Kushman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJUYGxbCW-details-588" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJUYGxbCW-details-588"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Adversarial perturbations of normal images are usually imperceptible to humans, but they can seriously confuse state-of-the-art machine learning models. What makes them so special in the eyes of image classifiers? In this paper, we show empirically that adversarial examples mainly lie in the low probability regions of the training distribution, regardless of attack types and targeted models. Using statistical hypothesis testing, we find that modern neural density models are surprisingly good at detecting imperceptible image perturbations. Based on this discovery, we devised PixelDefend, a new approach that purifies a maliciously perturbed image by moving it back towards the distribution seen in the training data. The purified image is then run through an unmodified classifier, making our method agnostic to both the classifier and the attacking method. As a result, PixelDefend can be used to protect already deployed models and be combined with other model-specific defenses. Experiments show that our method greatly improves resilience across a wide variety of state-of-the-art attacking methods, increasing accuracy on the strongest attack from 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Examples, Generative Models, Purification, Hypothesis Testing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bys4ob-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=Bys4ob-Rb">
          Certified Defenses against Adversarial Examples 
        </a>
        
          <a href="https://openreview.net/pdf?id=Bys4ob-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aditir%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aditir@stanford.edu">Aditi Raghunathan</a>, <a href="https://openreview.net/profile?email=jsteinhardt%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsteinhardt@cs.stanford.edu">Jacob Steinhardt</a>, <a href="https://openreview.net/profile?email=pliang%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pliang@cs.stanford.edu">Percy Liang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bys4ob-Rb-details-432" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bys4ob-Rb-details-432"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this work, we study this problem for neural networks with one hidden layer. We first propose a method based on a semidefinite relaxation that outputs a certificate that for a given network and test input, no attack can force the error to exceed a certain value. Second, as this certificate is differentiable, we jointly optimize it with the network parameters, providing an adaptive regularizer that encourages robustness against all attacks. On MNIST, our approach produces a network and a certificate that no that perturbs each pixel by at most $\epsilon = 0.1$ can cause more than $35\%$ test error.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We demonstrate a certifiable, trainable, and scalable method for defending against adversarial examples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, certificate of robustness, convex relaxations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkJ3ibb0-">
      <h4>
        <a href="https://openreview.net/forum?id=BkJ3ibb0-">
          Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=BkJ3ibb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pouya%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pouya@umiacs.umd.edu">Pouya Samangouei</a>, <a href="https://openreview.net/profile?email=mayak%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mayak@umiacs.umd.edu">Maya Kabkab</a>, <a href="https://openreview.net/profile?email=rama%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rama@umiacs.umd.edu">Rama Chellappa</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkJ3ibb0--details-507" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkJ3ibb0--details-507"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In recent years, deep neural network approaches have been widely adopted for machine learning tasks, including classification. However, they were shown to be vulnerable to adversarial perturbations: carefully crafted small perturbations can cause misclassification of legitimate images. We propose Defense-GAN, a new framework leveraging the expressive capability of generative models to defend deep neural networks against such attacks. Defense-GAN is trained to model the distribution of unperturbed images. At inference time, it finds a close output to a given image which does not contain the adversarial changes. This output is then fed to the classifier. Our proposed method can be used with any classification model and does not modify the classifier structure or training procedure. It can also be used as a defense against any attack as it does not assume knowledge of the process for generating the adversarial examples. We empirically show that Defense-GAN is consistently effective against different attack methods and improves on existing defense strategies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Defense-GAN uses a Generative Adversarial Network to defend against white-box and black-box attacks in classification models.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkZvSe-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkZvSe-RZ">
          Ensemble Adversarial Training: Attacks and Defenses
        </a>
        
          <a href="https://openreview.net/pdf?id=rkZvSe-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tramer%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tramer@cs.stanford.edu">Florian Tramèr</a>, <a href="https://openreview.net/profile?email=alexey%40kurakin.me" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexey@kurakin.me">Alexey Kurakin</a>, <a href="https://openreview.net/profile?email=ngp5056%40cse.psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ngp5056@cse.psu.edu">Nicolas Papernot</a>, <a href="https://openreview.net/profile?email=goodfellow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goodfellow@google.com">Ian Goodfellow</a>, <a href="https://openreview.net/profile?email=dabo%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dabo@cs.stanford.edu">Dan Boneh</a>, <a href="https://openreview.net/profile?email=mcdaniel%40cse.psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcdaniel@cse.psu.edu">Patrick McDaniel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkZvSe-RZ-details-542" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkZvSe-RZ-details-542"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model's loss.
      We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we find that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step.
      We further introduce Ensemble Adversarial Training, a technique that augments training data with perturbations transferred from other models. On ImageNet, Ensemble Adversarial Training yields models with strong robustness to black-box attacks. In particular, our most robust model won the first round of the NIPS 2017 competition on Defenses against Adversarial Attacks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adversarial training with single-step methods overfits, and remains vulnerable to simple black-box and white-box attacks. We show that including adversarial examples from multiple sources helps defend against black-box attacks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Examples, Adversarial Training, Attacks, Defenses, ImageNet</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJyVzQ-C-">
      <h4>
        <a href="https://openreview.net/forum?id=SJyVzQ-C-">
          Fraternal Dropout
        </a>
        
          <a href="https://openreview.net/pdf?id=SJyVzQ-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=konrad.zolna%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="konrad.zolna@gmail.com">Konrad Zolna</a>, <a href="https://openreview.net/profile?email=devansh.arpit%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="devansh.arpit@umontreal.ca">Devansh Arpit</a>, <a href="https://openreview.net/profile?email=dasuhubd%40ncsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dasuhubd@ncsu.edu">Dendi Suhubdy</a>, <a href="https://openreview.net/profile?email=bengioy%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengioy@iro.umontreal.ca">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJyVzQ-C--details-818" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJyVzQ-C--details-818"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks (RNNs) are important class of architectures among neural networks useful for language modeling and sequential prediction. However, optimizing RNNs is known to be harder compared to feed-forward neural networks. A number of techniques have been proposed in literature to address this problem. In this paper we propose a simple technique called fraternal dropout that takes advantage of dropout to achieve this goal. Specifically, we propose to train two identical copies of an RNN (that share parameters) with different dropout masks while minimizing the difference between their (pre-softmax) predictions. In this way our regularization encourages the representations of RNNs to be invariant to dropout mask, thus being robust. We show that our regularization term is upper bounded by the expectation-linear dropout objective which has been shown to address the gap due to the difference between the train and inference phases of dropout. We evaluate our model and achieve state-of-the-art results in sequence modeling tasks on two benchmark datasets - Penn Treebank and Wikitext-2. We also show that our approach leads to performance improvement by a significant margin in image captioning (Microsoft COCO) and semi-supervised (CIFAR-10) tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose to train two identical copies of an recurrent neural network (that share parameters) with different dropout masks while minimizing the difference between their (pre-softmax) predictions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">fraternal dropout, activity regularization, recurrent neural networks, RNN, LSTM, faster convergence</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJcKhk-Ab">
      <h4>
        <a href="https://openreview.net/forum?id=SJcKhk-Ab">
          Can recurrent neural networks warp time?
        </a>
        
          <a href="https://openreview.net/pdf?id=SJcKhk-Ab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=corentin.tallec%40polytechnique.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="corentin.tallec@polytechnique.edu">Corentin Tallec</a>, <a href="https://openreview.net/profile?email=yol%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yol@fb.com">Yann Ollivier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJcKhk-Ab-details-298" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJcKhk-Ab-details-298"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Successful recurrent models such as long short-term memories (LSTMs) and gated recurrent units (GRUs) use \emph{ad hoc} gating mechanisms.  Empirically these models have been found to improve the learning of medium to long term temporal dependencies and to help with vanishing gradient issues.
      	
      We prove that learnable gates in a recurrent model formally provide \emph{quasi-invariance to general time transformations} in the input data. We recover part of the LSTM architecture from a simple axiomatic approach.
      	
      This result leads to a new way of initializing gate biases in LSTMs and GRUs. Experimentally, this new \emph{chrono initialization} is shown to greatly improve learning of long term dependencies, with minimal implementation effort.
      
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Proves that gating mechanisms provide invariance to time transformations. Introduces and tests a new initialization for LSTMs from this insight.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyUNwulC-">
      <h4>
        <a href="https://openreview.net/forum?id=HyUNwulC-">
          Parallelizing Linear Recurrent Neural Nets Over Sequence Length
        </a>
        
          <a href="https://openreview.net/pdf?id=HyUNwulC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eric%40ericmart.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="eric@ericmart.in">Eric Martin</a>, <a href="https://openreview.net/profile?email=chris.j.cundy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chris.j.cundy@gmail.com">Chris Cundy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyUNwulC--details-763" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyUNwulC--details-763"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks (RNNs) are widely used to model sequential data but
      their non-linear dependencies between sequence elements prevent parallelizing
      training over sequence length. We show the training of RNNs with only linear
      sequential dependencies can be parallelized over the sequence length using the
      parallel scan algorithm, leading to rapid training on long sequences even with
      small minibatch size. We develop a parallel linear recurrence CUDA kernel and
      show that it can be applied to immediately speed up training and inference of
      several state of the art RNN architectures by up to 9x.  We abstract recent work
      on linear RNNs into a new framework of linear surrogate RNNs and develop a
      linear surrogate model for the long short-term memory unit, the GILR-LSTM, that
      utilizes parallel linear recurrence.  We extend sequence learning to new
      extremely long sequence regimes that were previously out of reach by
      successfully training a GILR-LSTM on a synthetic sequence classification task
      with a one million timestep dependency.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">use parallel scan to parallelize linear recurrent neural nets. train model on length 1 million dependency</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">rnn, sequence, parallel, qrnn, sru, gilr, gilr-lstm</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkTEFfZRb">
      <h4>
        <a href="https://openreview.net/forum?id=HkTEFfZRb">
          Attacking Binarized Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HkTEFfZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gallowaa%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gallowaa@uoguelph.ca">Angus Galloway</a>, <a href="https://openreview.net/profile?email=gwtaylor%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gwtaylor@uoguelph.ca">Graham W. Taylor</a>, <a href="https://openreview.net/profile?email=mmoussa%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="mmoussa@uoguelph.ca">Medhat Moussa</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkTEFfZRb-details-441" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkTEFfZRb-details-441"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks with low-precision weights and activations offer compelling
      efficiency advantages over their full-precision equivalents. The two most
      frequently discussed benefits of quantization are reduced memory consumption,
      and a faster forward pass when implemented with efficient bitwise
      operations. We propose a third benefit of very low-precision neural networks:
      improved robustness against some adversarial attacks, and in the worst case,
      performance that is on par with full-precision models. We focus on the very
      low-precision case where weights and activations are both quantized to $\pm$1,
      and note that stochastically quantizing weights in just one layer can sharply
      reduce the impact of iterative attacks. We observe that non-scaled binary neural
      networks exhibit a similar effect to the original \emph{defensive distillation}
      procedure that led to \emph{gradient masking}, and a false notion of security.
      We address this by conducting both black-box and white-box experiments with
      binary models that do not artificially mask gradients.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We conduct adversarial attacks against binarized neural networks and show that we reduce the impact of the strongest attacks, while maintaining comparable accuracy in a black-box setting</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, adversarial attacks, binary, binarized neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1jBcueAb">
      <h4>
        <a href="https://openreview.net/forum?id=S1jBcueAb">
          Depthwise Separable Convolutions for Neural Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=S1jBcueAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lukaszkaiser%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukaszkaiser@google.com">Lukasz Kaiser</a>, <a href="https://openreview.net/profile?email=aidan.n.gomez%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aidan.n.gomez@gmail.com">Aidan N. Gomez</a>, <a href="https://openreview.net/profile?email=fchollet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fchollet@google.com">Francois Chollet</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1jBcueAb-details-579" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1jBcueAb-details-579"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Depthwise separable convolutions reduce the number of parameters and computation used in convolutional operations while increasing representational efficiency.
      They have been shown to be successful in image classification models, both in obtaining better models than previously possible for a given parameter count (the Xception architecture) and considerably reducing the number of parameters required to perform at a given level (the MobileNets family of architectures). Recently, convolutional sequence-to-sequence networks have been applied to machine translation tasks with good results. In this work, we study how depthwise separable convolutions can be applied to neural machine translation. We introduce a new architecture inspired by Xception and ByteNet, called SliceNet, which enables a significant reduction of the parameter count and amount of computation needed to obtain results like ByteNet, and, with a similar parameter count, achieves better results.
      In addition to showing that depthwise separable convolutions perform well for machine translation, we investigate the architectural changes that they enable: we observe that thanks to depthwise separability, we can increase the length of convolution windows, removing the need for filter dilation. We also introduce a new super-separable convolution operation that further reduces the number of parameters and computational cost of the models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Depthwise separable convolutions improve neural machine translation: the more separable the better.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">convolutions, neural machine translation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rywHCPkAW">
      <h4>
        <a href="https://openreview.net/forum?id=rywHCPkAW">
          Noisy Networks For Exploration
        </a>
        
          <a href="https://openreview.net/pdf?id=rywHCPkAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=meirefortunato%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="meirefortunato@google.com">Meire Fortunato</a>, <a href="https://openreview.net/profile?email=mazar%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mazar@google.com">Mohammad Gheshlaghi Azar</a>, <a href="https://openreview.net/profile?email=piot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="piot@google.com">Bilal Piot</a>, <a href="https://openreview.net/profile?email=jmenick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmenick@google.com">Jacob Menick</a>, <a href="https://openreview.net/profile?email=mtthss%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mtthss@google.com">Matteo Hessel</a>, <a href="https://openreview.net/profile?email=iosband%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iosband@google.com">Ian Osband</a>, <a href="https://openreview.net/profile?email=gravesa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gravesa@google.com">Alex Graves</a>, <a href="https://openreview.net/profile?email=vmnih%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vmnih@google.com">Volodymyr Mnih</a>, <a href="https://openreview.net/profile?email=munos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="munos@google.com">Remi Munos</a>, <a href="https://openreview.net/profile?email=dhcontact%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhcontact@google.com">Demis Hassabis</a>, <a href="https://openreview.net/profile?email=pietquin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pietquin@google.com">Olivier Pietquin</a>, <a href="https://openreview.net/profile?email=cblundell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cblundell@google.com">Charles Blundell</a>, <a href="https://openreview.net/profile?email=legg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="legg@google.com">Shane Legg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rywHCPkAW-details-645" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rywHCPkAW-details-645"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce NoisyNet, a deep reinforcement learning agent with parametric noise added to its weights, and show that the induced stochasticity of the agent’s policy can be used to aid efficient exploration. The parameters of the noise are learned with gradient descent along with the remaining network weights.  NoisyNet is straightforward to implement and adds little computational overhead. We find that replacing the conventional exploration heuristics for A3C, DQN and Dueling agents (entropy reward and epsilon-greedy respectively) with NoisyNet yields substantially higher scores for a wide range of Atari games, in some cases advancing the agent from sub to super-human performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A deep reinforcement learning agent with parametric noise added to its weights can be used to aid efficient exploration.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning, Exploration, Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkc-TeZ0W">
      <h4>
        <a href="https://openreview.net/forum?id=Hkc-TeZ0W">
          A Hierarchical Model for Device Placement
        </a>
        
          <a href="https://openreview.net/pdf?id=Hkc-TeZ0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=azalia%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="azalia@google.com">Azalia Mirhoseini</a>, <a href="https://openreview.net/profile?email=agoldie%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="agoldie@google.com">Anna Goldie</a>, <a href="https://openreview.net/profile?email=hyhieu%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyhieu@cmu.edu">Hieu Pham</a>, <a href="https://openreview.net/profile?email=bsteiner%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bsteiner@google.com">Benoit Steiner</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>, <a href="https://openreview.net/profile?email=jeff%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeff@google.com">Jeff Dean</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hkc-TeZ0W-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkc-TeZ0W-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a hierarchical model for efficient placement of computational graphs onto hardware devices, especially in heterogeneous environments with a mixture of CPUs, GPUs, and other computational devices. Our method learns to assign graph operations to groups and to allocate those groups to available devices. The grouping and device allocations are learned jointly. The proposed method is trained with policy gradient and requires no human intervention. Experiments with widely-used
      computer vision and natural language models show that our algorithm can find optimized, non-trivial placements for TensorFlow computational graphs with over 80,000 operations. In addition, our approach outperforms placements by human
      experts as well as a previous state-of-the-art placement method based on deep reinforcement learning. Our method achieves runtime reductions of up to 60.6% per training step when applied to models such as Neural Machine Translation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a hierarchical model for efficient, end-to-end placement of computational graphs onto hardware devices.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, device placement, policy gradient optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJJLHbb0-">
      <h4>
        <a href="https://openreview.net/forum?id=BJJLHbb0-">
          Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection
        </a>
        
          <a href="https://openreview.net/pdf?id=BJJLHbb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bzong%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bzong@nec-labs.com">Bo Zong</a>, <a href="https://openreview.net/profile?email=qsong%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qsong@nec-labs.com">Qi Song</a>, <a href="https://openreview.net/profile?email=renqiang%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="renqiang@nec-labs.com">Martin Renqiang Min</a>, <a href="https://openreview.net/profile?email=weicheng%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weicheng@nec-labs.com">Wei Cheng</a>, <a href="https://openreview.net/profile?email=lume%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lume@nec-labs.com">Cristian Lumezanu</a>, <a href="https://openreview.net/profile?email=dkcho%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkcho@nec-labs.com">Daeki Cho</a>, <a href="https://openreview.net/profile?email=haifeng%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haifeng@nec-labs.com">Haifeng Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJJLHbb0--details-349" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJJLHbb0--details-349"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Unsupervised anomaly detection on multi- or high-dimensional data is of great importance in both fundamental machine learning research and industrial applications, for which density estimation lies at the core. Although previous approaches based on dimensionality reduction followed by density estimation have made fruitful progress, they mainly suffer from decoupled model learning with inconsistent optimization goals and incapability of preserving essential information in the low-dimensional space. In this paper, we present a Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection. Our model utilizes a deep autoencoder to generate a low-dimensional representation and reconstruction error for each input data point, which is further fed into a Gaussian Mixture Model (GMM). Instead of using decoupled two-stage training and the standard Expectation-Maximization (EM) algorithm, DAGMM jointly optimizes the parameters of the deep autoencoder and the mixture model simultaneously in an end-to-end fashion, leveraging a separate estimation network to facilitate the parameter learning of the mixture model. The joint optimization, which well balances autoencoding reconstruction, density estimation of latent representation, and regularization, helps the autoencoder escape from less attractive local optima and further reduce reconstruction errors, avoiding the need of pre-training. Experimental results on several public benchmark datasets show that, DAGMM significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An end-to-end trained deep neural network that leverages Gaussian Mixture Modeling to perform density estimation and unsupervised anomaly detection in a low-dimensional space learned by deep autoencoder.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Density estimation, unsupervised anomaly detection, high-dimensional data, Deep autoencoder, Gaussian mixture modeling, latent low-dimensional space</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BySRH6CpW">
      <h4>
        <a href="https://openreview.net/forum?id=BySRH6CpW">
          Learning Discrete Weights Using the Local Reparameterization Trick
        </a>
        
          <a href="https://openreview.net/pdf?id=BySRH6CpW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=oran.sh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oran.sh@gmail.com">Oran Shayer</a>, <a href="https://openreview.net/profile?email=dan.levi%40gm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dan.levi@gm.com">Dan Levi</a>, <a href="https://openreview.net/profile?email=ethanf%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ethanf@cs.toronto.edu">Ethan Fetaya</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BySRH6CpW-details-18" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BySRH6CpW-details-18"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent breakthroughs in computer vision make use of large deep neural networks, utilizing the substantial speedup offered by GPUs. For applications running on limited hardware, however, high precision real-time processing can still be a challenge.  One approach to solving this problem is training networks with binary or ternary weights, thus removing the need to calculate multiplications and significantly reducing memory size. In this work, we introduce LR-nets (Local reparameterization networks), a new method for training neural networks with discrete weights using stochastic parameters. We show how a simple modification to the local reparameterization trick, previously used to train Gaussian distributed weights, enables the training of discrete weights. Using the proposed training we test both binary and ternary models on MNIST, CIFAR-10 and ImageNet benchmarks and reach state-of-the-art results on most experiments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Training binary/ternary networks using local reparameterization with the CLT approximation</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, discrete weight network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ_wN01C-">
      <h4>
        <a href="https://openreview.net/forum?id=BJ_wN01C-">
          Deep Rewiring: Training very sparse deep networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ_wN01C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bellec%40igi.tugraz.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="bellec@igi.tugraz.at">Guillaume Bellec</a>, <a href="https://openreview.net/profile?email=kappel%40igi.tugraz.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="kappel@igi.tugraz.at">David Kappel</a>, <a href="https://openreview.net/profile?email=maass%40igi.tugraz.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="maass@igi.tugraz.at">Wolfgang Maass</a>, <a href="https://openreview.net/profile?email=legenstein%40igi.tugraz.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="legenstein@igi.tugraz.at">Robert Legenstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ_wN01C--details-247" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ_wN01C--details-247"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them. But also generic hardware and software implementations of deep learning run more efficiently for sparse networks. Several methods exist for pruning connections of a neural network after it was trained without connectivity constraints. We present an algorithm, DEEP R, that enables us to train directly a sparsely connected neural network. DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded. We demonstrate that DEEP R can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance. DEEP R is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper presents Deep Rewiring, an algorithm that can be used to train deep neural networks when the network connectivity is severely constrained during training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, pruning, LSTM, convolutional networks, recurrent neural network, sparse networks, neuromorphic hardware, energy efficient computing, low memory hardware, stochastic differential equation, fokker-planck equation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJQHjzZ0-">
      <h4>
        <a href="https://openreview.net/forum?id=SJQHjzZ0-">
          Quantitatively Evaluating GANs With Divergences Proposed for Training
        </a>
        
          <a href="https://openreview.net/pdf?id=SJQHjzZ0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daniel.im%40aifounded.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.im@aifounded.com">Daniel Jiwoong Im</a>, <a href="https://openreview.net/profile?email=hma02%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="hma02@uoguelph.ca">He Ma</a>, <a href="https://openreview.net/profile?email=gwtaylor%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gwtaylor@uoguelph.ca">Graham W. Taylor</a>, <a href="https://openreview.net/profile?email=kristinbranson%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kristinbranson@gmail.com">Kristin Branson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 28 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJQHjzZ0--details-787" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJQHjzZ0--details-787"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial networks (GANs) have been extremely effective in approximating complex distributions of high-dimensional, input data samples, and substantial progress has been made in understanding and improving GAN performance in terms of both theory and application. 
      However, we currently lack quantitative methods for model assessment. Because of this, while many GAN variants being proposed, we have relatively little understanding of their relative abilities. In this paper, we evaluate the performance of various types of GANs using divergence and distance functions typically used only for training. We observe consistency across the various proposed metrics and, interestingly, the test-time metrics do not favour networks that use the same training-time criterion. We also compare the proposed metrics to human perceptual scores.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An empirical evaluation on generative adversarial networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative adversarial networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkLhaGZRW">
      <h4>
        <a href="https://openreview.net/forum?id=BkLhaGZRW">
          Improving GAN Training via Binarized Representation Entropy (BRE) Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=BkLhaGZRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yanshuai.cao%40borealisai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanshuai.cao@borealisai.com">Yanshuai Cao</a>, <a href="https://openreview.net/profile?email=gavin.ding%40borealisai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gavin.ding@borealisai.com">Gavin Weiguang Ding</a>, <a href="https://openreview.net/profile?email=yikchau.y.lui%40borealisai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yikchau.y.lui@borealisai.com">Kry Yik-Chau Lui</a>, <a href="https://openreview.net/profile?email=ruitong.huang%40borealisai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruitong.huang@borealisai.com">Ruitong Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkLhaGZRW-details-83" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkLhaGZRW-details-83"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel regularizer to improve the training of Generative Adversarial Networks (GANs). The motivation is that when the discriminator D spreads out its model capacity in the right way, the learning signals given to the generator G are more informative and diverse, which helps G to explore better and discover the real data manifold while avoiding large unstable jumps due to the erroneous extrapolation made by D . Our regularizer guides the rectifier discriminator D to better allocate its model capacity, by encouraging the binary activation patterns on selected internal layers of D to have a high joint entropy. Experimental results on both synthetic data and real datasets demonstrate improvements in stability and convergence speed of the GAN training, as well as higher sample quality. The approach also leads to higher classification accuracies in semi-supervised learning.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1NYjfbR-">
      <h4>
        <a href="https://openreview.net/forum?id=r1NYjfbR-">
          Generative networks as inverse problems with Scattering transforms
        </a>
        
          <a href="https://openreview.net/pdf?id=r1NYjfbR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tomas.angles%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomas.angles@ens.fr">Tomás Angles</a>, <a href="https://openreview.net/profile?email=stephane.mallat%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephane.mallat@ens.fr">Stéphane Mallat</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1NYjfbR--details-806" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1NYjfbR--details-806"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Nets (GANs) and Variational Auto-Encoders (VAEs) provide impressive image generations from Gaussian white noise, but the underlying mathematics are not well understood. We compute deep convolutional network generators by inverting a fixed embedding operator. Therefore, they do not require to be optimized with a discriminator or an encoder. The embedding is Lipschitz continuous to deformations so that generators transform linear interpolations between input white noise vectors into deformations between output images. This embedding is computed with a wavelet Scattering transform. Numerical experiments demonstrate that the resulting Scattering generators have similar properties as GANs or VAEs, without learning a discriminative network or an encoder.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce generative networks that do not require to be learned with a discriminator or an encoder; they are obtained by inverting a special embedding operator defined by a wavelet Scattering transform.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Unsupervised Learning, Inverse Problems, Convolutional Networks, Generative Models, Scattering Transform</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJGWO9k0Z">
      <h4>
        <a href="https://openreview.net/forum?id=BJGWO9k0Z">
          Critical Percolation as a Framework to Analyze the Training of Deep Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJGWO9k0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zoharahoz%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zoharahoz@gmail.com">Zohar Ringel</a>, <a href="https://openreview.net/profile?email=rodrigo.bem%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rodrigo.bem@gmail.com">Rodrigo Andrade de Bem</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJGWO9k0Z-details-80" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJGWO9k0Z-details-80"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper we approach two relevant deep learning topics: i) tackling of graph structured input data and ii) a better understanding and analysis of deep networks and related learning algorithms. With this in mind we focus on the topological classification of reachability in a particular subset of planar graphs (Mazes). Doing so, we are able to model the topology of data while staying in Euclidean space, thus allowing its processing with standard CNN architectures. We suggest a suitable architecture for this problem and show that it can express a perfect solution to the classification task. The shape of the cost function around this solution is also derived and, remarkably, does not depend on the size of the maze in the large maze limit. Responsible for this behavior are rare events in the dataset which strongly regulate the shape of the cost function near this global minimum. We further identify an obstacle to learning in the form of poorly performing local minima in which the network chooses to ignore some of the inputs. We further support our claims with training experiments and numerical analysis of the cost function on networks with up to $128$ layers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A toy dataset based on critical percolation in a planar graph provides an analytical window to the training dynamics of deep neural networks  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Convolutional Networks, Loss function landscape, Graph Structured Data, Training Complexity, Theory of deep learning, Percolation theory, Anderson Localization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkNGsseC-">
      <h4>
        <a href="https://openreview.net/forum?id=HkNGsseC-">
          On the Expressive Power of Overlapping Architectures of Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HkNGsseC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=or.sharir%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="or.sharir@cs.huji.ac.il">Or Sharir</a>, <a href="https://openreview.net/profile?email=shashua%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shashua@cs.huji.ac.il">Amnon Shashua</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkNGsseC--details-870" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkNGsseC--details-870"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Expressive efficiency refers to the relation between two architectures A and B, whereby any function realized by B could be replicated by A, but there exists functions realized by A, which cannot be replicated by B unless its size grows significantly larger. For example, it is known that deep networks are exponentially efficient with respect to shallow networks, in the sense that a shallow network must grow exponentially large in order to approximate the functions represented by a deep network of polynomial size. In this work, we extend the study of expressive efficiency to the attribute of network connectivity and in particular to the effect of "overlaps" in the convolutional process, i.e., when the stride of the convolution is smaller than its filter size (receptive field).
      To theoretically analyze this aspect of network's design, we focus on a well-established surrogate for ConvNets called Convolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically that our results hold for standard ConvNets as well. Specifically, our analysis shows that having overlapping local receptive fields, and more broadly denser connectivity, results in an exponential increase in the expressive capacity of neural networks. Moreover, while denser connectivity can increase the expressive capacity, we show that the most common types of modern architectures already exhibit exponential increase in expressivity, without relying on fully-connected layers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We analyze how the degree of overlaps between the receptive fields of a convolutional network affects its expressive power.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Expressive Efficiency, Overlapping, Receptive Fields</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ94fqApW">
      <h4>
        <a href="https://openreview.net/forum?id=HJ94fqApW">
          Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ94fqApW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jxy198%40ist.psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jxy198@ist.psu.edu">Jianbo Ye</a>, <a href="https://openreview.net/profile?email=xinl%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinl@adobe.com">Xin Lu</a>, <a href="https://openreview.net/profile?email=zlin%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlin@adobe.com">Zhe Lin</a>, <a href="https://openreview.net/profile?email=jwang%40ist.psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwang@ist.psu.edu">James Z. Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ94fqApW-details-318" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ94fqApW-details-318"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model pruning has become a useful technique that improves the computational efficiency of deep learning, making it possible to deploy solutions in resource-limited scenarios. A widely-used practice in relevant work assumes that a smaller-norm parameter or feature plays a less informative role at the inference time. In this paper, we propose a channel pruning technique for accelerating the computations of deep convolutional neural networks (CNNs) that does not critically rely on this assumption. Instead, it focuses on direct simplification of the channel-to-channel computation graph of a CNN without the need of performing a computationally difficult and not-always-useful task of making high-dimensional tensors of CNN structured sparse. Our approach takes two stages: first to adopt an end-to-end stochastic training method that eventually forces the outputs of some channels to be constant, and then to prune those constant channels from the original neural network by adjusting the biases of their impacting layers such that the resulting compact model can be quickly fine-tuned. Our approach is mathematically appealing from an optimization perspective and easy to reproduce. We experimented our approach through several image learning benchmarks and demonstrate its interest- ing aspects and competitive performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A CNN model pruning method using ISTA and rescaling trick to enforce sparsity of scaling parameters in batch normalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">model pruning, batch normalization, convolutional neural network, ISTA</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJiHXGWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJiHXGWAZ">
          Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting
        </a>
        
          <a href="https://openreview.net/pdf?id=SJiHXGWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yaguang%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaguang@usc.edu">Yaguang Li</a>, <a href="https://openreview.net/profile?email=rose%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rose@caltech.edu">Rose Yu</a>, <a href="https://openreview.net/profile?email=shahabi%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shahabi@usc.edu">Cyrus Shahabi</a>, <a href="https://openreview.net/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJiHXGWAZ-details-116" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJiHXGWAZ-details-116"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Spatiotemporal forecasting has various applications in neuroscience, climate and transportation domain. Traffic forecasting is one canonical example of such learning task. The task is challenging due to (1) complex spatial dependency on road networks, (2) non-linear temporal dynamics with changing road conditions and (3) inherent difficulty of long-term forecasting. To address these challenges, we propose to model the traffic flow as a diffusion process on a directed graph and introduce Diffusion Convolutional Recurrent Neural Network (DCRNN), a deep learning framework for traffic forecasting that incorporates both spatial and temporal dependency in the traffic flow. Specifically, DCRNN captures the spatial dependency using bidirectional random walks on the graph, and the temporal dependency using the encoder-decoder architecture with scheduled sampling. We evaluate the framework on two real-world large-scale road network traffic datasets and observe consistent improvement of 12% - 15% over state-of-the-art baselines</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A neural sequence model that learns to forecast on a directed graph.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Traffic prediction, spatiotemporal forecasting, diffusion, graph convolution, random walk, long-term forecasting</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkHDoG-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=SkHDoG-Cb">
          Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings
        </a>
        
          <a href="https://openreview.net/pdf?id=SkHDoG-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kw1jjang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kw1jjang@gmail.com">Kangwook Lee</a>, <a href="https://openreview.net/profile?email=gnsrla12%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="gnsrla12@kaist.ac.kr">Hoon Kim</a>, <a href="https://openreview.net/profile?email=chsuh%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="chsuh@kaist.ac.kr">Changho Suh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkHDoG-Cb-details-408" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkHDoG-Cb-details-408"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Collecting a large dataset with high quality annotations is expensive and time-consuming. Recently, Shrivastava et al. (2017) propose Simulated+Unsupervised (S+U) learning: It first learns a mapping from synthetic data to real data, translates a large amount of labeled synthetic data to the ones that resemble real data, and then trains a learning model on the translated data. Bousmalis et al. (2017) propose a similar framework that jointly trains a translation mapping and a learning model. 
      While these algorithms are shown to achieve the state-of-the-art performances on various tasks, it may have a room for improvement, as they do not fully leverage flexibility of data simulation process and consider only the forward (synthetic to real) mapping. While these algorithms are shown to achieve the state-of-the-art performances on various tasks, it may have a room for improvement, as it does not fully leverage flexibility of data simulation process and consider only the forward (synthetic to real) mapping. Inspired by this limitation, we propose a new S+U learning algorithm, which fully leverage the flexibility  of  data  simulators and bidirectional mappings between synthetic data and real data. We show that our approach achieves the improved performance on the gaze estimation task, outperforming (Shrivastava et al., 2017).</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryH20GbRW">
      <h4>
        <a href="https://openreview.net/forum?id=ryH20GbRW">
          Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions
        </a>
        
          <a href="https://openreview.net/pdf?id=ryH20GbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sjoerd%40idsia.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjoerd@idsia.ch">Sjoerd van Steenkiste</a>, <a href="https://openreview.net/profile?email=mbchang%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbchang@berkeley.edu">Michael Chang</a>, <a href="https://openreview.net/profile?email=klaus%40idsia.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="klaus@idsia.ch">Klaus Greff</a>, <a href="https://openreview.net/profile?email=juergen%40idsia.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="juergen@idsia.ch">Jürgen Schmidhuber</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryH20GbRW-details-648" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryH20GbRW-details-648"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Common-sense physical reasoning is an essential ingredient for any intelligent agent operating in the real-world. For example, it can be used to simulate the environment, or to infer the state of parts of the world that are currently unobserved. In order to match real-world conditions this causal knowledge must be learned without access to supervised data. To address this problem we present a novel method that learns to discover objects and model their physical interactions from raw visual images in a purely unsupervised fashion. It incorporates prior knowledge about the compositional nature of human perception to factor interactions between object-pairs and learn efficiently. On videos of bouncing balls we show the superior modelling capabilities of our method compared to other unsupervised neural approaches that do not incorporate such prior knowledge. We demonstrate its ability to handle occlusion and show that it can extrapolate learned knowledge to scenes with different numbers of objects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a novel approach to common-sense physical reasoning that learns to discover objects and model their physical interactions from raw visual images in a purely unsupervised fashion</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Common-sense Physical Reasoning, Intuitive Physics, Representation Learning, Model building</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkCsm6lRb">
      <h4>
        <a href="https://openreview.net/forum?id=HkCsm6lRb">
          Generative Models of Visually Grounded Imagination
        </a>
        
          <a href="https://openreview.net/pdf?id=HkCsm6lRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vrama%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vrama@gatech.edu">Ramakrishna Vedantam</a>, <a href="https://openreview.net/profile?email=iansf%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iansf@google.com">Ian Fischer</a>, <a href="https://openreview.net/profile?email=jonathanhuang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonathanhuang@google.com">Jonathan Huang</a>, <a href="https://openreview.net/profile?email=murphyk%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="murphyk@gmail.com">Kevin Murphy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkCsm6lRb-details-212" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkCsm6lRb-details-212"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before. We call the ability to create images of novel semantic concepts visually grounded imagination. In this paper, we show how we can modify variational auto-encoders to perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C’s). Finally, we perform a detailed comparison of our method with two existing joint image-attribute VAE methods (the JMVAE method of Suzuki et al., 2017 and the BiVCCA method of Wang et al., 2016) by applying them to two datasets: the MNIST-with-attributes dataset (which we introduce here), and the CelebA dataset (Liu et al., 2015).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A VAE-variant which can create diverse images corresponding to novel concrete or abstract "concepts" described using attribute vectors.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">variational autoencoders, generative models, language, vision, abstraction, compositionality, hierarchy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1wEFyWCW">
      <h4>
        <a href="https://openreview.net/forum?id=r1wEFyWCW">
          Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions
        </a>
        
          <a href="https://openreview.net/pdf?id=r1wEFyWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=reedscot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="reedscot@google.com">Scott Reed</a>, <a href="https://openreview.net/profile?email=yutianc%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yutianc@google.com">Yutian Chen</a>, <a href="https://openreview.net/profile?email=tpaine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tpaine@google.com">Thomas Paine</a>, <a href="https://openreview.net/profile?email=avdnoord%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avdnoord@google.com">Aäron van den Oord</a>, <a href="https://openreview.net/profile?email=aeslami%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aeslami@google.com">S. M. Ali Eslami</a>, <a href="https://openreview.net/profile?email=danilor%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danilor@google.com">Danilo Rezende</a>, <a href="https://openreview.net/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>, <a href="https://openreview.net/profile?email=nandodefreitas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nandodefreitas@google.com">Nando de Freitas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1wEFyWCW-details-173" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1wEFyWCW-details-173"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep autoregressive models have shown state-of-the-art performance in density estimation for natural images on large-scale datasets such as ImageNet.  However, such models require many thousands of gradient-based weight updates and unique image examples for training. Ideally, the models would rapidly learn visual concepts from only a handful of examples, similar to the manner in which humans learns across many vision tasks.  In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation. Our proposed modifications to PixelCNN result in state-of-the art few-shot density estimation on the Omniglot dataset.  Furthermore, we visualize the learned attention policy and find that it learns intuitive algorithms for simple tasks such as image mirroring on ImageNet and handwriting on Omniglot without supervision. Finally, we extend the model to natural images and demonstrate few-shot image generation on the Stanford Online Products dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Few-shot learning PixelCNN</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">few-shot learning, density models, meta learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rknt2Be0-">
      <h4>
        <a href="https://openreview.net/forum?id=rknt2Be0-">
          Compositional Obverter Communication Learning from Raw Visual Input
        </a>
        
          <a href="https://openreview.net/pdf?id=rknt2Be0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mp2893%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mp2893@gatech.edu">Edward Choi</a>, <a href="https://openreview.net/profile?email=angeliki%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="angeliki@google.com">Angeliki Lazaridou</a>, <a href="https://openreview.net/profile?email=nandodefreitas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nandodefreitas@google.com">Nando de Freitas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 28 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rknt2Be0--details-580" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rknt2Be0--details-580"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the distinguishing aspects of human language is its compositionality, which allows us to describe complex environments with limited vocabulary. Previously, it has been shown that neural network agents can learn to communicate in a highly structured, possibly compositional language based on disentangled input (e.g. hand- engineered features). Humans, however, do not learn to communicate based on well-summarized features. In this work, we train neural agents to simultaneously develop visual perception from raw image pixels, and learn to communicate with a sequence of discrete symbols. The agents play an image description game where the image contains factors such as colors and shapes. We train the agents using the obverter technique where an agent introspects to generate messages that maximize its own understanding. Through qualitative analysis, visualization and a zero-shot test, we show that the agents can develop, out of raw image pixels, a language with compositional properties, given a proper pressure from the environment.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train neural network agents to develop a language with compositional properties from raw pixel input.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">compositional language, obverter, multi-agent communication, raw pixel input</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkN2Il-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkN2Il-RZ">
          SCAN: Learning Hierarchical Compositional Visual Concepts
        </a>
        
          <a href="https://openreview.net/pdf?id=rkN2Il-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=irinah%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="irinah@google.com">Irina Higgins</a>, <a href="https://openreview.net/profile?email=sonnerat%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sonnerat@google.com">Nicolas Sonnerat</a>, <a href="https://openreview.net/profile?email=lmatthey%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lmatthey@google.com">Loic Matthey</a>, <a href="https://openreview.net/profile?email=arkap%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arkap@google.com">Arka Pal</a>, <a href="https://openreview.net/profile?email=cpburgess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cpburgess@google.com">Christopher P Burgess</a>, <a href="https://openreview.net/profile?email=matko%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matko@google.com">Matko Bošnjak</a>, <a href="https://openreview.net/profile?email=mshanahan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mshanahan@google.com">Murray Shanahan</a>, <a href="https://openreview.net/profile?email=botvinick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botvinick@google.com">Matthew Botvinick</a>, <a href="https://openreview.net/profile?email=demishassabis%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="demishassabis@google.com">Demis Hassabis</a>, <a href="https://openreview.net/profile?email=lerchner%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lerchner@google.com">Alexander Lerchner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkN2Il-RZ-details-78" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkN2Il-RZ-details-78"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The seemingly infinite diversity of the natural world arises from a relatively small set of coherent rules, such as the laws of physics or chemistry. We conjecture that these rules give rise to regularities that can be discovered through primarily unsupervised experiences and represented as abstract concepts. If such representations are compositional and hierarchical, they can be recombined into an exponentially large set of new concepts. This paper describes SCAN (Symbol-Concept Association Network), a new framework for learning such abstractions in the visual domain. SCAN learns concepts through fast symbol association, grounding them in disentangled visual primitives that are discovered in an unsupervised manner. Unlike state of the art multimodal generative model baselines, our approach requires very few pairings between symbols and images and makes no assumptions about the form of symbol representations. Once trained, SCAN is capable of multimodal bi-directional inference, generating a diverse set of image samples from symbolic descriptions and vice versa. It also allows for traversal and manipulation of the implicit hierarchy of visual concepts through symbolic instructions and learnt logical recombination operations. Such manipulations enable SCAN to break away from its training data distribution and imagine novel visual concepts through symbolically instructed recombination of previously learnt concepts.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a neural variational model for learning language-guided compositional visual concepts.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">grounded visual concepts, compositional representation, concept hierarchy, disentangling, beta-VAE, variational autoencoder, deep learning, generative model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJCXZQbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJCXZQbAZ">
          Hierarchical Density Order Embeddings
        </a>
        
          <a href="https://openreview.net/pdf?id=HJCXZQbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pa338%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pa338@cornell.edu">Ben Athiwaratkun</a>, <a href="https://openreview.net/profile?email=andrew%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrew@cornell.edu">Andrew Gordon Wilson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJCXZQbAZ-details-434" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJCXZQbAZ-details-434"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">By representing words with probability densities rather than point vectors, proba- bilistic word embeddings can capture rich and interpretable semantic information and uncertainty (Vilnis &amp; McCallum, 2014; Athiwaratkun &amp; Wilson, 2017). The uncertainty information can be particularly meaningful in capturing entailment relationships – whereby general words such as “entity” correspond to broad distributions that encompass more specific words such as “animal” or “instrument”. We introduce density order embeddings, which learn hierarchical representations through encapsulation of probability distributions. In particular, we propose simple yet effective loss functions and distance metrics, as well as graph-based schemes to select negative samples to better learn hierarchical probabilistic representations. Our approach provides state-of-the-art performance on the WordNet hypernym relationship prediction task and the challenging HyperLex lexical entailment dataset – while retaining a rich and interpretable probabilistic representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">embeddings, word embeddings, probabilistic embeddings, hierarchical representation, probabilistic representation, order embeddings, wordnet, hyperlex</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkN_r2lR-">
      <h4>
        <a href="https://openreview.net/forum?id=BkN_r2lR-">
          Identifying Analogies Across Domains
        </a>
        
          <a href="https://openreview.net/pdf?id=BkN_r2lR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yedidh%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yedidh@fb.com">Yedid Hoshen</a>, <a href="https://openreview.net/profile?email=wolf%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wolf@fb.com">Lior Wolf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkN_r2lR--details-648" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkN_r2lR--details-648"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Identifying analogies across domains without supervision is a key task for artificial intelligence. Recent advances in cross domain image mapping have concentrated on translating images across domains. Although the progress made is impressive, the visual fidelity many times does not suffice for identifying the matching sample from the other domain. In this paper, we tackle this very task of finding exact analogies between datasets i.e. for every image from domain A find an analogous image in domain B. We present a matching-by-synthesis approach: AN-GAN, and show that it outperforms current techniques. We further show that the cross-domain mapping task can be broken into two parts: domain alignment and learning the mapping function. The tasks can be iteratively solved, and as the alignment is improved, the unsupervised translation function reaches quality comparable to full supervision. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Finding correspondences between domains by performing matching/mapping iterations</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised mapping, cross domain mapping</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B17JTOe0-">
      <h4>
        <a href="https://openreview.net/forum?id=B17JTOe0-">
          Emergence of grid-like representations by training recurrent neural networks to perform spatial localization
        </a>
        
          <a href="https://openreview.net/pdf?id=B17JTOe0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ccueva%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ccueva@gmail.com">Christopher J. Cueva</a>, <a href="https://openreview.net/profile?email=weixxpku%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weixxpku@gmail.com">Xue-Xin Wei</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B17JTOe0--details-155" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B17JTOe0--details-155"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Decades of research on the neural code underlying spatial navigation have revealed a diverse set of neural response properties. The Entorhinal Cortex (EC) of the mammalian brain contains a rich set of spatial correlates, including grid cells which encode space using tessellating patterns. However, the mechanisms and functional significance of these spatial representations remain largely mysterious. As a new way to understand these neural representations, we trained recurrent neural networks (RNNs) to perform navigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find that grid-like spatial response patterns emerge in trained networks, along with units that exhibit other spatial correlates, including border cells and band-like cells. All these different functional types of neurons have been observed experimentally. The order of the emergence of grid-like and border cells is also consistent with observations from developmental studies. Together, our results suggest that grid cells, border cells and others as observed in EC may be a natural solution for representing space efficiently given the predominant recurrent connections in the neural circuits.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">To our knowledge, this is the first study to show how neural representations of space, including grid-like cells and border cells as observed in the brain, could emerge from training a recurrent neural network to perform navigation tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural network, grid cell, neural representation of space</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJhIM0xAW">
      <h4>
        <a href="https://openreview.net/forum?id=HJhIM0xAW">
          Learning a neural response metric for retinal prosthesis
        </a>
        
          <a href="https://openreview.net/pdf?id=HJhIM0xAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nishalps%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nishalps@stanford.edu">Nishal P Shah</a>, <a href="https://openreview.net/profile?email=sasidhar%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sasidhar@stanford.edu">Sasidhar Madugula</a>, <a href="https://openreview.net/profile?email=ej%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ej@stanford.edu">EJ Chichilnisky</a>, <a href="https://openreview.net/profile?email=singer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="singer@google.com">Yoram Singer</a>, <a href="https://openreview.net/profile?email=shlens%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shlens@google.com">Jonathon Shlens</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJhIM0xAW-details-883" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJhIM0xAW-details-883"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Retinal prostheses for treating incurable blindness are designed to electrically stimulate surviving retinal neurons,  causing them to send artificial visual signals to the brain. However, electrical stimulation generally cannot precisely reproduce  normal patterns of neural activity in the retina. Therefore, an electrical stimulus must be selected that produces a neural response as close as possible to the desired response. This requires a technique for computing a distance between the desired response and the achievable response that is meaningful in terms of the visual signal being conveyed. Here we propose a method to learn such a metric on neural responses, directly from recorded light responses of a population of retinal ganglion cells (RGCs) in the primate retina. The learned metric produces a measure of similarity of RGC population responses that accurately reflects the similarity of the visual input. Using data from electrical stimulation experiments, we demonstrate that this metric may improve the performance of a prosthesis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Metric learning, Computational Neuroscience, Retina, Neural Prosthesis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJj6qGbRW">
      <h4>
        <a href="https://openreview.net/forum?id=BJj6qGbRW">
          Few-Shot Learning with Graph Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJj6qGbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vgsatorras%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vgsatorras@gmail.com">Victor Garcia Satorras</a>, <a href="https://openreview.net/profile?email=bruna%40cims.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bruna@cims.nyu.edu">Joan Bruna Estrach</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJj6qGbRW-details-689" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJj6qGbRW-details-689"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose to study the problem of few-shot learning with the prism of inference on a partially observed graphical model, constructed from a collection of input images whose label can be either observed or not. By assimilating generic message-passing inference algorithms with their neural-network counterparts, we define a graph neural network architecture that generalizes several of the recently proposed few-shot learning models. Besides providing improved numerical performance, our framework is easily extended to variants of few-shot learning, such as semi-supervised or active learning, demonstrating the ability of graph-based models to operate well on ‘relational’ tasks.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1nQvfgA-">
      <h4>
        <a href="https://openreview.net/forum?id=S1nQvfgA-">
          Semantically Decomposing the Latent Spaces of Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S1nQvfgA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cdonahue%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdonahue@ucsd.edu">Chris Donahue</a>, <a href="https://openreview.net/profile?email=zlipton%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlipton@cmu.edu">Zachary C. Lipton</a>, <a href="https://openreview.net/profile?email=abalsubr%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abalsubr@stanford.edu">Akshay Balsubramani</a>, <a href="https://openreview.net/profile?email=jmcauley%40cs.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmcauley@cs.ucsd.edu">Julian McAuley</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1nQvfgA--details-637" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1nQvfgA--details-637"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a new algorithm for training generative adversarial networks to jointly learn latent codes for both identities (e.g. individual humans) and observations (e.g. specific photographs). In practice, this means that by fixing the identity portion of latent codes, we can generate diverse images of the same subject, and by fixing the observation portion we can traverse the manifold of subjects while maintaining contingent aspects such as lighting and pose. Our algorithm features a pairwise training scheme in which each sample from the generator consists of two images with a common identity code. Corresponding samples from the real dataset consist of two distinct photographs of the same subject. In order to fool the discriminator, the generator must produce images that are both photorealistic, distinct, and appear to depict the same person. We augment both the DCGAN and BEGAN approaches with Siamese discriminators to accommodate pairwise training. Experiments with human judges and an off-the-shelf face verification system demonstrate our algorithm’s ability to generate convincing, identity-matched photographs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">SD-GANs disentangle latent codes according to known commonalities in a dataset (e.g. photographs depicting the same person).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">disentangled representations, generative adversarial networks, generative modeling, image synthesis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By-7dz-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=By-7dz-AZ">
          A Framework for the Quantitative Evaluation of Disentangled Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=By-7dz-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=s1668298%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="s1668298@ed.ac.uk">Cian Eastwood</a>, <a href="https://openreview.net/profile?email=ckiw%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ckiw@inf.ed.ac.uk">Christopher K. I. Williams</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By-7dz-AZ-details-477" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By-7dz-AZ-details-477"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent AI research has emphasised the importance of learning disentangled representations of the explanatory factors  behind data. Despite the growing interest in models which can learn such representations, visual inspection remains the standard evaluation metric. While various desiderata have been implied in recent definitions, it is currently unclear what exactly makes one disentangled representation better than another. In this work we propose a framework for the quantitative evaluation of disentangled representations when the ground-truth latent structure is available. Three criteria are explicitly defined and quantified to elucidate the quality of learnt representations and thus compare models on an equal basis. To illustrate the appropriateness of the framework, we employ it to compare quantitatively the representations learned by recent state-of-the-art models.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJcSzz-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJcSzz-CZ">
          Meta-Learning for Semi-Supervised Few-Shot Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=HJcSzz-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mren%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mren@cs.toronto.edu">Mengye Ren</a>, <a href="https://openreview.net/profile?email=eleni%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eleni@cs.toronto.edu">Eleni Triantafillou</a>, <a href="https://openreview.net/profile?email=sachinr%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sachinr@princeton.edu">Sachin Ravi</a>, <a href="https://openreview.net/profile?email=jsnell%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsnell@cs.toronto.edu">Jake Snell</a>, <a href="https://openreview.net/profile?email=kswersky%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kswersky@google.com">Kevin Swersky</a>, <a href="https://openreview.net/profile?email=jbt%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbt@mit.edu">Joshua B. Tenenbaum</a>, <a href="https://openreview.net/profile?email=hugolarochelle%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hugolarochelle@google.com">Hugo Larochelle</a>, <a href="https://openreview.net/profile?email=zemel%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zemel@cs.toronto.edu">Richard S. Zemel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 02 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJcSzz-CZ-details-0" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJcSzz-CZ-details-0"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In few-shot classification, we are interested in learning algorithms that train a classifier from only a handful of labeled examples. Recent progress in few-shot classification has featured meta-learning, in which a parameterized model for a learning algorithm is defined and trained on episodes representing different classification problems, each with a small labeled training set and its corresponding test set. In this work, we advance this few-shot classification paradigm towards a scenario where unlabeled examples are also available within each episode. We consider two situations: one where all unlabeled examples are assumed to belong to the same set of classes as the labeled examples of the episode, as well as the more challenging situation where examples from other distractor classes are also provided. To address this paradigm, we propose novel extensions of Prototypical Networks (Snell et al., 2017) that are augmented with the ability to use unlabeled examples when producing prototypes. These models are trained in an end-to-end way on episodes, to learn to leverage the unlabeled examples successfully. We evaluate these methods on versions of the Omniglot and miniImageNet benchmarks, adapted to this new framework augmented with unlabeled examples. We also propose a new split of ImageNet, consisting of a large set of classes, with a hierarchical structure. Our experiments confirm that our Prototypical Networks can learn to improve their predictions due to unlabeled examples, much like a semi-supervised algorithm would.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose novel extensions of Prototypical Networks that are augmented with the ability to use unlabeled examples when producing prototypes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Few-shot learning, semi-supervised learning, meta-learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1q-TM-AW">
      <h4>
        <a href="https://openreview.net/forum?id=H1q-TM-AW">
          A DIRT-T Approach to Unsupervised Domain Adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=H1q-TM-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ruishu%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruishu@stanford.edu">Rui Shu</a>, <a href="https://openreview.net/profile?email=buih%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="buih@google.com">Hung Bui</a>, <a href="https://openreview.net/profile?email=hirokaz2%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hirokaz2@stanford.edu">Hirokazu Narui</a>, <a href="https://openreview.net/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 19 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1q-TM-AW-details-926" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1q-TM-AW-details-926"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Domain adaptation refers to the problem of leveraging labeled data in a source domain to learn an accurate model in a target domain where labels are scarce or unavailable. A recent approach for finding a common representation of the two domains is via domain adversarial training (Ganin &amp; Lempitsky, 2015), which attempts to induce a feature extractor that matches the source and target feature distributions in some feature space. However, domain adversarial training faces two critical limitations: 1) if the feature extraction function has high-capacity, then feature distribution matching is a weak constraint, 2) in non-conservative domain adaptation (where no single classifier can perform well in both the source and target domains), training the model to do well on the source domain hurts performance on the target domain. In this paper, we address these issues through the lens of the cluster assumption, i.e., decision boundaries should not cross high-density data regions. We propose two novel and related models: 1) the Virtual Adversarial Domain Adaptation (VADA) model, which combines domain adversarial training with a penalty term that punishes the violation the cluster assumption; 2) the Decision-boundary Iterative Refinement Training with a Teacher (DIRT-T) model, which takes the VADA model as initialization and employs natural gradient steps to further minimize the cluster assumption violation. Extensive empirical results demonstrate that the combination of these two models significantly improve the state-of-the-art performance on the digit, traffic sign, and Wi-Fi recognition domain adaptation benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">SOTA on unsupervised domain adaptation by leveraging the cluster assumption.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">domain adaptation, unsupervised learning, semi-supervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1Dx7fbCW">
      <h4>
        <a href="https://openreview.net/forum?id=r1Dx7fbCW">
          Generalizing Across Domains via Cross-Gradient Training
        </a>
        
          <a href="https://openreview.net/pdf?id=r1Dx7fbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shivshankariitb%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shivshankariitb@gmail.com">Shiv Shankar*</a>, <a href="https://openreview.net/profile?email=viharipiratla%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="viharipiratla@gmail.com">Vihari Piratla*</a>, <a href="https://openreview.net/profile?email=soumen%40cse.iitb.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="soumen@cse.iitb.ac.in">Soumen Chakrabarti</a>, <a href="https://openreview.net/profile?email=sidch%40cse.iitb.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="sidch@cse.iitb.ac.in">Siddhartha Chaudhuri</a>, <a href="https://openreview.net/profile?email=pjyothi%40cse.iitb.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="pjyothi@cse.iitb.ac.in">Preethi Jyothi</a>, <a href="https://openreview.net/profile?email=sunita%40iitb.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="sunita@iitb.ac.in">Sunita Sarawagi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1Dx7fbCW-details-216" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1Dx7fbCW-details-216"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present CROSSGRAD , a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD jointly trains a label and a domain classifier on examples perturbed by loss gradients of each other’s objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that
       (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and 
      (2) data augmentation is a more stable and accurate method than domain adversarial training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Domain guided augmentation of data provides a robust and stable method of domain generalization</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">domain generalization, domain adaptation, adversarial learning, adversarial examples</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByRWCqvT-">
      <h4>
        <a href="https://openreview.net/forum?id=ByRWCqvT-">
          Learning to cluster in order to transfer across domains and tasks
        </a>
        
          <a href="https://openreview.net/pdf?id=ByRWCqvT-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yenchang.hsu%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yenchang.hsu@gatech.edu">Yen-Chang Hsu</a>, <a href="https://openreview.net/profile?email=zhaoyang.lv%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaoyang.lv@gatech.edu">Zhaoyang Lv</a>, <a href="https://openreview.net/profile?email=zkira%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkira@gatech.edu">Zsolt Kira</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByRWCqvT--details-621" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByRWCqvT--details-621"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces a novel method to perform transfer learning across domains and tasks, formulating it as a problem of learning to cluster. The key insight is that, in addition to features, we can transfer similarity information and this is sufficient to learn a similarity function and clustering network to perform both domain adaptation and cross-task transfer learning. We begin by reducing categorical information to pairwise constraints, which only considers whether two instances belong to the same class or not (pairwise semantic similarity). This similarity is category-agnostic and can be learned from data in the source domain using a similarity network. We then present two novel approaches for performing transfer learning using this similarity function. First, for unsupervised domain adaptation, we design a new loss function to regularize classification with a constrained clustering loss, hence learning a clustering network with the transferred similarity metric generating the training inputs. Second, for cross-task learning (i.e., unsupervised clustering with unseen categories), we propose a framework to reconstruct and estimate the number of semantic clusters, again using the clustering network. Since the similarity network is noisy, the key is to use a robust clustering algorithm, and we show that our formulation is more robust than the alternative constrained and unconstrained clustering approaches. Using this method, we first show state of the art results for the challenging cross-task problem, applied on Omniglot and ImageNet. Our results show that we can reconstruct semantic clusters with high accuracy. We then evaluate the performance of cross-domain transfer using images from the Office-31 and SVHN-MNIST tasks and present top accuracy on both datasets.  Our approach doesn't explicitly deal with domain discrepancy. If we combine with a domain adaptation loss, it shows further improvement.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A learnable clustering objective to facilitate transfer learning across domains and tasks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">transfer learning, similarity prediction, clustering, domain adaptation, unsupervised learning, computer vision, deep learning, constrained clustering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1T2hmZAb">
      <h4>
        <a href="https://openreview.net/forum?id=H1T2hmZAb">
          Deep Complex Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H1T2hmZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chiheb.trabelsi%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="chiheb.trabelsi@polymtl.ca">Chiheb Trabelsi</a>, <a href="https://openreview.net/profile?email=olexa.bilaniuk%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="olexa.bilaniuk@umontreal.ca">Olexa Bilaniuk</a>, <a href="https://openreview.net/profile?email=ying.zhang%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ying.zhang@umontreal.ca">Ying Zhang</a>, <a href="https://openreview.net/profile?email=serdyuk%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="serdyuk@iro.umontreal.ca">Dmitriy Serdyuk</a>, <a href="https://openreview.net/profile?email=sandeep.subramanian.1%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="sandeep.subramanian.1@umontreal.ca">Sandeep Subramanian</a>, <a href="https://openreview.net/profile?email=jfsantos%40emt.inrs.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfsantos@emt.inrs.ca">Joao Felipe Santos</a>, <a href="https://openreview.net/profile?email=soroush.mehri%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="soroush.mehri@microsoft.com">Soroush Mehri</a>, <a href="https://openreview.net/profile?email=negar%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="negar@elementai.com">Negar Rostamzadeh</a>, <a href="https://openreview.net/profile?email=yoshua.bengio%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@umontreal.ca">Yoshua Bengio</a>, <a href="https://openreview.net/profile?email=christopher.pal%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="christopher.pal@polymtl.ca">Christopher J Pal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1T2hmZAb-details-37" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1T2hmZAb-details-37"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">At present, the vast majority of building blocks, techniques, and architectures for deep learning are based on real-valued operations and representations. However, recent work on recurrent neural networks and older fundamental theoretical analysis suggests that complex numbers could have a richer representational capacity and could also facilitate noise-robust memory retrieval mechanisms. Despite their attractive properties and potential for opening up entirely new neural architectures, complex-valued deep neural networks have been marginalized due to the absence of the building blocks required to design such models. In this work, we provide the key atomic components for complex-valued deep neural networks and apply them to convolutional feed-forward networks. More precisely, we rely on complex convolutions and present algorithms for complex batch-normalization, complex weight initialization strategies for complex-valued neural nets and we use them in experiments with end-to-end training schemes. We demonstrate that such complex-valued models are competitive with their real-valued counterparts. We test deep complex models on several computer vision tasks, on music transcription using the MusicNet dataset and on Speech spectrum prediction using TIMIT. We achieve state-of-the-art performance on these audio-related tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, complex-valued neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkwBEMWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HkwBEMWCZ">
          Skip Connections Eliminate Singularities
        </a>
        
          <a href="https://openreview.net/pdf?id=HkwBEMWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aeminorhan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aeminorhan@gmail.com">Emin Orhan</a>, <a href="https://openreview.net/profile?email=xaq%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xaq@rice.edu">Xaq Pitkow</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkwBEMWCZ-details-629" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkwBEMWCZ-details-629"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Skip connections made the training of very deep networks possible and have become an indispensable component in a variety of neural architectures. A completely satisfactory explanation for their success remains elusive. Here, we present a novel explanation for the benefits of skip connections in training very deep networks. The difficulty of training deep networks is partly due to the singularities caused by the non-identifiability of the model. Several such singularities have been identified in previous works: (i) overlap singularities caused by the permutation symmetry of nodes in a given layer, (ii) elimination singularities corresponding to the elimination, i.e. consistent deactivation, of nodes, (iii) singularities generated by the linear dependence of the nodes. These singularities cause degenerate manifolds in the loss landscape that slow down learning. We argue that skip connections eliminate these singularities by breaking the permutation symmetry of nodes, by reducing the possibility of node elimination and by making the nodes less linearly dependent. Moreover, for typical initializations, skip connections move the network away from the "ghosts" of these singularities and sculpt the landscape around them to alleviate the learning slow-down. These hypotheses are supported by evidence from simplified models, as well as from experiments with deep networks trained on real-world datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Degenerate manifolds arising from the non-identifiability of the model slow down learning in deep networks; skip connections help by breaking degeneracies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, optimization, skip connections</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1cWzoxA-">
      <h4>
        <a href="https://openreview.net/forum?id=H1cWzoxA-">
          Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling
        </a>
        
          <a href="https://openreview.net/pdf?id=H1cWzoxA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tao.shen%40student.uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="tao.shen@student.uts.edu.au">Tao Shen</a>, <a href="https://openreview.net/profile?email=tianyizh%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianyizh@uw.edu">Tianyi Zhou</a>, <a href="https://openreview.net/profile?email=guodong.long%40uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="guodong.long@uts.edu.au">Guodong Long</a>, <a href="https://openreview.net/profile?email=jing.jiang%40uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="jing.jiang@uts.edu.au">Jing Jiang</a>, <a href="https://openreview.net/profile?email=chengqi.zhang%40uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="chengqi.zhang@uts.edu.au">Chengqi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1cWzoxA--details-892" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1cWzoxA--details-892"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks (RNN), convolutional neural networks (CNN) and self-attention networks (SAN) are commonly used to produce context-aware representations. RNN can capture long-range dependency but is hard to parallelize and not time-efficient. CNN focuses on local dependency but does not perform well on some tasks. SAN can model both such dependencies via highly parallelizable computation, but memory requirement grows rapidly in line with sequence length. In this paper, we propose a model, called "bi-directional block self-attention network (Bi-BloSAN)", for RNN/CNN-free sequence encoding. It requires as little memory as RNN but with all the merits of SAN. Bi-BloSAN splits the entire sequence into blocks, and applies an intra-block SAN to each block for modeling local context, then applies an inter-block SAN to the outputs for all blocks to capture long-range dependency. Thus, each SAN only needs to process a short sequence, and only a small amount of memory is required. Additionally, we use feature-level attention to handle the variation of contexts around the same word, and use forward/backward masks to encode temporal order information. On nine benchmark datasets for different NLP tasks, Bi-BloSAN achieves or improves upon state-of-the-art accuracy, and shows better efficiency-memory trade-off than existing RNN/CNN/SAN. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A self-attention network for RNN/CNN-free sequence encoding with small memory consumption, highly parallelizable computation and state-of-the-art performance on several NLP tasks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, attention mechanism, sequence modeling, natural language processing, sentence embedding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry8dvM-R-">
      <h4>
        <a href="https://openreview.net/forum?id=ry8dvM-R-">
          Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=ry8dvM-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=crosenbaum%40umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="crosenbaum@umass.edu">Clemens Rosenbaum</a>, <a href="https://openreview.net/profile?email=tklinger%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tklinger@us.ibm.com">Tim Klinger</a>, <a href="https://openreview.net/profile?email=mdriemer%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mdriemer@us.ibm.com">Matthew Riemer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry8dvM-R--details-4" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry8dvM-R--details-4"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Multi-task learning (MTL) with neural networks leverages commonalities in tasks to improve performance, but often suffers from task interference which reduces the benefits of transfer. To address this issue we introduce the routing network paradigm, a novel neural network and training algorithm. A routing network is a kind of self-organizing neural network consisting of two components: a router and a set of one or more function blocks. A function block may be any neural network – for example a fully-connected or a convolutional layer. Given an input the router makes a routing decision, choosing a function block to apply and passing the output back to the router recursively, terminating when a fixed recursion depth is reached. In this way the routing network dynamically composes different function blocks for each input. We employ a collaborative multi-agent reinforcement learning (MARL) approach to jointly train the router and function blocks. We evaluate our model against cross-stitch networks and shared-layer baselines on multi-task settings of the MNIST, mini-imagenet, and CIFAR-100 datasets. Our experiments demonstrate a significant improvement in accuracy, with sharper convergence. In addition, routing networks have nearly constant per-task training cost while cross-stitch networks scale linearly with the number of tasks. On CIFAR100 (20 tasks) we obtain cross-stitch performance levels with an 85% average reduction in training time.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">routing networks: a new kind of neural network which learns to adaptively route its input for multi-task learning</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-task, transfer, routing, marl, multi-agent, reinforcement, self-organizing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkhlb8lCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkhlb8lCZ">
          Wavelet Pooling for Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rkhlb8lCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tlwilli3%40aggies.ncat.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tlwilli3@aggies.ncat.edu">Travis Williams</a>, <a href="https://openreview.net/profile?email=eeli%40ncat.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eeli@ncat.edu">Robert Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkhlb8lCZ-details-289" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkhlb8lCZ-details-289"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional Neural Networks continuously advance the progress of 2D and 3D image and object classification. The steadfast usage of this algorithm requires constant evaluation and upgrading of foundational concepts to maintain progress. Network regularization techniques typically focus on convolutional layer operations, while leaving pooling layer operations without suitable options. We introduce Wavelet Pooling as another alternative to traditional neighborhood pooling. This method decomposes features into a second level decomposition, and discards the first-level subbands to reduce feature dimensions. This method addresses the overfitting problem encountered by max pooling, while reducing features in a more structurally compact manner than pooling via neighborhood regions. Experimental results on four benchmark classification datasets demonstrate our proposed method outperforms or performs comparatively with methods like max, mean, mixed, and stochastic pooling. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Pooling is achieved using wavelets instead of traditional neighborhood approaches (max, average, etc).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Pooling, Wavelet, CNN, Neural Network, Deep Learning, Classification, Machine Learning, Object Recognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ1Xmf-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=SJ1Xmf-Rb">
          FearNet: Brain-Inspired Model for Incremental Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ1Xmf-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rmk6217%40rit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rmk6217@rit.edu">Ronald Kemker</a>, <a href="https://openreview.net/profile?email=kanan%40rit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kanan@rit.edu">Christopher Kanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ1Xmf-Rb-details-258" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ1Xmf-Rb-details-258"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting. Arguably, the best method for incremental class learning is iCaRL, but it requires storing  training examples for each class, making it challenging to scale. Here, we propose FearNet for incremental class learning. FearNet is a generative model that does not store previous examples, making it memory efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall.  FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Incremental Learning, Lifelong Learning, Supervised Learning, Catastrophic Forgetting, Brain-Inspired, Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJehNfW0-">
      <h4>
        <a href="https://openreview.net/forum?id=BJehNfW0-">
          Do GANs learn the distribution? Some Theory and Empirics
        </a>
        
          <a href="https://openreview.net/pdf?id=BJehNfW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arora%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arora@cs.princeton.edu">Sanjeev Arora</a>, <a href="https://openreview.net/profile?email=risteski%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="risteski@cs.princeton.edu">Andrej Risteski</a>, <a href="https://openreview.net/profile?email=y.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.zhang@cs.princeton.edu">Yi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJehNfW0--details-199" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJehNfW0--details-199"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Do GANS (Generative Adversarial Nets) actually learn the target distribution? The foundational paper of Goodfellow et al. (2014) suggested they do, if they were given sufficiently large deep nets, sample size, and computation time. A recent theoretical analysis in Arora et al. (2017) raised doubts whether the same holds when discriminator has bounded size. It showed that the training objective can approach its optimum value even if the generated distribution has very low support. In other words, the training objective is unable to prevent mode collapse. The current paper makes two contributions. (1) It proposes a novel test for estimating support size using the birthday paradox of discrete probability. Using this  evidence is presented that well-known GANs approaches do learn distributions of fairly low support.  (2) It theoretically studies encoder-decoder GANs architectures (e.g., BiGAN/ALI), which were proposed to learn more meaningful features via GANs, and consequently to also solve the mode-collapse issue. Our result shows that such encoder-decoder training objectives also cannot guarantee learning of the full distribution because they cannot prevent serious mode collapse. More seriously, they cannot prevent learning meaningless codes for data, contrary to usual intuition.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a support size estimator of GANs's learned distribution to show they indeed suffer from mode collapse, and we prove that encoder-decoder GANs do not avoid the issue as well.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, mode collapse, birthday paradox, support size estimation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BydjJte0-">
      <h4>
        <a href="https://openreview.net/forum?id=BydjJte0-">
          Towards Reverse-Engineering Black-Box Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BydjJte0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joon%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="joon@mpi-inf.mpg.de">Seong Joon Oh</a>, <a href="https://openreview.net/profile?email=maxaug%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="maxaug@mpi-inf.mpg.de">Max Augustin</a>, <a href="https://openreview.net/profile?email=mfritz%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mfritz@mpi-inf.mpg.de">Mario Fritz</a>, <a href="https://openreview.net/profile?email=schiele%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="schiele@mpi-inf.mpg.de">Bernt Schiele</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BydjJte0--details-999" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BydjJte0--details-999"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many deployed learned models are black boxes: given input, returns output. Internal information about the model, such as the architecture, optimisation procedure, or training data, is not disclosed explicitly as it might contain proprietary information or make the system more vulnerable. This work shows that such attributes of neural networks can be exposed from a sequence of queries. This has multiple implications. On the one hand, our work exposes the vulnerability of black-box neural networks to different types of attacks -- we show that the revealed internal information helps generate more effective adversarial examples against the black box model. On the other hand, this technique can be used for better protection of private content from automatic recognition models using adversarial examples. Our paper suggests that it is actually hard to draw a line between white box and black box models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Querying a black-box neural network reveals a lot of information about it; we propose novel "metamodels" for effectively extracting information from a black box.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">black box, security, privacy, attack, metamodel, adversarial example, reverse-engineering, machine learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1J_rgWRW">
      <h4>
        <a href="https://openreview.net/forum?id=B1J_rgWRW">
          Understanding Deep Neural Networks with Rectified Linear Units
        </a>
        
          <a href="https://openreview.net/pdf?id=B1J_rgWRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arora%40cs.jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arora@cs.jhu.edu">Raman Arora</a>, <a href="https://openreview.net/profile?email=basu.amitabh%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="basu.amitabh@jhu.edu">Amitabh Basu</a>, <a href="https://openreview.net/profile?email=mianjy%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mianjy@jhu.edu">Poorya Mianjy</a>, <a href="https://openreview.net/profile?email=amukhe14%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amukhe14@jhu.edu">Anirbit Mukherjee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1J_rgWRW-details-973" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1J_rgWRW-details-973"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper we investigate the family of functions representable by deep neural networks (DNN) with rectified linear units (ReLU). We give an algorithm to train a ReLU DNN with one hidden layer to {\em global optimality} with runtime polynomial in the data size albeit exponential in the input dimension. Further, we improve on the known lower bounds on size (from exponential to super exponential) for approximating a ReLU deep net function by a shallower ReLU net. Our gap theorems hold for smoothly parametrized families of ``hard'' functions, contrary to countable, discrete families known in the literature.  An example consequence of our gap theorems is the following: for every natural number $k$ there exists a function representable by a ReLU DNN with $k^2$ hidden layers and total size $k^3$, such that any ReLU DNN with at most $k$ hidden layers will require at least $\frac12k^{k+1}-1$ total nodes. Finally, for the family of $\R^n\to \R$ DNNs with ReLU activations, we show a new lowerbound on the number of affine pieces, which is larger than previous constructions in certain regimes of the network architecture and most distinctively our lowerbound is demonstrated by an explicit construction of a \emph{smoothly parameterized} family of functions attaining this scaling. Our construction utilizes the theory of zonotopes from polyhedral theory.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper 1) characterizes functions representable by ReLU DNNs, 2) formally studies the benefit of depth in such architectures,  3) gives an algorithm to implement empirical risk minimization to global optimality for two layer ReLU nets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">expressive power, benefits of depth, empirical risk minimization, global optimality, computational hardness, combinatorial optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rytNfI1AZ">
      <h4>
        <a href="https://openreview.net/forum?id=rytNfI1AZ">
          Training wide residual networks for deployment using a single bit for each weight
        </a>
        
          <a href="https://openreview.net/pdf?id=rytNfI1AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mark.mcdonnell%40unisa.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="mark.mcdonnell@unisa.edu.au">Mark D. McDonnell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rytNfI1AZ-details-173" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rytNfI1AZ-details-173"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">For fast and energy-efficient deployment of trained deep neural networks on resource-constrained embedded hardware,  each learned weight parameter should ideally be represented and stored using a single bit.  Error-rates usually increase when this requirement is imposed. Here, we report large improvements in error rates on multiple datasets, for deep convolutional neural networks deployed with 1-bit-per-weight. Using wide residual networks as our main baseline, our approach simplifies existing methods that binarize weights by applying the sign function in training; we apply  scaling factors for each layer with constant unlearned values equal to the layer-specific standard deviations used for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with 1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve error rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We also considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test results of 0.27%, 1.9%, and 41.3% / 19.1%  respectively. For CIFAR, our error rates halve previously reported values, and are within about 1% of our error-rates for the same network with full-precision weights. For networks that overfit, we also show significant improvements in error rate by not learning batch normalization scale and offset parameters. This applies to both full precision and 1-bit-per-weight networks. Using a warm-restart learning-rate schedule, we found that training for 1-bit-per-weight is just as fast as full-precision networks, with better accuracy than standard schedules, and achieved about 98%-99% of peak performance in just 62 training epochs for CIFAR-10/100. For full training code and trained models in MATLAB, Keras and PyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train wide residual networks that can be immediately deployed using only a single bit for each convolutional weight, with signficantly better accuracy than past methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">wide residual networks, model compression, quantization, 1-bit weights</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyzbhfWRW">
      <h4>
        <a href="https://openreview.net/forum?id=HyzbhfWRW">
          Learn to Pay Attention
        </a>
        
          <a href="https://openreview.net/pdf?id=HyzbhfWRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=saumya.jetley%40stx.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="saumya.jetley@stx.ox.ac.uk">Saumya Jetley</a>, <a href="https://openreview.net/profile?email=nicklord%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicklord@robots.ox.ac.uk">Nicholas A. Lord</a>, <a href="https://openreview.net/profile?email=namhoon.lee%40eng.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="namhoon.lee@eng.ox.ac.uk">Namhoon Lee</a>, <a href="https://openreview.net/profile?email=philip.torr%40eng.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="philip.torr@eng.ox.ac.uk">Philip H. S. Torr</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyzbhfWRW-details-549" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyzbhfWRW-details-549"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose an end-to-end-trainable attention module for convolutional neural network (CNN) architectures built for image classification. The module takes as input the 2D feature vector maps which form the intermediate representations of the input image at different stages in the CNN pipeline, and outputs a 2D matrix of scores for each map. Standard CNN architectures are modified through the incorporation of this module, and trained under the constraint that a convex combination of the intermediate 2D feature vectors, as parametrised by the score matrices, must alone be used for classification. Incentivised to amplify the relevant and suppress the irrelevant or misleading, the scores thus assume the role of attention values. Our experimental observations provide clear evidence to this effect: the learned attention maps neatly highlight the regions of interest while suppressing background clutter. Consequently, the proposed function is able to bootstrap standard CNN architectures for the task of image classification, demonstrating superior generalisation over 6 unseen benchmark datasets. When binarised, our attention maps outperform other CNN-based attention maps, traditional saliency maps, and top object proposals for weakly supervised segmentation as demonstrated on the Object Discovery dataset. We also demonstrate improved robustness against the fast gradient sign method of adversarial attack.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper proposes a method for forcing CNNs to leverage spatial attention in learning more object-centric representations that perform better in various respects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, attention-aware representations, image classification, weakly supervised segmentation, domain shift, classifier generalisation, robustness to adversarial attack</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hko85plCW">
      <h4>
        <a href="https://openreview.net/forum?id=Hko85plCW">
          Monotonic Chunkwise Attention
        </a>
        
          <a href="https://openreview.net/pdf?id=Hko85plCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chungchengc%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chungchengc@google.com">Chung-Cheng Chiu*</a>, <a href="https://openreview.net/profile?email=craffel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="craffel@gmail.com">Colin Raffel*</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hko85plCW-details-764" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hko85plCW-details-764"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Sequence-to-sequence models with soft attention have been successfully applied to a wide variety of problems, but their decoding process incurs a quadratic time and space cost and is inapplicable to real-time sequence transduction. To address these issues, we propose Monotonic Chunkwise Attention (MoChA), which adaptively splits the input sequence into small chunks over which soft attention is computed. We show that models utilizing MoChA can be trained efficiently with standard backpropagation while allowing online and linear-time decoding at test time. When applied to online speech recognition, we obtain state-of-the-art results and match the performance of a model using an offline soft attention mechanism. In document summarization experiments where we do not expect monotonic alignments, we show significantly improved performance compared to a baseline monotonic attention-based model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An online and linear-time attention mechanism that performs soft attention over adaptively-located chunks of the input sequence.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">attention, sequence-to-sequence, speech recognition, document summarization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ_UL-k0b">
      <h4>
        <a href="https://openreview.net/forum?id=BJ_UL-k0b">
          Recasting Gradient-Based Meta-Learning as Hierarchical Bayes
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ_UL-k0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eringrant%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eringrant@berkeley.edu">Erin Grant</a>, <a href="https://openreview.net/profile?email=cbfinn%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbfinn@eecs.berkeley.edu">Chelsea Finn</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>, <a href="https://openreview.net/profile?email=trevor%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="trevor@eecs.berkeley.edu">Trevor Darrell</a>, <a href="https://openreview.net/profile?email=tom_griffiths%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom_griffiths@berkeley.edu">Thomas Griffiths</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ_UL-k0b-details-895" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ_UL-k0b-details-895"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al. (2017) as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identification of MAML as hierarchical Bayes provides a way to understand the algorithm’s operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for efficient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A specific gradient-based meta-learning algorithm, MAML, is equivalent to an inference procedure in a hierarchical Bayesian model. We use this connection to improve MAML via methods from approximate inference and curvature estimation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meta-learning, learning to learn, hierarchical Bayes, approximate Bayesian methods</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1Yy1BxCZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1Yy1BxCZ">
          Don't Decay the Learning Rate, Increase the Batch Size
        </a>
        
          <a href="https://openreview.net/pdf?id=B1Yy1BxCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=slsmith%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slsmith@google.com">Samuel L. Smith</a>, <a href="https://openreview.net/profile?email=pikinder%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pikinder@google.com">Pieter-Jan Kindermans</a>, <a href="https://openreview.net/profile?email=chrisying%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrisying@google.com">Chris Ying</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1Yy1BxCZ-details-954" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1Yy1BxCZ-details-954"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\epsilon$ and scaling the batch size $B \propto \epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train ResNet-50 on ImageNet to 76.1% validation accuracy in under 30 minutes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Decaying the learning rate and increasing the batch size during training are equivalent.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">batch size, learning rate, simulated annealing, large batch training, scaling rules, stochastic gradient descent, sgd, imagenet, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyMTkQZAb">
      <h4>
        <a href="https://openreview.net/forum?id=HyMTkQZAb">
          Kronecker-factored Curvature Approximations for Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyMTkQZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=james.martens%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.martens@gmail.com">James Martens</a>, <a href="https://openreview.net/profile?email=jimmy%40psi.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jimmy@psi.toronto.edu">Jimmy Ba</a>, <a href="https://openreview.net/profile?email=mattjj%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mattjj@csail.mit.edu">Matt Johnson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyMTkQZAb-details-199" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyMTkQZAb-details-199"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Kronecker-factor Approximate Curvature (Martens &amp; Grosse, 2015) (K-FAC) is a 2nd-order optimization method which has been shown to give state-of-the-art performance on large-scale neural network optimization tasks (Ba et al., 2017).  It is based on an approximation to the Fisher information matrix (FIM) that makes assumptions about the particular structure of the network and the way it is parameterized. The original K-FAC method was applicable only to fully-connected networks, although it has been recently extended by Grosse &amp; Martens (2016) to handle convolutional networks as well. In this work we extend the method to handle RNNs by introducing a novel approximation to the FIM for RNNs. This approximation works by modelling the covariance structure between the gradient contributions at different time-steps using a chain-structured linear Gaussian graphical model, summing the various cross-covariances, and computing the inverse in closed form. We demonstrate in experiments that our method significantly outperforms general purpose state-of-the-art optimizers like SGD with momentum and Adam on several challenging RNN training tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We extend the K-FAC method to RNNs by developing a new family of Fisher approximations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimization, K-FAC, natural gradient, recurrent neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByeqORgAW">
      <h4>
        <a href="https://openreview.net/forum?id=ByeqORgAW">
          Proximal Backpropagation
        </a>
        
          <a href="https://openreview.net/pdf?id=ByeqORgAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thomas.frerix%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.frerix@tum.de">Thomas Frerix</a>, <a href="https://openreview.net/profile?email=thomas.moellenhoff%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.moellenhoff@in.tum.de">Thomas Möllenhoff</a>, <a href="https://openreview.net/profile?email=michael.moeller%40uni-siegen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.moeller@uni-siegen.de">Michael Moeller</a>, <a href="https://openreview.net/profile?email=cremers%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="cremers@tum.de">Daniel Cremers</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByeqORgAW-details-727" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByeqORgAW-details-727"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose proximal backpropagation (ProxProp) as a novel algorithm that takes implicit instead of explicit gradient steps to update the network parameters during neural network training. Our algorithm is motivated by the step size limitation of explicit gradient descent, which poses an impediment for optimization. ProxProp is developed from a general point of view on the backpropagation algorithm, currently the most common technique to train neural networks via stochastic gradient descent and variants thereof. Specifically, we show that backpropagation of a prediction error is equivalent to sequential gradient descent steps on a quadratic penalty energy, which comprises the network activations as variables of the optimization. We further analyze theoretical properties of ProxProp and in particular prove that the algorithm yields a descent direction in parameter space and can therefore be combined with a wide variety of convergent algorithms. Finally, we devise an efficient numerical implementation that integrates well with popular deep learning frameworks. We conclude by demonstrating promising numerical results and show that ProxProp can be effectively combined with common first order optimizers such as Adam.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkLyJl-0-">
      <h4>
        <a href="https://openreview.net/forum?id=rkLyJl-0-">
          Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rkLyJl-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=skrishnan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skrishnan@google.com">Shankar Krishnan</a>, <a href="https://openreview.net/profile?email=yingxiao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yingxiao@google.com">Ying Xiao</a>, <a href="https://openreview.net/profile?email=rif%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rif@google.com">Rif. A. Saurous</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 17 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkLyJl-0--details-10" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkLyJl-0--details-10"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Progress in deep learning is slowed by the days or weeks it takes to train large models. The natural solution of using more hardware is limited by diminishing returns, and leads to inefficient use of additional resources. In this paper, we present a large batch, stochastic optimization algorithm that is both faster than widely used algorithms for fixed amounts of computation, and also scales up substantially better as more computational resources become available. Our algorithm implicitly computes the inverse Hessian of each mini-batch to produce descent directions; we do so without either an explicit approximation to the Hessian or Hessian-vector products. We demonstrate the effectiveness of our algorithm by successfully training large ImageNet models (InceptionV3, ResnetV1-50, ResnetV1-101 and InceptionResnetV2) with mini-batch sizes of up to 32000 with no loss in validation error relative to current baselines, and no increase in the total number of steps. At smaller mini-batch sizes, our optimizer improves the validation error in these models by 0.8-0.9\%. Alternatively, we can trade off this accuracy to reduce the number of training steps needed by roughly 10-30\%. Our work is practical and easily usable by others -- only one hyperparameter (learning rate) needs tuning, and furthermore, the algorithm is as computationally cheap as the commonly used Adam optimizer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe a practical optimization algorithm for deep neural networks that works faster and generates better models compared to widely used algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ33wwxRb">
      <h4>
        <a href="https://openreview.net/forum?id=rJ33wwxRb">
          SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ33wwxRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alonbrutzkus%40mail.tau.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="alonbrutzkus@mail.tau.ac.il">Alon Brutzkus</a>, <a href="https://openreview.net/profile?email=amir.globerson%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amir.globerson@gmail.com">Amir Globerson</a>, <a href="https://openreview.net/profile?email=eran.malach%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="eran.malach@mail.huji.ac.il">Eran Malach</a>, <a href="https://openreview.net/profile?email=shais%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shais@cs.huji.ac.il">Shai Shalev-Shwartz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ33wwxRb-details-22" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ33wwxRb-details-22"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks exhibit good generalization behavior in the
      over-parameterized regime, where the number of network parameters
      exceeds the number of observations. Nonetheless,
      current generalization bounds for neural networks fail to explain this
      phenomenon. In an attempt to bridge this gap, we study the problem of
      learning a two-layer over-parameterized neural network, when the data is generated by a linearly separable function. In the case where the network has Leaky
      ReLU activations, we provide both optimization and generalization guarantees for over-parameterized networks.
      Specifically, we prove convergence rates of SGD to a global
      minimum and provide generalization guarantees for this global minimum
      that are independent of the network size. 
      Therefore, our result clearly shows that the use of SGD for optimization both finds a global minimum, and avoids overfitting despite the high capacity of the model. This is the first theoretical demonstration that SGD can avoid overfitting, when learning over-specified neural network classifiers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that SGD learns two-layer over-parameterized neural networks with Leaky ReLU activations that provably generalize on linearly separable data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Non-convex Optmization, Generalization, Learning Theory, Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skz_WfbCZ">
      <h4>
        <a href="https://openreview.net/forum?id=Skz_WfbCZ">
          A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Skz_WfbCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bneyshabur%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bneyshabur@ttic.edu">Behnam Neyshabur</a>, <a href="https://openreview.net/profile?email=srinadh%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srinadh@ttic.edu">Srinadh Bhojanapalli</a>, <a href="https://openreview.net/profile?email=nati%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nati@ttic.edu">Nathan Srebro</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skz_WfbCZ-details-215" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skz_WfbCZ-details-215"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a generalization bound for feedforward neural networks in terms of the product of the spectral norm of the layers and the Frobenius norm of the weights.  The generalization bound is derived using a PAC-Bayes analysis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Networks, Generalization, PAC-Bayes, Sharpness</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1iuQjxCZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1iuQjxCZ">
          On the importance of single directions for generalization
        </a>
        
          <a href="https://openreview.net/pdf?id=r1iuQjxCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arimorcos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arimorcos@google.com">Ari S. Morcos</a>, <a href="https://openreview.net/profile?email=barrettdavid%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="barrettdavid@google.com">David G.T. Barrett</a>, <a href="https://openreview.net/profile?email=ncr%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ncr@google.com">Neil C. Rabinowitz</a>, <a href="https://openreview.net/profile?email=botvinick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botvinick@google.com">Matthew Botvinick</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 May 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1iuQjxCZ-details-244" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1iuQjxCZ-details-244"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite their ability to memorize large datasets, deep neural networks often achieve good generalization performance. However, the differences between the learned solutions of networks which generalize and those which do not remain unclear. Additionally, the tuning properties of single directions (defined as the activation of a single unit or some linear combination of units in response to some input) have been highlighted, but their importance has not been evaluated. Here, we connect these lines of inquiry to demonstrate that a network’s reliance on single directions is a good predictor of its generalization performance, across networks trained on datasets with different fractions of corrupted labels, across ensembles of networks trained on datasets with unmodified labels, across different hyper- parameters, and over the course of training. While dropout only regularizes this quantity up to a point, batch normalization implicitly discourages single direction reliance, in part by decreasing the class selectivity of individual units. Finally, we find that class selectivity is a poor predictor of task importance, suggesting not only that networks which generalize well minimize their dependence on individual units by reducing their selectivity, but also that individually selective units may not be necessary for strong network performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We find that deep networks which generalize poorly are more reliant on single directions than those that generalize well, and evaluate the impact of dropout and batch normalization, as well as class selectivity on single direction reliance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generalization, analysis, deep learning, selectivity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1q7n9gAb">
      <h4>
        <a href="https://openreview.net/forum?id=r1q7n9gAb">
          The Implicit Bias of Gradient Descent on Separable Data
        </a>
        
          <a href="https://openreview.net/pdf?id=r1q7n9gAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daniel.soudry%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.soudry@gmail.com">Daniel Soudry</a>, <a href="https://openreview.net/profile?email=elad.hoffer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="elad.hoffer@gmail.com">Elad Hoffer</a>, <a href="https://openreview.net/profile?email=mor.shpigel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mor.shpigel@gmail.com">Mor Shpigel Nacson</a>, <a href="https://openreview.net/profile?email=nati%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nati@ttic.edu">Nathan Srebro</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1q7n9gAb-details-116" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1q7n9gAb-details-116"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We show that gradient descent on an unregularized logistic regression
      problem, for almost all separable datasets, converges to the same direction as the max-margin solution. The result generalizes also to other monotone decreasing loss functions with an infimum at infinity, and we also discuss a multi-class generalizations to the cross entropy loss. Furthermore,
      we show this convergence is very slow, and only logarithmic in the
      convergence of the loss itself. This can help explain the benefit
      of continuing to optimize the logistic or cross-entropy loss even
      after the training error is zero and the training loss is extremely
      small, and, as we show, even if the validation loss increases. Our
      methodology can also aid in understanding implicit regularization
      in more complex models and with other optimization methods. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The normalized solution of gradient descent on logistic regression (or a similarly decaying loss) slowly converges to the L2 max margin solution on separable data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">gradient descent, implicit regularization, generalization, margin, logistic regression, loss functions, optimization, exponential tail, cross-entropy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByQpn1ZA-">
      <h4>
        <a href="https://openreview.net/forum?id=ByQpn1ZA-">
          Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step
        </a>
        
          <a href="https://openreview.net/pdf?id=ByQpn1ZA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=liam.fedus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liam.fedus@gmail.com">William Fedus*</a>, <a href="https://openreview.net/profile?email=mihaelacr%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mihaelacr@google.com">Mihaela Rosca*</a>, <a href="https://openreview.net/profile?email=balajiln%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="balajiln@google.com">Balaji Lakshminarayanan</a>, <a href="https://openreview.net/profile?email=adai%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adai@google.com">Andrew M. Dai</a>, <a href="https://openreview.net/profile?email=shakir%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shakir@google.com">Shakir Mohamed</a>, <a href="https://openreview.net/profile?email=goodfellow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goodfellow@google.com">Ian Goodfellow</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByQpn1ZA--details-357" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByQpn1ZA--details-357"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial networks (GANs) are a family of generative models that do not minimize a single training criterion. Unlike other generative models, the data distribution is learned via a game between a generator (the generative model) and a discriminator (a teacher providing training signal) that each minimize their own cost. GANs are designed to reach a Nash equilibrium at which each player cannot reduce their cost without changing the other players’ parameters. One useful approach for the theory of GANs is to show that a divergence between the training distribution and the model distribution obtains its minimum value at equilibrium. Several recent research directions have been motivated by the idea that this divergence is the primary guide for the learning process and that every step of learning should decrease the divergence. We show that this view is overly restrictive. During GAN training, the discriminator provides learning signal in situations where the gradients of the divergences between distributions would not be useful. We provide empirical counterexamples to the view of GAN training as divergence minimization. Specifically, we demonstrate that GANs are able to learn distributions in situations where the divergence minimization point of view predicts they would fail. We also show that gradient penalties motivated from the divergence minimization perspective are equally helpful when applied in other contexts in which the divergence minimization perspective does not predict they would be helpful. This contributes to a growing body of evidence that GAN training may be more usefully viewed as approaching Nash equilibria via trajectories that do not necessarily minimize a specific divergence at each step.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We find evidence that divergence minimization may not be an accurate characterization of GAN training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, GAN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1uxsye0Z">
      <h4>
        <a href="https://openreview.net/forum?id=S1uxsye0Z">
          Adaptive Dropout with Rademacher Complexity Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=S1uxsye0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhaikedavy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaikedavy@gmail.com">Ke Zhai</a>, <a href="https://openreview.net/profile?email=joyousprince%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joyousprince@gmail.com">Huan Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1uxsye0Z-details-445" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1uxsye0Z-details-445"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel framework to adaptively adjust the dropout rates for the deep neural network based on a Rademacher complexity bound. The state-of-the-art deep learning algorithms impose dropout strategy to prevent feature co-adaptation. However, choosing the dropout rates remains an art of heuristics or relies on empirical grid-search over some hyperparameter space. In this work, we show the network Rademacher complexity is bounded by a function related to the dropout rate vectors and the weight coefficient matrices. Subsequently, we impose this bound as a regularizer and provide a theoretical justified way to trade-off between model complexity and representation power. Therefore, the dropout rates and the empirical loss are unified into the same objective function, which is then optimized using the block coordinate descent algorithm. We discover that the adaptively adjusted dropout rates converge to some interesting distributions that reveal meaningful patterns.Experiments on the task of image and document classification also show our method achieves better performance compared to the state-of the-art dropout algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel framework to adaptively adjust the dropout rates for the deep neural network based on a Rademacher complexity bound.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">model complexity, regularization, deep learning, model generalization, adaptive dropout</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJij4yg0Z">
      <h4>
        <a href="https://openreview.net/forum?id=BJij4yg0Z">
          A Bayesian Perspective on Generalization and Stochastic Gradient Descent
        </a>
        
          <a href="https://openreview.net/pdf?id=BJij4yg0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=slsmith%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slsmith@google.com">Samuel L. Smith and Quoc V. Le</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJij4yg0Z-details-688" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJij4yg0Z-details-688"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider two questions at the heart of machine learning; how can we predict if a minimum will generalize to the test set, and why does stochastic gradient descent find minima that generalize well? Our work responds to \citet{zhang2016understanding}, who showed deep neural networks can easily memorize randomly labeled training data, despite generalizing well on real labels of the same inputs. We show that the same phenomenon occurs in small linear models. These observations are explained by the Bayesian evidence, which penalizes sharp minima but is invariant to model parameterization. We also demonstrate that, when one holds the learning rate fixed, there is an optimum batch size which maximizes the test set accuracy. We propose that the noise introduced by small mini-batches drives the parameters towards minima whose evidence is large. Interpreting stochastic gradient descent as a stochastic differential equation, we identify the ``noise scale" $g = \epsilon (\frac{N}{B} - 1) \approx \epsilon N/B$, where $\epsilon$ is the learning rate, $N$ the training set size and $B$ the batch size. Consequently the optimum batch size is proportional to both the learning rate and the size of the training set, $B_{opt} \propto \epsilon N$. We verify these predictions empirically.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Generalization is strongly correlated with the Bayesian evidence, and gradient noise drives SGD towards minima whose evidence is large.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generalization, stochastic gradient descent, stochastic differential equations, scaling rules, large batch training, bayes theorem, batch size</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyELrEeAb">
      <h4>
        <a href="https://openreview.net/forum?id=SyELrEeAb">
          Implicit Causal Models for Genome-wide Association Studies
        </a>
        
          <a href="https://openreview.net/pdf?id=SyELrEeAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dustin%40cs.columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dustin@cs.columbia.edu">Dustin Tran</a>, <a href="https://openreview.net/profile?email=david.blei%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.blei@columbia.edu">David M. Blei</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyELrEeAb-details-606" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyELrEeAb-details-606"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Progress in probabilistic generative models has accelerated, developing richer models with neural architectures, implicit densities, and with scalable algorithms for their Bayesian inference. However, there has been limited progress in models that capture causal relationships, for example, how individual genetic factors cause major human diseases. In this work, we focus on two challenges in particular: How do we build richer causal models, which can capture highly nonlinear relationships and interactions between multiple causes? How do we adjust for latent confounders, which are variables influencing both cause and effect and which prevent learning of causal relationships? To address these challenges, we synthesize ideas from causality and modern probabilistic modeling. For the first, we describe implicit causal models, a class of causal models that leverages neural architectures with an implicit density. For the second, we describe an implicit causal model that adjusts for confounders by sharing strength across examples. In experiments, we scale Bayesian inference on up to a billion genetic measurements. We achieve state of the art accuracy for identifying causal factors: we significantly outperform the second best result by an absolute difference of 15-45.3%.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Implicit models applied to causality and genetics</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJC2SzZCW">
      <h4>
        <a href="https://openreview.net/forum?id=HJC2SzZCW">
          Sensitivity and Generalization in Neural Networks: an Empirical Study
        </a>
        
          <a href="https://openreview.net/pdf?id=HJC2SzZCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=romann%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="romann@google.com">Roman Novak</a>, <a href="https://openreview.net/profile?email=yasamanb%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yasamanb@google.com">Yasaman Bahri</a>, <a href="https://openreview.net/profile?email=danabo%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danabo@google.com">Daniel A. Abolafia</a>, <a href="https://openreview.net/profile?email=jpennin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpennin@google.com">Jeffrey Pennington</a>, <a href="https://openreview.net/profile?email=jaschasd%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaschasd@google.com">Jascha Sohl-Dickstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJC2SzZCW-details-111" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJC2SzZCW-details-111"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In practice it is often found that large over-parameterized neural networks generalize better than their smaller counterparts, an observation that appears to conflict with classical notions of function complexity, which typically favor smaller models. In this work, we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations. Our experiments survey thousands of models with different architectures, optimizers, and other hyper-parameters, as well as four different image classification datasets.
      
      We find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the input-output Jacobian of the network, and that this correlates well with generalization. We further establish that factors associated with poor generalization -- such as full-batch training or using random labels -- correspond to higher sensitivity, while factors associated with good generalization  -- such as data augmentation and ReLU non-linearities -- give rise to more robust functions. Finally, we demonstrate how the input-output Jacobian norm can be predictive of generalization at the level of individual test points.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We perform massive experimental studies characterizing the relationships between Jacobian norms, linear regions, and generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generalization, complexity, experimental study, linear regions, Jacobian</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyyGPP0TZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyyGPP0TZ">
          Regularizing and Optimizing LSTM Language Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SyyGPP0TZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=smerity%40smerity.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="smerity@smerity.com">Stephen Merity</a>, <a href="https://openreview.net/profile?email=keskar.nitish%40u.northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="keskar.nitish@u.northwestern.edu">Nitish Shirish Keskar</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyyGPP0TZ-details-321" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyyGPP0TZ-details-321"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTM-based models. We propose the weight-dropped LSTM, which uses DropConnect on hidden-to-hidden weights, as a form of recurrent regularization. Further, we introduce NT-ASGD, a non-monotonically triggered  (NT) variant of the averaged stochastic gradient method (ASGD), wherein the averaging trigger is determined using a NT condition as opposed to being tuned by the user. Using these and other regularization strategies, our ASGD Weight-Dropped LSTM (AWD-LSTM) achieves state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2. We also explore the viability of the proposed regularization and optimization strategies in the context of the quasi-recurrent neural network (QRNN) and demonstrate comparable performance to the AWD-LSTM counterpart. The code for reproducing the results is open sourced and is available at https://github.com/salesforce/awd-lstm-lm.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Effective regularization and optimization strategies for LSTM-based language models achieves SOTA on PTB and WT2. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">language model, LSTM, regularization, optimization, ASGD, dropconnect</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1meywxRW">
      <h4>
        <a href="https://openreview.net/forum?id=H1meywxRW">
          DCN+: Mixed Objective And Deep Residual Coattention for Question Answering
        </a>
        
          <a href="https://openreview.net/pdf?id=H1meywxRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Victor Zhong</a>, <a href="https://openreview.net/profile?email=victor%40victorzhong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="victor@victorzhong.com">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1meywxRW-details-11" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1meywxRW-details-11"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">question answering, deep learning, natural language processing, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H196sainb">
      <h4>
        <a href="https://openreview.net/forum?id=H196sainb">
          Word translation without parallel data
        </a>
        
          <a href="https://openreview.net/pdf?id=H196sainb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=glample%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="glample@fb.com">Guillaume Lample</a>, <a href="https://openreview.net/profile?email=aconneau%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aconneau@fb.com">Alexis Conneau</a>, <a href="https://openreview.net/profile?email=ranzato%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ranzato@fb.com">Marc'Aurelio Ranzato</a>, <a href="https://openreview.net/profile?email=ludovic.denoyer%40upmc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludovic.denoyer@upmc.fr">Ludovic Denoyer</a>, <a href="https://openreview.net/profile?email=rvj%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rvj@fb.com">Hervé Jégou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H196sainb-details-438" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H196sainb-details-438"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Aligning languages without the Rosetta Stone: with no parallel data, we construct bilingual dictionaries using adversarial training, cross-domain local scaling, and an accurate proxy criterion for cross-validation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, machine translation, multilingual embeddings, parallel dictionary induction, adversarial training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkuGJ3kCb">
      <h4>
        <a href="https://openreview.net/forum?id=HkuGJ3kCb">
          All-but-the-Top: Simple and Effective Postprocessing for Word Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=HkuGJ3kCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jiaqimu2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiaqimu2@illinois.edu">Jiaqi Mu</a>, <a href="https://openreview.net/profile?email=pramodv%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pramodv@illinois.edu">Pramod Viswanath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 17 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkuGJ3kCb-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkuGJ3kCb-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Real-valued word representations have transformed NLP applications; popular examples are word2vec and GloVe, recognized for their ability to capture linguistic regularities. In this paper, we demonstrate a {\em very simple}, and yet counter-intuitive, postprocessing technique -- eliminate the common mean vector and a few top dominating directions from the word vectors -- that renders off-the-shelf representations {\em even stronger}. The postprocessing is empirically validated on a variety of lexical-level intrinsic tasks (word similarity, concept categorization, word analogy) and sentence-level tasks (semantic textural similarity and text classification) on multiple datasets and with a variety of representation methods and hyperparameter choices in multiple languages; in each case, the processed representations are consistently better than the original ones. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B18WgG-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=B18WgG-CZ">
          Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B18WgG-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sandeep.subramanian.1%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="sandeep.subramanian.1@umontreal.ca">Sandeep Subramanian</a>, <a href="https://openreview.net/profile?email=adam.trischler%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.trischler@microsoft.com">Adam Trischler</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>, <a href="https://openreview.net/profile?email=christopher.pal%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="christopher.pal@polymtl.ca">Christopher J Pal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B18WgG-CZ-details-187" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B18WgG-CZ-details-187"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A lot of the recent success in natural language processing (NLP) has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner. These representations are typically used as general purpose features for words across a range of NLP problems. However, extending this success to learning representations of sequences of words, such as sentences, remains an open problem. Recent work has explored unsupervised as well as supervised learning techniques with different training objectives to learn general purpose fixed-length sentence representations. In this work, we present a simple, effective multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model. 
      We train this model on several data sources with multiple training objectives on over 100 million sentences. Extensive experiments demonstrate that sharing a single recurrent sentence encoder across weakly related tasks leads to consistent improvements over previous methods. We present substantial improvements in the context of transfer learning and low-resource settings using our learned general-purpose representations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A large-scale multi-task learning framework with diverse training objectives to learn fixed-length sentence representations</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed sentence representations, multi-task learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1dHXnH6-">
      <h4>
        <a href="https://openreview.net/forum?id=r1dHXnH6-">
          Natural Language Inference over Interaction Space
        </a>
        
          <a href="https://openreview.net/pdf?id=r1dHXnH6-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yichen.gong%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yichen.gong@nyu.edu">Yichen Gong</a>, <a href="https://openreview.net/profile?email=heng.luo%40hobot.cc" class="profile-link" data-toggle="tooltip" data-placement="top" title="heng.luo@hobot.cc">Heng Luo</a>, <a href="https://openreview.net/profile?email=jian.zhang%40hobot.cc" class="profile-link" data-toggle="tooltip" data-placement="top" title="jian.zhang@hobot.cc">Jian Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1dHXnH6--details-53" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1dHXnH6--details-53"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Natural Language Inference (NLI) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis. We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space. We show that an interaction tensor (attention weight) contains semantic information to solve natural language inference, and a denser interaction tensor contains richer semantic information. One instance of such architecture, Densely Interactive Inference Network (DIIN), demonstrates the state-of-the-art performance on large scale NLI copora and large-scale NLI alike corpus. It's noteworthy that DIIN achieve a greater than 20% error reduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to the strongest published system.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">show multi-channel attention weight contains semantic feature to solve natural language inference task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural language inference, attention, SoTA, natural language understanding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ1nzBeA-">
      <h4>
        <a href="https://openreview.net/forum?id=SJ1nzBeA-">
          Multi-Task Learning for Document Ranking and Query Suggestion
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ1nzBeA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wasiahmad%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wasiahmad@cs.ucla.edu">Wasi Uddin Ahmad</a>, <a href="https://openreview.net/profile?email=kwchang%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kwchang@cs.ucla.edu">Kai-Wei Chang</a>, <a href="https://openreview.net/profile?email=hw5x%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hw5x@virginia.edu">Hongning Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ1nzBeA--details-398" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ1nzBeA--details-398"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a multi-task learning framework to jointly learn document ranking and query suggestion for web search. It consists of two major components, a document ranker, and a query recommender. Document ranker combines current query and session information and compares the combined representation with document representation to rank the documents. Query recommender tracks users' query reformulation sequence considering all previous in-session queries using a sequence to sequence approach. As both tasks are driven by the users' underlying search intent, we perform joint learning of these two components through session recurrence, which encodes search context and intent. Extensive comparisons against state-of-the-art document ranking and query suggestion algorithms are performed on the public AOL search log, and the promising results endorse the effectiveness of the joint learning framework.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Multitask Learning, Document Ranking, Query Suggestion</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgNdt26Z">
      <h4>
        <a href="https://openreview.net/forum?id=HkgNdt26Z">
          Distributed Fine-tuning of Language Models on Private Data
        </a>
        
          <a href="https://openreview.net/pdf?id=HkgNdt26Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=v.popov%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="v.popov@samsung.com">Vadim Popov</a>, <a href="https://openreview.net/profile?email=m.kudinov%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.kudinov@samsung.com">Mikhail Kudinov</a>, <a href="https://openreview.net/profile?email=p.irina%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="p.irina@samsung.com">Irina Piontkovskaya</a>, <a href="https://openreview.net/profile?email=p.vytovtov%40partner.samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="p.vytovtov@partner.samsung.com">Petr Vytovtov</a>, <a href="https://openreview.net/profile?email=a.nevidomsky%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.nevidomsky@samsung.com">Alex Nevidomsky</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 12 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkgNdt26Z-details-342" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgNdt26Z-details-342"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm. In language modeling, users’ language (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data. At the same time, public data can be used for obtaining general knowledge (i.e. general model of English). We study approaches to distributed fine-tuning of a general model on user private data with the additional requirements of maintaining the quality on the general data and minimization of communication costs. We propose a novel technique that significantly improves prediction quality on users’ language compared to a general model and outperforms gradient compression methods in terms of communication efficiency. The proposed procedure is fast and leads to an almost 70% perplexity reduction and 8.7 percentage point improvement in keystroke saving rate on informal English texts. Finally, we propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a method of distributed fine-tuning of language models on user devices without collection of private data</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed training, federated learning, language modeling, differential privacy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkT5Yg-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=SkT5Yg-RZ">
          Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play
        </a>
        
          <a href="https://openreview.net/pdf?id=SkT5Yg-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sainbar%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sainbar@cs.nyu.edu">Sainbayar Sukhbaatar</a>, <a href="https://openreview.net/profile?email=zlin%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlin@fb.com">Zeming Lin</a>, <a href="https://openreview.net/profile?email=kostrikov%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kostrikov@cs.nyu.edu">Ilya Kostrikov</a>, <a href="https://openreview.net/profile?email=gab%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gab@fb.com">Gabriel Synnaeve</a>, <a href="https://openreview.net/profile?email=aszlam%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aszlam@fb.com">Arthur Szlam</a>, <a href="https://openreview.net/profile?email=fergus%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fergus@cs.nyu.edu">Rob Fergus</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkT5Yg-RZ-details-16" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkT5Yg-RZ-details-16"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We describe a simple scheme that allows an agent to learn about its environment in an unsupervised manner. Our scheme pits two versions of the same agent, Alice and Bob, against one another. Alice proposes a task for Bob to complete; and then Bob attempts to complete the task.  In this work we will focus on two kinds of environments: (nearly) reversible environments and environments that can be reset. Alice will "propose" the task by doing a sequence of actions and then Bob must undo or repeat them, respectively.  Via an appropriate reward structure, Alice and Bob automatically generate a curriculum of exploration, enabling unsupervised training of the agent. When Bob is deployed on an RL task within the environment, this unsupervised training reduces the number of supervised episodes needed to learn, and in some cases converges to a higher reward.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Unsupervised learning for reinforcement learning using an automatic curriculum of self-play</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">self-play, automatic curriculum, intrinsic motivation, unsupervised learning, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyoDInJ0-">
      <h4>
        <a href="https://openreview.net/forum?id=SyoDInJ0-">
          Reinforcement Learning Algorithm Selection
        </a>
        
          <a href="https://openreview.net/pdf?id=SyoDInJ0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=romain.laroche%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="romain.laroche@gmail.com">Romain Laroche</a>, <a href="https://openreview.net/profile?email=raphael.feraud%40orange.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raphael.feraud@orange.com">Raphael Feraud</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyoDInJ0--details-19" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyoDInJ0--details-19"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper formalises the problem of online algorithm selection in the context of Reinforcement Learning (RL). The setup is as follows: given an episodic task and a finite number of off-policy RL algorithms, a meta-algorithm has to decide which RL algorithm is in control during the next episode so as to maximize the expected return. The article presents a novel meta-algorithm, called Epochal Stochastic Bandit Algorithm Selection (ESBAS). Its principle is to freeze the policy updates at each epoch, and to leave a rebooted stochastic bandit in charge of the algorithm selection. Under some assumptions, a thorough theoretical analysis demonstrates its near-optimality considering the structural sampling budget limitations. ESBAS is first empirically evaluated on a dialogue task where it is shown to outperform each individual algorithm in most configurations. ESBAS is then adapted to a true online setting where algorithms update their policies after each transition, which we call SSBAS. SSBAS is evaluated on a fruit collection task where it is shown to adapt the stepsize parameter more efficiently than the classical hyperbolic decay, and on an Atari game, where it improves the performance by a wide margin.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper formalises the problem of online algorithm selection in the context of Reinforcement Learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Multi-Armed Bandit, Algorithm Selection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1vuO-bCW">
      <h4>
        <a href="https://openreview.net/forum?id=S1vuO-bCW">
          Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=S1vuO-bCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eysenbach%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eysenbach@google.com">Benjamin Eysenbach</a>, <a href="https://openreview.net/profile?email=sg717%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sg717@cam.ac.uk">Shixiang Gu</a>, <a href="https://openreview.net/profile?email=julianibarz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="julianibarz@google.com">Julian Ibarz</a>, <a href="https://openreview.net/profile?email=slevine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slevine@google.com">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1vuO-bCW-details-497" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1vuO-bCW-details-497"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning algorithms can learn complex behavioral skills, but real-world application of these methods requires a considerable amount of experience to be collected by the agent. In practical settings, such as robotics, this involves repeatedly attempting a task, resetting the environment between each attempt. However, not all tasks are easily or automatically reversible. In practice, this learning process requires considerable human intervention. In this work, we propose an autonomous method for safe and efficient reinforcement learning that simultaneously learns a forward and backward policy, with the backward policy resetting the environment for a subsequent attempt. By learning a value function for the backward policy, we can automatically determine when the forward policy is about to enter a non-reversible state, providing for uncertainty-aware safety aborts. Our experiments illustrate that proper use of the backward policy can greatly reduce the number of manual resets required to learn a task and can reduce the number of unsafe actions that lead to non-reversible states.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an autonomous method for safe and efficient reinforcement learning that simultaneously learns a forward and backward policy, with the backward policy resetting the environment for a subsequent attempt.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">manual reset, continual learning, reinforcement learning, safety</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkabRiQpb">
      <h4>
        <a href="https://openreview.net/forum?id=BkabRiQpb">
          Consequentialist conditional cooperation in social dilemmas with imperfect information
        </a>
        
          <a href="https://openreview.net/pdf?id=BkabRiQpb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alexpeys%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexpeys@gmail.com">Alexander Peysakhovich</a>, <a href="https://openreview.net/profile?email=alerer%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alerer@fb.com">Adam Lerer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkabRiQpb-details-783" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkabRiQpb-details-783"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Social dilemmas, where mutual cooperation can lead to high payoffs but participants face incentives to cheat, are ubiquitous in multi-agent interaction. We wish to construct agents that cooperate with pure cooperators, avoid exploitation by pure defectors, and incentivize cooperation from the rest. However, often the actions taken by a partner are (partially) unobserved or the consequences of individual actions are hard to predict. We show that in a large class of games good strategies can be constructed by conditioning one's behavior solely on outcomes (ie. one's past rewards). We call this consequentialist conditional cooperation. We show how to construct such strategies using deep reinforcement learning techniques and demonstrate, both analytically and experimentally, that they are effective in social dilemmas beyond simple matrix games. We also show the limitations of relying purely on consequences and discuss the need for understanding both the consequences of and the intentions behind an action.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how to use deep RL to construct agents that can solve social dilemmas beyond matrix games.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, cooperation, social dilemma, multi-agent systems</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkZxCk-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SkZxCk-0Z">
          Can Neural Networks Understand Logical Entailment?
        </a>
        
          <a href="https://openreview.net/pdf?id=SkZxCk-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=richardevans%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="richardevans@google.com">Richard Evans</a>, <a href="https://openreview.net/profile?email=saxton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saxton@google.com">David Saxton</a>, <a href="https://openreview.net/profile?email=davidamos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidamos@google.com">David Amos</a>, <a href="https://openreview.net/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>, <a href="https://openreview.net/profile?email=etg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="etg@google.com">Edward Grefenstette</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkZxCk-0Z-details-5" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkZxCk-0Z-details-5"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a new dataset of logical entailments for the purpose of measuring models' ability to capture and exploit the structure of logical expressions against an entailment prediction task. We use this task to compare a series of architectures which are ubiquitous in the sequence-processing literature, in addition to a new model class---PossibleWorldNets---which computes entailment as a ``convolution over possible worlds''. Results show that convolutional networks present the wrong inductive bias for this class of problems relative to LSTM RNNs, tree-structured neural networks outperform LSTM RNNs due to their enhanced ability to exploit the syntax of logic, and PossibleWorldNets outperform all benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a new dataset of logical entailments for the purpose of measuring models' ability to capture and exploit the structure of logical expressions against an entailment prediction task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">structure, neural networks, logic, dataset</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyRVBzap-">
      <h4>
        <a href="https://openreview.net/forum?id=HyRVBzap-">
          Cascade Adversarial Machine Learning Regularized with a Unified Embedding
        </a>
        
          <a href="https://openreview.net/pdf?id=HyRVBzap-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=taesik.na%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="taesik.na@gatech.edu">Taesik Na</a>, <a href="https://openreview.net/profile?email=jonghwan.ko%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonghwan.ko@gatech.edu">Jong Hwan Ko</a>, <a href="https://openreview.net/profile?email=saibal.mukhopadhyay%40ece.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saibal.mukhopadhyay@ece.gatech.edu">Saibal Mukhopadhyay</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyRVBzap--details-122" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyRVBzap--details-122"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Injecting adversarial examples during training, known as adversarial training, can improve robustness against one-step attacks, but not for unknown iterative attacks. To address this challenge, we first show iteratively generated adversarial images easily transfer between networks trained with the same strategy. Inspired by this observation, we propose cascade adversarial training, which transfers the knowledge of the end results of adversarial training. We train a network from scratch by injecting iteratively generated adversarial images crafted from already defended networks in addition to one-step adversarial images from the network being trained. We also propose to utilize embedding space for both classification and low-level (pixel-level) similarity learning to ignore unknown pixel level perturbation. During training, we inject adversarial images without replacing their corresponding clean images and penalize the distance between the two embeddings (clean and adversarial). Experimental results show that cascade adversarial training together with our proposed low-level similarity learning efficiently enhances the robustness against iterative attacks, but at the expense of decreased robustness against one-step attacks. We show that combining those two techniques can also improve robustness under the worst case black box attack scenario.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Cascade adversarial training + low level similarity learning improve robustness against both white box and black box attacks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial machine learning, embedding, regularization, adversarial attack</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk9yuql0Z">
      <h4>
        <a href="https://openreview.net/forum?id=Sk9yuql0Z">
          Mitigating Adversarial Effects Through Randomization
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk9yuql0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cihangxie306%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cihangxie306@gmail.com">Cihang Xie</a>, <a href="https://openreview.net/profile?email=wjyouch%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wjyouch@gmail.com">Jianyu Wang</a>, <a href="https://openreview.net/profile?email=zhshuai.zhang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhshuai.zhang@gmail.com">Zhishuai Zhang</a>, <a href="https://openreview.net/profile?email=zhou.ren%40snapchat.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhou.ren@snapchat.com">Zhou Ren</a>, <a href="https://openreview.net/profile?email=alan.l.yuille%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alan.l.yuille@gmail.com">Alan Yuille</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 01 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk9yuql0Z-details-941" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk9yuql0Z-details-941"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks have demonstrated high accuracy on various tasks in recent years. However, they are extremely vulnerable to adversarial examples. For example, imperceptible perturbations added to clean images can cause convolutional neural networks to fail. In this paper, we propose to utilize randomization at inference time to mitigate adversarial effects. Specifically, we use two randomization operations: random resizing, which resizes the input images to a random size, and random padding, which pads zeros around the input images in a random manner.  Extensive experiments demonstrate that the proposed randomization method is very effective at defending against both single-step and iterative attacks. Our method provides the following advantages: 1) no additional training or fine-tuning, 2) very few additional computations, 3) compatible with other adversarial defense methods. By combining the proposed randomization method with an adversarially trained model,  it achieves a normalized score of 0.924 (ranked No.2 among 107 defense teams)  in the NIPS 2017 adversarial examples defense challenge, which is far better than using adversarial training alone with a normalized score of 0.773 (ranked No.56). The code is public available at https://github.com/cihangxie/NIPS2017_adv_challenge_defense.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkpiPMbA-">
      <h4>
        <a href="https://openreview.net/forum?id=BkpiPMbA-">
          Decision Boundary Analysis of Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=BkpiPMbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=_w%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="_w@eecs.berkeley.edu">Warren He</a>, <a href="https://openreview.net/profile?email=lxbosky%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxbosky@gmail.com">Bo Li</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkpiPMbA--details-176" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkpiPMbA--details-176"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks (DNNs) are vulnerable to adversarial examples, which are carefully crafted instances aiming to cause prediction errors for DNNs. Recent research on adversarial examples has examined local neighborhoods in the input space of DNN models. However, previous work has limited what regions to consider, focusing either on low-dimensional subspaces or small balls. In this paper, we argue that information from larger neighborhoods, such as from more directions and from greater distances, will better characterize the relationship between adversarial examples and the DNN models. First, we introduce an attack, OPTMARGIN, which generates adversarial examples robust to small perturbations. These examples successfully evade a defense that only considers a small ball around an input instance. Second, we analyze a larger neighborhood around input instances by looking at properties of surrounding decision boundaries, namely the distances to the boundaries and the adjacent classes. We find that the boundaries around these adversarial examples do not resemble the boundaries around benign examples. Finally, we show that, under scrutiny of the surrounding decision boundaries, our OPTMARGIN examples do not convincingly mimic benign examples. Although our experiments are limited to a few specific attacks, we hope these findings will motivate new, more evasive attacks and ultimately, effective defenses.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Looking at decision boundaries around an input gives you more information than a fixed small neighborhood</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial machine learning, supervised representation learning, decision regions, decision boundaries</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJWLfGWRb">
      <h4>
        <a href="https://openreview.net/forum?id=HJWLfGWRb">
          Matrix capsules with EM routing
        </a>
        
          <a href="https://openreview.net/pdf?id=HJWLfGWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=geoffhinton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="geoffhinton@google.com">Geoffrey E Hinton</a>, <a href="https://openreview.net/profile?email=sasabour%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sasabour@google.com">Sara Sabour</a>, <a href="https://openreview.net/profile?email=frosst%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="frosst@google.com">Nicholas Frosst</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 07 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>40 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJWLfGWRb-details-776" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJWLfGWRb-details-776"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Computer Vision, Deep Learning, Dynamic routing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJE-4xW0W">
      <h4>
        <a href="https://openreview.net/forum?id=BJE-4xW0W">
          CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training
        </a>
        
          <a href="https://openreview.net/pdf?id=BJE-4xW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mkocaoglu%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkocaoglu@utexas.edu">Murat Kocaoglu</a>, <a href="https://openreview.net/profile?email=22csnyder%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="22csnyder@gmail.com">Christopher Snyder</a>, <a href="https://openreview.net/profile?email=dimakis%40austin.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimakis@austin.utexas.edu">Alexandros G. Dimakis</a>, <a href="https://openreview.net/profile?email=sriram%40austin.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sriram@austin.utexas.edu">Sriram Vishwanath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJE-4xW0W-details-512" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJE-4xW0W-details-512"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce causal implicit generative models (CiGMs): models that allow sampling from not only the true observational but also the true interventional distributions. We show that adversarial training can be used to learn a CiGM, if the generator architecture is structured based on a given causal graph. We consider the application of conditional and interventional sampling of face images with binary feature labels, such as mustache, young. We preserve the dependency structure between the labels with a given causal graph. We devise a two-stage procedure for learning a CiGM over the labels and the image. First we train a CiGM over the binary labels using a  Wasserstein GAN where the generator neural network is consistent with the causal graph between the labels. Later, we combine this with a conditional GAN to generate images conditioned on the binary labels. We propose two new conditional GAN architectures: CausalGAN and CausalBEGAN. We show that the optimal generator of the CausalGAN, given the labels, samples from the image distributions conditioned on these labels. The conditional GAN combined with a trained CiGM for the labels is then a CiGM over the labels and the generated image. We show that the proposed architectures can be used to sample from observational and interventional image distributions, even for interventions which do not naturally occur in the dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce causal implicit generative models, which can sample from conditional and interventional distributions and also propose two new conditional GANs which we use for training them.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">causality, structural causal models, GANs, conditional GANs, BEGAN, adversarial training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJyEH91A-">
      <h4>
        <a href="https://openreview.net/forum?id=SJyEH91A-">
          Learning Wasserstein Embeddings
        </a>
        
          <a href="https://openreview.net/pdf?id=SJyEH91A-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ncourty%40irisa.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ncourty@irisa.fr">Nicolas Courty</a>, <a href="https://openreview.net/profile?email=remi.flamary%40unice.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="remi.flamary@unice.fr">Rémi Flamary</a>, <a href="https://openreview.net/profile?email=ducoffe%40i3s.unice.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ducoffe@i3s.unice.fr">Mélanie Ducoffe</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJyEH91A--details-207" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJyEH91A--details-207"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The Wasserstein distance received a lot of attention recently in the community of machine learning, especially for its principled way of comparing distributions. It has found numerous applications in several hard problems, such as domain adaptation, dimensionality reduction or generative models. However, its use is still limited by a heavy computational cost. Our goal is to alleviate this problem by providing an approximation mechanism that allows to break its inherent complexity. It relies on the search of an embedding where the Euclidean distance mimics the Wasserstein distance. We show that such an embedding can be found with a siamese architecture associated with a decoder network that allows to move from the embedding space back to the original input space. Once this embedding has been found, computing optimization problems in the Wasserstein space (e.g. barycenters, principal directions or even archetypes) can be conducted extremely fast. Numerical experiments supporting this idea are conducted on image datasets, and show the wide potential benefits of our method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that it is possible to fastly approximate Wasserstein distances computation by finding an appropriate embedding where Euclidean distance emulates the Wasserstein distance</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Wasserstein distance, metric embedding, Siamese architecture</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJNRFNlRW">
      <h4>
        <a href="https://openreview.net/forum?id=BJNRFNlRW">
          TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN
        </a>
        
          <a href="https://openreview.net/pdf?id=BJNRFNlRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chenxugz%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenxugz@gmail.com">Xu Chen</a>, <a href="https://openreview.net/profile?email=wangjiangb%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangjiangb@gmail.com">Jiang Wang</a>, <a href="https://openreview.net/profile?email=haoge2013%40u.northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haoge2013@u.northwestern.edu">Hao Ge</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJNRFNlRW-details-835" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJNRFNlRW-details-835"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We relate the minimax game of generative adversarial networks (GANs) to finding the saddle points of the Lagrangian function for a convex optimization problem, where the discriminator outputs and the distribution of generator outputs play the roles of primal variables and dual variables, respectively. This formulation shows the connection between the standard GAN training process and the primal-dual subgradient methods for convex optimization. The inherent connection does not only provide a theoretical convergence proof for training GANs in the function space, but also inspires a novel objective function for training. The modified objective function forces the distribution of generator outputs to be updated along the direction according to the primal-dual subgradient methods. A toy example shows that the proposed method is able to resolve mode collapse, which in this case cannot be avoided by the standard GAN or Wasserstein GAN. Experiments on both Gaussian mixture synthetic data and real-world image datasets demonstrate the performance of the proposed method on generating diverse samples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a primal-dual subgradient method for training GANs and this method effectively alleviates mode collapse.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, Primal-Dual Subgradient, Mode Collapse, Saddle Point</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyyP33gAZ">
      <h4>
        <a href="https://openreview.net/forum?id=HyyP33gAZ">
          Activation Maximization Generative Adversarial Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=HyyP33gAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=heyohai%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="heyohai@apex.sjtu.edu.cn">Zhiming Zhou</a>, <a href="https://openreview.net/profile?email=hcai%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="hcai@apex.sjtu.edu.cn">Han Cai</a>, <a href="https://openreview.net/profile?email=shu.rong%40yitu-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shu.rong@yitu-inc.com">Shu Rong</a>, <a href="https://openreview.net/profile?email=songyuxuan%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="songyuxuan@apex.sjtu.edu.cn">Yuxuan Song</a>, <a href="https://openreview.net/profile?email=kren%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="kren@apex.sjtu.edu.cn">Kan Ren</a>, <a href="https://openreview.net/profile?email=wnzhang%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wnzhang@sjtu.edu.cn">Weinan Zhang</a>, <a href="https://openreview.net/profile?email=j.wang%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.wang@cs.ucl.ac.uk">Jun Wang</a>, <a href="https://openreview.net/profile?email=yyu%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyu@apex.sjtu.edu.cn">Yong Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 19 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyyP33gAZ-details-124" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyyP33gAZ-details-124"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Class labels have been empirically shown useful in improving the sample quality of generative adversarial nets (GANs). In this paper, we mathematically study the properties of the current variants of GANs that make use of class label information. With class aware gradient and cross-entropy decomposition, we reveal how class labels and associated losses influence GAN's training. Based on that, we propose Activation Maximization Generative Adversarial Networks (AM-GAN) as an advanced solution. Comprehensive experiments have been conducted to validate our analysis and evaluate the effectiveness of our solution, where AM-GAN outperforms other strong baselines and achieves state-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we demonstrate that, with the Inception ImageNet classifier, Inception Score mainly tracks the diversity of the generator, and there is, however, no reliable evidence that it can reflect the true sample quality. We thus propose a new metric, called AM Score, to provide more accurate estimation on the sample quality. Our proposed model also outperforms the baseline methods in the new metric.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Understand how class labels help GAN training. Propose a new evaluation metric for generative models. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Nets, GANs, Evaluation Metrics, Generative Model, Deep Learning, Adversarial Learning, Inception Score, AM Score</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkVqXOxCb">
      <h4>
        <a href="https://openreview.net/forum?id=SkVqXOxCb">
          Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields
        </a>
        
          <a href="https://openreview.net/pdf?id=SkVqXOxCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=unterthiner%40bioinf.jku.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="unterthiner@bioinf.jku.at">Thomas Unterthiner</a>, <a href="https://openreview.net/profile?email=nessler%40bioinf.jku.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="nessler@bioinf.jku.at">Bernhard Nessler</a>, <a href="https://openreview.net/profile?email=seward%40bioinf.jku.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="seward@bioinf.jku.at">Calvin Seward</a>, <a href="https://openreview.net/profile?email=klambauer%40bioinf.jku.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="klambauer@bioinf.jku.at">Günter Klambauer</a>, <a href="https://openreview.net/profile?email=mheusel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mheusel@gmail.com">Martin Heusel</a>, <a href="https://openreview.net/profile?email=ramsauer%40bioinf.jku.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramsauer@bioinf.jku.at">Hubert Ramsauer</a>, <a href="https://openreview.net/profile?email=hochreit%40bioinf.jku.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="hochreit@bioinf.jku.at">Sepp Hochreiter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 01 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkVqXOxCb-details-158" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkVqXOxCb-details-158"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on LSUN bedrooms, CelebA faces, CIFAR-10 and the Google Billion Word text generation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Coulomb GANs can optimally learn a distribution by posing the distribution learning problem as optimizing a potential field</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Generative Adversarial Network, GAN, Generative Model, Potential Field</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJx9GQb0-">
      <h4>
        <a href="https://openreview.net/forum?id=SJx9GQb0-">
          Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect
        </a>
        
          <a href="https://openreview.net/pdf?id=SJx9GQb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yqweixiang%40knights.ucf.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yqweixiang@knights.ucf.edu">Xiang Wei</a>, <a href="https://openreview.net/profile?email=boqinggo%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boqinggo@outlook.com">Boqing Gong</a>, <a href="https://openreview.net/profile?email=zixia%40knights.ucf.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zixia@knights.ucf.edu">Zixia Liu</a>, <a href="https://openreview.net/profile?email=luwei%40bjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luwei@bjtu.edu.cn">Wei Lu</a>, <a href="https://openreview.net/profile?email=lwang%40cs.ucf.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lwang@cs.ucf.edu">Liqiang Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>31 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJx9GQb0--details-530" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJx9GQb0--details-530"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite being impactful on a  variety of problems and applications, the generative adversarial nets (GANs) are remarkably difficult to train. This issue is formally analyzed by \cite{arjovsky2017towards}, who also propose an alternative direction to avoid the caveats in the minmax two-player training of GANs. The corresponding algorithm, namely, Wasserstein GAN (WGAN) hinges on the 1-Lipschitz continuity of the discriminators. In this paper, we propose a novel approach for enforcing the Lipschitz continuity in the training procedure of WGANs. Our approach seamlessly connects WGAN with one of the recent semi-supervised learning approaches. As  a result, it gives rise to not only better photo-realistic samples  than the previous methods  but also state-of-the-art semi-supervised learning results.  In particular, to the best of our knowledge, our approach gives rise to the inception score of more than 5.0 with only 1,000 CIFAR10 images and is the first that exceeds the accuracy of 90\% the CIFAR10 datasets using only 4,000 labeled images.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, WGAN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJIgi_eCZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJIgi_eCZ">
          FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension
        </a>
        
          <a href="https://openreview.net/pdf?id=BJIgi_eCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=momohuang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="momohuang@gmail.com">Hsin-Yuan Huang</a>, <a href="https://openreview.net/profile?email=chezhu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chezhu@microsoft.com">Chenguang Zhu</a>, <a href="https://openreview.net/profile?email=yeshen%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yeshen@microsoft.com">Yelong Shen</a>, <a href="https://openreview.net/profile?email=wzchen%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wzchen@microsoft.com">Weizhu Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>28 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJIgi_eCZ-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJIgi_eCZ-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of "History of Word" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it identifies an attention scoring function that better utilizes the "history of word" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve SotA on SQuAD and adversarial SQuAD.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Attention Mechanism, Machine Comprehension, Natural Language Processing, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgOLb-0W">
      <h4>
        <a href="https://openreview.net/forum?id=rkgOLb-0W">
          Neural Language Modeling by Jointly Learning Syntax and Lexicon
        </a>
        
          <a href="https://openreview.net/pdf?id=rkgOLb-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yikang.shn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yikang.shn@gmail.com">Yikang Shen</a>, <a href="https://openreview.net/profile?email=lin.zhouhan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lin.zhouhan@gmail.com">Zhouhan Lin</a>, <a href="https://openreview.net/profile?email=chin-wei.huang%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="chin-wei.huang@umontreal.ca">Chin-wei Huang</a>, <a href="https://openreview.net/profile?email=aaron.courville%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaron.courville@gmail.com">Aaron Courville</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 19 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkgOLb-0W-details-925" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgOLb-0W-details-925"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a neural language model capable of unsupervised syntactic structure induction. The model leverages the structure information to form better semantic representations and better language modeling. Standard recurrent neural networks are limited by their structure and fail to efficiently use syntactic information. On the other hand, tree-structured recursive networks usually require additional structural supervision at the cost of human expert annotation. In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks (PRPN), that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model. In our model, the gradient can be directly back-propagated from the language model loss into the neural parsing network. Experiments show that the proposed model can discover the underlying syntactic structure and achieve state-of-the-art performance on word/character-level language model tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks (PRPN), that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Language model, unsupervised parsing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk6cfpRjZ">
      <h4>
        <a href="https://openreview.net/forum?id=rk6cfpRjZ">
          Learning Intrinsic Sparse Structures within Long Short-Term Memory
        </a>
        
          <a href="https://openreview.net/pdf?id=rk6cfpRjZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wei.wen%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wei.wen@duke.edu">Wei Wen</a>, <a href="https://openreview.net/profile?email=yuxhe%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuxhe@microsoft.com">Yuxiong He</a>, <a href="https://openreview.net/profile?email=samyamr%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="samyamr@microsoft.com">Samyam Rajbhandari</a>, <a href="https://openreview.net/profile?email=minjiaz%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="minjiaz@microsoft.com">Minjia Zhang</a>, <a href="https://openreview.net/profile?email=wenhanw%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenhanw@microsoft.com">Wenhan Wang</a>, <a href="https://openreview.net/profile?email=fangliu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fangliu@microsoft.com">Fang Liu</a>, <a href="https://openreview.net/profile?email=binhu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="binhu@microsoft.com">Bin Hu</a>, <a href="https://openreview.net/profile?email=yiran.chen%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiran.chen@duke.edu">Yiran Chen</a>, <a href="https://openreview.net/profile?email=hai.li%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hai.li@duke.edu">Hai Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk6cfpRjZ-details-177" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk6cfpRjZ-details-177"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model compression is significant for the wide adoption of Recurrent Neural Networks (RNNs) in both user devices possessing limited resources and business clusters requiring quick responses to large-scale service requests. This work aims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the sizes of basic structures within LSTM units, including input updates, gates, hidden states, cell states and outputs. Independently reducing the sizes of basic structures can result in inconsistent dimensions among them, and consequently, end up with invalid LSTM units. To overcome the problem, we propose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS will simultaneously decrease the sizes of all basic structures by one and thereby always maintain the dimension consistency. By learning ISS within LSTM units, the obtained LSTMs remain regular while having much smaller basic structures. Based on group Lasso regularization, our method achieves 10.59x speedup without losing any perplexity of a language modeling of Penn TreeBank dataset. It is also successfully evaluated through a compact model with only 2.69M weights for machine Question Answering of SQuAD dataset. Our approach is successfully extended to non- LSTM RNNs, like Recurrent Highway Networks (RHNs). Our source code is available.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Sparsity, Model Compression, Acceleration, LSTMs, Recurrent Neural Networks, Structural Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry018WZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=ry018WZAZ">
          Deep Active Learning for Named Entity Recognition
        </a>
        
          <a href="https://openreview.net/pdf?id=ry018WZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shenyanyao%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shenyanyao@utexas.edu">Yanyao Shen</a>, <a href="https://openreview.net/profile?email=yunhyoku%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yunhyoku@amazon.com">Hyokun Yun</a>, <a href="https://openreview.net/profile?email=zlipton%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlipton@cmu.edu">Zachary C. Lipton</a>, <a href="https://openreview.net/profile?email=kronrod%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kronrod@amazon.com">Yakov Kronrod</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Animashree Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry018WZAZ-details-76" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry018WZAZ-details-76"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning has yielded state-of-the-art performance on many natural language processing tasks including named entity recognition (NER). However, this typically requires large amounts of labeled data. In this work, we demonstrate that the amount of labeled training data can be drastically reduced when deep learning is combined with active learning. While active learning is sample-efficient, it can be computationally expensive since it requires iterative retraining. To speed this up, we introduce a lightweight architecture for NER, viz., the CNN-CNN-LSTM model consisting of convolutional character and word encoders and a  long short term memory (LSTM) tag decoder. The model achieves nearly state-of-the-art performance on standard datasets for the task while being computationally much more efficient than best performing models. We carry out incremental active learning, during the training process, and are able to nearly match state-of-the-art performance with just 25\% of the original training data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a lightweight architecture for named entity recognition and carry out incremental active learning, which is able to match state-of-the-art performance with just 25% of the original training data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">active learning, deep learning, named entity recognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syg-YfWCW">
      <h4>
        <a href="https://openreview.net/forum?id=Syg-YfWCW">
          Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=Syg-YfWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rajarshi%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rajarshi@cs.umass.edu">Rajarshi Das</a>, <a href="https://openreview.net/profile?email=sdhuliawala%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sdhuliawala@cs.umass.edu">Shehzaad Dhuliawala</a>, <a href="https://openreview.net/profile?email=manzil%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="manzil@cmu.edu">Manzil Zaheer</a>, <a href="https://openreview.net/profile?email=luke%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="luke@cs.umass.edu">Luke Vilnis</a>, <a href="https://openreview.net/profile?email=ishand%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ishand@cs.utexas.edu">Ishan Durugkar</a>, <a href="https://openreview.net/profile?email=akshay%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="akshay@cs.umass.edu">Akshay Krishnamurthy</a>, <a href="https://openreview.net/profile?email=alex%40smola.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="alex@smola.org">Alex Smola</a>, <a href="https://openreview.net/profile?email=mccallum%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mccallum@cs.umass.edu">Andrew McCallum</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 08 May 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>29 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syg-YfWCW-details-502" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syg-YfWCW-details-502"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. A popular approach to KB completion is to infer new relations by combinatory reasoning over the information found along other paths connecting a pair of entities. Given the enormous size of KBs and the exponential number of paths, previous path-based models have considered only the problem of predicting a missing relation given two entities, or evaluating the truth of a proposed triple. Additionally, these methods have traditionally used random paths between fixed entity pairs or more recently learned to pick paths between them. We propose a new algorithm, MINERVA, which addresses the much more difficult and practical task of answering questions where the relation is known, but only one entity. Since random walks are impractical in a setting with unknown destination and combinatorially many paths from a start node, we present a neural reinforcement learning approach which learns how to navigate the graph conditioned on the input query to find predictive paths. On a comprehensive evaluation on seven knowledge base datasets, we found MINERVA to be competitive with many current state-of-the-art methods. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a RL agent MINERVA which learns to walk on a knowledge graph and answer queries</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Knowledge Graphs, Reinforcement Learning, Query Answering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk7KsfW0-">
      <h4>
        <a href="https://openreview.net/forum?id=Sk7KsfW0-">
          Lifelong Learning with Dynamically Expandable Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk7KsfW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mmvc98%40unist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="mmvc98@unist.ac.kr">Jaehong Yoon</a>, <a href="https://openreview.net/profile?email=eunhoy%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="eunhoy@kaist.ac.kr">Eunho Yang</a>, <a href="https://openreview.net/profile?email=jtlee%40unist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jtlee@unist.ac.kr">Jeongtae Lee</a>, <a href="https://openreview.net/profile?email=sjhwang82%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang82@kaist.ac.kr">Sung Ju Hwang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk7KsfW0--details-868" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk7KsfW0--details-868"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel deep network architecture for lifelong learning which we refer to as Dynamically Expandable Network (DEN), that can dynamically decide its network capacity as it trains on a sequence of tasks, to learn a compact overlapping knowledge sharing structure among tasks. DEN is efficiently trained in an online manner by performing selective retraining, dynamically expands network capacity upon arrival of each task with only the necessary number of units, and effectively prevents semantic drift by splitting/duplicating units and timestamping them. We validate DEN on multiple public datasets in lifelong learning scenarios on multiple public datasets, on which it not only significantly outperforms existing lifelong learning methods for deep networks, but also achieves the same level of performance as the batch model with substantially fewer number of parameters. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel deep network architecture that can dynamically decide its network capacity as it trains on a lifelong learning scenario.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Transfer learning, Lifelong learning, Selective retraining, Dynamic network expansion</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1VjBebR-">
      <h4>
        <a href="https://openreview.net/forum?id=H1VjBebR-">
          The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings
        </a>
        
          <a href="https://openreview.net/pdf?id=H1VjBebR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tomer22g%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomer22g@gmail.com">Tomer Galanti</a>, <a href="https://openreview.net/profile?email=liorwolf%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liorwolf@gmail.com">Lior Wolf</a>, <a href="https://openreview.net/profile?email=sagiebenaim%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sagiebenaim@gmail.com">Sagie Benaim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1VjBebR--details-20" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1VjBebR--details-20"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We discuss the feasibility of the following learning problem: given unmatched samples from two domains and nothing else, learn a mapping between the two, which preserves semantics. Due to the lack of paired samples and without any definition of the semantic information, the problem might seem ill-posed. Specifically, in typical cases, it seems possible to build infinitely many alternative mappings  from every target mapping. This apparent ambiguity stands in sharp contrast to the recent empirical success in solving this problem.
      
      We identify the abstract notion of aligning two domains in a semantic way with concrete terms of minimal relative complexity. A theoretical framework for measuring the complexity of compositions of functions is developed in order to show that it is reasonable to expect the minimal complexity mapping to be unique. The measured complexity used is directly related to the depth of the neural networks being learned and a semantically aligned mapping could then be captured simply by learning using architectures that are not much bigger than the minimal architecture.
      
      Various predictions are made based on the hypothesis that semantic alignment can be captured by the minimal mapping. These are verified extensively. In addition, a new mapping algorithm is proposed and shown to lead to better mapping results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Our hypothesis is that given two domains, the lowest complexity mapping that has a low discrepancy approximates the target mapping.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Unsupervised learning, cross-domain mapping, Kolmogorov complexity, Occam's razor</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJuWrGW0Z">
      <h4>
        <a href="https://openreview.net/forum?id=BJuWrGW0Z">
          Dynamic Neural Program Embeddings for Program Repair
        </a>
        
          <a href="https://openreview.net/pdf?id=BJuWrGW0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kbwang%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kbwang@ucdavis.edu">Ke Wang</a>, <a href="https://openreview.net/profile?email=risin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="risin@microsoft.com">Rishabh Singh</a>, <a href="https://openreview.net/profile?email=su%40cs.ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="su@cs.ucdavis.edu">Zhendong Su</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJuWrGW0Z-details-97" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJuWrGW0Z-details-97"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, code completion, and fault localization. However, most existing program embeddings are based on syntactic features of programs, such as token sequences or abstract syntax trees. Unlike images and text, a program has well-deﬁned semantics that can be difﬁcult to capture by only considering its syntax (i.e. syntactically similar programs can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. We propose a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only capture program semantics more precisely, but also offer a more natural ﬁt for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on the task of classifying the types of errors that students make in their submissions to an introductory programming class and on the CodeHunt education platform. Our evaluation results show that the semantic program embeddings signiﬁcantly outperform the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with predictions made from our semantic embedding and demonstrate signiﬁcantly improved search efﬁciency.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new way of learning semantic program embedding</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Program Embedding, Program Semantics, Dynamic Traces</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Euwz-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=S1Euwz-Rb">
          Compositional Attention Networks for Machine Reasoning
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Euwz-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dorarad%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dorarad@cs.stanford.edu">Drew A. Hudson</a>, <a href="https://openreview.net/profile?email=manning%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="manning@cs.stanford.edu">Christopher D. Manning</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Euwz-Rb-details-921" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Euwz-Rb-details-921"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Compositional Attention Networks, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. While many types of neural networks are effective at learning and generalizing from massive quantities of data, this model moves away from monolithic black-box architectures towards a design that provides a strong prior for iterative reasoning, enabling it to support explainable and structured learning, as well as generalization from a modest amount of data. The model builds on the great success of existing recurrent cells such as LSTMs: It sequences a single recurrent Memory, Attention, and Control (MAC) cell, and by careful design imposes structural constraints on the operation of each cell and the interactions between them, incorporating explicit control and soft attention mechanisms into their interfaces. We demonstrate the model's strength and robustness on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that the new model is more computationally efficient, data-efficient, and requires an order of magnitude less time and/or data to achieve good results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a novel architecture, based on dynamic memory, attention and composition for the task of machine reasoning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Reasoning, Memory, Attention, VQA, CLEVR, Recurrent Neural Networks, Module Networks, Compositionality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkXmYfbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=BkXmYfbAZ">
          Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering
        </a>
        
          <a href="https://openreview.net/pdf?id=BkXmYfbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ekm%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ekm@cs.utexas.edu">Elliot Meyerson</a>, <a href="https://openreview.net/profile?email=risto%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="risto@cs.utexas.edu">Risto Miikkulainen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkXmYfbAZ-details-143" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkXmYfbAZ-details-143"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Existing deep multitask learning (MTL) approaches align layers shared between tasks in a parallel ordering. Such an organization significantly constricts the types of shared structure that can be learned. The necessity of parallel ordering for deep MTL is first tested by comparing it with permuted ordering of shared layers. The results indicate that a flexible ordering can enable more effective sharing, thus motivating the development of a soft ordering approach, which learns how shared layers are applied in different ways for different tasks. Deep MTL with soft ordering outperforms parallel ordering methods across a series of domains. These results suggest that the power of deep MTL comes from learning highly general building blocks that can be assembled to meet the demands of each task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Relaxing the constraint of shared hierarchies enables more effective deep multitask learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multitask learning, deep learning, modularity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJQRKzbA-">
      <h4>
        <a href="https://openreview.net/forum?id=BJQRKzbA-">
          Hierarchical Representations for Efficient Architecture Search
        </a>
        
          <a href="https://openreview.net/pdf?id=BJQRKzbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hanxiaol%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanxiaol@cs.cmu.edu">Hanxiao Liu</a>, <a href="https://openreview.net/profile?email=simonyan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="simonyan@google.com">Karen Simonyan</a>, <a href="https://openreview.net/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>, <a href="https://openreview.net/profile?email=chrisantha%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrisantha@google.com">Chrisantha Fernando</a>, <a href="https://openreview.net/profile?email=korayk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="korayk@google.com">Koray Kavukcuoglu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJQRKzbA--details-604" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJQRKzbA--details-604"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We explore efficient neural architecture search methods and show that a simple yet powerful evolutionary algorithm can discover new architectures with excellent performance. Our approach combines a novel hierarchical genetic representation scheme that imitates the modularized design pattern commonly adopted by human experts, and an expressive search space that supports complex topologies. Our algorithm efficiently discovers architectures that outperform a large number of manually designed models for image classification, obtaining top-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which is competitive with the best existing neural architecture search approaches. We also present results using random search, achieving 0.3% less top-1 accuracy on CIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36 hours down to 1 hour.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In this paper we propose a hierarchical architecture representation in which doing random or evolutionary architecture search yields highly competitive results using fewer computational resources than the prior art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, architecture search</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryTp3f-0-">
      <h4>
        <a href="https://openreview.net/forum?id=ryTp3f-0-">
          Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration
        </a>
        
          <a href="https://openreview.net/pdf?id=ryTp3f-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=evzliu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="evzliu@gmail.com">Evan Zheran Liu</a>, <a href="https://openreview.net/profile?email=kguu%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kguu@stanford.edu">Kelvin Guu</a>, <a href="https://openreview.net/profile?email=ppasupat%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ppasupat@cs.stanford.edu">Panupong Pasupat</a>, <a href="https://openreview.net/profile?email=tianlins%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianlins@cs.stanford.edu">Tianlin Shi</a>, <a href="https://openreview.net/profile?email=pliang%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pliang@cs.stanford.edu">Percy Liang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryTp3f-0--details-800" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryTp3f-0--details-800"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement learning (RL) agents improve through trial-and-error, but when reward is sparse and the agent cannot discover successful action sequences, learning stagnates. This has been a notable problem in training deep RL agents to perform web-based tasks, such as booking flights or replying to emails, where a single mistake can ruin the entire sequence of actions. A common remedy is to "warm-start" the agent by pre-training it to mimic expert demonstrations, but this is prone to overfitting. Instead, we propose to constrain exploration using demonstrations. From each demonstration, we induce high-level "workflows" which constrain the allowable actions at each time step to be similar to those in the demonstration (e.g., "Step 1: click on a textbox; Step 2: enter some text"). Our exploration policy then learns to identify successful workflows and samples actions that satisfy these workflows. Workflows prune out bad exploration directions and accelerate the agent’s ability to discover rewards. We use our approach to train a novel neural policy designed to handle the semi-structured nature of websites, and evaluate on a suite of web tasks, including the recent World of Bits benchmark. We achieve new state-of-the-art results, and show that workflow-guided exploration improves sample efficiency over behavioral cloning by more than 100x.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We solve the sparse rewards problem on web UI tasks using exploration guided by demonstrations</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, sparse rewards, web, exploration</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hksj2WWAW">
      <h4>
        <a href="https://openreview.net/forum?id=Hksj2WWAW">
          Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs
        </a>
        
          <a href="https://openreview.net/pdf?id=Hksj2WWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=farabsha%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="farabsha@uci.edu">Forough Arabshahi</a>, <a href="https://openreview.net/profile?email=sameer%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sameer@uci.edu">Sameer Singh</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Animashree Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hksj2WWAW-details-976" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hksj2WWAW-details-976"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural programming involves training neural networks to learn programs, mathematics, or logic from data. Previous works have failed to achieve good generalization performance, especially on problems and programs with high complexity or on large domains. This is because they mostly rely either on black-box function evaluations that do not capture the structure of the program, or on detailed execution traces that are expensive to obtain, and hence the training data has poor coverage of the domain under consideration. We present a novel framework that utilizes black-box function evaluations, in conjunction with symbolic expressions that define relationships between the given functions. We employ tree LSTMs to incorporate the structure of the symbolic expression trees. We use tree encoding for numbers present in function evaluation data, based on their decimal representation. We present an evaluation benchmark for this task to demonstrate our proposed model combines symbolic reasoning and function evaluation in a fruitful manner, obtaining high accuracies in our experiments. Our framework generalizes significantly better to expressions of higher depth and is able to fill partial equations with valid completions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">symbolic reasoning, mathematical equations, recursive neural networks, neural programing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkZB1XbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkZB1XbRZ">
          Scalable Private Learning with PATE
        </a>
        
          <a href="https://openreview.net/pdf?id=rkZB1XbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ngp5056%40cse.psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ngp5056@cse.psu.edu">Nicolas Papernot</a>, <a href="https://openreview.net/profile?email=shs037%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shs037@eng.ucsd.edu">Shuang Song</a>, <a href="https://openreview.net/profile?email=mironov%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mironov@google.com">Ilya Mironov</a>, <a href="https://openreview.net/profile?email=pseudorandom%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pseudorandom@google.com">Ananth Raghunathan</a>, <a href="https://openreview.net/profile?email=kunal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunal@google.com">Kunal Talwar</a>, <a href="https://openreview.net/profile?email=ulfar%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ulfar@google.com">Ulfar Erlingsson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkZB1XbRZ-details-906" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkZB1XbRZ-details-906"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The rapid adoption of machine learning has increased concerns about the privacy implications of machine learning models trained on sensitive data, such as medical records or other personal information. To address those concerns, one promising approach is Private Aggregation of Teacher Ensembles, or PATE, which transfers to a "student" model the knowledge of an ensemble of "teacher" models, with intuitive privacy provided by training teachers on disjoint data and strong privacy guaranteed by noisy aggregation of teachers’ answers. However, PATE has so far been evaluated only on simple classification tasks like MNIST, leaving unclear its utility when applied to larger-scale learning tasks and real-world datasets.
      
      In this work, we show how PATE can scale to learning tasks with large numbers of output classes and uncurated, imbalanced training data with errors. For this, we introduce new noisy aggregation mechanisms for teacher ensembles that are more selective and add less noise, and prove their tighter differential-privacy guarantees. Our new mechanisms build on two insights: the chance of teacher consensus is increased by using more concentrated noise and, lacking consensus, no answer need be given to a student. The consensus answers used are more likely to be correct, offer better intuitive privacy, and incur lower-differential privacy cost. Our evaluation shows our mechanisms improve on the original PATE on all measures, and scale to larger tasks with both high utility and very strong privacy (ε &lt; 1.0).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">privacy, differential privacy, machine learning, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1aIuk-RW">
      <h4>
        <a href="https://openreview.net/forum?id=H1aIuk-RW">
          Active Learning for Convolutional Neural Networks: A Core-Set Approach
        </a>
        
          <a href="https://openreview.net/pdf?id=H1aIuk-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ozansener%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ozansener@cs.stanford.edu">Ozan Sener</a>, <a href="https://openreview.net/profile?email=ssilvio%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ssilvio@stanford.edu">Silvio Savarese</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1aIuk-RW-details-194" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1aIuk-RW-details-194"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks (CNNs) have been successfully applied to many recognition and learning tasks using a universal recipe;  training a deep model on a very large dataset of supervised examples. However, this approach is rather restrictive in practice since collecting a large set of labeled images is very expensive. One way to ease this problem is coming up with smart ways for choosing images to be labelled from a  very large collection (i.e. active learning).
      
      Our empirical study suggests that many of the active learning heuristics in the literature are not effective when applied to CNNs when applied in batch setting. Inspired by these limitations, we define the problem of active learning as core-set selection, i.e. choosing set of points such that a model learned over the selected subset is competitive for the remaining data points. We further present a theoretical result characterizing the performance of any selected subset using the geometry of the datapoints. As an active learning algorithm, we choose the subset which is expected to yield best result according to our characterization. Our experiments show that the proposed method significantly outperforms existing approaches in image classification experiments by a large margin.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We approach to the problem of active learning as a core-set selection problem and show that this approach is especially useful in the batch active learning setting which is crucial when training CNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Active Learning, Convolutional Neural Networks, Core-Set Selection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkrSv0lA-">
      <h4>
        <a href="https://openreview.net/forum?id=BkrSv0lA-">
          Loss-aware Weight Quantization of Deep Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BkrSv0lA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lhouab%40cse.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="lhouab@cse.ust.hk">Lu Hou</a>, <a href="https://openreview.net/profile?email=jamesk%40cse.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamesk@cse.ust.hk">James T. Kwok</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkrSv0lA--details-777" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkrSv0lA--details-777"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The huge size of deep networks hinders their use in small computing devices. In this paper, we consider compressing the network by weight quantization. We extend a recently proposed loss-aware weight binarization scheme to ternarization, with possibly different scaling parameters for the positive and negative weights, and m-bit (where m &gt; 2) quantization. Experiments on feedforward and recurrent neural networks show that the proposed scheme outperforms state-of-the-art weight quantization algorithms, and is as accurate (or even more accurate) than the full-precision network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A loss-aware weight quantization algorithm that directly considers its effect on the loss is proposed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, network quantization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJk7Gf-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJk7Gf-CZ">
          Global Optimality Conditions for Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJk7Gf-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chulheey%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chulheey@mit.edu">Chulhee Yun</a>, <a href="https://openreview.net/profile?email=suvrit%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="suvrit@mit.edu">Suvrit Sra</a>, <a href="https://openreview.net/profile?email=jadbabai%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jadbabai@mit.edu">Ali Jadbabaie</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJk7Gf-CZ-details-457" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJk7Gf-CZ-details-457"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the error landscape of deep linear and nonlinear neural networks with the squared error loss. Minimizing the loss of a deep linear neural network is a nonconvex problem, and despite recent progress, our understanding of this loss surface is still incomplete. For deep linear networks, we present necessary and sufficient conditions for a critical point of the risk function to be a global minimum. Surprisingly, our conditions provide an efficiently checkable test for global optimality, while such tests are typically intractable in nonconvex optimization. We further extend these results to deep nonlinear neural networks and prove similar sufficient conditions for global optimality, albeit in a more limited function space setting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We provide efficiently checkable necessary and sufficient conditions for global optimality in deep linear neural networks, with some initial extensions to nonlinear settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep linear neural networks, global optimality, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ_aoCyRZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJ_aoCyRZ">
          SpectralNet: Spectral Clustering using Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ_aoCyRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=uri.shaham%40yale.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="uri.shaham@yale.edu">Uri Shaham</a>, <a href="https://openreview.net/profile?email=kelly.stanton%40yale.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kelly.stanton@yale.edu">Kelly Stanton</a>, <a href="https://openreview.net/profile?email=henry.li%40yale.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="henry.li@yale.edu">Henry Li</a>, <a href="https://openreview.net/profile?email=ronen.basri%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronen.basri@gmail.com">Ronen Basri</a>, <a href="https://openreview.net/profile?email=boaz.nadler%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boaz.nadler@gmail.com">Boaz Nadler</a>, <a href="https://openreview.net/profile?email=yuval.kluger%40yale.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuval.kluger@yale.edu">Yuval Kluger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ_aoCyRZ-details-506" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ_aoCyRZ-details-506"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Spectral clustering is a leading and popular technique in unsupervised data analysis.  Two of its major limitations are scalability and generalization of the spectral embedding (i.e., out-of-sample-extension). In this paper we introduce a deep learning approach to spectral clustering that overcomes the above shortcomings. Our network, which we call SpectralNet, learns a map that embeds input data points into the eigenspace of their associated graph Laplacian matrix and subsequently clusters them. We train SpectralNet using a procedure that involves constrained stochastic optimization. Stochastic optimization allows it to scale to large datasets, while the constraints, which are implemented using a special purpose output layer, allow us to keep the network output orthogonal. Moreover, the map learned by SpectralNet naturally generalizes the spectral embedding to unseen data points. To further improve the quality of the clustering, we replace the standard pairwise Gaussian affinities with affinities leaned from unlabeled data using a Siamese network.  Additional improvement can be achieved by applying the network to code representations produced, e.g., by standard autoencoders. Our end-to-end learning procedure is fully unsupervised. In addition, we apply VC dimension theory to derive a lower bound on the size of  SpectralNet.  State-of-the-art clustering results are reported for both the MNIST and Reuters datasets.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Unsupervised spectral clustering using deep neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, spectral clustering, siamese networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk8XMWgRb">
      <h4>
        <a href="https://openreview.net/forum?id=Hk8XMWgRb">
          Not-So-Random Features
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk8XMWgRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bbullins%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bbullins@cs.princeton.edu">Brian Bullins</a>, <a href="https://openreview.net/profile?email=cyril.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cyril.zhang@cs.princeton.edu">Cyril Zhang</a>, <a href="https://openreview.net/profile?email=y.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.zhang@cs.princeton.edu">Yi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk8XMWgRb-details-644" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk8XMWgRb-details-644"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a principled method for kernel learning, which relies on a Fourier-analytic characterization of translation-invariant or rotation-invariant kernels. Our method produces a sequence of feature maps, iteratively refining the SVM margin. We provide rigorous guarantees for optimality and generalization, interpreting our algorithm as online equilibrium-finding dynamics in a certain two-player min-max game. Evaluations on synthetic and real-world datasets demonstrate scalability and consistent improvements over related random features-based methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simple and practical algorithm for learning a margin-maximizing translation-invariant or spherically symmetric kernel from training data, using tools from Fourier analysis and regret minimization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">kernel learning, random features, online learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkn7CBaTW">
      <h4>
        <a href="https://openreview.net/forum?id=Hkn7CBaTW">
          Learning how to explain neural networks: PatternNet and PatternAttribution
        </a>
        
          <a href="https://openreview.net/pdf?id=Hkn7CBaTW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pikinder%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pikinder@google.com">Pieter-Jan Kindermans</a>, <a href="https://openreview.net/profile?email=kristof.schuett%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kristof.schuett@tu-berlin.de">Kristof T. Schütt</a>, <a href="https://openreview.net/profile?email=maximilian.aber%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="maximilian.aber@tu-berlin.de">Maximilian Alber</a>, <a href="https://openreview.net/profile?email=klaus-robert.mueller%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="klaus-robert.mueller@tu-berlin.de">Klaus-Robert Müller</a>, <a href="https://openreview.net/profile?email=dumitru%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dumitru@google.com">Dumitru Erhan</a>, <a href="https://openreview.net/profile?email=beenkim%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="beenkim@google.com">Been Kim</a>, <a href="https://openreview.net/profile?email=sven.daehne%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="sven.daehne@tu-berlin.de">Sven Dähne</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hkn7CBaTW-details-2" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkn7CBaTW-details-2"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of  simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Without learning, it is impossible to explain a machine learning model's decisions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine learning, interpretability, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByOfBggRZ">
      <h4>
        <a href="https://openreview.net/forum?id=ByOfBggRZ">
          Detecting Statistical Interactions from Neural Network Weights
        </a>
        
          <a href="https://openreview.net/pdf?id=ByOfBggRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tsangm%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsangm@usc.edu">Michael Tsang</a>, <a href="https://openreview.net/profile?email=dehuache%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dehuache@usc.edu">Dehua Cheng</a>, <a href="https://openreview.net/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 28 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByOfBggRZ-details-692" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByOfBggRZ-details-692"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Interpreting neural networks is a crucial and challenging task in machine learning. In this paper, we develop a novel framework for detecting statistical interactions captured by a feedforward multilayer neural network by directly interpreting its learned weights. Depending on the desired interactions, our method can achieve significantly better or similar interaction detection performance compared to the state-of-the-art without searching an exponential solution space of possible interactions. We obtain this accuracy and efficiency by observing that interactions between input features are created by the non-additive effect of nonlinear activation functions, and that interacting paths are encoded in weight matrices. We demonstrate the performance of our method and the importance of discovered interactions via experimental results on both synthetic datasets and real-world application datasets. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We detect statistical interactions captured by a feedforward multilayer neural network by directly interpreting its learned weights.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">statistical interaction detection, multilayer perceptron, generalized additive model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1ZdKJ-0W">
      <h4>
        <a href="https://openreview.net/forum?id=r1ZdKJ-0W">
          Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking
        </a>
        
          <a href="https://openreview.net/pdf?id=r1ZdKJ-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=a.bojchevski%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.bojchevski@in.tum.de">Aleksandar Bojchevski</a>, <a href="https://openreview.net/profile?email=guennemann%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="guennemann@in.tum.de">Stephan Günnemann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1ZdKJ-0W-details-432" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1ZdKJ-0W-details-432"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Methods that learn representations of nodes in a graph play a critical role in network analysis since they enable many downstream learning tasks. We propose Graph2Gauss - an approach that can efficiently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classification. Unlike most approaches that represent nodes as point vectors in a low-dimensional continuous space, we embed each node as a Gaussian distribution, allowing us to capture uncertainty about the representation. Furthermore, we propose an unsupervised method that handles inductive learning scenarios and is applicable to different types of graphs: plain/attributed, directed/undirected. By leveraging both the network structure and the associated node attributes, we are able to generalize to unseen nodes without additional training. To learn the embeddings we adopt a personalized ranking formulation w.r.t. the node distances that exploits the natural ordering of the nodes imposed by the network structure. Experiments on real world networks demonstrate the high performance of our approach, outperforming state-of-the-art network embedding methods on several different tasks. Additionally, we demonstrate the benefits of modeling uncertainty - by analyzing it we can estimate neighborhood diversity and detect the intrinsic latent dimensionality of a graph. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> We embed nodes in a graph as Gaussian distributions allowing us to capture uncertainty about their representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">node embeddings, graphs, unsupervised learning, inductive learning, uncertainty, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1BLjgZCb">
      <h4>
        <a href="https://openreview.net/forum?id=H1BLjgZCb">
          Generating Natural Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=H1BLjgZCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhengliz%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhengliz@uci.edu">Zhengli Zhao</a>, <a href="https://openreview.net/profile?email=ddua%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddua@uci.edu">Dheeru Dua</a>, <a href="https://openreview.net/profile?email=sameer%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sameer@uci.edu">Sameer Singh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1BLjgZCb-details-116" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1BLjgZCb-details-116"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a framework to generate “natural” adversaries against black-box classifiers for both visual and textual domains, by doing the search for adversaries in the latent semantic space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, generative adversarial networks, interpretability, image classification, textual entailment, machine translation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyydRMZC-">
      <h4>
        <a href="https://openreview.net/forum?id=HyydRMZC-">
          Spatially Transformed Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=HyydRMZC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaocw%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaocw@umich.edu">Chaowei Xiao</a>, <a href="https://openreview.net/profile?email=junyanzhu89%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="junyanzhu89@gmail.com">Jun-Yan Zhu</a>, <a href="https://openreview.net/profile?email=lxbosky%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxbosky@gmail.com">Bo Li</a>, <a href="https://openreview.net/profile?email=_w%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="_w@eecs.berkeley.edu">Warren He</a>, <a href="https://openreview.net/profile?email=mingyan%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingyan@umich.edu">Mingyan Liu</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>25 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyydRMZC--details-809" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyydRMZC--details-809"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent studies show that widely used Deep neural networks (DNNs) are vulnerable to the carefully crafted adversarial examples.
      Many advanced algorithms have been proposed to generate adversarial examples by leveraging the L_p distance for penalizing perturbations.
      Different defense methods have also been explored to defend against such adversarial attacks. 
      While the effectiveness of L_p distance as a metric of perceptual quality remains an active research area, in this paper we will instead focus on a different type of perturbation, namely spatial transformation, as opposed to manipulating the pixel values directly as in prior works.
      Perturbations generated through spatial transformation could result in large L_p distance measures, but our extensive experiments show that such spatially transformed adversarial examples are perceptually realistic and more difficult to defend against with existing defense systems. This potentially provides a new direction in adversarial example generation and the design of corresponding defenses.
      We visualize the spatial transformation based perturbation for different examples and show that our technique
      can produce realistic adversarial examples with smooth image deformation.
      Finally, we visualize the attention of deep networks with different types of adversarial examples to better understand how these examples are interpreted.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new approach for generating adversarial examples based on spatial transformation, which produces perceptually realistic examples compared to existing attacks. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, spatial transformation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryBnUWb0b">
      <h4>
        <a href="https://openreview.net/forum?id=ryBnUWb0b">
          Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data
        </a>
        
          <a href="https://openreview.net/pdf?id=ryBnUWb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=waf2107%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="waf2107@columbia.edu">William Falcon</a>, <a href="https://openreview.net/profile?email=hgs%40cs.columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hgs@cs.columbia.edu">Henning Schulzrinne</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryBnUWb0b-details-895" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryBnUWb0b-details-895"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In cities with tall buildings, emergency responders need an accurate floor level location to find 911 callers quickly. We introduce a system to estimate a victim's floor level via their mobile device's sensor data in a two-step process. First, we train a neural network to determine when a smartphone enters or exits a building via GPS signal changes. Second, we use a barometer equipped smartphone to measure the change in barometric pressure from the entrance of the building to the victim's indoor location. Unlike impractical previous approaches, our system is the first that does not require the use of beacons, prior knowledge of the building infrastructure, or knowledge of user behavior. We demonstrate real-world feasibility through 63 experiments across five different tall buildings throughout New York City where our system predicted the correct floor level with 100% accuracy.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We used an LSTM to detect when a smartphone walks into a building. Then we predict the device's floor level using data from sensors aboard the smartphone.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Recurrent Neural Networks, RNN, LSTM, Mobile Device, Sensors</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJLlmG-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJLlmG-AZ">
          Understanding image motion with group representations 
        </a>
        
          <a href="https://openreview.net/pdf?id=SJLlmG-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ajaegle%40upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajaegle@upenn.edu">Andrew Jaegle</a>, <a href="https://openreview.net/profile?email=stephi%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephi@seas.upenn.edu">Stephen Phillips</a>, <a href="https://openreview.net/profile?email=daphnei%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="daphnei@seas.upenn.edu">Daphne Ippolito</a>, <a href="https://openreview.net/profile?email=kostas%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kostas@seas.upenn.edu">Kostas Daniilidis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJLlmG-AZ-details-10" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJLlmG-AZ-details-10"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Motion is an important signal for agents in dynamic environments, but learning to represent motion from unlabeled video is a difficult and underconstrained problem. We propose a model of motion based on elementary group properties of transformations and use it to train a representation of image motion. While most methods of estimating motion are based on pixel-level constraints, we use these group properties to constrain the abstract representation of motion itself. We demonstrate that a deep neural network trained using this method captures motion in both synthetic 2D sequences and real-world sequences of vehicle motion, without requiring any labels. Networks trained to respect these constraints implicitly identify the image characteristic of motion in different sequence types. In the context of vehicle motion, this method extracts information useful for localization, tracking, and odometry. Our results demonstrate that this representation is useful for learning motion in the general setting where explicit labels are difficult to obtain.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose of method of using group properties to learn a representation of motion without labels and demonstrate the use of this method for representing 2D and 3D motion.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">vision, motion, recurrent neural networks, self-supervised learning, unsupervised learning, group theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1HhRfWRZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1HhRfWRZ">
          Learning Awareness Models
        </a>
        
          <a href="https://openreview.net/pdf?id=r1HhRfWRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bamos%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bamos@cs.cmu.edu">Brandon Amos</a>, <a href="https://openreview.net/profile?email=dinh.laurent%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dinh.laurent@gmail.com">Laurent Dinh</a>, <a href="https://openreview.net/profile?email=cabi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cabi@google.com">Serkan Cabi</a>, <a href="https://openreview.net/profile?email=tcr%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tcr@google.com">Thomas Rothörl</a>, <a href="https://openreview.net/profile?email=sergomez%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sergomez@google.com">Sergio Gómez Colmenarejo</a>, <a href="https://openreview.net/profile?email=alimuldal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alimuldal@google.com">Alistair Muldal</a>, <a href="https://openreview.net/profile?email=etom%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="etom@google.com">Tom Erez</a>, <a href="https://openreview.net/profile?email=tassa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tassa@google.com">Yuval Tassa</a>, <a href="https://openreview.net/profile?email=nandodefreitas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nandodefreitas@google.com">Nando de Freitas</a>, <a href="https://openreview.net/profile?email=mdenil%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mdenil@google.com">Misha Denil</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 01 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1HhRfWRZ-details-275" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1HhRfWRZ-details-275"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the setting of an agent with a fixed body interacting with an unknown and uncertain external world. We show that models trained to predict proprioceptive information about the agent's body come to represent objects in the external world. In spite of being trained with only internally available signals, these dynamic body models come to represent external objects through the necessity of predicting their effects on the agent's own body. That is, the model learns holistic persistent representations of objects in the world, even though the only training signals are body signals. Our dynamics model is able to successfully predict distributions over 132 sensor readings over 100 steps into the future and we demonstrate that even when the body is no longer in contact with an object, the latent variables of the dynamics model continue to represent its shape. We show that active data collection by maximizing the entropy of predictions about the body---touch sensors, proprioception and vestibular information---leads to learning of dynamic models that show superior performance when used for control. We also collect data from a real robotic hand and show that the same models can be used to answer questions about properties of objects in the real world. Videos with qualitative results of our models are available at https://goo.gl/mZuqAV.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train predictive models on proprioceptive information and show they represent properties of external objects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Awareness, Prediction, Seq2seq, Robots</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyzKd1bCW">
      <h4>
        <a href="https://openreview.net/forum?id=SyzKd1bCW">
          Backpropagation through the Void: Optimizing control variates for black-box gradient estimation
        </a>
        
          <a href="https://openreview.net/pdf?id=SyzKd1bCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wgrathwohl%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wgrathwohl@cs.toronto.edu">Will Grathwohl</a>, <a href="https://openreview.net/profile?email=choidami%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="choidami@cs.toronto.edu">Dami Choi</a>, <a href="https://openreview.net/profile?email=ywu%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywu@cs.toronto.edu">Yuhuai Wu</a>, <a href="https://openreview.net/profile?email=roeder%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="roeder@cs.toronto.edu">Geoff Roeder</a>, <a href="https://openreview.net/profile?email=duvenaud%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="duvenaud@cs.toronto.edu">David Duvenaud</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyzKd1bCW-details-975" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyzKd1bCW-details-975"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Gradient-based optimization is the foundation of deep learning and reinforcement learning.
      Even when the mechanism being optimized is unknown or not differentiable, optimization using high-variance or biased gradient estimates is still often the best strategy. We introduce a general framework for learning low-variance, unbiased gradient estimators for black-box functions of random variables, based on gradients of a learned function.
      These estimators can be jointly trained with model parameters or policies, and are applicable in both discrete and continuous settings. We give unbiased, adaptive analogs of state-of-the-art reinforcement learning methods such as advantage actor-critic. We also demonstrate this framework for training discrete latent-variable models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a general method for unbiased estimation of gradients of black-box functions of random variables. We apply this method to discrete variational inference and reinforcement learning. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimization, machine learning, variational inference, reinforcement learning, gradient estimation, deep learning, discrete optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylSzl-R-">
      <h4>
        <a href="https://openreview.net/forum?id=rylSzl-R-">
          On Unifying Deep Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=rylSzl-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhitinghu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhitinghu@gmail.com">Zhiting Hu</a>, <a href="https://openreview.net/profile?email=yangtze2301%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangtze2301@gmail.com">Zichao Yang</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>, <a href="https://openreview.net/profile?email=epxing%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="epxing@cs.cmu.edu">Eric P. Xing</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rylSzl-R--details-514" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylSzl-R--details-514"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep generative models have achieved impressive success in recent years. Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as powerful frameworks for deep generative model learning, have largely been considered as two distinct paradigms and received extensive independent studies respectively. This paper aims to establish formal connections between GANs and VAEs through a new formulation of them. We interpret sample generation in GANs as performing posterior inference, and show that GANs and VAEs involve minimizing KL divergences of respective posterior and inference distributions with opposite directions, extending the two learning phases of classic wake-sleep algorithm, respectively. The unified view provides a powerful tool to analyze a diverse set of existing model variants, and enables to transfer techniques across research lines in a principled way. For example, we apply the importance weighting method in VAE literatures for improved GAN learning, and enhance VAEs with an adversarial mechanism that leverages generated samples. Experiments show generality and effectiveness of the transfered techniques. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A unified statistical view of the broad class of deep generative models </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep generative models, generative adversarial networks, variational autoencoders, variational inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyZoi-WRb">
      <h4>
        <a href="https://openreview.net/forum?id=HyZoi-WRb">
          Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=HyZoi-WRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sebastian.nowozin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.nowozin@microsoft.com">Sebastian Nowozin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyZoi-WRb-details-674" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyZoi-WRb-details-674"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The importance-weighted autoencoder (IWAE) approach of Burda et al. defines a sequence of increasingly tighter bounds on the marginal likelihood of latent variable models. Recently, Cremer et al. reinterpreted the IWAE bounds as ordinary variational evidence lower bounds (ELBO) applied to increasingly accurate variational distributions. In this work, we provide yet another perspective on the IWAE bounds. We interpret each IWAE bound as a biased estimator of the true marginal likelihood where for the bound defined on $K$ samples we show the bias to be of order O(1/K). In our theoretical analysis of the IWAE objective we derive asymptotic bias and variance expressions. Based on this analysis we develop jackknife variational inference (JVI),
      a family of bias-reduced estimators reducing the bias to $O(K^{-(m+1)})$ for any given m &lt; K while retaining computational efficiency. Finally, we demonstrate that JVI leads to improved evidence estimates in variational autoencoders. We also report first results on applying JVI to learning variational autoencoders.
      
      Our implementation is available at https://github.com/Microsoft/jackknife-variational-inference</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Variational inference is biased, let's debias it.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">variational inference, approximate inference, generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkrC3GbRW">
      <h4>
        <a href="https://openreview.net/forum?id=rkrC3GbRW">
          Learning a Generative Model for Validity in Complex Discrete Structures
        </a>
        
          <a href="https://openreview.net/pdf?id=rkrC3GbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=david.janz93%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.janz93@gmail.com">Dave Janz</a>, <a href="https://openreview.net/profile?email=josvdwest%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="josvdwest@gmail.com">Jos van der Westhuizen</a>, <a href="https://openreview.net/profile?email=tbpaige%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tbpaige@gmail.com">Brooks Paige</a>, <a href="https://openreview.net/profile?email=matt.kusner%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matt.kusner@gmail.com">Matt Kusner</a>, <a href="https://openreview.net/profile?email=jmh233%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmh233@cam.ac.uk">José Miguel Hernández-Lobato</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkrC3GbRW-details-393" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkrC3GbRW-details-393"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep generative models have been successfully used to learn representations for high-dimensional discrete spaces by representing discrete objects as sequences and employing powerful sequence-based deep models. Unfortunately, these sequence-based models often produce invalid sequences: sequences which do not represent any underlying discrete structure; invalid sequences hinder the utility of such models. As a step towards solving this problem, we propose to learn a deep recurrent validator model, which can estimate whether a partial sequence can function as the beginning of a full, valid sequence. This validator provides insight as to how individual sequence elements influence the validity of the overall sequence, and can be used to constrain sequence based models to generate valid sequences — and thus faithfully model discrete objects. Our approach is inspired by reinforcement learning, where an oracle which can evaluate validity of complete sequences provides a sparse reward signal. We demonstrate its effectiveness as a generative model of Python 3 source code for mathematical expressions, and in improving the ability of a variational autoencoder trained on SMILES strings to decode valid molecular structures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Active learning, Reinforcement learning, Molecules</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkTS8lZAb">
      <h4>
        <a href="https://openreview.net/forum?id=rkTS8lZAb">
          Boundary Seeking GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=rkTS8lZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=erroneus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="erroneus@gmail.com">R Devon Hjelm</a>, <a href="https://openreview.net/profile?email=apjacob%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="apjacob@uwaterloo.ca">Athul Paul Jacob</a>, <a href="https://openreview.net/profile?email=adam.trischler%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.trischler@microsoft.com">Adam Trischler</a>, <a href="https://openreview.net/profile?email=tong.che%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="tong.che@umontreal.ca">Gerry Che</a>, <a href="https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>, <a href="https://openreview.net/profile?email=yoshua.bengio%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@umontreal.ca">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkTS8lZAb-details-959" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkTS8lZAb-details-959"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial networks are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation.  In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We address training GANs with discrete data by formulating a policy gradient that generalizes across f-divergences</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative adversarial networks, generative learning, deep learning, neural networks, adversarial learning, discrete data</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk0wHx-RW">
      <h4>
        <a href="https://openreview.net/forum?id=Hk0wHx-RW">
          Learning Sparse Latent Representations with the Deep Copula Information Bottleneck
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk0wHx-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aleksander.wieczorek%40unibas.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aleksander.wieczorek@unibas.ch">Aleksander Wieczorek*</a>, <a href="https://openreview.net/profile?email=mario.wieser%40unibas.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="mario.wieser@unibas.ch">Mario Wieser*</a>, <a href="https://openreview.net/profile?email=d.murezzan%40unibas.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.murezzan@unibas.ch">Damian Murezzan</a>, <a href="https://openreview.net/profile?email=volker.roth%40unibas.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="volker.roth@unibas.ch">Volker Roth</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk0wHx-RW-details-942" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk0wHx-RW-details-942"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep latent variable models are powerful tools for representation learning. In this paper, we adopt the deep information bottleneck model, identify its shortcomings and propose a model that circumvents them. To this end, we apply a copula transformation which, by restoring the invariance properties of the information bottleneck method, leads to disentanglement of the features in the latent space. Building on that, we show how this transformation translates to sparsity of the latent space in the new model.  We evaluate our method on artificial and real data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We apply the copula transformation to the Deep Information Bottleneck which leads to restored invariance properties and a disentangled latent space with superior predictive capabilities.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Information Bottleneck, Deep Information Bottleneck, Deep Variational Information Bottleneck, Variational Autoencoder, Sparsity, Disentanglement, Interpretability, Copula, Mutual Information</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1cZsf-RW">
      <h4>
        <a href="https://openreview.net/forum?id=S1cZsf-RW">
          WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling
        </a>
        
          <a href="https://openreview.net/pdf?id=S1cZsf-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhanghao_xidian%40163.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanghao_xidian@163.com">Hao Zhang</a>, <a href="https://openreview.net/profile?email=bchen%40mail.xidian.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="bchen@mail.xidian.edu.cn">Bo Chen</a>, <a href="https://openreview.net/profile?email=gdd_xidian%40126.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdd_xidian@126.com">Dandan Guo</a>, <a href="https://openreview.net/profile?email=mzhou%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mzhou@utexas.edu">Mingyuan Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1cZsf-RW-details-63" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1cZsf-RW-details-63"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">To train an inference network jointly with a deep generative topic model, making it both scalable to big corpora and fast in out-of-sample prediction, we develop Weibull hybrid autoencoding inference (WHAI) for deep latent Dirichlet allocation, which infers posterior samples via a hybrid of stochastic-gradient MCMC and autoencoding variational Bayes. The generative network of WHAI has a hierarchy of gamma distributions, while the inference network of WHAI is a Weibull upward-downward variational autoencoder, which integrates a deterministic-upward deep neural network, and a stochastic-downward deep generative model based on a hierarchy of Weibull distributions. The Weibull distribution can be used to well approximate a gamma distribution with an analytic Kullback-Leibler divergence, and has a simple reparameterization via the uniform noise, which help efficiently compute the gradients of the evidence lower bound with respect to the parameters of the inference network. The effectiveness and efficiency of WHAI are illustrated with experiments on big corpora.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1MczcgR-">
      <h4>
        <a href="https://openreview.net/forum?id=H1MczcgR-">
          Understanding Short-Horizon Bias in Stochastic Meta-Optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=H1MczcgR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ywu%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywu@cs.toronto.edu">Yuhuai Wu</a>, <a href="https://openreview.net/profile?email=mren%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mren@cs.toronto.edu">Mengye Ren</a>, <a href="https://openreview.net/profile?email=rjliao%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rjliao@cs.toronto.edu">Renjie Liao</a>, <a href="https://openreview.net/profile?email=rgrosse%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgrosse@cs.toronto.edu">Roger Grosse.</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 06 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1MczcgR--details-779" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1MczcgR--details-779"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Careful tuning of the learning rate, or even schedules thereof, can be crucial to effective neural net training. There has been much recent interest in gradient-based meta-optimization, where one tunes hyperparameters, or even learns an optimizer, in order to minimize the expected loss when the training procedure is unrolled. But because the training procedure must be unrolled thousands of times, the meta-objective must be defined with an orders-of-magnitude shorter time horizon than is typical for neural net training. We show that such short-horizon meta-objectives cause a serious bias towards small step sizes, an effect we term short-horizon bias. We introduce a toy problem, a noisy quadratic cost function, on which we analyze short-horizon bias by deriving and comparing the optimal schedules for short and long time horizons. We then run meta-optimization experiments (both offline and online) on standard benchmark datasets, showing that meta-optimization chooses too small a learning rate by multiple orders of magnitude, even when run with a moderately long time horizon (100 steps) typical of work in the area. We believe short-horizon bias is a fundamental problem that needs to be addressed if meta-optimization is to scale to practical neural net training regimes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate the bias in the short-horizon meta-optimization objective.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meta-learning; optimization; short-horizon bias.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkpoTaxA-">
      <h4>
        <a href="https://openreview.net/forum?id=rkpoTaxA-">
          Self-ensembling for visual domain adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=rkpoTaxA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=g.french%40uea.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="g.french@uea.ac.uk">Geoff French</a>, <a href="https://openreview.net/profile?email=m.mackiewicz%40uea.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.mackiewicz@uea.ac.uk">Michal Mackiewicz</a>, <a href="https://openreview.net/profile?email=m.fisher%40uea.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.fisher@uea.ac.uk">Mark Fisher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkpoTaxA--details-19" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkpoTaxA--details-19"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper explores the use of self-ensembling for visual domain adaptation problems. Our technique is derived from the mean teacher variant (Tarvainen et. al 2017) of temporal ensembling (Laine et al. 2017), a technique that achieved state of the art results in the area of semi-supervised learning. We introduce a number of modifications to their approach for challenging domain adaptation scenarios and evaluate its effectiveness. Our approach achieves state of the art results in a variety of benchmarks, including our winning entry in the VISDA-2017 visual domain adaptation challenge. In small image benchmarks, our algorithm not only outperforms prior art, but can also achieve accuracy that is close to that of a classifier trained in a supervised fashion.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Self-ensembling based algorithm for visual domain adaptation, state of the art results, won VisDA-2017 image classification domain adaptation challenge.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, neural networks, domain adaptation, images, visual, computer vision</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJi9WOeRb">
      <h4>
        <a href="https://openreview.net/forum?id=SJi9WOeRb">
          Gradient Estimators for Implicit Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SJi9WOeRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yl494%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yl494@cam.ac.uk">Yingzhen Li</a>, <a href="https://openreview.net/profile?email=ret26%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ret26@cam.ac.uk">Richard E. Turner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJi9WOeRb-details-647" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJi9WOeRb-details-647"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Implicit models, which allow for the generation of samples but not for point-wise evaluation of probabilities, are omnipresent in real-world problems tackled by machine learning and a hot topic of current research. Some examples include data simulators that are widely used in engineering and scientific research, generative adversarial networks (GANs) for image synthesis, and hot-off-the-press approximate inference techniques relying on implicit distributions. The majority of existing approaches to learning implicit models rely on approximating the intractable distribution or optimisation objective for gradient-based optimisation, which is liable to produce inaccurate updates and thus poor models. This paper alleviates the need for such approximations by proposing the \emph{Stein gradient estimator}, which directly estimates the score function of the implicitly defined distribution. The efficacy of the proposed estimator is empirically demonstrated by examples that include meta-learning for approximate inference and entropy regularised GANs that provide improved sample diversity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduced a novel gradient estimator using Stein's method, and compared with other methods on learning implicit models for approximate inference and image generation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Implicit Models, Approximate Inference, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1nZ1weCZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1nZ1weCZ">
          Learning to Multi-Task by Active Sampling
        </a>
        
          <a href="https://openreview.net/pdf?id=B1nZ1weCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sahil%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="sahil@cse.iitm.ac.in">Sahil Sharma*</a>, <a href="https://openreview.net/profile?email=me14b148%40smail.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="me14b148@smail.iitm.ac.in">Ashutosh Kumar Jha*</a>, <a href="https://openreview.net/profile?email=ee14b123%40ee.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="ee14b123@ee.iitm.ac.in">Parikshit S Hegde</a>, <a href="https://openreview.net/profile?email=ravi%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="ravi@cse.iitm.ac.in">Balaraman Ravindran</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1nZ1weCZ-details-396" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1nZ1weCZ-details-396"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the long-standing challenges in Artificial Intelligence for learning goal-directed behavior is to build a single agent which can solve multiple tasks. Recent progress in multi-task learning for goal-directed sequential problems has been in the form of distillation based learning wherein a student network learns from multiple task-specific expert networks by mimicking the task-specific policies of the expert networks. While such approaches offer a promising solution to the multi-task learning problem, they require supervision from large expert networks which require extensive data and computation time for training.
      In this work, we propose an efficient multi-task learning framework which solves multiple goal-directed tasks in an on-line setup without the need for expert supervision. Our work uses active learning principles to achieve multi-task learning by sampling the harder tasks more than the easier ones. We propose three distinct models under our active sampling framework. An adaptive method with extremely competitive multi-tasking performance. A UCB-based meta-learner which casts the problem of picking the next task to train on as a multi-armed bandit problem. A meta-learning method that casts the next-task picking problem as a full Reinforcement Learning problem and uses actor-critic methods for optimizing the multi-tasking performance directly. We demonstrate results in the Atari 2600 domain on seven multi-tasking instances: three 6-task instances, one 8-task instance, two 12-task instances and one 21-task instance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Letting a meta-learner decide the task to train on for an agent in a multi-task setting improves multi-tasking ability substantially</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkHywl-A-">
      <h4>
        <a href="https://openreview.net/forum?id=rkHywl-A-">
          Learning Robust Rewards with Adverserial Inverse Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rkHywl-A-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=justinjfu%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="justinjfu@eecs.berkeley.edu">Justin Fu</a>, <a href="https://openreview.net/profile?email=katieluo%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="katieluo@berkeley.edu">Katie Luo</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkHywl-A--details-932" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkHywl-A--details-932"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement learning provides a powerful and general framework for decision
      making and control, but its application in practice is often hindered by the need
      for extensive feature and reward engineering. Deep reinforcement learning methods
      can remove the need for explicit engineering of policy or value features, but
      still require a manually specified reward function. Inverse reinforcement learning
      holds the promise of automatic reward acquisition, but has proven exceptionally
      difficult to apply to large, high-dimensional problems with unknown dynamics. In
      this work, we propose AIRL, a practical and scalable inverse reinforcement learning
      algorithm based on an adversarial reward learning formulation that is competitive
      with direct imitation learning algorithms. Additionally, we show that AIRL is
      able to recover portable reward functions that are robust to changes in dynamics,
      enabling us to learn policies even under significant variation in the environment
      seen during training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an adversarial inverse reinforcement learning algorithm capable of learning reward functions which can transfer to new, unseen environments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">inverse reinforcement learning, deep reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1DmUzWAW">
      <h4>
        <a href="https://openreview.net/forum?id=B1DmUzWAW">
          A Simple Neural Attentive Meta-Learner
        </a>
        
          <a href="https://openreview.net/pdf?id=B1DmUzWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nmishra%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nmishra@berkeley.edu">Nikhil Mishra</a>, <a href="https://openreview.net/profile?email=rohaninejadm%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rohaninejadm@berkeley.edu">Mostafa Rohaninejad</a>, <a href="https://openreview.net/profile?email=adslcx%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adslcx@gmail.com">Xi Chen</a>, <a href="https://openreview.net/profile?email=pabbeel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@gmail.com">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 25 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1DmUzWAW-details-654" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1DmUzWAW-details-654"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information.  In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks.  On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">a simple RNN-based meta-learner that achieves SOTA performance on popular benchmarks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meta-learning, few-shot learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SywXXwJAb">
      <h4>
        <a href="https://openreview.net/forum?id=SywXXwJAb">
          Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design
        </a>
        
          <a href="https://openreview.net/pdf?id=SywXXwJAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yoavlevine%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoavlevine@cs.huji.ac.il">Yoav Levine</a>, <a href="https://openreview.net/profile?email=davidyakira%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidyakira@cs.huji.ac.il">David Yakira</a>, <a href="https://openreview.net/profile?email=cohennadav%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="cohennadav@cs.huji.ac.il">Nadav Cohen</a>, <a href="https://openreview.net/profile?email=shashua%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shashua@cs.huji.ac.il">Amnon Shashua</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SywXXwJAb-details-881" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SywXXwJAb-details-881"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Formal understanding of the inductive bias behind deep convolutional networks, i.e. the relation between the network's architectural features and the functions it is able to model, is limited. In this work, we establish a fundamental connection between the fields of quantum physics and deep learning, and use it for obtaining novel theoretical observations regarding the inductive bias of convolutional networks. Specifically, we show a structural equivalence between the function realized by a convolutional arithmetic circuit (ConvAC) and a quantum many-body wave function, which facilitates the use of quantum entanglement measures as quantifiers of a deep network's expressive ability to model correlations. Furthermore, the construction of a deep ConvAC in terms of a quantum Tensor Network is enabled. This allows us to perform a graph-theoretic analysis of a convolutional network, tying its expressiveness to a min-cut in its underlying graph. We demonstrate a practical outcome in the form of a direct control over the inductive bias via the number of channels (width) of each layer. We empirically validate our findings on standard convolutional networks which involve ReLU activations and max pooling. The description of a deep convolutional network in well-defined graph-theoretic tools and the structural connection to quantum entanglement, are two interdisciplinary bridges that are brought forth by this work.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Employing quantum entanglement measures for quantifying correlations in deep learning, and using the connection to fit the deep network's architecture to correlations in the data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, quantum entanglement, quantum physics, many body physics, data correlations, inductive bias, tensor networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skp1ESxRZ">
      <h4>
        <a href="https://openreview.net/forum?id=Skp1ESxRZ">
          Towards Synthesizing Complex Programs From Input-Output Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=Skp1ESxRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xinyun.chen%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinyun.chen@berkeley.edu">Xinyun Chen</a>, <a href="https://openreview.net/profile?email=liuchang%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuchang@eecs.berkeley.edu">Chang Liu</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skp1ESxRZ-details-651" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skp1ESxRZ-details-651"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In recent years, deep learning techniques have been developed to improve the performance of program synthesis from input-output examples. Albeit its significant progress, the programs that can be synthesized by state-of-the-art approaches are still simple in terms of their complexity. In this work, we move a significant step forward along this direction by proposing a new class of challenging tasks in the domain of program synthesis from input-output examples: learning a context-free parser from pairs of input programs and their parse trees. We show that this class of tasks are much more challenging than previously studied tasks, and the test accuracy of existing approaches is almost 0%.
      
      We tackle the challenges by developing three novel techniques inspired by three novel observations, which reveal the key ingredients of using deep learning to synthesize a complex program. First, the use of a non-differentiable machine is the key to effectively restrict the search space. Thus our proposed approach learns a neural program operating a domain-specific non-differentiable machine. Second, recursion is the key to achieve generalizability. Thus, we bake-in the notion of recursion in the design of our non-differentiable machine. Third, reinforcement learning is the key to learn how to operate the non-differentiable machine, but it is also hard to train the model effectively with existing reinforcement learning algorithms from a cold boot. We develop a novel two-phase reinforcement learning-based search algorithm to overcome this issue. In our evaluation, we show that using our novel approach, neural parsing programs can be learned to achieve 100% test accuracy on test inputs that are 500x longer than the training samples.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1WRibb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=S1WRibb0Z">
          Expressive power of recurrent neural networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S1WRibb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=khrulkov.v%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="khrulkov.v@gmail.com">Valentin Khrulkov</a>, <a href="https://openreview.net/profile?email=sasha.v.novikov%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sasha.v.novikov@gmail.com">Alexander Novikov</a>, <a href="https://openreview.net/profile?email=i.oseledets%40skoltech.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="i.oseledets@skoltech.ru">Ivan Oseledets</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1WRibb0Z-details-565" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1WRibb0Z-details-565"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks are surprisingly efficient at solving practical tasks,
      but the theory behind this phenomenon is only starting to catch up with
      the practice. Numerous works show that depth is the key to this efficiency.
      A certain class of deep convolutional networks – namely those that correspond
      to the Hierarchical Tucker (HT) tensor decomposition – has been
      proven to have exponentially higher expressive power than shallow networks.
      I.e. a shallow network of exponential width is required to realize
      the same score function as computed by the deep architecture. In this paper,
      we prove the expressive power theorem (an exponential lower bound on
      the width of the equivalent shallow network) for a class of recurrent neural
      networks – ones that correspond to the Tensor Train (TT) decomposition.
      This means that even processing an image patch by patch with an RNN
      can be exponentially more efficient than a (shallow) convolutional network
      with one hidden layer. Using theoretical results on the relation between
      the tensor decompositions we compare expressive powers of the HT- and
      TT-Networks. We also implement the recurrent TT-Networks and provide
      numerical evidence of their expressivity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove the exponential efficiency of recurrent-type neural networks over shallow networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Recurrent Neural Networks, Tensor Train, tensor decompositions, expressive power</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJlMAAeC-">
      <h4>
        <a href="https://openreview.net/forum?id=rJlMAAeC-">
          Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction
        </a>
        
          <a href="https://openreview.net/pdf?id=rJlMAAeC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaoda99%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoda99@gmail.com">Da Xiao</a>, <a href="https://openreview.net/profile?email=liaoruoyu%40caiyunapp.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liaoruoyu@caiyunapp.com">Jo-Yu Liao</a>, <a href="https://openreview.net/profile?email=yuan%40caiyunapp.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuan@caiyunapp.com">Xingyuan Yuan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJlMAAeC--details-482" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJlMAAeC--details-482"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">To overcome the limitations of Neural Programmer-Interpreters (NPI) in its universality and learnability, we propose the incorporation of combinator abstraction into neural programing and a new NPI architecture to support this abstraction, which we call Combinatory Neural Programmer-Interpreter (CNPI). Combinator abstraction dramatically reduces the number and complexity of programs that need to be interpreted by the core controller of CNPI, while still allowing the CNPI to represent and interpret arbitrary complex programs by the collaboration of the core with the other components. We propose a small set of four combinators to capture the most pervasive programming patterns. Due to the finiteness and simplicity of this combinator set and the offloading of some burden of interpretation from the core, we are able construct a CNPI that is universal with respect to the set of all combinatorizable programs, which is adequate for solving most algorithmic tasks. Moreover, besides supervised training on execution traces, CNPI can be trained by policy gradient reinforcement learning with appropriately designed curricula.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural programming, Neural Programmer-Interpreter</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJvvRoe0W">
      <h4>
        <a href="https://openreview.net/forum?id=HJvvRoe0W">
          An image representation based convolutional network for DNA classification
        </a>
        
          <a href="https://openreview.net/pdf?id=HJvvRoe0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yinbojian93%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yinbojian93@gmail.com">Bojian Yin</a>, <a href="https://openreview.net/profile?email=m.balvert%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.balvert@cwi.nl">Marleen Balvert</a>, <a href="https://openreview.net/profile?email=d.zambrano%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.zambrano@cwi.nl">Davide Zambrano</a>, <a href="https://openreview.net/profile?email=a.schoenhuth%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.schoenhuth@cwi.nl">Alexander Schoenhuth</a>, <a href="https://openreview.net/profile?email=s.m.bohte%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.m.bohte@cwi.nl">Sander Bohte</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJvvRoe0W-details-332" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJvvRoe0W-details-332"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The folding structure of the DNA molecule combined with helper molecules, also referred to as the chromatin, is highly relevant for the functional properties of DNA. The chromatin structure is largely determined by the underlying primary DNA sequence, though the interaction is not yet fully understood. In this paper we develop a convolutional neural network that takes an image-representation of primary DNA sequence as its input, and predicts key determinants of chromatin structure. The method is developed such that it is capable of detecting interactions between distal elements in the DNA sequence, which are known to be highly relevant. Our experiments show that the method outperforms several existing methods both in terms of prediction accuracy and training time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A method to transform DNA sequences into 2D images using space-filling Hilbert Curves to enhance the strengths of CNNs</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">DNA sequences, Hilbert curves, Convolutional neural networks, chromatin structure</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rydeCEhs-">
      <h4>
        <a href="https://openreview.net/forum?id=rydeCEhs-">
          SMASH: One-Shot Model Architecture Search through HyperNetworks
        </a>
        
          <a href="https://openreview.net/pdf?id=rydeCEhs-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ajb5%40hw.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajb5@hw.ac.uk">Andrew Brock</a>, <a href="https://openreview.net/profile?email=t.lim%40hw.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="t.lim@hw.ac.uk">Theo Lim</a>, <a href="https://openreview.net/profile?email=j.m.ritchie%40hw.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.m.ritchie@hw.ac.uk">J.M. Ritchie</a>, <a href="https://openreview.net/profile?email=nick.weston%40renishaw.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nick.weston@renishaw.com">Nick Weston</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rydeCEhs--details-574" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rydeCEhs--details-574"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Designing architectures for deep neural networks requires expert knowledge and substantial computation time. We propose a technique to accelerate architecture selection by learning an auxiliary HyperNet that generates the weights of a main model conditioned on that model's architecture. By comparing the relative validation performance of networks with HyperNet-generated weights, we can effectively search over a wide range of architectures at the cost of a single training run. To facilitate this search, we develop a flexible mechanism based on memory read-writes that allows us to define a wide range of network connectivity patterns, with ResNet, DenseNet, and FractalNet blocks as special cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100, STL-10, ModelNet10, and Imagenet32x32, achieving competitive performance with similarly-sized hand-designed networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A technique for accelerating neural architecture selection by approximating the weights of each candidate architecture instead of training them individually.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meta-learning, architecture search, deep learning, computer vision</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByBAl2eAZ">
      <h4>
        <a href="https://openreview.net/forum?id=ByBAl2eAZ">
          Parameter Space Noise for Exploration
        </a>
        
          <a href="https://openreview.net/pdf?id=ByBAl2eAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=matthiasplappert%40me.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthiasplappert@me.com">Matthias Plappert</a>, <a href="https://openreview.net/profile?email=rein.houthooft%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rein.houthooft@openai.com">Rein Houthooft</a>, <a href="https://openreview.net/profile?email=prafulla%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="prafulla@openai.com">Prafulla Dhariwal</a>, <a href="https://openreview.net/profile?email=szymon%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="szymon@openai.com">Szymon Sidor</a>, <a href="https://openreview.net/profile?email=richardchen%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="richardchen@openai.com">Richard Y. Chen</a>, <a href="https://openreview.net/profile?email=peter%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peter@openai.com">Xi Chen</a>, <a href="https://openreview.net/profile?email=asfour%40kit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asfour@kit.edu">Tamim Asfour</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>, <a href="https://openreview.net/profile?email=marcin%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marcin@openai.com">Marcin Andrychowicz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByBAl2eAZ-details-865" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByBAl2eAZ-details-865"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning (RL) methods generally engage in exploratory behavior through noise injection in the action space. An alternative is to add noise directly to the agent's parameters, which can lead to more consistent exploration and a richer set of behaviors. Methods such as evolutionary strategies use parameter perturbations, but discard all temporal structure in the process and require significantly more samples. Combining parameter noise with traditional RL methods allows to combine the best of both worlds. We demonstrate that both off- and on-policy methods benefit from this approach through experimental comparison of DQN, DDPG, and TRPO on high-dimensional discrete action environments as well as continuous control tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Parameter space noise allows reinforcement learning algorithms to explore by perturbing parameters instead of actions, often leading to significantly improved exploration performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, exploration, parameter noise</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1VVsebAZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1VVsebAZ">
          Synthesizing realistic neural population activity patterns using Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1VVsebAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=manuel.molano%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="manuel.molano@iit.it">Manuel Molano-Mazon</a>, <a href="https://openreview.net/profile?email=aonken%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="aonken@inf.ed.ac.uk">Arno Onken</a>, <a href="https://openreview.net/profile?email=epiasini%40sas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="epiasini@sas.upenn.edu">Eugenio Piasini*</a>, <a href="https://openreview.net/profile?email=stefano.panzeri%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefano.panzeri@iit.it">Stefano Panzeri*</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1VVsebAZ-details-273" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1VVsebAZ-details-273"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The ability to synthesize realistic patterns of neural activity is crucial for studying neural information processing. Here we used the Generative Adversarial Networks (GANs) framework to simulate the concerted activity of a population of neurons.
      We adapted the Wasserstein-GAN variant to facilitate the generation of unconstrained neural population activity patterns while still benefiting from parameter sharing in the temporal domain.
      We demonstrate that our proposed GAN, which we termed Spike-GAN, generates spike trains that match accurately the first- and second-order statistics of datasets of tens of neurons and also approximates well their higher-order statistics. We applied Spike-GAN to a real dataset recorded from salamander retina and showed that it performs as well as state-of-the-art approaches based on the maximum entropy and the dichotomized Gaussian frameworks. Importantly, Spike-GAN does not require to specify a priori the statistics to be matched by the model, and so constitutes a more flexible method than these alternative approaches.
      Finally, we show how to exploit a trained Spike-GAN  to construct 'importance maps' to detect the most relevant statistical structures present in a spike train. 
      Spike-GAN provides a powerful, easy-to-use technique for generating realistic spiking neural activity and for describing the most relevant features of the large-scale neural population recordings studied in modern systems neuroscience.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using Wasserstein-GANs to generate realistic neural activity and to detect the most relevant features present in neural population patterns.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GANs, Wasserstein-GANs, convolutional networks, neuroscience, spike train patterns, spike train analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ8c3f-0b">
      <h4>
        <a href="https://openreview.net/forum?id=BJ8c3f-0b">
          Auto-Encoding Sequential Monte Carlo
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ8c3f-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tuananh%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="tuananh@robots.ox.ac.uk">Tuan Anh Le</a>, <a href="https://openreview.net/profile?email=maximilian.igl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maximilian.igl@gmail.com">Maximilian Igl</a>, <a href="https://openreview.net/profile?email=twgr%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="twgr@robots.ox.ac.uk">Tom Rainforth</a>, <a href="https://openreview.net/profile?email=tom%40jin.me.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom@jin.me.uk">Tom Jin</a>, <a href="https://openreview.net/profile?email=fwood%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="fwood@robots.ox.ac.uk">Frank Wood</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ8c3f-0b-details-952" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ8c3f-0b-details-952"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We build on auto-encoding sequential Monte Carlo (AESMC): a method for model and proposal learning based on maximizing the lower bound to the log marginal likelihood in a broad family of structured probabilistic models. Our approach relies on the efficiency of sequential Monte Carlo (SMC) for performing inference in structured probabilistic models and the flexibility of deep neural networks to model complex conditional probability distributions. We develop additional theoretical insights and introduce a new training procedure which improves both model and proposal learning. We demonstrate that our approach provides a fast, easy-to-implement and scalable means for simultaneous model learning and proposal adaptation in deep generative models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We build on auto-encoding sequential Monte Carlo, gain new theoretical insights and develop an improved training procedure based on those insights.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Variational Autoencoders, Inference amortization, Model learning, Sequential Monte Carlo, ELBOs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJewuJWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJewuJWCZ">
          Learning to Teach
        </a>
        
          <a href="https://openreview.net/pdf?id=HJewuJWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=fyabc%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="fyabc@mail.ustc.edu.cn">Yang Fan</a>, <a href="https://openreview.net/profile?email=fetia%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fetia@microsoft.com">Fei Tian</a>, <a href="https://openreview.net/profile?email=taoqin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taoqin@microsoft.com">Tao Qin</a>, <a href="https://openreview.net/profile?email=tyliu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tyliu@microsoft.com">Xiang-Yang Li</a>, Tie-Yan Liu
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJewuJWCZ-details-832" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJewuJWCZ-details-832"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Teaching plays a very important role in our society, by spreading human knowledge and educating our next generations. A good teacher will select appropriate teaching materials, impact suitable methodologies, and set up targeted examinations, according to the learning behaviors of the students. In the field of artificial intelligence, however, one has not fully explored the role of teaching, and pays most attention to machine \emph{learning}. In this paper, we argue that equal attention, if not more, should be paid to teaching, and furthermore, an optimization framework (instead of heuristics) should be used to obtain good teaching strategies. We call this approach ``learning to teach''. In the approach, two intelligent agents interact with each other: a student model (which corresponds to the learner in traditional machine learning algorithms), and a teacher model (which determines the appropriate data, loss function, and hypothesis space to facilitate the training of the student model). The teacher model leverages the feedback from the student model to optimize its own teaching strategies by means of reinforcement learning, so as to achieve teacher-student co-evolution. To demonstrate the practical value of our proposed approach, we take the training of deep neural networks (DNN) as an example, and show that by using the learning to teach techniques, we are able to use much less training data and fewer iterations to achieve almost the same accuracy for different kinds of DNN models (e.g., multi-layer perceptron, convolutional neural networks and recurrent neural networks) under various machine learning tasks (e.g., image classification and text understanding).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose and verify the effectiveness of learning to teach, a new framework to automatically guide machine learning process.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syhr6pxCW">
      <h4>
        <a href="https://openreview.net/forum?id=Syhr6pxCW">
          PixelNN: Example-based Image Synthesis
        </a>
        
          <a href="https://openreview.net/pdf?id=Syhr6pxCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aayushb%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aayushb@cs.cmu.edu">Aayush Bansal</a>, <a href="https://openreview.net/profile?email=yaser%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaser@cs.cmu.edu">Yaser Sheikh</a>, <a href="https://openreview.net/profile?email=deva%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="deva@cs.cmu.edu">Deva Ramanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syhr6pxCW-details-797" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syhr6pxCW-details-797"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a simple nearest-neighbor (NN) approach that synthesizes high-frequency photorealistic images from an ``incomplete'' signal such as a low-resolution image, a surface normal map, or edges. Current state-of-the-art deep generative models designed for such conditional image synthesis lack two important things: (1) they are unable to generate a large set of diverse outputs, due to the mode collapse problem. (2) they are not interpretable, making it difficult to control the synthesized output. We demonstrate that NN approaches potentially address such limitations, but suffer in accuracy on small datasets. We design a simple pipeline that combines the best of both worlds:  the first stage uses a convolutional neural network (CNN) to map the input to a (overly-smoothed) image, and the second stage uses a pixel-wise nearest neighbor method to map the smoothed output to multiple high-quality, high-frequency outputs in a controllable manner. Importantly, pixel-wise matching allows our method to compose novel high-frequency content by cutting-and-pasting pixels from different training exemplars.  We demonstrate our approach for various input modalities, and for various domains ranging from human faces, pets, shoes, and handbags.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Pixel-wise nearest neighbors used for generating multiple images from incomplete priors such as a low-res images, surface normals, edges etc.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">conditional image synthesis, nearest neighbors</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1l8BtlCb">
      <h4>
        <a href="https://openreview.net/forum?id=B1l8BtlCb">
          Non-Autoregressive Neural Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=B1l8BtlCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jiataogu%40eee.hku.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiataogu@eee.hku.hk">Jiatao Gu</a>, <a href="https://openreview.net/profile?email=james.bradbury%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.bradbury@salesforce.com">James Bradbury</a>, <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=vli%40eee.hku.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="vli@eee.hku.hk">Victor O.K. Li</a>, <a href="https://openreview.net/profile?email=rsocher%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsocher@salesforce.com">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1l8BtlCb-details-234" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1l8BtlCb-details-234"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Existing approaches to neural machine translation condition each output word on previously generated outputs. We introduce a model that avoids this autoregressive property and produces its outputs in parallel, allowing an order of magnitude lower latency during inference. Through knowledge distillation, the use of input token fertilities as a latent variable, and policy gradient fine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative to the autoregressive Transformer network used as a teacher. We demonstrate substantial cumulative improvements associated with each of the three aspects of our training strategy, and validate our approach on IWSLT 2016 English–German and two WMT language pairs. By sampling fertilities in parallel at inference time, our non-autoregressive model achieves near-state-of-the-art performance of 29.8 BLEU on WMT 2016 English–Romanian.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the first NMT model with fully parallel decoding, reducing inference latency by 10x.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine translation, non-autoregressive, transformer, fertility, nmt</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJtEm4p6Z">
      <h4>
        <a href="https://openreview.net/forum?id=HJtEm4p6Z">
          Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HJtEm4p6Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pingwei01%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pingwei01@baidu.com">Wei Ping</a>, <a href="https://openreview.net/profile?email=pengkainan%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pengkainan@baidu.com">Kainan Peng</a>, <a href="https://openreview.net/profile?email=gibianskyandrew%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gibianskyandrew@baidu.com">Andrew Gibiansky</a>, <a href="https://openreview.net/profile?email=sercanarik%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sercanarik@baidu.com">Sercan O. Arik</a>, <a href="https://openreview.net/profile?email=kannanajay%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kannanajay@baidu.com">Ajay Kannan</a>, <a href="https://openreview.net/profile?email=sharan%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sharan@baidu.com">Sharan Narang</a>, <a href="https://openreview.net/profile?email=raiman%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raiman@openai.com">Jonathan Raiman</a>, <a href="https://openreview.net/profile?email=miller_john%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="miller_john@berkeley.edu">John Miller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJtEm4p6Z-details-61" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJtEm4p6Z-details-61"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training an order of magnitude faster. We scale Deep Voice 3 to dataset sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on a single GPU server.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">2000-Speaker Neural TTS, Monotonic Attention, Speech Synthesis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1Ddp1-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=r1Ddp1-Rb">
          mixup: Beyond Empirical Risk Minimization
        </a>
        
          <a href="https://openreview.net/pdf?id=r1Ddp1-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hongyiz%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongyiz@mit.edu">Hongyi Zhang</a>, <a href="https://openreview.net/profile?email=moustaphacisse%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="moustaphacisse@fb.com">Moustapha Cisse</a>, <a href="https://openreview.net/profile?email=ynd%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ynd@fb.com">Yann N. Dauphin</a>, <a href="https://openreview.net/profile?email=dlp%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlp@fb.com">David Lopez-Paz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1Ddp1-Rb-details-132" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1Ddp1-Rb-details-132"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels.  By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples.  Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures.  We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Training on convex combinations between random training examples and their labels improves generalization in deep neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">empirical risk minimization, vicinal risk minimization, generalization, data augmentation, image classification, generative adversarial networks, adversarial examples, random labels</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyiAuyb0b">
      <h4>
        <a href="https://openreview.net/forum?id=HyiAuyb0b">
          TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HyiAuyb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amiranas%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="amiranas@cs.uni-freiburg.de">Artemij Amiranashvili</a>, <a href="https://openreview.net/profile?email=adosovitskiy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adosovitskiy@gmail.com">Alexey Dosovitskiy</a>, <a href="https://openreview.net/profile?email=vkoltun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkoltun@gmail.com">Vladlen Koltun</a>, <a href="https://openreview.net/profile?email=brox%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="brox@cs.uni-freiburg.de">Thomas Brox</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 17 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyiAuyb0b-details-116" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyiAuyb0b-details-116"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Our understanding of reinforcement learning (RL) has been shaped by theoretical and empirical results that were obtained decades ago using tabular representations and linear function approximators. These results suggest that RL methods that use temporal differencing (TD) are superior to direct Monte Carlo estimation (MC). How do these results hold up in deep RL, which deals with perceptually complex environments and deep nonlinear models? In this paper, we re-examine the role of TD in modern deep RL, using specially designed environments that control for specific factors that affect performance, such as reward sparsity, reward delay, and the perceptual complexity of the task. When comparing TD with infinite-horizon MC, we are able to reproduce classic results in modern settings. Yet we also find that finite-horizon MC is not inferior to TD, even when rewards are sparse or delayed. This makes MC a viable alternative to TD in deep RL.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, reinforcement learning, temporal difference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry1arUgCW">
      <h4>
        <a href="https://openreview.net/forum?id=ry1arUgCW">
          DORA The Explorer: Directed Outreaching Reinforcement Action-Selection
        </a>
        
          <a href="https://openreview.net/pdf?id=ry1arUgCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lior.fox%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="lior.fox@mail.huji.ac.il">Lior Fox</a>, <a href="https://openreview.net/profile?email=leshem.choshen%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="leshem.choshen@mail.huji.ac.il">Leshem Choshen</a>, <a href="https://openreview.net/profile?email=yonatan.loewenstein%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="yonatan.loewenstein@mail.huji.ac.il">Yonatan Loewenstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry1arUgCW-details-176" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry1arUgCW-details-176"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Exploration is a fundamental aspect of Reinforcement Learning, typically implemented using stochastic action-selection. Exploration, however, can be more efficient if directed toward gaining new world knowledge. Visit-counters have been proven useful both in practice and in theory for directed exploration. However, a major limitation of counters is their locality. While there are a few model-based solutions to this shortcoming, a model-free approach is still missing.
      We propose $E$-values, a generalization of counters that can be used to evaluate the propagating exploratory value over state-action trajectories. We compare our approach to commonly used RL techniques, and show that using $E$-values improves learning and performance over traditional counters. We also show how our method can be implemented with function approximation to efficiently learn continuous MDPs. We demonstrate this by showing that our approach surpasses state of the art performance in the Freeway Atari 2600 game.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a generalization of visit-counters that evaluate the propagating exploratory value over trajectories, enabling efficient exploration for model-free RL</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Exploration, Model-Free</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skw0n-W0Z">
      <h4>
        <a href="https://openreview.net/forum?id=Skw0n-W0Z">
          Temporal Difference Models: Model-Free Deep RL for Model-Based Control
        </a>
        
          <a href="https://openreview.net/pdf?id=Skw0n-W0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vitchyr%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitchyr@berkeley.edu">Vitchyr Pong*</a>, <a href="https://openreview.net/profile?email=sg717%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sg717@cam.ac.uk">Shixiang Gu*</a>, <a href="https://openreview.net/profile?email=mdalal%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mdalal@berkeley.edu">Murtaza Dalal</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skw0n-W0Z-details-8" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skw0n-W0Z-details-8"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model-free reinforcement learning (RL) has been proven to be a powerful, general tool for learning complex behaviors. However, its sample efficiency is often impractically large for solving challenging real-world problems, even for off-policy algorithms such as Q-learning. A limiting factor in classic model-free RL is that the learning signal consists only of scalar rewards, ignoring much of the rich information contained in state transition tuples. Model-based RL uses this information, by training a predictive model, but often does not achieve the same asymptotic performance as model-free RL due to model bias. We introduce temporal difference models (TDMs), a family of goal-conditioned value functions that can be trained with model-free learning and used for model-based control. TDMs combine the benefits of model-free and model-based RL: they leverage the rich information in state transitions to learn very efficiently, while still attaining asymptotic performance that exceeds that of direct model-based RL methods. Our experimental results show that, on a range of continuous control tasks, TDMs provide a substantial improvement in efficiency compared to state-of-the-art model-based and model-free methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that a special goal-condition value function trained with model free methods can be used within model-based control, resulting in substantially better sample efficiency and performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">model-based reinforcement learning, model-free reinforcement learning, temporal difference learning, predictive learning, predictive models, optimal control, off-policy reinforcement learning, deep learning, deep reinforcement learning, q learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1dh6Ax0Z">
      <h4>
        <a href="https://openreview.net/forum?id=H1dh6Ax0Z">
          TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=H1dh6Ax0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gregory.farquhar%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="gregory.farquhar@cs.ox.ac.uk">Gregory Farquhar</a>, <a href="https://openreview.net/profile?email=tim.rocktaeschel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tim.rocktaeschel@gmail.com">Tim Rocktäschel</a>, <a href="https://openreview.net/profile?email=maximilian.igl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maximilian.igl@gmail.com">Maximilian Igl</a>, <a href="https://openreview.net/profile?email=shimon.whiteson%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shimon.whiteson@gmail.com">Shimon Whiteson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1dh6Ax0Z-details-197" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1dh6Ax0Z-details-197"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Combining deep model-free reinforcement learning with on-line planning is a promising approach to building on the successes of deep RL. On-line planning with look-ahead trees has proven successful in environments where transition models are known a priori. However, in complex environments where transition models need to be learned from data, the deficiencies of learned models have limited their utility for planning. To address these challenges, we propose TreeQN, a differentiable, recursive, tree-structured model that serves as a drop-in replacement for any value function network in deep RL with discrete actions. TreeQN dynamically constructs a tree by recursively applying a transition model in a learned abstract state space and then aggregating predicted rewards and state-values using a tree backup to estimate Q-values. We also propose ATreeC, an actor-critic variant that augments TreeQN with a softmax layer to form a stochastic policy network. Both approaches are trained end-to-end, such that the learned model is optimised for its actual use in the tree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a box-pushing task, as well as n-step DQN and value prediction networks (Oh et al., 2017) on multiple Atari games. Furthermore, we present ablation studies that demonstrate the effect of different auxiliary losses on learning transition models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present TreeQN and ATreeC, new architectures for deep reinforcement learning in discrete-action domains that integrate differentiable on-line tree planning into the action-value function or policy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, deep learning, planning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S19dR9x0b">
      <h4>
        <a href="https://openreview.net/forum?id=S19dR9x0b">
          Alternating Multi-bit Quantization for Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S19dR9x0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xuen%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuen@pku.edu.cn">Chen Xu</a>, <a href="https://openreview.net/profile?email=tianduo%40taobao.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianduo@taobao.com">Jianqiang Yao</a>, <a href="https://openreview.net/profile?email=zlin%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlin@pku.edu.cn">Zhouchen Lin</a>, <a href="https://openreview.net/profile?email=santong.oww%40taobao.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="santong.oww@taobao.com">Wenwu Ou</a>, <a href="https://openreview.net/profile?email=lingzun.cyb%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lingzun.cyb@alibaba-inc.com">Yuanbin Cao</a>, <a href="https://openreview.net/profile?email=qingfeng%40taobao.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qingfeng@taobao.com">Zhirong Wang</a>, <a href="https://openreview.net/profile?email=zha%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zha@cis.pku.edu.cn">Hongbin Zha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S19dR9x0b-details-517" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S19dR9x0b-details-517"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks have achieved excellent performance in many applications. However, on portable devices with limited resources, the models are often too large to deploy. For applications on the server with large scale concurrent requests, the latency during inference can also be very critical for costly computing resources. In this work, we address these problems by quantizing the network, both weights and activations, into multiple binary codes {-1,+1}. We formulate the quantization as an optimization problem. Under the key observation that once the quantization coefficients are fixed the binary codes can be derived efficiently by binary search tree, alternating minimization is then applied.  We test the quantization for two well-known RNNs, i.e., long short term memory (LSTM) and gated recurrent unit (GRU), on the language models. Compared with the full-precision counter part, by 2-bit quantization we can achieve ~16x memory saving and  ~6x real inference acceleration on CPUs, with only a reasonable loss in the accuracy. By 3-bit quantization, we can achieve almost no loss in the accuracy or even surpass the original model, with ~10.5x memory saving and ~3x real inference acceleration. Both results beat the exiting quantization works with large margins.  We extend our alternating quantization to image classification tasks. In both RNNs and feedforward neural networks, the method also achieves  excellent performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a  new  quantization method and apply it to quantize RNNs for both compression and acceleration</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Alternating Minimization, Quantized Recurrent Neural Network, Binary Search Tree</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJNMYceCW">
      <h4>
        <a href="https://openreview.net/forum?id=HJNMYceCW">
          Residual Loss Prediction: Reinforcement Learning With No Incremental Feedback
        </a>
        
          <a href="https://openreview.net/pdf?id=HJNMYceCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hal%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hal@umiacs.umd.edu">Hal Daumé III</a>, <a href="https://openreview.net/profile?email=jl%40hunch.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="jl@hunch.net">John Langford</a>, <a href="https://openreview.net/profile?email=amr%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amr@cs.umd.edu">Amr Sharaf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJNMYceCW-details-888" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJNMYceCW-details-888"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider reinforcement learning and bandit structured prediction problems with very sparse loss feedback: only at the end of an episode. We introduce a novel algorithm, RESIDUAL LOSS PREDICTION (RESLOPE), that solves such problems by automatically learning an internal representation of a denser reward function. RESLOPE operates as a reduction to contextual bandits, using its learned loss representation to solve the credit assignment problem, and a contextual bandit oracle to trade-off exploration and exploitation. RESLOPE enjoys a no-regret reduction-style theoretical guarantee and outperforms state of the art reinforcement learning algorithms in both MDP environments and bandit structured prediction settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a novel algorithm for solving reinforcement learning and bandit structured prediction problems with very sparse loss feedback.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Structured Prediction, Contextual Bandits, Learning Reduction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyOK1Sg0W">
      <h4>
        <a href="https://openreview.net/forum?id=SyOK1Sg0W">
          Adaptive Quantization of Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SyOK1Sg0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=khoram%40wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="khoram@wisc.edu">Soroosh Khoram</a>, <a href="https://openreview.net/profile?email=jli%40ece.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jli@ece.wisc.edu">Jing Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyOK1Sg0W-details-34" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyOK1Sg0W-details-34"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite the state-of-the-art accuracy of Deep Neural Networks (DNN) in various classification problems, their deployment onto resource constrained edge computing devices remains challenging due to their large size and complexity. Several recent studies have reported remarkable results in reducing this complexity through quantization of DNN models. However, these studies usually do not consider the changes in the loss function when performing quantization, nor do they take the different importances of DNN model parameters to the accuracy into account. We address these issues in this paper by proposing a new method, called adaptive quantization, which simplifies a trained DNN model by finding a unique, optimal precision for each network parameter such that the increase in loss is minimized. The optimization problem at the core of this method iteratively uses the loss function gradient to determine an error margin for each parameter and assigns it a precision accordingly. Since this problem uses linear functions, it is computationally cheap and, as we will show, has a closed-form approximate solution. Experiments on MNIST, CIFAR, and SVHN datasets showed that the proposed method can achieve near or better than state-of-the-art reduction in model size with similar error rates. Furthermore, it can achieve compressions close to floating-point model compression methods without loss of accuracy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An adaptive method for fixed-point quantization of neural networks based on theoretical analysis rather than heuristics. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Neural Networks, Model Quantization, Model Compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkUp6GZRW">
      <h4>
        <a href="https://openreview.net/forum?id=BkUp6GZRW">
          Boosting the Actor with Dual Critic
        </a>
        
          <a href="https://openreview.net/pdf?id=BkUp6GZRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bohr.dai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bohr.dai@gmail.com">Bo Dai</a>, <a href="https://openreview.net/profile?email=ashaw596%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashaw596@gatech.edu">Albert Shaw</a>, <a href="https://openreview.net/profile?email=niaohe%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="niaohe@illinois.edu">Niao He</a>, <a href="https://openreview.net/profile?email=lihongli.cs%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lihongli.cs@gmail.com">Lihong Li</a>, <a href="https://openreview.net/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkUp6GZRW-details-266" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkUp6GZRW-details-266"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper proposes a new actor-critic-style algorithm called Dual Actor-Critic or Dual-AC.  It is derived in a principled way from the Lagrangian dual form of the Bellman optimality equation, which can be viewed as a two-player game between the actor and a critic-like function, which is named as dual critic.  Compared to its actor-critic relatives, Dual-AC has the desired property that the actor and dual critic are updated cooperatively to optimize the same objective function, providing a more transparent way for learning the critic that is directly related to the objective function of the actor. We then provide a concrete algorithm that can effectively solve the minimax optimization problem, using techniques of multi-step bootstrapping, path regularization, and stochastic dual ascent algorithm. We demonstrate that the proposed algorithm achieves the state-of-the-art performances across several benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose Dual Actor-Critic algorithm, which is derived in a principled way from the Lagrangian dual form of the Bellman optimality equation. The algorithm achieves the state-of-the-art performances across several benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, actor-critic algorithm, Lagrangian duality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJk59JZ0b">
      <h4>
        <a href="https://openreview.net/forum?id=BJk59JZ0b">
          Guide Actor-Critic for Continuous Control
        </a>
        
          <a href="https://openreview.net/pdf?id=BJk59JZ0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=voot.tangkaratt%40riken.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="voot.tangkaratt@riken.jp">Voot Tangkaratt</a>, <a href="https://openreview.net/profile?email=abbas.a%40ua.pt" class="profile-link" data-toggle="tooltip" data-placement="top" title="abbas.a@ua.pt">Abbas Abdolmaleki</a>, <a href="https://openreview.net/profile?email=masashi.sugiyama%40riken.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="masashi.sugiyama@riken.jp">Masashi Sugiyama</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJk59JZ0b-details-602" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJk59JZ0b-details-602"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Actor-critic methods solve reinforcement learning problems by updating a parameterized policy known as an actor in a direction that increases an estimate of the expected return known as a critic. However, existing actor-critic methods only use values or gradients of the critic to update the policy parameter. In this paper, we propose a novel actor-critic method called the guide actor-critic (GAC). GAC firstly learns a guide actor that locally maximizes the critic and then it updates the policy parameter based on the guide actor by supervised learning. Our main theoretical contributions are two folds. First, we show that GAC updates the guide actor by performing second-order optimization in the action space where the curvature matrix is based on the Hessians of the critic. Second, we show that the deterministic policy gradient method is a special case of GAC when the Hessians are ignored. Through experiments, we show that our method is a promising reinforcement learning method for continuous controls.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper proposes a novel actor-critic method that uses Hessians of a critic to update an actor.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning, actor-critic, continuous control</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByOnmlWC-">
      <h4>
        <a href="https://openreview.net/forum?id=ByOnmlWC-">
          Policy Optimization by Genetic Distillation 
        </a>
        
          <a href="https://openreview.net/pdf?id=ByOnmlWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gangwan2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gangwan2@illinois.edu">Tanmay Gangwani</a>, <a href="https://openreview.net/profile?email=jianpeng%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianpeng@illinois.edu">Jian Peng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByOnmlWC--details-923" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByOnmlWC--details-923"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Genetic algorithms have been widely used in many practical optimization problems.
      Inspired by natural selection, operators, including mutation, crossover
      and selection, provide effective heuristics for search and black-box optimization.
      However, they have not been shown useful for deep reinforcement learning, possibly
      due to the catastrophic consequence of parameter crossovers of neural networks.
      Here, we present Genetic Policy Optimization (GPO), a new genetic algorithm
      for sample-efficient deep policy optimization. GPO uses imitation learning
      for policy crossover in the state space and applies policy gradient methods for mutation.
      Our experiments on MuJoCo tasks show that GPO as a genetic algorithm
      is able to provide superior performance over the state-of-the-art policy gradient
      methods and achieves comparable or higher sample efficiency.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Genetic algorithms based approach for optimizing deep neural network policies</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Genetic algorithms, deep reinforcement learning, imitation learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkA-IE06W">
      <h4>
        <a href="https://openreview.net/forum?id=SkA-IE06W">
          When is a Convolutional Filter Easy to Learn?
        </a>
        
          <a href="https://openreview.net/pdf?id=SkA-IE06W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ssdu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ssdu@cs.cmu.edu">Simon S. Du</a>, <a href="https://openreview.net/profile?email=jasonlee%40marshall.usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jasonlee@marshall.usc.edu">Jason D. Lee</a>, <a href="https://openreview.net/profile?email=yuandong%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuandong@fb.com">Yuandong Tian</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkA-IE06W-details-455" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkA-IE06W-details-455"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function. Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input. We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches. To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions. Our theory also justifies the two-stage learning rate strategy in deep neural networks. While our focus is theoretical, we also present experiments that justify our theoretical findings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove randomly initialized (stochastic) gradient descent learns a convolutional filter in polynomial time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, convolutional neural network, non-convex optimization, convergence analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkrsAzWAb">
      <h4>
        <a href="https://openreview.net/forum?id=BkrsAzWAb">
          Online Learning Rate Adaptation with Hypergradient Descent
        </a>
        
          <a href="https://openreview.net/pdf?id=BkrsAzWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gunes%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="gunes@robots.ox.ac.uk">Atilim Gunes Baydin</a>, <a href="https://openreview.net/profile?email=rcornish%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="rcornish@robots.ox.ac.uk">Robert Cornish</a>, <a href="https://openreview.net/profile?email=david.martinez2%40wadh.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.martinez2@wadh.ox.ac.uk">David Martinez Rubio</a>, <a href="https://openreview.net/profile?email=schmidtm%40cs.ubc.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="schmidtm@cs.ubc.ca">Mark Schmidt</a>, <a href="https://openreview.net/profile?email=fwood%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="fwood@robots.ox.ac.uk">Frank Wood</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 26 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkrsAzWAb-details-512" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkrsAzWAb-details-512"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a general method for improving the convergence rate of gradient-based optimizers that is easy to implement and works well in practice.  We demonstrate the effectiveness of the method in a range of optimization problems by applying it to stochastic gradient descent, stochastic gradient descent with Nesterov momentum, and Adam, showing that it significantly reduces the need for the manual tuning of the initial learning rate for these commonly used algorithms.  Our method works by dynamically updating the learning rate during optimization using the gradient with respect to the learning rate of the update rule itself.  Computing this "hypergradient" needs little additional computation, requires only one extra copy of the original gradient to be stored in memory, and relies upon nothing more than what is provided by reverse-mode automatic differentiation.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyWrIgW0W">
      <h4>
        <a href="https://openreview.net/forum?id=HyWrIgW0W">
          Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyWrIgW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pratikac%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pratikac@ucla.edu">Pratik Chaudhari</a>, <a href="https://openreview.net/profile?email=soatto%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="soatto@ucla.edu">Stefano Soatto</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyWrIgW0W-details-193" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyWrIgW0W-details-193"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such out-of-equilibrium behavior is a consequence of highly non-isotropic gradient noise in SGD; the covariance matrix of mini-batch gradients for deep networks has a rank as small as 1% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sgd, variational inference, gradient noise, out-of-equilibrium</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByrZyglCb">
      <h4>
        <a href="https://openreview.net/forum?id=ByrZyglCb">
          Robustness of Classifiers to Universal Perturbations: A Geometric Perspective
        </a>
        
          <a href="https://openreview.net/pdf?id=ByrZyglCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=seyed.moosavi%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="seyed.moosavi@epfl.ch">Seyed-Mohsen Moosavi-Dezfooli</a>, <a href="https://openreview.net/profile?email=fawzi%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fawzi@cs.ucla.edu">Alhussein Fawzi</a>, <a href="https://openreview.net/profile?email=omar.fawzi%40ens-lyon.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="omar.fawzi@ens-lyon.fr">Omar Fawzi</a>, <a href="https://openreview.net/profile?email=pascal.frossard%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="pascal.frossard@epfl.ch">Pascal Frossard</a>, <a href="https://openreview.net/profile?email=soatto%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="soatto@cs.ucla.edu">Stefano Soatto</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByrZyglCb-details-84" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByrZyglCb-details-84"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we provide a quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exist shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Analysis of vulnerability of classifiers to universal perturbations and relation to the curvature of the decision boundary.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Universal perturbations, robustness, curvature</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1hYRMbCW">
      <h4>
        <a href="https://openreview.net/forum?id=B1hYRMbCW">
          On the regularization of Wasserstein GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=B1hYRMbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=henning.petzka%40iais.fraunhofer.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="henning.petzka@iais.fraunhofer.de">Henning Petzka</a>, <a href="https://openreview.net/profile?email=asja.fischer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="asja.fischer@gmail.com">Asja Fischer</a>, <a href="https://openreview.net/profile?email=lukovnik%40cs.uni-bonn.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukovnik@cs.uni-bonn.de">Denis Lukovnikov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1hYRMbCW-details-847" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1hYRMbCW-details-847"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Since their invention, generative adversarial networks (GANs) have become a popular approach for learning to model a distribution of real (unlabeled) data. Convergence problems during training are overcome by Wasserstein GANs which minimize the distance between the model and the empirical distribution in terms of a different metric, but thereby introduce a Lipschitz constraint into the optimization problem. A simple way to enforce the Lipschitz constraint on the class of functions, which can be modeled by the neural network, is weight clipping. Augmenting the loss by a regularization term that penalizes the deviation of the gradient norm of the critic (as a function of the network's input) from one, was proposed as an alternative that improves training. We present theoretical arguments why using a weaker regularization term enforcing the Lipschitz constraint is preferable. These arguments are supported by experimental results on several data sets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new regularization term can improve your training of wasserstein gans</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk8ZcAxR-">
      <h4>
        <a href="https://openreview.net/forum?id=Bk8ZcAxR-">
          Eigenoption Discovery through the Deep Successor Representation
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk8ZcAxR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=machado%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="machado@ualberta.ca">Marlos C. Machado</a>, <a href="https://openreview.net/profile?email=crosenbaum%40umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="crosenbaum@umass.edu">Clemens Rosenbaum</a>, <a href="https://openreview.net/profile?email=xiaoxiao.guo%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoxiao.guo@ibm.com">Xiaoxiao Guo</a>, <a href="https://openreview.net/profile?email=miao.liu1%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="miao.liu1@ibm.com">Miao Liu</a>, <a href="https://openreview.net/profile?email=gtesauro%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gtesauro@us.ibm.com">Gerald Tesauro</a>, <a href="https://openreview.net/profile?email=mcam%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcam@us.ibm.com">Murray Campbell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk8ZcAxR--details-911" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk8ZcAxR--details-911"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Options in reinforcement learning allow agents to hierarchically decompose a task into subtasks, having the potential to speed up learning and planning. However, autonomously learning effective sets of options is still a major challenge in the field. In this paper we focus on the recently introduced idea of using representation learning methods to guide the option discovery process. Specifically, we look at eigenoptions, options obtained from representations that encode diffusive information flow in the environment. We extend the existing algorithms for eigenoption discovery to settings with stochastic transitions and in which handcrafted features are not available.  We propose an algorithm that discovers eigenoptions while learning non-linear state representations from raw pixels. It exploits recent successes in the deep reinforcement learning literature and the equivalence between proto-value functions and the successor representation. We use traditional tabular domains to provide intuition about our approach and Atari 2600 games to demonstrate its potential.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how we can use the successor representation to discover eigenoptions in stochastic domains, from raw pixels. Eigenoptions are options learned to navigate the latent dimensions of a learned representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, options, successor representation, proto-value functions, Atari, Arcade Learning Environment</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk9zbyZCZ">
      <h4>
        <a href="https://openreview.net/forum?id=Bk9zbyZCZ">
           Neural Map: Structured Memory for Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk9zbyZCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eparisot%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eparisot@andrew.cmu.edu">Emilio Parisotto</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk9zbyZCZ-details-808" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk9zbyZCZ-details-808"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A critical component to enabling intelligent reasoning in partially observable environments is memory. Despite this importance, Deep Reinforcement Learning (DRL) agents have so far used relatively simple memory architectures, with the main methods to overcome partial observability being either a temporal convolution over the past k frames or an LSTM layer. More recent work (Oh et al., 2016) has went beyond these architectures by using memory networks which can allow more sophisticated addressing schemes over the past k frames. But even these architectures are unsatisfactory due to the reason that they are limited to only remembering information from the last k frames. In this paper, we develop a memory system with an adaptable write operator that is customized to the sorts of 3D environments that DRL agents typically interact with. This architecture, called the Neural Map, uses a spatially structured 2D memory image to learn to store arbitrary information about the environment over long time lags. We demonstrate empirically that the Neural Map surpasses previous DRL memories on a set of challenging 2D and 3D maze environments and show that it is capable of generalizing to environments that were not seen during training. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, deep learning, memory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry6-G_66b">
      <h4>
        <a href="https://openreview.net/forum?id=ry6-G_66b">
          Active Neural Localization
        </a>
        
          <a href="https://openreview.net/pdf?id=ry6-G_66b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chaplot%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chaplot@cs.cmu.edu">Devendra Singh Chaplot</a>, <a href="https://openreview.net/profile?email=eparisot%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eparisot@andrew.cmu.edu">Emilio Parisotto</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry6-G_66b-details-400" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry6-G_66b-details-400"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Localization is the problem of estimating the location of an autonomous agent from an observation and a map of the environment. Traditional methods of localization, which filter the belief based on the observations, are sub-optimal in the number of steps required, as they do not decide the actions taken by the agent. We propose "Active Neural Localizer", a fully differentiable neural network that learns to localize efficiently. The proposed model incorporates ideas of traditional filtering-based localization methods, by using a structured belief of the state with multiplicative interactions to propagate belief, and combines it with a policy model to minimize the number of steps required for localization. Active Neural Localizer is trained end-to-end with reinforcement learning. We use a variety of simulation environments for our experiments which include random 2D mazes, random mazes in the Doom game engine and a photo-realistic environment in the Unreal game engine. The results on the 2D environments show the effectiveness of the learned policy in an idealistic setting while results on the 3D environments demonstrate the model's capability of learning the policy and perceptual model jointly from raw-pixel based RGB observations. We also show that a model trained on random textures in the Doom environment generalizes well to a photo-realistic office space environment in the Unreal engine. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">"Active Neural Localizer", a fully differentiable neural network that learns to localize efficiently using deep reinforcement learning.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1al7jg0b">
      <h4>
        <a href="https://openreview.net/forum?id=B1al7jg0b">
          Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation
        </a>
        
          <a href="https://openreview.net/pdf?id=B1al7jg0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=x.he%40jacobs-university.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="x.he@jacobs-university.de">Xu He</a>, <a href="https://openreview.net/profile?email=h.jaeger%40jacobs-university.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="h.jaeger@jacobs-university.de">Herbert Jaeger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1al7jg0b-details-748" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1al7jg0b-details-748"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Catastrophic interference has been a major roadblock in the research of continual learning. Here we propose a variant of the back-propagation algorithm, "Conceptor-Aided Backprop" (CAB), in which gradients are shielded by conceptors against degradation of previously learned tasks. Conceptors have their origin in reservoir computing, where they have been previously shown to overcome catastrophic forgetting. CAB extends these results to deep feedforward networks. On the disjoint and permuted MNIST tasks, CAB outperforms two other methods for coping with catastrophic interference that have recently been proposed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a variant of the backpropagation algorithm, in which gradients are shielded by conceptors against degradation of previously learned tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Catastrophic Interference, Conceptor, Backpropagation, Continual Learning, Lifelong Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyfHgI6aW">
      <h4>
        <a href="https://openreview.net/forum?id=HyfHgI6aW">
          Memory Augmented Control Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyfHgI6aW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arbaazk%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arbaazk@seas.upenn.edu">Arbaaz Khan</a>, <a href="https://openreview.net/profile?email=clarkz%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="clarkz@seas.upenn.edu">Clark Zhang</a>, <a href="https://openreview.net/profile?email=natanasov%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="natanasov@ucsd.edu">Nikolay Atanasov</a>, <a href="https://openreview.net/profile?email=konstantinos.karydis%40ucr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="konstantinos.karydis@ucr.edu">Konstantinos Karydis</a>, <a href="https://openreview.net/profile?email=vijay.kumar%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vijay.kumar@seas.upenn.edu">Vijay Kumar</a>, <a href="https://openreview.net/profile?email=ddlee%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddlee@seas.upenn.edu">Daniel D. Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyfHgI6aW-details-617" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyfHgI6aW-details-617"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Planning problems in partially observable environments cannot be solved directly with convolutional networks and require some form of memory. But, even memory networks with sophisticated addressing schemes are unable to learn intelligent reasoning satisfactorily due to the complexity of simultaneously learning to access memory and plan. To mitigate these challenges we propose the Memory Augmented Control Network (MACN). The network splits planning into a hierarchical process. At a lower level, it learns to plan in a locally observed space. At a higher level, it uses a collection of policies computed on locally observed spaces to learn an optimal plan in the global environment it is operating in. The performance of the network is evaluated on path planning tasks in environments in the presence of simple and complex obstacles and in addition, is tested for its ability to generalize to new environments not seen in the training set.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Memory Augmented Network to plan in partially observable environments. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">planning, memory networks, deep learning, robotics</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B13njo1R-">
      <h4>
        <a href="https://openreview.net/forum?id=B13njo1R-">
          Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control
        </a>
        
          <a href="https://openreview.net/pdf?id=B13njo1R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gberseth%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gberseth@gmail.com">Glen Berseth</a>, <a href="https://openreview.net/profile?email=cheng.k.xie%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cheng.k.xie@gmail.com">Cheng Xie</a>, <a href="https://openreview.net/profile?email=pcernek%40cs.ubc.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="pcernek@cs.ubc.ca">Paul Cernek</a>, <a href="https://openreview.net/profile?email=van%40cs.ubc.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="van@cs.ubc.ca">Michiel Van de Panne</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B13njo1R--details-181" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B13njo1R--details-181"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning has demonstrated increasing capabilities for continuous control problems,
      including agents that can move with skill and agility through their environment. 
      An open problem in this setting is that of developing good strategies for integrating or merging policies
      for multiple skills, where each individual skill is a specialist in a specific skill and its associated state distribution. 
      We extend policy distillation methods to the continuous action setting and leverage this technique to combine \expert policies,
      as evaluated in the domain of simulated bipedal locomotion across different classes of terrain.
      We also introduce an input injection method for augmenting an existing policy network to exploit new input features.
      Lastly, our method uses transfer learning to assist in the efficient acquisition of new skills.
      The combination of these methods allows a policy to be incrementally augmented with new skills.
      We compare our progressive learning and integration via distillation (PLAID) method
      against three alternative baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A continual learning method that uses distillation to combine expert policies and transfer learning to accelerate learning new skills.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Distillation, Transfer Learning, Continual Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1hcZZ-AW">
      <h4>
        <a href="https://openreview.net/forum?id=B1hcZZ-AW">
          N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B1hcZZ-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anubhava%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anubhava@andrew.cmu.edu">Anubhav Ashok</a>, <a href="https://openreview.net/profile?email=nrhineha%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nrhineha@cs.cmu.edu">Nicholas Rhinehart</a>, <a href="https://openreview.net/profile?email=fares.beainy%40volvo.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fares.beainy@volvo.com">Fares Beainy</a>, <a href="https://openreview.net/profile?email=kkitani%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kkitani@cs.cmu.edu">Kris M. Kitani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1hcZZ-AW-details-896" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1hcZZ-AW-details-896"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While bigger and deeper neural network architectures continue to advance the state-of-the-art for many computer vision tasks, real-world adoption of these networks is impeded by hardware and speed constraints. Conventional model compression methods attempt to address this problem by modifying the architecture manually or using pre-defined heuristics. Since the space of all reduced architectures is very large, modifying the architecture of a deep neural network in this way is a difficult task. In this paper, we tackle this issue by introducing a principled method for learning reduced network architectures in a data-driven way using reinforcement learning. Our approach takes a larger 'teacher' network as input and outputs a compressed 'student' network derived from the 'teacher' network. In the first stage of our method, a recurrent policy network aggressively removes layers from the large 'teacher' model. In the second stage, another  recurrent policy network carefully reduces the size of each remaining layer. The resulting network is then evaluated to obtain a reward -- a score based on the accuracy and compression of the network. Our approach uses this reward signal with policy gradients to train the policies to find a locally optimal student network. Our experiments show that we can achieve compression rates of more than 10x for models such as ResNet-34 while maintaining similar performance to the input 'teacher' network. We also present a valuable transfer learning result which shows that policies which are pre-trained on smaller 'teacher' networks can be used to rapidly speed up training on larger 'teacher' networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel reinforcement learning based approach to compress deep neural networks with knowledge distillation</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, Neural networks, Model compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJJQVZW0b">
      <h4>
        <a href="https://openreview.net/forum?id=SJJQVZW0b">
          Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SJJQVZW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tianmin.shu%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianmin.shu@ucla.edu">Tianmin Shu</a>, <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJJQVZW0b-details-633" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJJQVZW0b-details-633"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning policies for complex tasks that require multiple different skills is a major challenge in reinforcement learning (RL). It is also a requirement for its deployment in real-world scenarios. This paper proposes a novel framework for efficient multi-task reinforcement learning. Our framework trains agents to employ hierarchical policies that decide when to use a previously learned policy and when to learn a new skill. This enables agents to continually acquire new skills during different stages of training. Each learned task corresponds to a human language description. Because agents can only access previously learned skills through these descriptions, the agent can always provide a human-interpretable description of its choices. In order to help the agent learn the complex temporal dependencies necessary for the hierarchical policy, we provide it with a stochastic temporal grammar that modulates when to rely on previously learned skills and when to execute new skills. We validate our approach on Minecraft games designed to explicitly test the ability to reuse previously learned skills while simultaneously learning new skills.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel hierarchical policy network which can reuse previously learned skills alongside and as subcomponents of new skills by discovering the underlying relations between skills.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Hierarchical Policy, Interpretable Policy, Deep Reinforcement Learning, Multi-task Reinforcement Learning, Skill Acquisition, Language Grounding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJwelMbR-">
      <h4>
        <a href="https://openreview.net/forum?id=rJwelMbR-">
          Divide-and-Conquer Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rJwelMbR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dibya.ghosh%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dibya.ghosh@berkeley.edu">Dibya Ghosh</a>, <a href="https://openreview.net/profile?email=avisingh%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="avisingh@cs.berkeley.edu">Avi Singh</a>, <a href="https://openreview.net/profile?email=aravraj%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aravraj@cs.washington.edu">Aravind Rajeswaran</a>, <a href="https://openreview.net/profile?email=vikash%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vikash@cs.washington.edu">Vikash Kumar</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJwelMbR--details-354" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJwelMbR--details-354"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Standard model-free deep reinforcement learning (RL) algorithms sample a new initial state for each trial, allowing them to optimize policies that can perform well even in highly stochastic environments. However, problems that exhibit considerable initial state variation typically produce high-variance gradient estimates for model-free RL, making direct policy or value function optimization challenging. In this paper, we develop a novel algorithm that instead partitions the initial state space into "slices", and optimizes an ensemble of policies, each on a different slice. The ensemble is gradually unified into a single policy that can succeed on the whole state space. This approach, which we term divide-and-conquer RL, is able to solve complex tasks where conventional deep RL methods are ineffective. Our results show that divide-and-conquer RL greatly outperforms conventional policy gradient methods on challenging grasping, manipulation, and locomotion tasks, and exceeds the performance of a variety of prior methods. Videos of policies learned by our algorithm can be viewed at https://sites.google.com/view/dnc-rl/
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, reinforcement learning, policy gradients, model-free</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1e5ef-C-">
      <h4>
        <a href="https://openreview.net/forum?id=B1e5ef-C-">
          A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs
        </a>
        
          <a href="https://openreview.net/pdf?id=B1e5ef-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arora%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arora@cs.princeton.edu">Sanjeev Arora</a>, <a href="https://openreview.net/profile?email=mkhodak%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkhodak@princeton.edu">Mikhail Khodak</a>, <a href="https://openreview.net/profile?email=nsaunshi%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nsaunshi@cs.princeton.edu">Nikunj Saunshi</a>, <a href="https://openreview.net/profile?email=kiran.vodrahalli%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kiran.vodrahalli@columbia.edu">Kiran Vodrahalli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1e5ef-C--details-916" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1e5ef-C--details-916"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Low-dimensional vector embeddings, computed using LSTMs or simpler techniques, are a popular approach for capturing the “meaning” of text and a form of unsupervised learning useful for downstream tasks. However, their power is not theoretically understood. The current paper derives formal understanding by looking at the subcase of linear embedding schemes. Using the theory of compressed sensing we show that representations combining the constituent word vectors are essentially information-preserving linear measurements of Bag-of-n-Grams (BonG) representations of text. This leads to a new theoretical result about LSTMs: low-dimensional embeddings derived from a low-memory LSTM are provably at least as powerful on classification tasks, up to small error, as a linear classifier over BonG vectors, a result that extensive empirical work has thus far been unable to show. Our experiments support these theoretical findings and establish strong, simple, and unsupervised baselines on standard benchmarks that in some cases are state of the art among word-level methods. We also show a surprising new property of embeddings such as GloVe and word2vec: they form a good sensing matrix for text that is more efficient than random matrices, the standard sparse recovery tool, which may explain why they lead to better representations in practice.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use the theory of compressed sensing to prove that LSTMs can do at least as well on linear text classification as Bag-of-n-Grams.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">theory, LSTM, unsupervised learning, word embeddings, compressed sensing, sparse recovery, document representation, text classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkSDMA36Z">
      <h4>
        <a href="https://openreview.net/forum?id=BkSDMA36Z">
          A New Method of Region Embedding for Text Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=BkSDMA36Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chao.qiao%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chao.qiao@outlook.com">chao qiao</a>, <a href="https://openreview.net/profile?email=bohuang0321%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bohuang0321@gmail.com">bo huang</a>, <a href="https://openreview.net/profile?email=niuguocheng%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="niuguocheng@baidu.com">guocheng niu</a>, <a href="https://openreview.net/profile?email=lidaren%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lidaren@baidu.com">daren li</a>, <a href="https://openreview.net/profile?email=dongdaxiang%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dongdaxiang@baidu.com">daxiang dong</a>, <a href="https://openreview.net/profile?email=hewei06%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hewei06@baidu.com">wei he</a>, <a href="https://openreview.net/profile?email=yudianhai%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yudianhai@baidu.com">dianhai yu</a>, <a href="https://openreview.net/profile?email=wu_hua%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wu_hua@baidu.com">hua wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>26 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkSDMA36Z-details-849" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkSDMA36Z-details-849"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">To represent a text as a bag of properly identified “phrases” and use the representation for processing the text is proved to be useful. The key question here is how to identify the phrases and represent them. The traditional method of utilizing n-grams can be regarded as an approximation of the approach. Such a method can suffer from data sparsity, however, particularly when the length of n-gram is large. In this paper, we propose a new method of learning and utilizing task-specific distributed representations of n-grams, referred to as “region embeddings”. Without loss of generality we address text classification. We specifically propose two models for region embeddings. In our models, the representation of a word has two parts, the embedding of the word itself, and a weighting matrix to interact with the local context, referred to as local context unit. The region embeddings are learned and used in the classification task, as parameters of the neural network classifier. Experimental results show that our proposed method outperforms existing methods in text classification on several benchmark datasets. The results also indicate that our method can indeed capture the salient phrasal expressions in the texts.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">region embedding, local context unit, text classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Dh8Tg0-">
      <h4>
        <a href="https://openreview.net/forum?id=S1Dh8Tg0-">
          Fix your classifier: the marginal value of training the last weight layer
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Dh8Tg0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=elad.hoffer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="elad.hoffer@gmail.com">Elad Hoffer</a>, <a href="https://openreview.net/profile?email=itayhubara%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="itayhubara@gmail.com">Itay Hubara</a>, <a href="https://openreview.net/profile?email=daniel.soudry%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.soudry@gmail.com">Daniel Soudry</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Dh8Tg0--details-221" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Dh8Tg0--details-221"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks are commonly used as models for classification for a wide variety of tasks. Typically, a learned affine transformation is placed at the end of such models, yielding a per-class value used for classification. This classifier can have a vast number of parameters, which grows linearly with the number of possible classes, thus requiring increasingly more resources.
      
      In this work we argue that this classifier can be fixed, up to a global scale constant, with little or no loss of accuracy for most tasks, allowing memory and computational benefits. Moreover, we show that by initializing the classifier with a Hadamard matrix we can speed up inference as well. We discuss the implications for current understanding of neural network models.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">You can fix the classifier in neural networks without losing accuracy</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyRnez-RW">
      <h4>
        <a href="https://openreview.net/forum?id=HyRnez-RW">
          Multi-Mention Learning for Reading Comprehension with Neural Cascades
        </a>
        
          <a href="https://openreview.net/pdf?id=HyRnez-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=swabha%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="swabha@cs.cmu.edu">Swabha Swayamdipta</a>, <a href="https://openreview.net/profile?email=aparikh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aparikh@google.com">Ankur P. Parikh</a>, <a href="https://openreview.net/profile?email=tomkwiat%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomkwiat@google.com">Tom Kwiatkowski</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyRnez-RW-details-316" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyRnez-RW-details-316"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reading comprehension is a challenging task, especially when executed across longer or across multiple evidence documents, where the answer is likely to reoccur. Existing neural architectures typically do not scale to the entire evidence, and hence, resort to selecting a single passage in the document (either via truncation or other means), and carefully searching for the answer within that passage. However, in some cases, this strategy can be suboptimal,  since by focusing on a specific passage, it becomes difficult to leverage multiple mentions of the same answer throughout the document. In this work, we take a different approach by constructing lightweight models that are combined in a cascade to find the answer. Each submodel consists only of feed-forward networks equipped with an attention mechanism, making it trivially parallelizable. We show that our approach can scale to approximately an order of magnitude larger evidence documents and can aggregate information from multiple mentions of each answer candidate across the document. Empirically, our approach achieves state-of-the-art performance on both the Wikipedia and web domains of the TriviaQA dataset, outperforming more complex, recurrent architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose neural cascades, a simple and trivially parallelizable approach to reading comprehension, consisting only of feed-forward nets and attention that achieves state-of-the-art performance on the TriviaQA dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reading comprehension, multi-loss, question answering, scalable, TriviaQA, feed-forward, latent variable, attention</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1SnX5xCb">
      <h4>
        <a href="https://openreview.net/forum?id=r1SnX5xCb">
          Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1SnX5xCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jsyoon0823%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsyoon0823@gmail.com">Jinsung Yoon</a>, <a href="https://openreview.net/profile?email=zame%40econ.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zame@econ.ucla.edu">William R. Zame</a>, <a href="https://openreview.net/profile?email=mihaela.vanderschaar%40oxford-man.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mihaela.vanderschaar@oxford-man.ox.ac.uk">Mihaela van der Schaar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1SnX5xCb-details-163" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1SnX5xCb-details-163"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">For every prediction we might wish to make, we must decide what to observe (what source of information) and when to observe it. Because making observations is costly, this decision must trade off the value of information against the cost of observation. Making observations (sensing) should be an active choice. To solve the problem of active sensing we develop a novel deep learning architecture: Deep Sensing. At training time, Deep Sensing learns how to issue predictions at various cost-performance points. To do this, it creates multiple representations at various performance levels associated with different measurement rates (costs). This requires learning how to estimate the value of real measurements vs. inferred measurements, which in turn requires learning how to infer missing (unobserved) measurements.  To infer missing measurements, we develop a Multi-directional Recurrent Neural Network (M-RNN).  An M-RNN differs from a bi-directional RNN in that it sequentially operates across streams in addition to within streams, and because the timing of inputs into the hidden layers is both lagged and advanced.  At runtime, the operator prescribes a performance level or a cost constraint, and Deep Sensing determines what measurements to take and what to infer from those measurements, and then issues predictions. To demonstrate the power of our method, we apply it to two real-world medical datasets with significantly improved performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Active Sensing, Timely Prediction, Irregular Sampling, Missing Data</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkZy-bW0-">
      <h4>
        <a href="https://openreview.net/forum?id=HkZy-bW0-">
          Temporally Efficient Deep Learning with Spikes
        </a>
        
          <a href="https://openreview.net/pdf?id=HkZy-bW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=peter.ed.oconnor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peter.ed.oconnor@gmail.com">Peter O'Connor</a>, <a href="https://openreview.net/profile?email=e.gavves%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.gavves@uva.nl">Efstratios Gavves</a>, <a href="https://openreview.net/profile?email=reisser.matthias%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="reisser.matthias@gmail.com">Matthias Reisser</a>, <a href="https://openreview.net/profile?email=m.welling%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.welling@uva.nl">Max Welling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkZy-bW0--details-119" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkZy-bW0--details-119"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The vast majority of natural sensory data is temporally redundant. For instance, video frames or audio samples which are sampled at nearby points in time tend to have similar values.  Typically, deep learning algorithms take no advantage of this redundancy to reduce computations.  This can be an obscene waste of energy.  We present a variant on backpropagation for neural networks in which computation scales with the rate of change of the data - not the rate at which we process the data.  We do this by implementing a form of Predictive Coding wherein neurons communicate a combination of their state, and their temporal change in state, and quantize this signal using Sigma-Delta modulation.  Intriguingly, this simple communication rule give rise to units that resemble biologically-inspired leaky integrate-and-fire neurons, and to a spike-timing-dependent weight-update similar to Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule observed in the brain.  We demonstrate that on MNIST, on a temporal variant of MNIST, and on Youtube-BB, a dataset with videos in the wild, our algorithm performs about as well as a standard deep network trained with backpropagation, despite only communicating discrete values between layers.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An algorithm for training neural networks efficiently on temporally redundant data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">online learning, spiking networks, deep learning, temporal</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry-TW-WAb">
      <h4>
        <a href="https://openreview.net/forum?id=ry-TW-WAb">
          Variational Network Quantization
        </a>
        
          <a href="https://openreview.net/pdf?id=ry-TW-WAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mail%40janachterhold.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mail@janachterhold.de">Jan Achterhold</a>, <a href="https://openreview.net/profile?email=jan.koehler%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jan.koehler@de.bosch.com">Jan Mathias Koehler</a>, <a href="https://openreview.net/profile?email=anke.schmeink%40rwth-aachen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="anke.schmeink@rwth-aachen.de">Anke Schmeink</a>, <a href="https://openreview.net/profile?email=tim.genewein%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tim.genewein@gmail.com">Tim Genewein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry-TW-WAb-details-267" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry-TW-WAb-details-267"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, the preparation of a neural network for pruning and few-bit quantization is formulated as a variational inference problem. To this end, a quantizing prior that leads to a multi-modal, sparse posterior distribution over weights, is introduced and a differentiable Kullback-Leibler divergence approximation for this prior is derived. After training with Variational Network Quantization, weights can be replaced by deterministic quantization values with small to negligible loss of task accuracy (including pruning by setting weights to 0). The method does not require fine-tuning after quantization. Results are shown for ternary quantization on LeNet-5 (MNIST) and DenseNet (CIFAR-10).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We quantize and prune neural network weights using variational Bayesian inference with a multi-modal, sparsity inducing prior.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Network compression, variational inferene, ternary network, Bayesian neural network, weight quantization, weight sharing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJJySbbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJJySbbAZ">
          Training GANs with Optimism
        </a>
        
          <a href="https://openreview.net/pdf?id=SJJySbbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=costis%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="costis@mit.edu">Constantinos Daskalakis</a>, <a href="https://openreview.net/profile?email=ailyas%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ailyas@mit.edu">Andrew Ilyas</a>, <a href="https://openreview.net/profile?email=vasy%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vasy@microsoft.com">Vasilis Syrgkanis</a>, <a href="https://openreview.net/profile?email=haoyangz%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haoyangz@mit.edu">Haoyang Zeng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJJySbbAZ-details-432" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJJySbbAZ-details-432"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GANs, Optimistic Mirror Decent, Cycling, Last Iterate Convergence, Optimistic Adam</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJA7xfb0b">
      <h4>
        <a href="https://openreview.net/forum?id=SJA7xfb0b">
          Sobolev GAN
        </a>
        
          <a href="https://openreview.net/pdf?id=SJA7xfb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mroueh%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mroueh@us.ibm.com">Youssef Mroueh</a>, <a href="https://openreview.net/profile?email=chunlial%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chunlial@cs.cmu.edu">Chun-Liang Li</a>, <a href="https://openreview.net/profile?email=tom.sercu1%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom.sercu1@ibm.com">Tom Sercu</a>, <a href="https://openreview.net/profile?email=anant.raj%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="anant.raj@tuebingen.mpg.de">Anant Raj</a>, <a href="https://openreview.net/profile?email=chengyu%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chengyu@us.ibm.com">Yu Cheng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJA7xfb0b-details-203" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJA7xfb0b-details-203"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a new Integral Probability Metric (IPM) between distributions: the Sobolev IPM. The Sobolev IPM compares the mean discrepancy of two distributions for functions (critic) restricted to a Sobolev ball defined with respect to a dominant measure mu. We show that the Sobolev IPM compares two distributions in high dimensions based on weighted conditional Cumulative Distribution Functions (CDF) of each coordinate on a leave one out basis. The Dominant measure mu plays a crucial role as it defines the support on which conditional CDFs are compared. Sobolev IPM can be seen as an extension of the one dimensional Von-Mises Cramer statistics to high dimensional distributions. We show how Sobolev IPM can be used to train Generative Adversarial Networks (GANs). We then exploit the intrinsic conditioning implied by Sobolev IPM in text generation. Finally we show that a variant of Sobolev GAN achieves competitive results in semi-supervised learning on CIFAR-10, thanks to the smoothness enforced on the critic by Sobolev GAN which relates to Laplacian regularization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We define a new Integral Probability Metric (Sobolev IPM) and show how it can be used for training GANs for text generation and semi-supervised learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN theory, Integral Probability Metrics, elliptic PDE and diffusion, GAN for discrete sequences, semi-supervised learning.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1sUHgb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=H1sUHgb0Z">
          Learning From Noisy Singly-labeled Data
        </a>
        
          <a href="https://openreview.net/pdf?id=H1sUHgb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=khetan2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="khetan2@illinois.edu">Ashish Khetan</a>, <a href="https://openreview.net/profile?email=zlipton%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlipton@cmu.edu">Zachary C. Lipton</a>, <a href="https://openreview.net/profile?email=anima%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anima@amazon.com">Animashree Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1sUHgb0Z-details-80" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1sUHgb0Z-details-80"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Supervised learning depends on annotated examples, which are taken to be the ground truth. But these labels often come from noisy crowdsourcing platforms, like Amazon Mechanical Turk. Practitioners typically collect multiple labels per example and aggregate the results to mitigate noise (the classic crowdsourcing problem). Given a fixed annotation budget and unlimited unlabeled data, redundant annotation comes at the expense of fewer labeled examples. This raises two fundamental questions: (1) How can we best learn from noisy workers? (2) How should we allocate our labeling budget to maximize the performance of a classifier? We propose a new algorithm for jointly modeling labels and worker quality from noisy crowd-sourced data. The alternating minimization proceeds in rounds, estimating worker quality from disagreement with the current model and then updating the model by optimizing a loss function that accounts for the current estimate of worker quality. Unlike previous approaches, even with only one annotation per example, our algorithm can estimate worker quality. We establish a generalization error bound for models learned with our algorithm and establish theoretically that it's better to label many examples once (vs less multiply) when worker quality exceeds a threshold. Experiments conducted on both ImageNet (with simulated noisy workers) and MS-COCO (using the real crowdsourced labels) confirm our algorithm's benefits. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new approach for learning a model from noisy crowdsourced annotations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">crowdsourcing, noisy annotations, deep leaerning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1Y8hhg0b">
      <h4>
        <a href="https://openreview.net/forum?id=H1Y8hhg0b">
          Learning Sparse Neural Networks through L_0 Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=H1Y8hhg0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=c.louizos%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="c.louizos@uva.nl">Christos Louizos</a>, <a href="https://openreview.net/profile?email=m.welling%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.welling@uva.nl">Max Welling</a>, <a href="https://openreview.net/profile?email=dpkingma%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dpkingma@openai.com">Diederik P. Kingma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1Y8hhg0b-details-251" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1Y8hhg0b-details-251"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a practical method for $L_0$ norm regularization for neural networks: pruning the network during training by encouraging weights to become exactly zero. Such regularization is interesting since (1) it can greatly speed up training and inference, and (2) it can improve generalization. AIC and BIC, well-known model selection criteria, are special cases of $L_0$ regularization. However, since the $L_0$ norm of weights is non-differentiable, we cannot incorporate it directly as a regularization term in the objective function. We propose a solution through the inclusion of a collection of non-negative stochastic gates, which collectively determine which weights to set to zero. We show that, somewhat surprisingly, for certain distributions over the gates, the expected $L_0$ regularized objective is differentiable with respect to the distribution parameters. We further propose the \emph{hard concrete} distribution for the gates, which is obtained by ``stretching'' a binary concrete distribution and then transforming its samples with a hard-sigmoid. The parameters of the distribution over the gates can then be jointly optimized with the original network parameters. As a result our method allows for straightforward and efficient learning of model structures with stochastic gradient descent and allows for conditional computation in a principled way. We perform various experiments to demonstrate the effectiveness of the resulting approach and regularizer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how to optimize the expected L_0 norm of parametric models with gradient descent and introduce a new distribution that facilitates hard gating.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Sparsity, compression, hard and soft attention.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkQqq0gRb">
      <h4>
        <a href="https://openreview.net/forum?id=BkQqq0gRb">
          Variational Continual Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BkQqq0gRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vcn22%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="vcn22@cam.ac.uk">Cuong V. Nguyen</a>, <a href="https://openreview.net/profile?email=yl494%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yl494@cam.ac.uk">Yingzhen Li</a>, <a href="https://openreview.net/profile?email=tdb40%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="tdb40@cam.ac.uk">Thang D. Bui</a>, <a href="https://openreview.net/profile?email=ret26%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ret26@cam.ac.uk">Richard E. Turner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 May 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkQqq0gRb-details-655" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkQqq0gRb-details-655"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that VCL outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper develops a principled method for continual learning in deep models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">continual learning, online variational inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1-nGgWC-">
      <h4>
        <a href="https://openreview.net/forum?id=H1-nGgWC-">
          Gaussian Process Behaviour in Wide Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H1-nGgWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=am554%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="am554@cam.ac.uk">Alexander G. de G. Matthews</a>, <a href="https://openreview.net/profile?email=jh2084%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jh2084@cam.ac.uk">Jiri Hron</a>, <a href="https://openreview.net/profile?email=mr504%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mr504@cam.ac.uk">Mark Rowland</a>, <a href="https://openreview.net/profile?email=ret26%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ret26@cam.ac.uk">Richard E. Turner</a>, <a href="https://openreview.net/profile?email=zoubin%40eng.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="zoubin@eng.cam.ac.uk">Zoubin Ghahramani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 22 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1-nGgWC--details-447" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1-nGgWC--details-447"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Whilst deep neural networks have shown great empirical success, there is still much work to be done to understand their theoretical properties. In this paper, we study the relationship between Gaussian processes with a recursive kernel definition and random wide fully connected feedforward networks with more than one hidden layer. We exhibit limiting procedures under which finite deep networks will converge in distribution to the corresponding Gaussian process. To evaluate convergence rates empirically, we use maximum mean discrepancy. We then exhibit situations where existing Bayesian deep networks are close to Gaussian processes in terms of the key quantities of interest. Any Gaussian process has a flat representation. Since this behaviour may be undesirable in certain situations we discuss ways in which it might be prevented.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Gaussian Processes, Bayesian Deep Learning, Theory of Deep Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H135uzZ0-">
      <h4>
        <a href="https://openreview.net/forum?id=H135uzZ0-">
          Mixed Precision Training of Convolutional Neural Networks using Integer Operations
        </a>
        
          <a href="https://openreview.net/pdf?id=H135uzZ0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dipankar.das%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dipankar.das@intel.com">Dipankar Das</a>, <a href="https://openreview.net/profile?email=naveen.k.mellempudi%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="naveen.k.mellempudi@intel.com">Naveen Mellempudi</a>, <a href="https://openreview.net/profile?email=dheevatsa.mudigere%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dheevatsa.mudigere@intel.com">Dheevatsa Mudigere</a>, <a href="https://openreview.net/profile?email=dhiraj.d.kalamkar%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhiraj.d.kalamkar@intel.com">Dhiraj Kalamkar</a>, <a href="https://openreview.net/profile?email=sasikanth.avancha%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sasikanth.avancha@intel.com">Sasikanth Avancha</a>, <a href="https://openreview.net/profile?email=kunal.banerjee%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunal.banerjee@intel.com">Kunal Banerjee</a>, <a href="https://openreview.net/profile?email=srinivas.sridharan%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="srinivas.sridharan@intel.com">Srinivas Sridharan</a>, <a href="https://openreview.net/profile?email=karthikeyan.vaidyanathan%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karthikeyan.vaidyanathan@intel.com">Karthik Vaidyanathan</a>, <a href="https://openreview.net/profile?email=bharat.kaul%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bharat.kaul@intel.com">Bharat Kaul</a>, <a href="https://openreview.net/profile?email=evangelos.georganas%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="evangelos.georganas@intel.com">Evangelos Georganas</a>, <a href="https://openreview.net/profile?email=alexander.heinecke%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexander.heinecke@intel.com">Alexander Heinecke</a>, <a href="https://openreview.net/profile?email=pradeep.dubey%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pradeep.dubey@intel.com">Pradeep Dubey</a>, <a href="https://openreview.net/profile?email=jesus.corbal%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jesus.corbal@intel.com">Jesus Corbal</a>, <a href="https://openreview.net/profile?email=nikita.a.shustrov%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikita.a.shustrov@intel.com">Nikita Shustrov</a>, <a href="https://openreview.net/profile?email=roman.s.dubtsov%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="roman.s.dubtsov@intel.com">Roma Dubtsov</a>, <a href="https://openreview.net/profile?email=evarist.m.fomenko%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="evarist.m.fomenko@intel.com">Evarist Fomenko</a>, <a href="https://openreview.net/profile?email=vadim.o.pirogov%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vadim.o.pirogov@intel.com">Vadim Pirogov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H135uzZ0--details-833" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H135uzZ0--details-833"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The state-of-the-art (SOTA) for mixed precision training is dominated by variants of low precision floating point operations, and in particular, FP16 accumulating into FP32 Micikevicius et al. (2017). On the other hand, while a lot of research has also happened in the domain of low and mixed-precision Integer training, these works either present results for non-SOTA networks (for instance only AlexNet for ImageNet-1K), or relatively small datasets (like CIFAR-10). In this work, we train state-of-the-art visual understanding neural networks on the ImageNet-1K dataset, with Integer operations on General Purpose (GP) hardware. In particular, we focus on Integer Fused-Multiply-and-Accumulate (FMA) operations which take two pairs of INT16 operands and accumulate results into an INT32 output.We propose a shared exponent representation of tensors and develop a Dynamic Fixed Point (DFP) scheme suitable for common neural network operations. The nuances of developing an efficient integer convolution kernel is examined, including methods to handle overflow of the INT32 accumulator. We implement CNN training for ResNet-50, GoogLeNet-v1, VGG-16 and AlexNet; and these networks achieve or exceed SOTA accuracy within the same number of iterations as their FP32 counterparts without any change in hyper-parameters and with a 1.8X improvement in end-to-end training throughput. To the best of our knowledge these results represent the first INT16 training results on GP hardware for ImageNet-1K dataset using SOTA CNNs and achieve highest reported accuracy using half precision </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Mixed precision training pipeline using 16-bit integers on general purpose HW;  SOTA accuracy for ImageNet-class CNNs; Best reported accuracy for ImageNet-1K classification task with any reduced precision training;</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning training, reduced precision, imagenet, dynamic fixed point</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkFqf0lAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SkFqf0lAZ">
          Memory Architectures in Recurrent Neural Network Language Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SkFqf0lAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dyogatama%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dyogatama@google.com">Dani Yogatama</a>, <a href="https://openreview.net/profile?email=yishu.miao%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yishu.miao@cs.ox.ac.uk">Yishu Miao</a>, <a href="https://openreview.net/profile?email=melisgl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="melisgl@google.com">Gabor Melis</a>, <a href="https://openreview.net/profile?email=lingwang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lingwang@google.com">Wang Ling</a>, <a href="https://openreview.net/profile?email=akuncoro%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akuncoro@google.com">Adhiguna Kuncoro</a>, <a href="https://openreview.net/profile?email=cdyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdyer@google.com">Chris Dyer</a>, <a href="https://openreview.net/profile?email=pblunsom%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pblunsom@google.com">Phil Blunsom</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 01 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkFqf0lAZ-details-220" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkFqf0lAZ-details-220"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We compare and analyze sequential, random access, and stack memory architectures for recurrent neural network language models. Our experiments on the Penn Treebank and Wikitext-2 datasets show that stack-based memory architectures consistently achieve the best performance in terms of held out perplexity. We also propose a generalization to existing continuous stack models (Joulin &amp; Mikolov,2015; Grefenstette et al., 2015)  to allow a variable number of pop operations more naturally that further improves performance. We further evaluate these language models in terms of their ability to capture non-local syntactic dependencies on a subject-verb agreement dataset  (Linzen et al., 2016) and establish new state of the art results using memory augmented language models. Our results demonstrate the value of stack-structured memory for explaining the distribution of words in natural language, in line with linguistic theories claiming a context-free backbone for natural language.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry_WPG-A-">
      <h4>
        <a href="https://openreview.net/forum?id=ry_WPG-A-">
          On the Information Bottleneck Theory of Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=ry_WPG-A-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=asaxe%40fas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asaxe@fas.harvard.edu">Andrew Michael Saxe</a>, <a href="https://openreview.net/profile?email=ybansal%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ybansal@g.harvard.edu">Yamini Bansal</a>, <a href="https://openreview.net/profile?email=dapello%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dapello@g.harvard.edu">Joel Dapello</a>, <a href="https://openreview.net/profile?email=madvani%40fas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="madvani@fas.harvard.edu">Madhu Advani</a>, <a href="https://openreview.net/profile?email=artemyk%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="artemyk@gmail.com">Artemy Kolchinsky</a>, <a href="https://openreview.net/profile?email=tracey.brendan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tracey.brendan@gmail.com">Brendan Daniel Tracey</a>, <a href="https://openreview.net/profile?email=davidcox%40fas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidcox@fas.harvard.edu">David Daniel Cox</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry_WPG-A--details-958" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry_WPG-A--details-958"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The practical successes of deep neural networks have not been matched by theoretical progress that satisfyingly explains their behavior. In this work, we study the information bottleneck (IB) theory of deep learning, which makes three specific claims: first, that deep networks undergo two distinct phases consisting of an initial fitting phase and a subsequent compression phase; second, that the compression phase is causally related to the excellent generalization performance of deep networks; and third, that the compression phase occurs due to the diffusion-like behavior of stochastic gradient descent. Here we show that none of these claims hold true in the general case. Through a combination of analytical results and simulation, we demonstrate that the information plane trajectory is predominantly a function of the neural nonlinearity employed: double-sided saturating nonlinearities like tanh yield a compression phase as neural activations enter the saturation regime, but linear activation functions and single-sided saturating nonlinearities like the widely used ReLU in fact do not. Moreover, we find that there is no evident causal connection between compression and generalization: networks that do not compress are still capable of generalization, and vice versa. Next, we show that the compression phase, when it exists, does not arise from stochasticity in training by demonstrating that we can replicate the IB findings using full batch gradient descent rather than stochastic gradient descent. Finally, we show that when an input domain consists of a subset of task-relevant and task-irrelevant information, hidden representations do compress the task-irrelevant information, although the overall information about the input may monotonically increase with training time, and that this compression happens concurrently with the fitting process rather than during a subsequent compression period.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that several claims of the information bottleneck theory of deep learning are not true in the general case.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">information bottleneck, deep learning, deep linear networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
</ul>
</div>
    <div role="tabpanel" class="tab-pane fade  " id="workshop-papers">
      
    <ul class="list-unstyled submissions-list">
    <li class="note " data-id="BJJ9bz-0-">
      <h4>
        <a href="https://openreview.net/forum?id=BJJ9bz-0-">
          Reinforcement Learning from Imperfect Demonstrations
        </a>
        
          <a href="https://openreview.net/pdf?id=BJJ9bz-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yg%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yg@eecs.berkeley.edu">Yang Gao</a>, <a href="https://openreview.net/profile?email=huazhe_xu%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huazhe_xu@eecs.berkeley.edu">Huazhe(Harry) Xu</a>, <a href="https://openreview.net/profile?email=lin-j14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lin-j14@mails.tsinghua.edu.cn">Ji Lin</a>, <a href="https://openreview.net/profile?email=fy%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fy@eecs.berkeley.edu">Fisher Yu</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>, <a href="https://openreview.net/profile?email=trevor%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="trevor@eecs.berkeley.edu">Trevor Darrell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJJ9bz-0--details-962" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJJ9bz-0--details-962"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Robust real-world  learning should benefit from both demonstrations and interaction with the environment. Current approaches to learning from demonstration and reward perform supervised learning on expert demonstration data and use reinforcement learning  to further improve performance based on reward from the environment. These tasks have divergent losses which are difficult to jointly optimize; further, such methods can be very sensitive to noisy demonstrations. We propose a unified reinforcement learning algorithm that effectively normalizes the Q-function, reducing the Q-values of actions unseen in the demonstration data.  Our Normalized Actor-Critic (NAC) method can learn from demonstration data of arbitrary quality and also leverages rewards from an interactive environment.  NAC learns an initial policy network from demonstration and refines the policy in a real environment. Crucially, both learning from demonstration and interactive refinement use exactly the same objective, unlike prior approaches that combine distinct supervised and reinforcement losses. This makes NAC robust to suboptimal demonstration data, since the method is not forced to mimic all of the examples in the dataset. We show that our unified reinforcement learning algorithm can learn robustly and  outperform existing baselines when evaluated on several realistic driving games.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">learning from demonstration, reinforcement learning, maximum entropy learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJjvxl-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=HJjvxl-Cb">
          Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor
        </a>
        
          <a href="https://openreview.net/pdf?id=HJjvxl-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=haarnoja%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haarnoja@berkeley.edu">Tuomas Haarnoja</a>, <a href="https://openreview.net/profile?email=azhou42%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="azhou42@berkeley.edu">Aurick Zhou</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJjvxl-Cb-details-499" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJjvxl-Cb-details-499"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy - that is, succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as either off-policy Q-learning, or on-policy policy gradient methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, maximum entropy learning, stochastic actor-critic</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk6H0ZbRb">
      <h4>
        <a href="https://openreview.net/forum?id=rk6H0ZbRb">
          Intriguing Properties of Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=rk6H0ZbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cubuk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cubuk@google.com">Ekin Dogus Cubuk</a>, <a href="https://openreview.net/profile?email=barretzoph%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="barretzoph@google.com">Barret Zoph</a>, <a href="https://openreview.net/profile?email=schsam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schsam@google.com">Samuel Stern Schoenholz</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk6H0ZbRb-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk6H0ZbRb-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is becoming increasingly clear that many machine learning classifiers are vulnerable to adversarial examples. In attempting to explain the origin of adversarial examples, previous studies have typically focused on the fact that neural networks operate on high dimensional data, they overfit, or they are too linear. Here we show that distributions of logit differences have a universal functional form. This functional form is independent of architecture, dataset, and training protocol; nor does it change during training. This leads to adversarial error having a universal scaling, as a power-law, with respect to the size of the adversarial perturbation. We show that this universality holds for a broad range of datasets (MNIST, CIFAR10, ImageNet, and random data), models (including state-of-the-art deep networks, linear models, adversarially trained networks, and networks trained on randomly shuffled labels), and attacks (FGSM, step l.l., PGD). Motivated by these results, we study the effects of reducing prediction entropy on adversarial robustness. Finally, we study the effect of network architectures on adversarial sensitivity. To do this, we use neural architecture search with reinforcement learning to find adversarially robust architectures on CIFAR10. Our resulting architecture is more robust to white \emph{and} black box attacks compared to previous attempts.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adversarial error has similar power-law form for all datasets and models studied, and architecture matters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, universality, neural architecture search</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJy0fcgRZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJy0fcgRZ">
          Capturing Human Category Representations by Sampling in Deep Feature Spaces
        </a>
        
          <a href="https://openreview.net/pdf?id=BJy0fcgRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=peterson.c.joshua%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peterson.c.joshua@gmail.com">Joshua Peterson</a>, <a href="https://openreview.net/profile?email=kaghi%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaghi@berkeley.edu">Krishan Aghi</a>, <a href="https://openreview.net/profile?email=suchow%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="suchow@berkeley.edu">Jordan Suchow</a>, <a href="https://openreview.net/profile?email=alexku%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexku@berkeley.edu">Alexander Ku</a>, <a href="https://openreview.net/profile?email=tom_griffiths%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom_griffiths@berkeley.edu">Tom Griffiths</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJy0fcgRZ-details-790" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJy0fcgRZ-details-790"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Understanding how people represent categories is a core problem in cognitive science, with the flexibility of human learning remaining a gold standard to which modern artificial intelligence and machine learning aspire. Decades of psychological research have yielded a variety of formal theories of categories, yet validating these theories with naturalistic stimuli remains a challenge. The problem is that human category representations cannot be directly observed and running informative experiments with naturalistic stimuli such as images requires having a workable representation of these stimuli. Deep neural networks have recently been successful in a range of computer vision tasks and provide a way to represent the features of images. In this paper, we introduce a method for estimating the structure of human categories that draws on ideas from both cognitive science and machine learning, blending human-based algorithms with state-of-the-art deep representation learners. We provide qualitative and quantitative results as a proof of concept for the feasibility of the method. Samples drawn from human distributions rival the quality of current state-of-the-art generative models and outperform alternative methods for estimating the structure of human categories.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">using deep neural networks and clever algorithms to capture human mental visual concepts</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">category representations, psychology, cognitive science, deep neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy4c-3xRW">
      <h4>
        <a href="https://openreview.net/forum?id=Sy4c-3xRW">
          DropMax: Adaptive Stochastic Softmax
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy4c-3xRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hblee%40unist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="hblee@unist.ac.kr">Hae Beom Lee</a>, <a href="https://openreview.net/profile?email=stonecold%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="stonecold@postech.ac.kr">Juho Lee</a>, <a href="https://openreview.net/profile?email=yangeh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangeh@gmail.com">Eunho Yang</a>, <a href="https://openreview.net/profile?email=sjhwang82%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang82@gmail.com">Sung Ju Hwang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy4c-3xRW-details-710" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy4c-3xRW-details-710"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose DropMax, a stochastic version of softmax classifier which at each iteration drops non-target classes with some probability, for each instance. Specifically, we overlay binary masking variables over class output probabilities, which are learned based on the input via regularized variational inference. This stochastic regularization has an effect of building an ensemble classifier out of combinatorial number of classifiers with different decision boundaries. Moreover, the learning of dropout probabilities for non-target classes on each instance allows the classifier to focus more on classification against the most confusing classes. We validate our model on multiple public datasets for classification, on which it obtains improved accuracy over regular softmax classifier and other baselines. Further analysis of the learned dropout masks shows that our model indeed selects confusing classes more often when it performs classification.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJUX_MWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJUX_MWCZ">
          Predict Responsibly: Increasing Fairness by Learning to Defer
        </a>
        
          <a href="https://openreview.net/pdf?id=SJUX_MWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=david.madras%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.madras@mail.utoronto.ca">David Madras</a>, <a href="https://openreview.net/profile?email=zemel%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zemel@cs.toronto.edu">Toniann Pitassi</a>, <a href="https://openreview.net/profile?email=toni%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="toni@cs.toronto.edu">Richard Zemel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJUX_MWCZ-details-858" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJUX_MWCZ-details-858"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">When machine learning models are used for high-stakes decisions, they should predict accurately, fairly, and responsibly. To fulfill these three requirements, a model must be able to output a reject option (i.e. say "``I Don't Know") when it is not qualified to make a prediction. In this work, we propose learning to defer, a method by which a model can defer judgment to a downstream decision-maker such as a human user. We show that learning to defer generalizes the rejection learning framework in two ways: by considering the effect of other agents in the decision-making process, and by allowing for optimization of complex objectives. We propose a learning algorithm which accounts for potential biases held by decision-makerslater in a pipeline. Experiments on real-world datasets demonstrate that learning
      to defer can make a model not only more accurate but also less biased. Even when
      operated by highly biased users, we show that
      deferring models can still greatly improve the fairness of the entire pipeline.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Incorporating the ability to say I-don't-know can improve the fairness of a classifier without sacrificing too much accuracy, and this improvement magnifies when the classifier has insight into downstream decision-making.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Fairness, IDK, Calibration, Automated decision-making, Transparency, Accountability</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1hsJCe0Z">
      <h4>
        <a href="https://openreview.net/forum?id=r1hsJCe0Z">
          Semantic Code Repair using Neuro-Symbolic Transformation Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1hsJCe0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jacobdevlin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jacobdevlin@google.com">Jacob Devlin</a>, <a href="https://openreview.net/profile?email=juesato%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="juesato@gmail.com">Jonathan  Uesato</a>, <a href="https://openreview.net/profile?email=risin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="risin@microsoft.com">Rishabh Singh</a>, <a href="https://openreview.net/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1hsJCe0Z-details-179" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1hsJCe0Z-details-179"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the problem of semantic code repair, which can be broadly defined as automatically fixing non-syntactic bugs in source code. The majority of past work in semantic code repair assumed access to unit tests against which candidate repairs could be validated. In contrast, the goal here is to develop a strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program. Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs. Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete. Specifically, the architecture (1) generates a  shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space. We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs. Our model is able to predict the exact correct repair 41% of the time with a single guess, compared to 13% accuracy for an attentional sequence-to-sequence model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A neural architecture for scoring and ranking program repair candidates to perform semantic program repair statically without access to unit tests.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">semantic program repair, neural program embeddings, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk3pnae0b">
      <h4>
        <a href="https://openreview.net/forum?id=rk3pnae0b">
          Topic-Based Question Generation
        </a>
        
          <a href="https://openreview.net/pdf?id=rk3pnae0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wenpeng.hu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenpeng.hu@pku.edu.cn">Wenpeng Hu</a>, <a href="https://openreview.net/profile?email=liub%40cs.uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liub@cs.uic.edu">Bing Liu</a>, <a href="https://openreview.net/profile?email=ruiyan%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruiyan@pku.edu.cn">Rui Yan</a>, <a href="https://openreview.net/profile?email=zhaody%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaody@pku.edu.cn">Dongyan Zhao</a>, <a href="https://openreview.net/profile?email=jwma%40math.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwma@math.pku.edu.cn">Jinwen Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk3pnae0b-details-377" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk3pnae0b-details-377"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Asking questions is an important ability for a chatbot. This paper focuses on question generation. Although there are existing works on question generation based on a piece of descriptive text, it remains to be a very challenging problem. In the paper, we propose a new question generation problem, which also requires the input of a target topic in addition to a piece of descriptive text. The key reason for proposing the new problem is that in practical applications, we found that useful questions need to be targeted toward some relevant topics. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. To solve the problem, we propose a novel neural network that is able to generate topic-specific questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating topics in the questions or answers. Experimental results show that our model outperforms the state-of-the-art baseline.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a neural network that is able to generate topic-specific questions.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJDJNzWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJDJNzWAZ">
          Time-Dependent Representation for Neural Event Sequence Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=SJDJNzWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=liyang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liyang@google.com">Yang Li</a>, <a href="https://openreview.net/profile?email=dunan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dunan@google.com">Nan Du</a>, <a href="https://openreview.net/profile?email=bengio%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengio@google.com">Samy Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJDJNzWAZ-details-814" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJDJNzWAZ-details-814"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Existing sequence prediction methods are mostly concerned with time-independent sequences, in which the actual time span between events is irrelevant and the distance between events is simply the difference between their order positions in the sequence. While this time-independent view of sequences is applicable for data such as natural languages, e.g., dealing with words in a sentence, it is inappropriate and inefficient for many real world events that are observed and collected at unequally spaced points of time as they naturally arise, e.g., when a person goes to a grocery store or makes a phone call. The time span between events can carry important information about the sequence dependence of human behaviors. In this work, we propose a set of methods for using time in sequence prediction. Because neural sequence models such as RNN are more amenable for handling token-like input, we propose two methods for time-dependent event representation, based on the intuition on how time is tokenized in everyday life and previous work on embedding contextualization. We also introduce two methods for using next event duration as regularization for training a sequence prediction model. We discuss these methods based on recurrent neural nets. We evaluate these methods as well as baseline models on five datasets that resemble a variety of sequence prediction tasks. The experiments revealed that the proposed methods offer accuracy gain over baseline models in a range of settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Proposed methods for time-dependent event representation and regularization for sequence prediction; Evaluated these methods on five datasets that involve a range of sequence prediction tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural sequence prediction, Embedding, LSTM, Regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkHl6MWC-">
      <h4>
        <a href="https://openreview.net/forum?id=SkHl6MWC-">
          Regularization Neural Networks via Constrained Virtual  Movement Field
        </a>
        
          <a href="https://openreview.net/pdf?id=SkHl6MWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhd.zhang.ai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhd.zhang.ai@gmail.com">Zhendong Zhang</a>, <a href="https://openreview.net/profile?email=zhengzk%40xidian.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhengzk@xidian.edu.cn">Cheolkon Jung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkHl6MWC--details-555" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkHl6MWC--details-555"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We provide a novel thinking of regularization neural networks. We smooth the objective of neural networks w.r.t small adversarial perturbations of the inputs. Different from previous works, we assume the adversarial perturbations are caused by the movement field. When the magnitude of movement field approaches 0, we call it virtual movement field. By introducing the movement field, we cast the problem of finding adversarial perturbations into the problem of finding adversarial movement field. By adding proper geometrical constraints to the movement field, such smoothness can be approximated in closed-form by solving a min-max problem and its geometric meaning is clear. We define the approximated smoothness as the regularization term.  We derive three regularization terms as running examples which measure the smoothness w.r.t shift, rotation and scale respectively by adding different constraints. We evaluate our methods on synthetic data, MNIST and CIFAR-10. Experimental results show that our proposed method can significantly improve the baseline neural networks. Compared with the state of the art regularization methods, proposed method achieves a tradeoff between accuracy and geometrical interpretability as well as computational cost.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJWrK9lAb">
      <h4>
        <a href="https://openreview.net/forum?id=rJWrK9lAb">
          Autoregressive Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJWrK9lAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yasin001%40e.ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="yasin001@e.ntu.edu.sg">Yasin Yazici</a>, <a href="https://openreview.net/profile?email=ekhyap%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ekhyap@ntu.edu.sg">Kim-Hui Yap</a>, <a href="https://openreview.net/profile?email=stefan.winkler%40adsc.com.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefan.winkler@adsc.com.sg">Stefan Winkler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJWrK9lAb-details-965" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJWrK9lAb-details-965"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Networks (GANs) learn a generative model by playing an adversarial game between a generator and an auxiliary discriminator, which classifies data samples vs. generated ones. However, it does not explicitly model feature co-occurrences in samples. In this paper, we propose a novel Autoregressive Generative Adversarial Network (ARGAN), that models the latent distribution of data using an autoregressive model, rather than relying on binary classification of samples into data/generated categories. In this way, feature co-occurrences in samples can be more efficiently captured. Our model was evaluated on two widely used datasets: CIFAR-10 and STL-10. Its performance is competitive with respect to other GAN models both quantitatively and qualitatively.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, Latent Space Modeling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy1d-ebAb">
      <h4>
        <a href="https://openreview.net/forum?id=Hy1d-ebAb">
          Learning Deep Generative Models of Graphs
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy1d-ebAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yujiali%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yujiali@google.com">Yujia Li</a>, <a href="https://openreview.net/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>, <a href="https://openreview.net/profile?email=cdyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdyer@google.com">Chris Dyer</a>, <a href="https://openreview.net/profile?email=razp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="razp@google.com">Razvan Pascanu</a>, <a href="https://openreview.net/profile?email=peterbattaglia%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peterbattaglia@google.com">Peter Battaglia</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy1d-ebAb-details-98" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy1d-ebAb-details-98"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Graphs are fundamental data structures required to model many important real-world data, from knowledge graphs, physical and social interactions to molecules and proteins. In this paper, we study the problem of learning generative models of graphs from a dataset of graphs of interest. After learning, these models can be used to generate samples with similar properties as the ones in the dataset.  Such models can be useful in a lot of applications, e.g. drug discovery and knowledge graph construction. The task of learning generative models of graphs, however, has its unique challenges. In particular, how to handle symmetries in graphs and ordering of its elements during the generation process are important issues. We propose a generic graph neural net based model that is capable of generating any arbitrary graph.  We study its performance on a few graph generation tasks compared to baselines that exploit domain knowledge.  We discuss potential issues and open problems for such generative models going forward.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We study the graph generation problem and propose a powerful deep generative model capable of generating arbitrary graphs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Model of Graphs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lfpfZAb">
      <h4>
        <a href="https://openreview.net/forum?id=r1lfpfZAb">
          Learning to Write by Learning the Objective
        </a>
        
          <a href="https://openreview.net/pdf?id=r1lfpfZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ahai%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahai@cs.washington.edu">Ari Holtzman</a>, <a href="https://openreview.net/profile?email=jbuys%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbuys@cs.washington.edu">Jan Buys</a>, <a href="https://openreview.net/profile?email=mbforbes%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbforbes@cs.washington.edu">Maxwell Forbes</a>, <a href="https://openreview.net/profile?email=antoineb%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoineb@cs.washington.edu">Antoine Bosselut</a>, <a href="https://openreview.net/profile?email=yejin%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yejin@cs.washington.edu">Yejin Choi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1lfpfZAb-details-438" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lfpfZAb-details-438"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent Neural Networks (RNNs) are powerful autoregressive sequence models for learning prevalent patterns in natural language.   Yet language generated by RNNs often shows several degenerate characteristics that are uncommon in human language; while fluent, RNN language production can be overly generic, repetitive, and even self-contradictory.  We postulate that the objective function optimized by RNN language models, which amounts to the overall perplexity of a text, is not expressive enough to capture the abstract qualities of good generation such as Grice’s Maxims. In this paper, we introduce a general learning framework that can construct a decoding objective better suited for generation. Starting with a generatively trained RNN language model, our framework learns to construct a substantially stronger generator by combining several discriminatively trained models that can collectively address the limitations of RNN generation.  Human evaluation demonstrates that text generated by the resulting generator is preferred over  that  of  baselines  by  a  large  margin  and  significantly  enhances  the  overall coherence, style, and information content of the generated text.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We build a stronger natural language generator by discriminatively training scoring functions that rank candidate generations with respect to various qualities of good writing.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural language generation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryZ283gAZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryZ283gAZ">
          Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations
        </a>
        
          <a href="https://openreview.net/pdf?id=ryZ283gAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=luyiping9712%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luyiping9712@pku.edu.cn">Yiping Lu</a>, <a href="https://openreview.net/profile?email=zhongaoxiao%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhongaoxiao@gmail.com">Aoxiao Zhong</a>, <a href="https://openreview.net/profile?email=quanzhengli5%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="quanzhengli5@gmail.com">Quanzheng Li</a>, <a href="https://openreview.net/profile?email=dongbin%40math.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dongbin@math.pku.edu.cn">Bin Dong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryZ283gAZ-details-780" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryZ283gAZ-details-780"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks have become the state-of-the-art models in numerous machine learning tasks. However, general guidance to network architecture design is still missing. In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multi-step method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress (&gt;50%) the original networks while maintaining a similar performance. This can be explained mathematically using the concept of modified equation from numerical analysis. Last but not least, we also establish a connection between stochastic control and noise injection in the training process which helps to improve generalization of the networks. Furthermore, by relating stochastic training strategy with stochastic dynamic system, we can easily apply stochastic training to the networks with the LM-architecture. As an example, we introduced stochastic depth to LM-ResNet and achieve significant improvement over the original LM-ResNet on CIFAR10.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper bridges deep network architectures with numerical (stochastic) differential equations. This new perspective enables new designs of more effective deep neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep convolutional network, residual network, dynamic system, stochastic dynamic system, modified equation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B14uJzW0b">
      <h4>
        <a href="https://openreview.net/forum?id=B14uJzW0b">
          No Spurious Local Minima in a Two Hidden Unit ReLU Network
        </a>
        
          <a href="https://openreview.net/pdf?id=B14uJzW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wucw14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wucw14@mails.tsinghua.edu.cn">Chenwei Wu</a>, <a href="https://openreview.net/profile?email=jiajunlu%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiajunlu@usc.edu">Jiajun Luo</a>, <a href="https://openreview.net/profile?email=jasonlee%40marshall.usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jasonlee@marshall.usc.edu">Jason D. Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B14uJzW0b-details-485" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B14uJzW0b-details-485"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning models can be efficiently optimized via stochastic gradient descent, but there is little theoretical evidence to support this. A key question in optimization is to understand when the optimization landscape of a neural network is amenable to gradient-based optimization. We focus on a simple neural network two-layer ReLU network with two hidden units, and show that all local minimizers are global. This combined with recent work of Lee et al. (2017); Lee et al. (2016) show that  gradient descent converges to the global minimizer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Recovery guarantee of stochastic gradient descent with random initialization for learning a two-layer neural network with two hidden nodes, unit-norm weights, ReLU activation functions and Gaussian inputs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Non-convex optimization, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bki4EfWCb">
      <h4>
        <a href="https://openreview.net/forum?id=Bki4EfWCb">
          Inference Suboptimality in Variational Autoencoders
        </a>
        
          <a href="https://openreview.net/pdf?id=Bki4EfWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ccremer%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ccremer@cs.toronto.edu">Chris Cremer</a>, <a href="https://openreview.net/profile?email=lxuechen%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxuechen@cs.toronto.edu">Xuechen Li</a>, <a href="https://openreview.net/profile?email=duvenaud%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="duvenaud@cs.toronto.edu">David Duvenaud</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bki4EfWCb-details-198" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bki4EfWCb-details-198"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Amortized inference has led to efficient approximate inference for large datasets. The quality of posterior inference is largely determined by two factors: a) the ability of the variational distribution to model the true posterior and b) the capacity of the recognition network to generalize inference over all datapoints. We analyze approximate inference in variational autoencoders in terms of these factors. We find that suboptimal inference is often due to amortizing inference rather than the limited complexity of the approximating distribution. We show that this is due partly to the generator learning to accommodate the choice of approximation. Furthermore, we show that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We decompose the gap between the marginal log-likelihood and the evidence lower bound and study the effect of the approximate posterior on the true posterior distribution in VAEs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Approximate Inference, Amortization, Posterior Approximations, Variational Autoencoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lMMx1CW">
      <h4>
        <a href="https://openreview.net/forum?id=B1lMMx1CW">
          THE EFFECTIVENESS OF A TWO-LAYER NEURAL NETWORK FOR RECOMMENDATIONS
        </a>
        
          <a href="https://openreview.net/pdf?id=B1lMMx1CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rybakovo%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rybakovo@amazon.com">Oleg Rybakov</a>, <a href="https://openreview.net/profile?email=vijaim%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vijaim@amazon.com">Vijai Mohan</a>, <a href="https://openreview.net/profile?email=avishkar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avishkar@gmail.com">Avishkar Misra</a>, <a href="https://openreview.net/profile?email=slegrand%40a9.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slegrand@a9.com">Scott LeGrand</a>, <a href="https://openreview.net/profile?email=rgeorgej%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgeorgej@amazon.com">Rejith Joseph</a>, <a href="https://openreview.net/profile?email=kiuk%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kiuk@amazon.com">Kiuk Chung</a>, <a href="https://openreview.net/profile?email=singsidd%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="singsidd@amazon.com">Siddharth Singh</a>, <a href="https://openreview.net/profile?email=qian.you%40snapchat.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qian.you@snapchat.com">Qian You</a>, <a href="https://openreview.net/profile?email=enalisni%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="enalisni@uci.edu">Eric Nalisnick</a>, <a href="https://openreview.net/profile?email=leodirac%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="leodirac@amazon.com">Leo Dirac</a>, <a href="https://openreview.net/profile?email=rluo%40pstat.ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rluo@pstat.ucsb.edu">Runfei Luo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1lMMx1CW-details-576" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lMMx1CW-details-576"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a personalized recommender system using neural network for recommending
      products, such as eBooks, audio-books, Mobile Apps, Video and Music.
      It produces recommendations based on customer’s implicit feedback history such
      as purchases, listens or watches. Our key contribution is to formulate recommendation
      problem as a model that encodes historical behavior to predict the future
      behavior using soft data split, combining predictor and auto-encoder models. We
      introduce convolutional layer for learning the importance (time decay) of the purchases
      depending on their purchase date and demonstrate that the shape of the time
      decay function can be well approximated by a parametrical function. We present
      offline experimental results showing that neural networks with two hidden layers
      can capture seasonality changes, and at the same time outperform other modeling
      techniques, including our recommender in production. Most importantly, we
      demonstrate that our model can be scaled to all digital categories, and we observe
      significant improvements in an online A/B test. We also discuss key enhancements
      to the neural network model and describe our production pipeline. Finally
      we open-sourced our deep learning library which supports multi-gpu model parallel
      training. This is an important feature in building neural network based recommenders
      with large dimensionality of input and output data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Improving recommendations using time sensitive modeling with neural networks in multiple product categories on a retail website</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Recommender systems, deep learning, personalization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk8wKk-R-">
      <h4>
        <a href="https://openreview.net/forum?id=rk8wKk-R-">
          Convolutional Sequence Modeling Revisited
        </a>
        
          <a href="https://openreview.net/pdf?id=rk8wKk-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shaojieb%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shaojieb@cs.cmu.edu">Shaojie Bai</a>, <a href="https://openreview.net/profile?email=zkolter%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkolter@cs.cmu.edu">J. Zico Kolter</a>, <a href="https://openreview.net/profile?email=vkoltun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkoltun@gmail.com">Vladlen Koltun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk8wKk-R--details-936" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk8wKk-R--details-936"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper revisits the problem of sequence modeling using convolutional 
      architectures.  Although both convolutional and recurrent architectures have a
      long history in sequence prediction, the current "default" mindset in much of
      the deep learning community is that generic sequence modeling is best handled
      using recurrent networks.  The goal of this paper is to question this assumption. 
      Specifically, we consider a simple generic temporal convolution network (TCN),
      which adopts features from modern ConvNet architectures such as a dilations and 
      residual connections.  We show that on a variety of sequence modeling tasks,
      including many frequently used as benchmarks for evaluating recurrent networks,
      the TCN outperforms baseline RNN methods (LSTMs, GRUs, and vanilla RNNs) and
      sometimes even highly specialized approaches.  We further show that the
      potential "infinite memory" advantage that RNNs have over TCNs is largely
      absent in practice: TCNs indeed exhibit longer effective history sizes than their 
      recurrent counterparts.   As a whole, we argue that it may be time to (re)consider 
      ConvNets as the default "go to" architecture for sequence modeling.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We argue that convolutional networks should be considered the default starting point for sequence modeling tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Temporal Convolutional Network, Sequence Modeling, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkfmn5n6W">
      <h4>
        <a href="https://openreview.net/forum?id=Hkfmn5n6W">
          Exponentially vanishing sub-optimal local minima in multilayer neural networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Hkfmn5n6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daniel.soudry%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.soudry@gmail.com">Daniel Soudry</a>, <a href="https://openreview.net/profile?email=elad.hoffer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="elad.hoffer@gmail.com">Elad Hoffer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hkfmn5n6W-details-988" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkfmn5n6W-details-988"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Background: Statistical mechanics results (Dauphin et al. (2014); Choromanska et al. (2015)) suggest that local minima with high error are exponentially rare in high dimensions. However, to prove low error guarantees for Multilayer Neural Networks (MNNs), previous works so far required either a heavily modified MNN model or training method, strong assumptions on the labels (e.g., “near” linear separability), or an unrealistically wide hidden layer with \Omega\(N) units. 
      
      Results: We examine a MNN with one hidden layer of piecewise linear units, a single output, and a quadratic loss. We prove that, with high probability in the limit of N\rightarrow\infty datapoints, the volume of differentiable regions of the empiric loss containing sub-optimal differentiable local minima is exponentially vanishing in comparison with the same volume of global minima, given standard normal input of dimension d_0=\tilde{\Omega}(\sqrt{N}), and a more realistic number of d_1=\tilde{\Omega}(N/d_0) hidden units. We demonstrate our results numerically: for example, 0% binary classification training error on CIFAR with only N/d_0 = 16 hidden neurons.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">"Bad" local minima are vanishing in a multilayer neural net: a proof with more reasonable assumptions than before</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural networks, theory, optimization, local minima, loss landscape</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxLBMZCb">
      <h4>
        <a href="https://openreview.net/forum?id=ByxLBMZCb">
          Learning Deep Models: Critical Points and Local Openness
        </a>
        
          <a href="https://openreview.net/pdf?id=ByxLBMZCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nouiehed%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nouiehed@usc.edu">Maher Nouiehed</a>, <a href="https://openreview.net/profile?email=razaviya%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="razaviya@usc.edu">Meisam Razaviyayn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByxLBMZCb-details-504" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxLBMZCb-details-504"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">With the increasing interest in deeper understanding of  the loss surface of many non-convex deep models, this paper presents a unifying framework to study the local/global optima equivalence of the optimization problems arising from training of such non-convex models.  Using the "local openness" property of the underlying training models,  we provide simple sufficient conditions under which any local optimum of the resulting optimization problem is  globally optimal. We first completely characterize the local openness of matrix multiplication mapping in its range. Then we use our characterization to: 1) show that every local optimum of two layer linear networks is globally optimal.  Unlike many existing results in the literature, our result requires no assumption  on the target data matrix Y, and input data matrix X. 2) develop almost complete characterization of the local/global optima equivalence of multi-layer linear neural networks. We provide various counterexamples to show the necessity of each of our assumptions. 3) show global/local optima equivalence of non-linear deep models having certain pyramidal structure. Unlike some existing works, our result requires no assumption on the differentiability of the activation functions and can go beyond "full-rank" cases. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Training Deep Models, Non-convex Optimization, Local and Global Equivalence, Local Openness</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJGY8GbR-">
      <h4>
        <a href="https://openreview.net/forum?id=rJGY8GbR-">
          Deep Mean Field Theory: Layerwise Variance and Width Variation as Methods to Control Gradient Explosion
        </a>
        
          <a href="https://openreview.net/pdf?id=rJGY8GbR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gregyang%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gregyang@microsoft.com">Greg Yang</a>, <a href="https://openreview.net/profile?email=schsam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schsam@google.com">Sam S. Schoenholz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJGY8GbR--details-527" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJGY8GbR--details-527"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">	A recent line of work has studied the statistical properties of neural networks to great success from a {\it mean field theory} perspective, making and verifying very precise predictions of neural network behavior and test time performance.
      	In this paper, we build upon these works to explore two methods for taming the behaviors of random residual networks (with only fully connected layers and no batchnorm).
      	The first method is {\it width variation (WV)}, i.e. varying the widths of layers as a function of depth.
      	We show that width decay reduces gradient explosion without affecting the mean forward dynamics of the random network.
      	The second method is {\it variance variation (VV)}, i.e. changing the initialization variances of weights and biases over depth.
      	We show VV, used appropriately, can reduce gradient explosion of tanh and ReLU resnets from $\exp(\Theta(\sqrt L))$ and $\exp(\Theta(L))$ respectively to constant $\Theta(1)$.
      	A complete phase-diagram is derived for how variance decay affects different dynamics, such as those of gradient and activation norms.
      	In particular, we show the existence of many phase transitions where these dynamics switch between exponential, polynomial, logarithmic, and even constant behaviors.
      	Using the obtained mean field theory, we are able to track surprisingly well how VV at initialization time affects training and test time performance on MNIST after a set number of epochs: the level sets of test/train set accuracies coincide with the level sets of the expectations of certain gradient norms or of metric expressivity (as defined in \cite{yang_meanfield_2017}), a measure of expansion in a random neural network.
      	Based on insights from past works in deep mean field theory and information geometry, we also provide a new perspective on the gradient explosion/vanishing problems: they lead to ill-conditioning of the Fisher information matrix, causing optimization troubles.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">By setting the width or the initialization variance of each layer differently, we can actually subdue gradient explosion problems in residual networks (with fully connected layers and no batchnorm). A mathematical theory is developed that not only tells you how to do it, but also surprisingly is able to predict, after you apply such tricks, how fast your network trains to achieve a certain test set performance. This is some black magic stuff, and it's called "Deep Mean Field Theory."</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">mean field, dynamics, residual network, variance variation, width variation, initialization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BygpQlbA-">
      <h4>
        <a href="https://openreview.net/forum?id=BygpQlbA-">
          Towards Provable Control for Unknown Linear Dynamical Systems
        </a>
        
          <a href="https://openreview.net/pdf?id=BygpQlbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arora%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arora@cs.princeton.edu">Sanjeev Arora</a>, <a href="https://openreview.net/profile?email=ehazan%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ehazan@cs.princeton.edu">Elad Hazan</a>, <a href="https://openreview.net/profile?email=holdenl%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="holdenl@princeton.edu">Holden Lee</a>, <a href="https://openreview.net/profile?email=karans%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="karans@cs.princeton.edu">Karan Singh</a>, <a href="https://openreview.net/profile?email=cyril.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cyril.zhang@cs.princeton.edu">Cyril Zhang</a>, <a href="https://openreview.net/profile?email=y.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.zhang@cs.princeton.edu">Yi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BygpQlbA--details-889" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BygpQlbA--details-889"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the control of symmetric linear dynamical systems with unknown dynamics and a hidden state. Using a recent spectral filtering technique for concisely representing such systems in a linear basis, we formulate optimal control in this setting as a convex program. This approach eliminates the need to solve the non-convex problem of explicit identification of the system and its latent state, and allows for provable optimality guarantees for the control signal. We give the first efficient algorithm for finding the optimal control signal with an arbitrary time horizon T, with sample complexity (number of training rollouts) polynomial only in log(T) and other relevant parameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using a novel representation of symmetric linear dynamical systems with a latent state, we formulate optimal control as a convex program, giving the first polynomial-time algorithm that solves optimal control with sample complexity only polylogarithmic in the time horizon.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimal control, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJYQLb-RW">
      <h4>
        <a href="https://openreview.net/forum?id=HJYQLb-RW">
          On the limitations of first order approximation in GAN dynamics
        </a>
        
          <a href="https://openreview.net/pdf?id=HJYQLb-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jerryzli%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jerryzli@mit.edu">Jerry Li</a>, <a href="https://openreview.net/profile?email=madry%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="madry@mit.edu">Aleksander Madry</a>, <a href="https://openreview.net/profile?email=jpeebles%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpeebles@mit.edu">John Peebles</a>, <a href="https://openreview.net/profile?email=ludwigs%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludwigs@mit.edu">Ludwig Schmidt</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJYQLb-RW-details-102" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJYQLb-RW-details-102"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Networks (GANs) have been proposed as an approach to learning generative models. While GANs have demonstrated promising performance on multiple vision tasks, their learning dynamics are not yet well understood, neither in theory nor in practice. In particular, the work in this domain has been focused so far only on understanding the properties of the stationary solutions that this dynamics might converge to, and of the behavior of that dynamics in this solutions’ immediate neighborhood.
      
      To address this issue, in this work we take a first step towards a principled study of the GAN dynamics itself. To this end, we propose a model that, on one hand, exhibits several of the common problematic convergence behaviors (e.g., vanishing gradient, mode collapse, diverging or oscillatory behavior), but on the other hand, is sufficiently simple to enable rigorous convergence analysis.
      
      This methodology enables us to exhibit an interesting phenomena: a GAN with an optimal discriminator provably converges, while guiding the GAN training using only a first order approximation of the discriminator leads to unstable GAN dynamics and mode collapse. This suggests that such usage of the first order approximation of the discriminator, which is a de-facto standard in all the existing GAN dynamics, might be one of the factors that makes GAN training so challenging in practice. Additionally, our convergence result constitutes the first rigorous analysis of a dynamics of a concrete parametric GAN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">To understand GAN training, we define simple GAN dynamics, and show quantitative differences between optimal and first order updates in this model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GANs, first order dynamics, convergence, mode collapse</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1YynweCb">
      <h4>
        <a href="https://openreview.net/forum?id=H1YynweCb">
          Kronecker Recurrent Units
        </a>
        
          <a href="https://openreview.net/pdf?id=H1YynweCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cijo.jose%40idiap.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="cijo.jose@idiap.ch">Cijo Jose</a>, <a href="https://openreview.net/profile?email=moustaphacisse%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="moustaphacisse@fb.com">Moustapha Cisse</a>, <a href="https://openreview.net/profile?email=francois.fleuret%40idiap.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="francois.fleuret@idiap.ch">Francois Fleuret</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1YynweCb-details-45" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1YynweCb-details-45"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Our work addresses two important issues with recurrent neural networks: (1) they are over-parameterized, and (2) the recurrent weight matrix is ill-conditioned. The former increases the sample complexity of learning and the training time. The latter causes the vanishing and exploding gradient problem. We present a flexible recurrent neural network model called Kronecker Recurrent Units (KRU). KRU achieves parameter efficiency in RNNs through a Kronecker factored recurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by enforcing soft unitary constraints on the factors. Thanks to the small dimensionality of the factors, maintaining these constraints is computationally efficient. Our experimental results on seven standard data-sets reveal that KRU can reduce the number of parameters by three orders of magnitude in the recurrent weight matrix compared to the existing recurrent models, without trading the statistical performance. These results in particular show that while there are advantages in having a high dimensional recurrent space, the capacity of the recurrent part of the model can be dramatically reduced.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Out work presents a Kronecker factorization of recurrent weight matrices for parameter efficient and well conditioned recurrent neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Recurrent neural network, Vanishing and exploding gradients, Parameter efficiency, Kronecker matrices, Soft unitary constraint</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk4Fz2e0b">
      <h4>
        <a href="https://openreview.net/forum?id=rk4Fz2e0b">
          Graph Partition Neural Networks for Semi-Supervised Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=rk4Fz2e0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rjliao%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rjliao@cs.toronto.edu">Renjie Liao</a>, <a href="https://openreview.net/profile?email=mabrocks%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mabrocks@microsoft.com">Marc Brockschmidt</a>, <a href="https://openreview.net/profile?email=dtarlow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dtarlow@google.com">Daniel Tarlow</a>, <a href="https://openreview.net/profile?email=algaunt%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="algaunt@microsoft.com">Alexander Gaunt</a>, <a href="https://openreview.net/profile?email=urtasun%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="urtasun@cs.toronto.edu">Raquel Urtasun</a>, <a href="https://openreview.net/profile?email=zemel%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zemel@cs.toronto.edu">Richard S. Zemel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk4Fz2e0b-details-26" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk4Fz2e0b-details-26"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present graph partition neural networks (GPNN), an extension of graph neural networks (GNNs) able to handle extremely large graphs. GPNNs alternate between locally propagating information between nodes in small subgraphs and globally propagating information between the subgraphs. To efficiently partition graphs, we experiment with spectral partitioning and also propose a modified multi-seed flood fill for fast processing of large scale graphs. We extensively test our model on a variety of semi-supervised node classification tasks. Experimental results indicate that GPNNs are either superior or comparable to state-of-the-art methods on a wide variety of datasets for graph-based semi-supervised classification. We also show that GPNNs can achieve similar performance as standard GNNs with fewer propagation steps.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HymuJz-A-">
      <h4>
        <a href="https://openreview.net/forum?id=HymuJz-A-">
          Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HymuJz-A-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=junkyung_kim%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junkyung_kim@brown.edu">Junkyung Kim</a>, <a href="https://openreview.net/profile?email=matthew_ricci_1%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew_ricci_1@brown.edu">Matthew Ricci</a>, <a href="https://openreview.net/profile?email=thomas_serre%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas_serre@brown.edu">Thomas Serre</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HymuJz-A--details-576" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HymuJz-A--details-576"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The robust and efficient recognition of visual relations in images is a hallmark of biological vision. Here, we argue that, despite recent progress in visual recognition, modern machine vision algorithms are severely limited in their ability to learn visual relations. Through controlled experiments, we demonstrate that visual-relation problems strain convolutional neural networks (CNNs). The networks eventually break altogether when rote memorization becomes impossible such as when the intra-class variability exceeds their capacity. We further show that another type of feedforward network, called a relational network (RN), which was shown to successfully solve seemingly difficult visual question answering (VQA) problems on the CLEVR datasets, suffers similar limitations. Motivated by the comparable success of biological vision, we argue that feedback mechanisms including working memory and attention are the key computational components underlying abstract visual reasoning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using a novel, controlled, visual-relation challenge, we show that same-different tasks critically strain the capacity of CNNs; we argue that visual relations can be better solved using attention-mnemonic strategies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Visual Relations, Visual Reasoning, SVRT, Attention, Working Memory, Convolutional Neural Network, Deep Learning, Relational Network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyunbfbAb">
      <h4>
        <a href="https://openreview.net/forum?id=SyunbfbAb">
          FigureQA: An Annotated Figure Dataset for Visual Reasoning
        </a>
        
          <a href="https://openreview.net/pdf?id=SyunbfbAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=samira.ebrahimi%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="samira.ebrahimi@microsoft.com">Samira Ebrahimi Kahou</a>, <a href="https://openreview.net/profile?email=adatkins%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adatkins@microsoft.com">Adam Atkinson</a>, <a href="https://openreview.net/profile?email=vincent.michalski%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="vincent.michalski@umontreal.ca">Vincent Michalski</a>, <a href="https://openreview.net/profile?email=kadar.akos%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kadar.akos@gmail.com">Ákos Kádár</a>, <a href="https://openreview.net/profile?email=adam.trischler%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.trischler@microsoft.com">Adam Trischler</a>, <a href="https://openreview.net/profile?email=yoshua.bengio%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@umontreal.ca">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyunbfbAb-details-794" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyunbfbAb-details-794"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce FigureQA, a visual reasoning corpus of over one million question-answer pairs grounded in over 100,000 images. The images are synthetic, scientific-style figures from five classes: line plots, dot-line plots, vertical and horizontal bar graphs, and pie charts. We formulate our reasoning task by generating questions from 15 templates; questions concern various relationships between plot elements and examine characteristics like the maximum, the minimum, area-under-the-curve, smoothness, and intersection. To resolve, such questions often require reference to multiple plot elements and synthesis of information distributed spatially throughout a figure. To facilitate the training of machine learning systems, the corpus also includes side data that can be used to formulate auxiliary objectives. In particular, we provide the numerical data used to generate each figure as well as bounding-box annotations for all plot elements. We study the proposed visual reasoning task by training several models, including the recently proposed Relation Network as strong baseline. Preliminary results indicate that the task poses a significant machine learning challenge. We envision FigureQA as a first step towards developing models that can intuitively recognize patterns from visual representations of data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a question-answering dataset, FigureQA, as a first step towards developing models that can intuitively recognize patterns from visual representations of data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">dataset, computer vision, deep learning, visual reasoning, relational reasoning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylJ1D1C-">
      <h4>
        <a href="https://openreview.net/forum?id=SylJ1D1C-">
          PDE-Net: Learning PDEs from Data
        </a>
        
          <a href="https://openreview.net/pdf?id=SylJ1D1C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zlong%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlong@pku.edu.cn">Zichao Long</a>, <a href="https://openreview.net/profile?email=luyiping9712%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luyiping9712@pku.edu.cn">Yiping Lu</a>, <a href="https://openreview.net/profile?email=xianzhongma%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xianzhongma@pku.edu.cn">Xianzhong Ma</a>, <a href="https://openreview.net/profile?email=dongbin%40math.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dongbin@math.pku.edu.cn">Bin Dong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SylJ1D1C--details-562" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylJ1D1C--details-562"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Partial differential equations (PDEs)  play a prominent role in many disciplines such as applied mathematics, physics, chemistry, material science, computer science, etc. PDEs are commonly derived based on physical laws or empirical observations. However, the governing equations for many complex systems in modern applications are still not fully known. With the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of hidden physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models. The basic idea of the proposed PDE-Net is to learn differential operators by learning convolution kernels (filters), and apply neural networks or other machine learning methods to approximate the unknown nonlinear responses. Comparing with existing approaches, which either assume the form of the nonlinear response is known or fix certain finite difference approximations of differential operators, our approach has the most flexibility by learning both differential operators and the nonlinear responses. A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network. These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory). We also discuss relations of the PDE-Net with some existing networks in computer vision such as Network-In-Network (NIN) and Residual Neural Network (ResNet). Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper proposes a new feed-forward network, call PDE-Net, to learn PDEs from data. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep convolution network, partial differential equation, physical laws</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1TgE7WR-">
      <h4>
        <a href="https://openreview.net/forum?id=S1TgE7WR-">
          Covariant Compositional Networks For Learning Graphs
        </a>
        
          <a href="https://openreview.net/pdf?id=S1TgE7WR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=risi%40cs.uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="risi@cs.uchicago.edu">Risi Kondor</a>, <a href="https://openreview.net/profile?email=hytruongson%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hytruongson@uchicago.edu">Truong Son Hy</a>, <a href="https://openreview.net/profile?email=hopan%40cs.uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hopan@cs.uchicago.edu">Horace Pan</a>, <a href="https://openreview.net/profile?email=brandona%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="brandona@uchicago.edu">Brandon M. Anderson</a>, <a href="https://openreview.net/profile?email=shubhendu%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shubhendu@ttic.edu">Shubhendu Trivedi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1TgE7WR--details-391" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1TgE7WR--details-391"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Most existing neural networks for learning graphs deal with the issue of permutation invariance by conceiving of the network as a message passing scheme, where each node sums the feature vectors coming from its neighbors. We argue that this imposes a limitation on their representation power, and instead propose a new general architecture for representing objects consisting of a hierarchy of parts, which we call Covariant Compositional Networks (CCNs). Here covariance means that the activation of each neuron must transform in a specific way under permutations, similarly to steerability in CNNs. We achieve covariance by making each activation transform according to a tensor representation of the permutation group, and derive the corresponding tensor aggregation rules that each neuron must implement. Experiments show that CCNs can outperform competing methods on some standard graph learning benchmarks. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A general framework for creating covariant graph neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph neural networks, message passing, label propagation, high order representation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyUkxxZ0b">
      <h4>
        <a href="https://openreview.net/forum?id=SyUkxxZ0b">
          Adversarial Spheres
        </a>
        
          <a href="https://openreview.net/pdf?id=SyUkxxZ0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gilmer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gilmer@google.com">Justin Gilmer</a>, <a href="https://openreview.net/profile?email=lmetz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lmetz@google.com">Luke Metz</a>, <a href="https://openreview.net/profile?email=fartash.faghri%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fartash.faghri@google.com">Fartash Faghri</a>, <a href="https://openreview.net/profile?email=schsam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schsam@google.com">Sam Schoenholz</a>, <a href="https://openreview.net/profile?email=maithra%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maithra@google.com">Maithra Raghu</a>, <a href="https://openreview.net/profile?email=goodfellow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goodfellow@google.com">Martin Wattenberg</a>, Ian Goodfellow
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyUkxxZ0b-details-175" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyUkxxZ0b-details-175"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">    State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size $O(1/\sqrt{d})$. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that our theoretical analysis of this very simple case will point the way forward to explore how the geometry of complex real-world data sets leads to adversarial examples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We hypothesize that the vulnerability of image models to small adversarial perturbation is a naturally occurring result of the high dimensional geometry of the data manifold. We explore and theoretically prove this hypothesis for a simple synthetic dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Examples, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryZ8sz-Ab">
      <h4>
        <a href="https://openreview.net/forum?id=ryZ8sz-Ab">
          Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping
        </a>
        
          <a href="https://openreview.net/pdf?id=ryZ8sz-Ab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yu-ky14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yu-ky14@mails.tsinghua.edu.cn">Keyi Yu</a>, <a href="https://openreview.net/profile?email=liu301%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liu301@illinois.edu">Yang Liu</a>, <a href="https://openreview.net/profile?email=aschwing%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aschwing@illinois.edu">Alexander G. Schwing</a>, <a href="https://openreview.net/profile?email=jianpeng%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianpeng@illinois.edu">Jian Peng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryZ8sz-Ab-details-340" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryZ8sz-Ab-details-340"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent advances in recurrent neural nets (RNNs) have shown much promise in many applications in natural language processing. For most of these tasks, such as sentiment analysis of customer reviews, a recurrent neural net model parses the entire review before forming a decision. We argue that reading the entire input is not always necessary in practice, since a lot of reviews are often easy to classify, i.e., a decision can be formed after reading some crucial sentences or words in the provided text. In this paper, we present an approach of fast reading for text classification. Inspired by several well-known human reading techniques, our approach implements an intelligent recurrent agent which evaluates the importance of the current snippet in order to decide whether to make a prediction, or to skip some texts, or to re-read part of the sentence. Our agent uses an RNN module to encode information from the past and the current tokens, and applies a policy module to form decisions. With an end-to-end training algorithm based on policy gradient, we train and test our agent on several text classification datasets and achieve both higher efficiency and better accuracy compared to previous approaches. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We develop an end-to-end trainable approach for skimming, rereading and early stopping applicable to classification tasks. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Topic Classification, Sentiment Analysis, Natural Language Processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1KJJf-R-">
      <h4>
        <a href="https://openreview.net/forum?id=B1KJJf-R-">
          Neural Program Search: Solving Data Processing Tasks from Description and Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=B1KJJf-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=illia%40near.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="illia@near.ai">Illia Polosukhin</a>, <a href="https://openreview.net/profile?email=alex%40near.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="alex@near.ai">Alexander Skidanov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1KJJf-R--details-936" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1KJJf-R--details-936"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a Neural Program Search, an algorithm to generate programs from natural language description and a small number of input / output examples. The algorithm combines methods from Deep Learning and Program Synthesis fields by designing rich domain-specific language (DSL) and defining efficient search algorithm guided by a Seq2Tree model on it. To evaluate the quality of the approach we also present a semi-synthetic dataset of descriptions with test examples and corresponding programs. We show that our algorithm significantly outperforms sequence-to-sequence model with attention baseline.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Program synthesis from natural language description and input / output examples via Tree-Beam Search over Seq2Tree model</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, Structured Prediction, Natural Language Processing, Neural Program Synthesis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy3XxCx0Z">
      <h4>
        <a href="https://openreview.net/forum?id=Sy3XxCx0Z">
          Natural Language Inference with External Knowledge
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy3XxCx0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cq1231%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cq1231@mail.ustc.edu.cn">Qian Chen</a>, <a href="https://openreview.net/profile?email=xiaodan.zhu%40queensu.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaodan.zhu@queensu.ca">Xiaodan Zhu</a>, <a href="https://openreview.net/profile?email=zhling%40ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhling@ustc.edu.cn">Zhen-Hua Ling</a>, <a href="https://openreview.net/profile?email=diana.inkpen%40uottawa.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="diana.inkpen@uottawa.ca">Diana Inkpen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy3XxCx0Z-details-836" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy3XxCx0Z-details-836"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Modeling informal inference in natural language is very challenging. With the recent availability of large annotated data, it has become feasible to train complex models such as neural networks to perform natural language inference (NLI), which have achieved state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform NLI from the data? If not, how can NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we aim to answer these questions by enriching the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models with external knowledge further improve the state of the art on the Stanford Natural Language Inference (SNLI) dataset. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">the proposed models with external knowledge further improve the state of the art on the SNLI dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural language inference, external knowledge, state of the art</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk4w0A0Tb">
      <h4>
        <a href="https://openreview.net/forum?id=Sk4w0A0Tb">
          Rotational Unit of Memory 
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk4w0A0Tb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rumenrd%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rumenrd@mit.edu">Rumen Dangovski</a>, <a href="https://openreview.net/profile?email=ljing%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ljing@mit.edu">Li Jing</a>, <a href="https://openreview.net/profile?email=soljacic%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="soljacic@mit.edu">Marin Soljacic</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk4w0A0Tb-details-743" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk4w0A0Tb-details-743"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The concepts of unitary evolution matrices and associative memory have boosted the field of Recurrent Neural Networks (RNN) to state-of-the-art performance in a variety of sequential tasks.  However, RNN still has a limited capacity to manipulate long-term memory.  To bypass this weakness the most successful applications of RNN use external techniques such as attention mechanisms. In this paper we propose a novel RNN model that unifies the state-of-the-art approaches: Rotational Unit of Memory (RUM). The core of RUM is its rotational operation, which is,  naturally,  a unitary matrix, providing architectures with the power to learn long-term dependencies by overcoming the vanishing and exploding gradients problem.  Moreover,  the rotational unit also serves as associative memory. We evaluate our model on synthetic memorization, question answering and language modeling tasks.   RUM learns the Copying Memory task completely and improves the state-of-the-art result in the Recall task.  RUM’s performance in the bAbI Question Answering task is comparable to that of models with attention mechanism. We also improve the state-of-the-art result to 1.189 bits-per-character (BPC) loss in the Character Level Penn Treebank (PTB) task, which is to signify the applications of RUM to real-world sequential data. The universality of our construction, at the core of RNN, establishes RUM as a promising approach to language modeling, speech recognition and machine translation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel RNN model which outperforms significantly the current frontier of models in a variety of sequential tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNN, unitary approach, associative memory, language modeling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byd-EfWCb">
      <h4>
        <a href="https://openreview.net/forum?id=Byd-EfWCb">
          Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks
        </a>
        
          <a href="https://openreview.net/pdf?id=Byd-EfWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vitali.zhelezniak%40babylonhealth.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitali.zhelezniak@babylonhealth.com">Vitalii Zhelezniak</a>, <a href="https://openreview.net/profile?email=dan.busbridge%40babylonhealth.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dan.busbridge@babylonhealth.com">Dan Busbridge</a>, <a href="https://openreview.net/profile?email=april.shen%40babylonhealth.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="april.shen@babylonhealth.com">April Shen</a>, <a href="https://openreview.net/profile?email=slsmith%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slsmith@google.com">Samuel L. Smith</a>, <a href="https://openreview.net/profile?email=nils.hammerla%40babylonhealth.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nils.hammerla@babylonhealth.com">Nils Y. Hammerla</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Byd-EfWCb-details-423" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byd-EfWCb-details-423"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. Introducing the concept of an optimal representation space, we provide a simple theoretical resolution to this apparent paradox. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">By introducing the notion of an optimal representation space, we provide a theoretical argument and experimental validation that an unsupervised model for sentences can perform well on both supervised similarity and unsupervised transfer tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed representations, sentence embedding, representation learning, unsupervised learning, encoder-decoder, RNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxY-sl0W">
      <h4>
        <a href="https://openreview.net/forum?id=rkxY-sl0W">
          Tree-to-tree Neural Networks for Program Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=rkxY-sl0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xinyun.chen%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinyun.chen@berkeley.edu">Xinyun Chen</a>, <a href="https://openreview.net/profile?email=liuchang%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuchang@eecs.berkeley.edu">Chang Liu</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkxY-sl0W-details-516" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxY-sl0W-details-516"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Program translation is an important tool to migrate legacy code in one language into an ecosystem built in a different language. In this work, we are the first to consider employing deep neural networks toward tackling this problem. We observe that program translation is a modular procedure, in which a sub-tree of the source tree is translated into the corresponding target sub-tree at each step. To capture this intuition, we design a tree-to-tree neural network as an encoder-decoder architecture to translate a source tree into a target one. Meanwhile, we develop an attention mechanism for the tree-to-tree model, so that when the decoder expands one non-terminal in the target tree, the attention mechanism locates the corresponding sub-tree in the source tree to guide the expansion of the decoder. We evaluate the program translation capability of our tree-to-tree model against several state-of-the-art approaches. Compared against other neural translation models, we observe that our approach is consistently better than the baselines with a margin of up to 15 points. Further, our approach can improve the previous state-of-the-art program translation approaches by a margin of 20 points on the translation of real-world projects.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkoXnkWAb">
      <h4>
        <a href="https://openreview.net/forum?id=BkoXnkWAb">
          Shifting Mean Activation Towards Zero with Bipolar Activation Functions
        </a>
        
          <a href="https://openreview.net/pdf?id=BkoXnkWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=larseidnes%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="larseidnes@gmail.com">Lars Hiller Eidnes</a>, <a href="https://openreview.net/profile?email=arild.nokland%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arild.nokland@gmail.com">Arild Nøkland</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkoXnkWAb-details-792" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkoXnkWAb-details-792"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a simple extension to the ReLU-family of activation functions that allows them to shift the mean activation across a layer towards zero. Combined with proper weight initialization, this alleviates the need for normalization layers. We explore the training of deep vanilla recurrent neural networks (RNNs) with up to 144 layers, and show that bipolar activation functions help learning in this setting. On the Penn Treebank and Text8 language modeling tasks we obtain competitive results, improving on the best reported results for non-gated networks. In experiments with convolutional neural networks without batch normalization, we find that bipolar activations produce a faster drop in training error, and results in a lower test error on the CIFAR-10 classification task.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By3v9k-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=By3v9k-RZ">
          LEARNING TO ORGANIZE KNOWLEDGE WITH N-GRAM MACHINES
        </a>
        
          <a href="https://openreview.net/pdf?id=By3v9k-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=fanyang1%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fanyang1@cs.cmu.edu">Fan Yang</a>, <a href="https://openreview.net/profile?email=niejiazhong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="niejiazhong@google.com">Jiazhong Nie</a>, <a href="https://openreview.net/profile?email=wcohen%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wcohen@cs.cmu.edu">William W. Cohen</a>, <a href="https://openreview.net/profile?email=nlao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nlao@google.com">Ni Lao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By3v9k-RZ-details-602" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By3v9k-RZ-details-602"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks (DNNs) had great success on NLP tasks such as language modeling, machine translation and certain question answering (QA) tasks. However, the success is limited at more knowledge intensive tasks such as QA from a big corpus. Existing end-to-end deep QA models (Miller et al., 2016; Weston et al., 2014) need to read the entire text after observing the question, and therefore their complexity in responding a question is linear in the text size. This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web. We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size. More specifically, we use sequence-to-sequence models to encode knowledge symbolically and generate programs to answer questions from the encoded knowledge. We apply our approach, called the N-Gram Machine (NGM), to the bAbI tasks (Weston et al., 2015) and a special version of them (“life-long bAbI”) which has stories of up to 10 million sentences. Our experiments show that NGM can successfully solve both of these tasks accurately and efficiently. Unlike fully differentiable memory models, NGM’s time complexity and answering quality are not affected by the story length. The whole system of NGM is trained end-to-end with REINFORCE (Williams, 1992). To avoid high variance in gradient estimation, which is typical in discrete latent variable models, we use beam search instead of sampling. To tackle the exponentially large search space, we use a stabilized auto-encoding objective and a structure tweak procedure to iteratively reduce and refine the search space.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a framework that learns to encode knowledge symbolically and generate programs to reason about the encoded knowledge.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neuro-symbolic reasoning, information extraction, learn to search</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkcTe-bR-">
      <h4>
        <a href="https://openreview.net/forum?id=HkcTe-bR-">
          Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design
        </a>
        
          <a href="https://openreview.net/pdf?id=HkcTe-bR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daniel.neil%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.neil@benevolent.ai">Daniel Neil</a>, <a href="https://openreview.net/profile?email=marwin.segler%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="marwin.segler@benevolent.ai">Marwin Segler</a>, <a href="https://openreview.net/profile?email=laura.guasch%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="laura.guasch@benevolent.ai">Laura Guasch</a>, <a href="https://openreview.net/profile?email=mohamed.ahmed%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohamed.ahmed@benevolent.ai">Mohamed Ahmed</a>, <a href="https://openreview.net/profile?email=dean.plumbley%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="dean.plumbley@benevolent.ai">Dean Plumbley</a>, <a href="https://openreview.net/profile?email=matthew.sellwood%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.sellwood@benevolent.ai">Matthew Sellwood</a>, <a href="https://openreview.net/profile?email=nathan.brown%40benevolent.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="nathan.brown@benevolent.ai">Nathan Brown</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkcTe-bR--details-820" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkcTe-bR--details-820"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The design of small molecules with bespoke properties is of central importance to drug discovery.  However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works.  This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design.  The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry.  Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate a variety of RL algorithms for molecular generation and define new benchmarks (to be released as an OpenAI Gym), finding PPO and a hill-climbing MLE algorithm work best.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, molecule design, de novo design, ppo, sample-efficient reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkBYYyZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=SkBYYyZRZ">
          Searching for Activation Functions
        </a>
        
          <a href="https://openreview.net/pdf?id=SkBYYyZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=prajitram%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="prajitram@gmail.com">Prajit Ramachandran</a>, <a href="https://openreview.net/profile?email=barretzoph%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="barretzoph@google.com">Barret Zoph</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkBYYyZRZ-details-219" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkBYYyZRZ-details-219"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, f(x) = x * sigmoid(beta * x), which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9% for Mobile NASNet-A and 0.6% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use search techniques to discover novel activation functions, and our best discovered activation function, f(x) = x * sigmoid(beta * x), outperforms ReLU on a number of challenging tasks like ImageNet.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meta learning, activation functions</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByQZjx-0-">
      <h4>
        <a href="https://openreview.net/forum?id=ByQZjx-0-">
          Faster Discovery of Neural Architectures by Searching for Paths in a Large Model
        </a>
        
          <a href="https://openreview.net/pdf?id=ByQZjx-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hyhieu%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyhieu@cmu.edu">Hieu Pham</a>, <a href="https://openreview.net/profile?email=mguan%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mguan@stanford.edu">Melody Y. Guan</a>, <a href="https://openreview.net/profile?email=barretzoph%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="barretzoph@google.com">Barret Zoph</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>, <a href="https://openreview.net/profile?email=jeff%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeff@google.com">Jeff Dean</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByQZjx-0--details-279" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByQZjx-0--details-279"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose Efficient Neural Architecture Search (ENAS), a faster and less expensive approach to automated model design than previous methods. In ENAS, a controller learns to discover neural network architectures by searching for an optimal path within a larger model. The controller is trained with policy gradient to select a path that maximizes the expected reward on the validation set. Meanwhile the model corresponding to the selected path is trained to minimize the cross entropy loss. On the Penn Treebank dataset, ENAS can discover a novel architecture thats achieves a test perplexity of 57.8, which is state-of-the-art among automatic model design methods on Penn Treebank. On the CIFAR-10 dataset, ENAS can design novel architectures that achieve a test error of 2.89%, close to the 2.65% achieved by standard NAS (Zoph et al., 2017). Most importantly, our experiments show that ENAS is more than 10x faster and 100x less resource-demanding than NAS.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An approach that speeds up neural architecture search by 10x, whilst using 100x less computing resource.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural architecture search</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1pW0WZAW">
      <h4>
        <a href="https://openreview.net/forum?id=r1pW0WZAW">
          Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies
        </a>
        
          <a href="https://openreview.net/pdf?id=r1pW0WZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rdipietro%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rdipietro@gmail.com">Robert DiPietro</a>, <a href="https://openreview.net/profile?email=christian.rupprecht%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="christian.rupprecht@in.tum.de">Christian Rupprecht</a>, <a href="https://openreview.net/profile?email=nassir.navab%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nassir.navab@tum.de">Nassir Navab</a>, <a href="https://openreview.net/profile?email=hager%40cs.jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hager@cs.jhu.edu">Gregory D. Hager</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1pW0WZAW-details-488" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1pW0WZAW-details-488"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks (RNNs) have achieved state-of-the-art performance on many diverse tasks, from machine translation to surgical activity recognition, yet training RNNs to capture long-term dependencies remains difficult. To date, the vast majority of successful RNN architectures alleviate this problem using nearly-additive connections between states, as introduced by long short-term memory (LSTM). We take an orthogonal approach and introduce MIST RNNs, a NARX RNN architecture that allows direct connections from the very distant past. We show that MIST RNNs 1) exhibit superior vanishing-gradient properties in comparison to LSTM and previously-proposed NARX RNNs; 2) are far more efficient than previously-proposed NARX RNN architectures, requiring even fewer computations than LSTM; and 3) improve performance substantially over LSTM and Clockwork RNNs on tasks requiring very long-term dependencies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce MIST RNNs, which a) exhibit superior vanishing-gradient properties in comparison to LSTM; b) improve performance substantially over LSTM and Clockwork RNNs on tasks requiring very long-term dependencies; and c) are much more efficient than previously-proposed NARX RNNs, with even fewer parameters and operations than LSTM.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, long-term dependencies, long short-term memory, LSTM</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1lN69AT-">
      <h4>
        <a href="https://openreview.net/forum?id=S1lN69AT-">
          To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression
        </a>
        
          <a href="https://openreview.net/pdf?id=S1lN69AT-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mhzhu%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhzhu@cs.stanford.edu">Michael H. Zhu</a>, <a href="https://openreview.net/profile?email=suyoggupta%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="suyoggupta@google.com">Suyog Gupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1lN69AT--details-222" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1lN69AT--details-222"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model pruning seeks to induce sparsity in a deep neural network's various connection matrices, thereby reducing the number of nonzero-valued parameters in the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep networks at the cost of only a marginal loss in accuracy and achieve a sizable reduction in model size. This hints at the possibility that the baseline models in these experiments are perhaps severely over-parameterized at the outset and a viable alternative for model compression might be to simply reduce the number of hidden units while maintaining the model's dense connection structure, exposing a similar trade-off in model size and accuracy. We investigate these two distinct paths for model compression within the context of energy-efficient inference in resource-constrained environments and propose a new gradual pruning technique that is simple and straightforward to apply across a variety of models/datasets with minimal tuning and can be seamlessly incorporated within the training process. We compare the accuracy of large, but pruned models (large-sparse) and their smaller, but dense (small-dense) counterparts with identical memory footprint. Across a broad range of neural network architectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find large-sparse models to consistently outperform small-dense models and achieve up to 10x reduction in number of non-zero parameters with minimal loss in accuracy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We demonstrate that large, but pruned models (large-sparse) outperform their smaller, but dense (small-dense) counterparts with identical memory footprint.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">pruning, model sparsity, model compression, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkRsFSRpb">
      <h4>
        <a href="https://openreview.net/forum?id=SkRsFSRpb">
          GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkRsFSRpb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alessandro.bay%40cortexica.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alessandro.bay@cortexica.com">Alessandro Bay</a>, <a href="https://openreview.net/profile?email=biswasengupta%40yahoo.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="biswasengupta@yahoo.com">Biswa Sengupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkRsFSRpb-details-303" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkRsFSRpb-details-303"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\%.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryALZdAT-">
      <h4>
        <a href="https://openreview.net/forum?id=ryALZdAT-">
          Feature Incay for Representation Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=ryALZdAT-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yuyua%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuyua@microsoft.com">Yuhui Yuan</a>, <a href="https://openreview.net/profile?email=kuiyuanyang%40deepmotion.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="kuiyuanyang@deepmotion.ai">Kuiyuan Yang</a>, <a href="https://openreview.net/profile?email=1701214082%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="1701214082@pku.edu.cn">Jianyuan Guo</a>, <a href="https://openreview.net/profile?email=jingdw%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jingdw@microsoft.com">Jingdong Wang</a>, <a href="https://openreview.net/profile?email=chzhang%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chzhang@cis.pku.edu.cn">Chao Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 20 Apr 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryALZdAT--details-823" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryALZdAT--details-823"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Softmax-based loss is widely used in deep learning for multi-class classification, where each class is represented by a weight vector and each sample is represented as a feature vector. Different from traditional learning algorithms where features are pre-defined and only weight vectors are tunable through training, feature vectors are also tunable as representation learning in deep learning. Thus we investigate how to improve the classification performance by better adjusting the features. One main observation is that elongating the feature norm of both correctly-classified and mis-classified feature vectors improves learning: (1) increasing the feature norm of correctly-classified examples induce smaller training loss; (2) increasing the feature norm of mis-classified examples can upweight the contribution from hard examples. Accordingly, we propose feature incay to regularize representation learning by encouraging larger feature norm. In contrast to weight decay which shrinks the weight norm, feature incay is proposed to stretch the feature norm. Extensive empirical results on MNIST, CIFAR10, CIFAR100 and LFW demonstrate the effectiveness of feature incay. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">feature norm, regularization, softmax loss, feature incay</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkmaTz-0W">
      <h4>
        <a href="https://openreview.net/forum?id=HkmaTz-0W">
          Visualizing the Loss Landscape of Neural Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=HkmaTz-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=haoli%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haoli@cs.umd.edu">Hao Li</a>, <a href="https://openreview.net/profile?email=xuzh%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuzh@cs.umd.edu">Zheng Xu</a>, <a href="https://openreview.net/profile?email=taylor%40usna.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="taylor@usna.edu">Gavin Taylor</a>, <a href="https://openreview.net/profile?email=tomg%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomg@cs.umd.edu">Tom Goldstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkmaTz-0W-details-905" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkmaTz-0W-details-905"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural network training relies on our ability to find ````````"good" minimizers of highly non-convex loss functions. It is well known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and well-chosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effect on the underlying loss landscape, is not well understood.
      
      In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple ``"filter normalization" method that helps us visualize loss function curvature, and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture effects the loss landscape, and how training parameters affect the shape of minimizers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">visualization, loss surface, flatness, sharpness</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJTB5GZCb">
      <h4>
        <a href="https://openreview.net/forum?id=SJTB5GZCb">
          Extending the Framework of Equilibrium Propagation to General Dynamics
        </a>
        
          <a href="https://openreview.net/pdf?id=SJTB5GZCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=benjamin.scellier%40polytechnique.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="benjamin.scellier@polytechnique.edu">Benjamin Scellier</a>, <a href="https://openreview.net/profile?email=anirudhgoyal9119%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anirudhgoyal9119@gmail.com">Anirudh Goyal</a>, <a href="https://openreview.net/profile?email=jbinas%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbinas@gmail.com">Jonathan Binas</a>, <a href="https://openreview.net/profile?email=thomas.mesnard%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.mesnard@gmail.com">Thomas Mesnard</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJTB5GZCb-details-20" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJTB5GZCb-details-20"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The biological plausibility of the backpropagation algorithm has long been doubted by neuroscientists. Two major reasons are that neurons would need to send two different types of signal in the forward and backward phases, and that pairs of neurons would need to communicate through symmetric bidirectional connections.
      We present a simple two-phase learning procedure for fixed point recurrent networks that addresses both these issues.
      In our model, neurons perform leaky integration and synaptic weights are updated through a local mechanism.
      Our learning method extends the framework of Equilibrium Propagation to general dynamics, relaxing the requirement of an energy function.
      As a consequence of this generalization, the algorithm does not compute the true gradient of the objective function,
      but rather approximates it at a precision which is proven to be directly related to the degree of symmetry of the feedforward and feedback weights.
      We show experimentally that the intrinsic properties of the system lead to alignment of the feedforward and feedback weights, and that our algorithm optimizes the objective function.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe a biologically plausible learning algorithm for fixed point recurrent networks without tied weights</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Backpropagation, Fixed Point Recurrent Neural Network, Biologically Plausible Learning, Feedback Alignment, Dynamical System, Gradient-Free Optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkmiegW0b">
      <h4>
        <a href="https://openreview.net/forum?id=SkmiegW0b">
          Challenges in Disentangling Independent Factors of Variation
        </a>
        
          <a href="https://openreview.net/pdf?id=SkmiegW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=szabo%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="szabo@inf.unibe.ch">Attila  Szabo</a>, <a href="https://openreview.net/profile?email=hu%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="hu@inf.unibe.ch">Qiyang  Hu</a>, <a href="https://openreview.net/profile?email=portenier%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="portenier@inf.unibe.ch">Tiziano  Portenier</a>, <a href="https://openreview.net/profile?email=zwicker%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="zwicker@inf.unibe.ch">Matthias  Zwicker</a>, <a href="https://openreview.net/profile?email=paolo.favaro%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="paolo.favaro@inf.unibe.ch">Paolo  Favaro</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkmiegW0b-details-942" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkmiegW0b-details-942"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">
      We study the problem of building models that disentangle independent factors of variation. Such models encode features that can efficiently be used for classification and to transfer attributes between different images in image synthesis. As data we use a weakly labeled training set, where labels indicate what single factor has changed between two data samples, although the relative value of the change is unknown. This labeling is of particular interest as it may be readily available without annotation costs. We introduce an autoencoder model and train it through constraints on image pairs and triplets. We show the role of feature dimensionality and adversarial training theoretically and experimentally. We formally prove the existence of the reference ambiguity, which is inherently present in the disentangling task when weakly labeled data is used. The numerical value of a factor has different meaning in different reference frames. When the reference depends on other factors, transferring that factor becomes ambiguous. We demonstrate experimentally that the proposed model can successfully transfer attributes on several datasets, but show also cases when the reference ambiguity occurs.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">It is a mostly theoretical paper that describes the challenges in disentangling factors of variation, using autoencoders and GAN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">disentangling, factors, attribute, transfer, autoencoder, GAN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkpYwMZRb">
      <h4>
        <a href="https://openreview.net/forum?id=HkpYwMZRb">
          Gradients explode - Deep Networks are shallow - ResNet explained
        </a>
        
          <a href="https://openreview.net/pdf?id=HkpYwMZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=george.philipp%40email.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="george.philipp@email.de">George Philipp</a>, <a href="https://openreview.net/profile?email=dawnsong%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong@gmail.com">Dawn Song</a>, <a href="https://openreview.net/profile?email=jgc%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgc@cs.cmu.edu">Jaime G. Carbonell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkpYwMZRb-details-683" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkpYwMZRb-details-683"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Whereas it is believed that techniques such as Adam, batch normalization and, more recently, SeLU nonlinearities ``solve'' the exploding gradient problem, we show that this is not the case and that in a range of popular MLP architectures, exploding gradients exist and that they limit the depth to which networks can be effectively trained, both in theory and in practice. We explain why exploding gradients occur and highlight the {\it collapsing domain problem}, which can arise in architectures that avoid exploding gradients. 
      
      ResNets have significantly lower gradients and thus can circumvent the exploding gradient problem, enabling the effective training of much deeper networks, which we show is a consequence of a surprising mathematical property. By noticing that {\it any neural network is a residual network}, we devise the {\it residual trick}, which reveals that introducing skip connections simplifies the network mathematically, and that this simplicity may be the major cause for their success.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that in contras to popular wisdom, the exploding gradient problem has not been solved and that it limits the depth to which MLPs can be effectively trained. We show why gradients explode and how ResNet handles them.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, MLP, ResNet, residual network, exploding gradient problem, vanishing gradient problem, effective depth, batch normalization, covariate shift</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syr8Qc1CW">
      <h4>
        <a href="https://openreview.net/forum?id=Syr8Qc1CW">
          DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images
        </a>
        
          <a href="https://openreview.net/pdf?id=Syr8Qc1CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaotaihong%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaotaihong@pku.edu.cn">Taihong Xiao</a>, <a href="https://openreview.net/profile?email=jphong%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jphong@pku.edu.cn">Jiapeng Hong</a>, <a href="https://openreview.net/profile?email=jwma%40math.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwma@math.pku.edu.cn">Jinwen Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syr8Qc1CW-details-955" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syr8Qc1CW-details-955"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Disentangling factors of variation has always been a challenging problem in representation learning. Existing algorithms suffer from many limitations, such as unpredictable disentangling factors, bad quality of generated images from encodings, lack of identity information, etc. In this paper, we proposed a supervised algorithm called DNA-GAN trying to disentangle different attributes of images. The latent representations of images are DNA-like, in which each individual piece represents an independent factor of variation. By annihilating the recessive piece and swapping a certain piece of two latent representations, we obtain another two different representations which could be decoded into images. In order to obtain realistic images and also disentangled representations, we introduced the discriminator for adversarial training. Experiments on Multi-PIE and CelebA datasets demonstrate the effectiveness of our method and the advantage of overcoming limitations existing in other methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We proposed a supervised algorithm, DNA-GAN, to disentangle multiple attributes of images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">disentangled representations, multi-attribute images, generative adversarial networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryDNZZZAW">
      <h4>
        <a href="https://openreview.net/forum?id=ryDNZZZAW">
          Multiple Source Domain Adaptation with Adversarial Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=ryDNZZZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=han.zhao%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="han.zhao@cs.cmu.edu">Han Zhao</a>, <a href="https://openreview.net/profile?email=shanghaz%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shanghaz@andrew.cmu.edu">Shanghang Zhang</a>, <a href="https://openreview.net/profile?email=guanhanw%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guanhanw@andrew.cmu.edu">Guanhang Wu</a>, <a href="https://openreview.net/profile?email=jpc%40isr.ist.utl.pt" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpc@isr.ist.utl.pt">Jo\~{a}o  P. Costeira</a>, <a href="https://openreview.net/profile?email=moura%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="moura@andrew.cmu.edu">Jos\'{e} M. F.  Moura</a>, <a href="https://openreview.net/profile?email=ggordon%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ggordon@cs.cmu.edu">Geoffrey J. Gordon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryDNZZZAW-details-974" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryDNZZZAW-details-974"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While domain adaptation has been actively researched in recent years, most theoretical results and algorithms focus on the single-source-single-target adaptation setting. Naive application of such algorithms on multiple source domain adaptation problem may lead to suboptimal solutions. We propose a new generalization bound for domain adaptation when there are multiple source domains with labeled instances and one target domain with unlabeled instances. Compared with existing bounds, the new bound does not require expert knowledge about the target distribution, nor the optimal combination rule for multisource domains. Interestingly, our theory also leads to an efficient learning strategy using adversarial neural networks: we show how to interpret it as learning feature representations that are invariant to the multiple domain shifts while still being discriminative for the learning task. To this end, we propose two models, both of which we call multisource domain adversarial networks (MDANs): the first model optimizes directly our bound, while the second model is a smoothed approximation of the first one, leading to a more data-efficient and task-adaptive model. The optimization tasks of both models are minimax saddle point problems that can be optimized by adversarial training. To demonstrate the effectiveness of MDANs, we conduct extensive experiments showing superior adaptation performance on three real-world datasets: sentiment analysis, digit classification, and vehicle counting. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial learning, domain adaptation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1I3M7Z0b">
      <h4>
        <a href="https://openreview.net/forum?id=H1I3M7Z0b">
          WSNet: Learning Compact and Efficient Networks with Weight Sampling
        </a>
        
          <a href="https://openreview.net/pdf?id=H1I3M7Z0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaojie.jin%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaojie.jin@u.nus.edu">Xiaojie Jin</a>, <a href="https://openreview.net/profile?email=superyyzg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="superyyzg@gmail.com">Yingzhen Yang</a>, <a href="https://openreview.net/profile?email=ning.xu%40snap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ning.xu@snap.com">Ning Xu</a>, <a href="https://openreview.net/profile?email=jiachao.yang%40snap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiachao.yang@snap.com">Jianchao Yang</a>, <a href="https://openreview.net/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>, <a href="https://openreview.net/profile?email=yanshuicheng%40360.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanshuicheng@360.com">Shuicheng Yan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1I3M7Z0b-details-370" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1I3M7Z0b-details-370"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">	We present a new approach and a novel architecture, termed WSNet, for learning compact and efficient deep neural networks. Existing approaches conventionally learn full model parameters independently and then compress them via \emph{ad hoc} processing such as model pruning or filter factorization. Alternatively, WSNet proposes learning model parameters by sampling from a compact set of learnable parameters, which naturally enforces {parameter sharing} throughout the learning process. We demonstrate that such a novel weight sampling approach (and induced WSNet) promotes both weights and computation sharing favorably. By employing this method, we can more efficiently learn much smaller networks with competitive performance compared to baseline networks with equal numbers of convolution filters. Specifically, we consider learning compact and efficient 1D convolutional neural networks for audio classification. Extensive experiments on multiple audio classification datasets verify the effectiveness of WSNet. Combined with weight quantization, the resulted models are up to \textbf{180$\times$} smaller and theoretically up to \textbf{16$\times$} faster than the well-established baselines, without noticeable performance drop.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a novel network architecture for learning compact and efficient deep neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, model compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rybAWfx0b">
      <h4>
        <a href="https://openreview.net/forum?id=rybAWfx0b">
          COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS
        </a>
        
          <a href="https://openreview.net/pdf?id=rybAWfx0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anuroop.sriram%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anuroop.sriram@gmail.com">Anuroop Sriram</a>, <a href="https://openreview.net/profile?email=junheewoo%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="junheewoo@baidu.com">Heewoo Jun</a>, <a href="https://openreview.net/profile?email=sanjeevsatheesh%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjeevsatheesh@baidu.com">Sanjeev Satheesh</a>, <a href="https://openreview.net/profile?email=adamcoates%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adamcoates@baidu.com">Adam Coates</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rybAWfx0b-details-176" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rybAWfx0b-details-176"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Sequence-to-Sequence Models, Speech Recognition, Language Models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1pWFzbAW">
      <h4>
        <a href="https://openreview.net/forum?id=S1pWFzbAW">
          Weightless: Lossy Weight Encoding For Deep Neural Network Compression
        </a>
        
          <a href="https://openreview.net/pdf?id=S1pWFzbAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=reagen%40fas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="reagen@fas.harvard.edu">Brandon Reagen</a>, <a href="https://openreview.net/profile?email=ugupta%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ugupta@g.harvard.edu">Udit Gupta</a>, <a href="https://openreview.net/profile?email=rdadolf%40seas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rdadolf@seas.harvard.edu">Robert Adolf</a>, <a href="https://openreview.net/profile?email=michaelm%40eecs.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="michaelm@eecs.harvard.edu">Michael Mitzenmacher</a>, <a href="https://openreview.net/profile?email=srush%40seas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srush@seas.harvard.edu">Alexander Rush</a>, <a href="https://openreview.net/profile?email=gywei%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gywei@g.harvard.edu">Gu-Yeon Wei</a>, <a href="https://openreview.net/profile?email=dbrooks%40eecs.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbrooks@eecs.harvard.edu">David Brooks</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 24 Aug 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1pWFzbAW-details-93" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1pWFzbAW-details-93"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The large memory requirements of deep neural networks strain the capabilities of many devices, limiting their deployment and adoption. Model compression methods effectively reduce the memory requirements of these models, usually through applying transformations such as weight pruning or quantization. In this paper, we present a novel scheme for lossy weight encoding which complements conventional compression techniques. The encoding is based on the Bloomier filter, a probabilistic data structure that can save space at the cost of introducing random errors. Leveraging the ability of neural networks to tolerate these imperfections and by re-training around the errors, the proposed technique, Weightless, can compress DNN weights by up to 496x; with the same model accuracy, this results in up to a 1.51x improvement over the state-of-the-art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new way to compress neural networks using probabilistic data structures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Neural Network, Compression, Sparsity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Auv-WRZ">
      <h4>
        <a href="https://openreview.net/forum?id=S1Auv-WRZ">
          Data Augmentation Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Auv-WRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=a.antoniou%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.antoniou@sms.ed.ac.uk">Anthreas Antoniou</a>, <a href="https://openreview.net/profile?email=a.storkey%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.storkey@ed.ac.uk">Amos Storkey</a>, <a href="https://openreview.net/profile?email=h.l.edwards%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="h.l.edwards@sms.ed.ac.uk">Harrison Edwards</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Auv-WRZ-details-894" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Auv-WRZ-details-894"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Effective training of neural networks requires much data. In the low-data regime,
      parameters are underdetermined, and learnt networks generalise poorly. Data
      Augmentation (Krizhevsky et al., 2012) alleviates this by using existing data
      more effectively. However standard data augmentation produces only limited
      plausible alternative data. Given there is potential to generate a much broader set
      of augmentations, we design and train a generative model to do data augmentation.
      The model, based on image conditional Generative Adversarial Networks, takes
      data from a source domain and learns to take any data item and generalise it
      to generate other within-class data items. As this generative process does not
      depend on the classes themselves, it can be applied to novel unseen classes of data.
      We show that a Data Augmentation Generative Adversarial Network (DAGAN)
      augments standard vanilla classifiers well. We also show a DAGAN can enhance
      few-shot learning systems such as Matching Networks. We demonstrate these
      approaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and
      VGG-Face data. In our experiments we can see over 13% increase in accuracy in
      the low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%
      to 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we
      observe an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in
      EMNIST (from 59.5% to 61.3%).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJrTwxbCb">
      <h4>
        <a href="https://openreview.net/forum?id=rJrTwxbCb">
          Empirical Analysis of the Hessian of Over-Parametrized Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJrTwxbCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=leventsagun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="leventsagun@gmail.com">Levent Sagun</a>, <a href="https://openreview.net/profile?email=ue225%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ue225@nyu.edu">Utku Evci</a>, <a href="https://openreview.net/profile?email=vug%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vug@fb.com">V. Ugur Guney</a>, <a href="https://openreview.net/profile?email=yann%40dauphin.io" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann@dauphin.io">Yann Dauphin</a>, <a href="https://openreview.net/profile?email=leonb%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="leonb@fb.com">Leon Bottou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJrTwxbCb-details-783" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJrTwxbCb-details-783"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the properties of common loss surfaces through their Hessian matrix. In particular, in the context of deep learning, we empirically show that the spectrum of the Hessian is composed of two parts: (1) the bulk centered near zero, (2) and outliers away from the bulk. We present numerical evidence and mathematical justifications to the following conjectures laid out by Sagun et. al. (2016): Fixing data, increasing the number of parameters merely scales the bulk of the spectrum; fixing the dimension and changing the data (for instance adding more clusters or making the data less separable) only affects the outliers. We believe that our observations have striking implications for non-convex optimization in high dimensions. First, the *flatness* of such landscapes (which can be measured by the singularity of the Hessian) implies that classical notions of basins of attraction may be quite misleading. And that the discussion of wide/narrow basins may be in need of a new perspective around over-parametrization and redundancy that are able to create *large* connected components at the bottom of the landscape. Second, the dependence of a small number of large eigenvalues to the data distribution can be linked to the spectrum of the covariance matrix of gradients of model outputs. With this in mind, we may reevaluate the connections within the data-architecture-algorithm framework of a model, hoping that it would shed light on the geometry of high-dimensional and non-convex spaces in modern applications. In particular, we present a case that links the two observations: small and large batch gradient descent appear to converge to different basins of attraction but we show that they are in fact connected through their flat region and so belong to the same basin.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The loss surface is *very* degenerate, and there are no barriers between large batch and small batch solutions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Over-parametrization, Hessian, Eigenvalues, Flat minima, Large batch Small batch</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1Z3W-b0W">
      <h4>
        <a href="https://openreview.net/forum?id=B1Z3W-b0W">
          Learning to Infer
        </a>
        
          <a href="https://openreview.net/pdf?id=B1Z3W-b0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jmarino%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmarino@caltech.edu">Joseph Marino</a>, <a href="https://openreview.net/profile?email=yyue%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyue@caltech.edu">Yisong Yue</a>, <a href="https://openreview.net/profile?email=stephan.mandt%40disneyresearch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephan.mandt@disneyresearch.com">Stephan Mandt</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1Z3W-b0W-details-652" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1Z3W-b0W-details-652"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Inference models, which replace an optimization-based inference procedure with a learned model, have been fundamental in advancing Bayesian deep learning, the most notable example being variational auto-encoders (VAEs). In this paper, we propose iterative inference models, which learn how to optimize a variational lower bound through repeatedly encoding gradients. Our approach generalizes VAEs under certain conditions, and by viewing VAEs in the context of iterative inference, we provide further insight into several recent empirical findings. We demonstrate the inference optimization capabilities of iterative inference models, explore unique aspects of these models, and show that they outperform standard inference models on typical benchmark data sets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new class of inference models that iteratively encode gradients to estimate approximate posterior distributions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Bayesian Deep Learning, Amortized Inference, Variational Auto-Encoders, Learning to Learn</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkCnm-bAb">
      <h4>
        <a href="https://openreview.net/forum?id=HkCnm-bAb">
          Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?
        </a>
        
          <a href="https://openreview.net/pdf?id=HkCnm-bAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=maithrar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maithrar@gmail.com">Maithra Raghu</a>, <a href="https://openreview.net/profile?email=alexirpan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexirpan@google.com">Alex Irpan</a>, <a href="https://openreview.net/profile?email=j.d.andreas%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.d.andreas@gmail.com">Jacob Andreas</a>, <a href="https://openreview.net/profile?email=rdk%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rdk@cs.cornell.edu">Robert Kleinberg</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc Le</a>, <a href="https://openreview.net/profile?email=kleinber%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kleinber@cs.cornell.edu">Jon Kleinberg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkCnm-bAb-details-857" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkCnm-bAb-details-857"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. 
      
      Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but also to compare approaches based on supervised and reinforcement learning, to analyze the power of multi-agent approaches in improving performance, and to evaluate generalization to environments outside the training set. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We adapt a family of combinatorial games with tunable difficulty and an optimal policy expressible as linear network, developing it as a rich environment for reinforcement learning, showing contrasts in performance with supervised learning, and analyzing multiagent learning and generalization. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, deep reinforcement learning, combinatorial games, optimality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bya8fGWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=Bya8fGWAZ">
          Value Propagation Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Bya8fGWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nantas%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="nantas@robots.ox.ac.uk">Nantas Nardelli</a>, <a href="https://openreview.net/profile?email=gab%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gab@fb.com">Gabriel Synnaeve</a>, <a href="https://openreview.net/profile?email=zlin%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlin@fb.com">Zeming Lin</a>, <a href="https://openreview.net/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>, <a href="https://openreview.net/profile?email=usunier%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="usunier@fb.com">Nicolas Usunier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bya8fGWAZ-details-692" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bya8fGWAZ-details-692"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Value Propagation (VProp), a parameter-efficient differentiable planning module built on Value Iteration which can successfully be trained in a reinforcement learning fashion to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments. We evaluate on configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes. Furthermore, we show that the module enables to learn to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose Value Propagation, a novel end-to-end planner which can learn to solve 2D navigation tasks via Reinforcement Learning, and that generalizes to larger and dynamic environments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Learning to plan, Reinforcement Learning, Value Iteration, Navigation, Convnets</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkfEzz-0-">
      <h4>
        <a href="https://openreview.net/forum?id=BkfEzz-0-">
          Neuron as an Agent
        </a>
        
          <a href="https://openreview.net/pdf?id=BkfEzz-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ohsawa%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="ohsawa@weblab.t.u-tokyo.ac.jp">Shohei Ohsawa</a>, <a href="https://openreview.net/profile?email=akuzawa-kei%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="akuzawa-kei@weblab.t.u-tokyo.ac.jp">Kei Akuzawa</a>, <a href="https://openreview.net/profile?email=matsushima%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="matsushima@weblab.t.u-tokyo.ac.jp">Tatsuya Matsushima</a>, <a href="https://openreview.net/profile?email=gustavo%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="gustavo@weblab.t.u-tokyo.ac.jp">Gustavo Bezerra</a>, <a href="https://openreview.net/profile?email=iwasawa%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="iwasawa@weblab.t.u-tokyo.ac.jp">Yusuke Iwasawa</a>, <a href="https://openreview.net/profile?email=kjn%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kjn@jp.ibm.com">Hiroshi Kajino</a>, <a href="https://openreview.net/profile?email=s.takenaka%40aediworks.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.takenaka@aediworks.com">Seiya Takenaka</a>, <a href="https://openreview.net/profile?email=matsuo%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="matsuo@weblab.t.u-tokyo.ac.jp">Yutaka Matsuo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkfEzz-0--details-485" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkfEzz-0--details-485"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Existing multi-agent reinforcement learning (MARL) communication methods have relied on a trusted third party (TTP) to distribute reward to agents, leaving them inapplicable in peer-to-peer environments. This paper proposes reward distribution using {\em Neuron as an Agent} (NaaA) in MARL without a TTP with two key ideas: (i) inter-agent reward distribution and (ii) auction theory. Auction theory is introduced because inter-agent reward distribution is insufficient for optimization. Agents in NaaA maximize their profits (the difference between reward and cost) and, as a theoretical result, the auction mechanism is shown to have agents autonomously evaluate counterfactual returns as the values of other agents. NaaA enables representation trades in peer-to-peer environments, ultimately regarding unit in neural networks as agents. Finally, numerical experiments (a single-agent environment from OpenAI Gym and a multi-agent environment from ViZDoom) confirm that NaaA framework optimization leads to better performance in reinforcement learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Neuron as an Agent (NaaA) enable us to train multi-agent communication without a trusted third party.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Multi-agent Reinforcement Learning, Communication, Reward Distribution, Trusted Third Party, Auction Theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk91SGWR-">
      <h4>
        <a href="https://openreview.net/forum?id=Hk91SGWR-">
          Investigating Human Priors for Playing Video Games
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk91SGWR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rach0012%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rach0012@berkeley.edu">Rachit Dubey</a>, <a href="https://openreview.net/profile?email=pulkitag%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pulkitag@berkeley.edu">Pulkit Agrawal</a>, <a href="https://openreview.net/profile?email=pathak%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pathak@berkeley.edu">Deepak Pathak</a>, <a href="https://openreview.net/profile?email=tom_griffiths%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom_griffiths@berkeley.edu">Thomas L. Griffiths</a>, <a href="https://openreview.net/profile?email=efros%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="efros@eecs.berkeley.edu">Alexei A. Efros</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk91SGWR--details-508" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk91SGWR--details-508"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">What makes humans so good at solving seemingly complex video games?  Unlike computers, humans bring in a great deal of prior knowledge about the world, enabling efficient decision making. This paper investigates the role of human priors for solving video games. Given a sample game, we conduct a series of ablation studies to quantify the importance of various priors. We do this by modifying the video game environment to systematically mask different types of visual information that could be used by humans as priors. We find that removal of some prior knowledge causes a drastic degradation in the speed with which human players solve the game, e.g. from 2 minutes to over 20 minutes. Furthermore, our results indicate that general priors, such as the importance of objects and visual consistency, are critical for efficient game-play.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Prior knowledge, Reinforcement learning, Cognitive Science</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJk51gJRb">
      <h4>
        <a href="https://openreview.net/forum?id=rJk51gJRb">
          Adversarial Policy Gradient for Alternating Markov Games
        </a>
        
          <a href="https://openreview.net/pdf?id=rJk51gJRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cgao3%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="cgao3@ualberta.ca">Chao Gao</a>, <a href="https://openreview.net/profile?email=mmueller%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="mmueller@ualberta.ca">Martin Mueller</a>, <a href="https://openreview.net/profile?email=hayward%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="hayward@ualberta.ca">Ryan Hayward</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJk51gJRb-details-93" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJk51gJRb-details-93"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Policy gradient reinforcement learning has been applied to two-player alternate-turn zero-sum games, e.g., in AlphaGo, self-play REINFORCE was used to improve the neural net model after supervised learning. In this paper, we emphasize that two-player zero-sum games with alternating turns, which have been previously formulated as Alternating Markov Games (AMGs), are different from standard MDP because of their two-agent nature. We exploit the difference in associated Bellman equations, which leads to different policy iteration algorithms. As policy gradient method is a kind of generalized policy iteration, we show how these differences in policy iteration are reflected in policy gradient for AMGs. We formulate an adversarial policy gradient and discuss potential possibilities for developing better policy gradient methods other than self-play REINFORCE. The core idea is to estimate the minimum rather than the mean for the “critic”. Experimental results on the game of Hex show the modified Monte Carlo policy gradient methods are able to learn better pure neural net policies than the REINFORCE variants. To apply learned neural weights to multiple board sizes Hex, we describe a board-size independent neural net architecture. We show that when combined with search, using a single neural net model, the resulting program consistently beats MoHex 2.0, the state-of-the-art computer Hex player, on board sizes from 9×9 to 13×13. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJInEZsTb">
      <h4>
        <a href="https://openreview.net/forum?id=BJInEZsTb">
          Learning Representations and Generative Models for 3D Point Clouds
        </a>
        
          <a href="https://openreview.net/pdf?id=BJInEZsTb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=optas%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="optas@cs.stanford.edu">Panos Achlioptas</a>, <a href="https://openreview.net/profile?email=diamanti%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="diamanti@stanford.edu">Olga Diamanti</a>, <a href="https://openreview.net/profile?email=ioannis%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ioannis@iro.umontreal.ca">Ioannis Mitliagkas</a>, <a href="https://openreview.net/profile?email=guibas%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guibas@cs.stanford.edu">Leonidas Guibas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJInEZsTb-details-57" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJInEZsTb-details-57"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and, Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.
      To perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, auto-encoders, 3D point clouds, generative models, GANs, Gaussian Mixture Models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJubPWZRW">
      <h4>
        <a href="https://openreview.net/forum?id=BJubPWZRW">
          Cross-View Training for Semi-Supervised Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BJubPWZRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kevclark%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevclark@cs.stanford.edu">Kevin Clark</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Thang Luong</a>, <a href="https://openreview.net/profile?email=thangluong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thangluong@google.com">Quoc V. Le</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJubPWZRW-details-453" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJubPWZRW-details-453"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Cross-View Training (CVT), a simple but effective method for deep semi-supervised learning. On labeled examples, the model is trained with standard cross-entropy loss. On an unlabeled example, the model first performs inference (acting as a "teacher") to produce soft targets. The model then learns from these soft targets (acting as a ``"student"). We deviate from prior work by adding multiple auxiliary student prediction layers to the model. The input to each student layer is a sub-network of the full model that has a restricted view of the input  (e.g., only seeing one region of an image). The students can learn from the teacher (the full model) because the teacher sees more of each example. Concurrently, the students improve the quality of the representations used by the teacher as they learn to make predictions with limited data. When combined with Virtual Adversarial Training, CVT improves upon the current state-of-the-art on semi-supervised CIFAR-10 and semi-supervised SVHN. We also apply CVT to train models on five natural language processing tasks using hundreds of millions of sentences of unlabeled data. On all tasks CVT substantially outperforms supervised learning alone, resulting in models that improve upon or are competitive with the current state-of-the-art.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Self-training with different views of the input gives excellent results for semi-supervised image recognition, sequence tagging, and dependency parsing.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">semi-supervised learning, image recognition, sequence tagging, dependency parsing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1DkN7ZCZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1DkN7ZCZ">
          Deep learning mutation prediction enables early stage lung cancer detection in liquid biopsy
        </a>
        
          <a href="https://openreview.net/pdf?id=H1DkN7ZCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sth2022%40med.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sth2022@med.cornell.edu">Steven T. Kothen-Hill</a>, <a href="https://openreview.net/profile?email=azviran%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="azviran@nygenome.org">Asaf Zviran</a>, <a href="https://openreview.net/profile?email=rschulman%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="rschulman@nygenome.org">Rafael C. Schulman</a>, <a href="https://openreview.net/profile?email=sdd325%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sdd325@nyu.edu">Sunil Deochand</a>, <a href="https://openreview.net/profile?email=fgaiti%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="fgaiti@nygenome.org">Federico Gaiti</a>, <a href="https://openreview.net/profile?email=dmaloney%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmaloney@nygenome.org">Dillon Maloney</a>, <a href="https://openreview.net/profile?email=khuang%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="khuang@nygenome.org">Kevin Y. Huang</a>, <a href="https://openreview.net/profile?email=wliao%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="wliao@nygenome.org">Will Liao</a>, <a href="https://openreview.net/profile?email=nrobine%40nygenome.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="nrobine@nygenome.org">Nicolas Robine</a>, <a href="https://openreview.net/profile?email=nao2013%40med.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nao2013@med.cornell.edu">Nathaniel D. Omans</a>, <a href="https://openreview.net/profile?email=dal3005%40med.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dal3005@med.cornell.edu">Dan A. Landau</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1DkN7ZCZ-details-705" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1DkN7ZCZ-details-705"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Somatic cancer mutation detection at ultra-low variant allele frequencies (VAFs) is an unmet challenge that is intractable with current state-of-the-art mutation calling methods. Specifically, the limit of VAF detection is closely related to the depth of coverage, due to the requirement of multiple supporting reads in extant methods, precluding the detection of mutations at VAFs that are orders of magnitude lower than the depth of coverage. Nevertheless, the ability to detect cancer-associated mutations in ultra low VAFs is a fundamental requirement for low-tumor burden cancer diagnostics applications such as early detection, monitoring, and therapy nomination using liquid biopsy methods (cell-free DNA). Here we defined a spatial representation of sequencing information adapted for convolutional architecture that enables variant detection at VAFs, in a manner independent of the depth of sequencing. This method enables the detection of cancer mutations even in VAFs as low as 10x-4^, &gt;2 orders of magnitude below the current state-of-the-art. We validated our method on both simulated plasma and on clinical cfDNA plasma samples from cancer patients and non-cancer controls. This method introduces a new domain within bioinformatics and personalized medicine – somatic whole genome mutation calling for liquid biopsy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> Current somatic mutation methods do not work with liquid biopsies (ie low coverage sequencing), we apply a CNN architecture to a unique representation of a read and its ailgnment, we show significant improvement over previous methods in the low frequency setting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">somatic mutation, variant calling, cancer, liquid biopsy, early detection, convolution, deep learning, machine learning, lung cancer, error suppression, mutect</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByaQIGg0-">
      <h4>
        <a href="https://openreview.net/forum?id=ByaQIGg0-">
          AUTOMATED DESIGN USING NEURAL NETWORKS AND GRADIENT DESCENT
        </a>
        
          <a href="https://openreview.net/pdf?id=ByaQIGg0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=loliverhennigh101%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="loliverhennigh101@gmail.com">Oliver Hennigh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByaQIGg0--details-364" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByaQIGg0--details-364"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel method that makes use of deep neural networks and gradient decent to perform automated design on complex real world engineering tasks. Our approach works by training a neural network to mimic the fitness function of a design optimization task and then, using the differential nature of the neural network, perform gradient decent to maximize the fitness. We demonstrate this methods effectiveness by designing an optimized heat sink and both 2D and 3D airfoils that maximize the lift drag ratio under steady state flow conditions. We highlight that our method has two distinct benefits over other automated design approaches. First, evaluating the neural networks prediction of fitness can be orders of magnitude faster then simulating the system of interest. Second, using gradient decent allows the design space to be searched much more efficiently then other gradient free methods. These two strengths work together to overcome some of the current shortcomings of automated design.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A method for performing automated design on real world objects such as heat sinks and wing airfoils that makes use of neural networks and gradient descent.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Automated Design, Gradient Descent</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyDMX0l0Z">
      <h4>
        <a href="https://openreview.net/forum?id=HyDMX0l0Z">
          Towards Effective GANs for Data Distributions with Diverse Modes
        </a>
        
          <a href="https://openreview.net/pdf?id=HyDMX0l0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sanchit%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanchit@cse.iitm.ac.in">Sanchit Agrawal</a>, <a href="https://openreview.net/profile?email=garry%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="garry@cse.iitm.ac.in">Gurneet Singh</a>, <a href="https://openreview.net/profile?email=miteshk%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="miteshk@cse.iitm.ac.in">Mitesh Khapra</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyDMX0l0Z-details-694" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyDMX0l0Z-details-694"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Networks (GANs), when trained on large datasets with diverse modes, are known to produce conflated images which do not distinctly belong to any of the modes. We hypothesize that this problem occurs due to the interaction between two facts: (1) For datasets with large variety, it is likely that the modes lie on separate manifolds. (2) The generator (G) is formulated as a continuous function, and the input noise is derived from a connected set, due to which G's output is a connected set. If G covers all modes, then there must be some portion of G's output which connects them. This corresponds to undesirable, conflated images. We develop theoretical arguments to support these intuitions. We propose a novel method to break the second assumption via learnable discontinuities in the latent noise space. Equivalently, it can be viewed as training several generators, thus creating discontinuities in the G function. We also augment the GAN formulation with a classifier C that predicts which noise partition/generator produced the output images, encouraging diversity between each partition/generator. We experiment on MNIST, celebA, STL-10, and a difficult dataset with clearly distinct modes, and show that the noise partitions correspond to different modes of the data distribution, and produce images of superior quality.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce theory to explain the failure of GANs on complex datasets and propose a solution to fix it.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, GANs, deep learning, unsupervised learning, generative models, adversarial learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkEtzzWAb">
      <h4>
        <a href="https://openreview.net/forum?id=rkEtzzWAb">
          Parametric Adversarial Divergences are Good Task Losses for Generative Modeling
        </a>
        
          <a href="https://openreview.net/pdf?id=rkEtzzWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gbxhuang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gbxhuang@gmail.com">Gabriel Huang</a>, <a href="https://openreview.net/profile?email=berard.hugo%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="berard.hugo@gmail.com">Hugo Berard</a>, <a href="https://openreview.net/profile?email=ahmed.touati%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahmed.touati@umontreal.ca">Ahmed Touati</a>, <a href="https://openreview.net/profile?email=gauthier.gidel%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="gauthier.gidel@inria.fr">Gauthier Gidel</a>, <a href="https://openreview.net/profile?email=pascal.vincent%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="pascal.vincent@umontreal.ca">Pascal Vincent</a>, <a href="https://openreview.net/profile?email=slacoste%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="slacoste@iro.umontreal.ca">Simon Lacoste-Julien</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkEtzzWAb-details-137" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkEtzzWAb-details-137"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative modeling of high dimensional data like images is a notoriously difficult and ill-defined problem. In particular, how to evaluate a learned generative model is unclear.
      In this paper, we argue that *adversarial learning*, pioneered with generative adversarial networks (GANs), provides an interesting framework to implicitly define more meaningful task losses for unsupervised tasks, such as for generating "visually realistic" images. By relating GANs and structured prediction under the framework of statistical decision theory, we put into light links between recent advances in structured prediction theory and the choice of the divergence in GANs. We argue that the insights about the notions of "hard" and "easy" to learn losses can be analogously extended to adversarial divergences. We also discuss the attractive properties of parametric adversarial divergences for generative modeling, and perform experiments to show the importance of choosing a divergence that reflects the final task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Parametric adversarial divergences implicitly define more meaningful task losses for generative modeling, we make parallels with structured prediction to study the properties of these divergences and their ability to encode the task of interest.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">parametric, adversarial, divergence, generative, modeling, gan, neural, network, task, loss, structured, prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1YUtYx0-">
      <h4>
        <a href="https://openreview.net/forum?id=r1YUtYx0-">
          Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms
        </a>
        
          <a href="https://openreview.net/pdf?id=r1YUtYx0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tomzahavy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomzahavy@gmail.com">Tom Zahavy</a>, <a href="https://openreview.net/profile?email=bingykang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bingykang@gmail.com">Bingyi Kang</a>, <a href="https://openreview.net/profile?email=silex%40campus.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="silex@campus.technion.ac.il">Alex Sivak</a>, <a href="https://openreview.net/profile?email=jshfeng%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jshfeng@gmail.com">Jiashi Feng</a>, <a href="https://openreview.net/profile?email=huan.xu%40isye.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huan.xu@isye.gatech.edu">Huan Xu</a>, <a href="https://openreview.net/profile?email=shiemannor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiemannor@gmail.com">Shie Mannor</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1YUtYx0--details-395" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1YUtYx0--details-395"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The question why deep learning algorithms generalize so well has attracted increasing
      research interest. However, most of the well-established approaches,
      such as hypothesis capacity, stability or sparseness, have not provided complete
      explanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus
      on the robustness approach (Xu &amp; Mannor, 2012), i.e., if the error of a hypothesis
      will not change much due to perturbations of its training examples, then it
      will also generalize well. As most deep learning algorithms are stochastic (e.g.,
      Stochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness
      arguments of Xu &amp; Mannor, and introduce a new approach – ensemble
      robustness – that concerns the robustness of a population of hypotheses. Through
      the lens of ensemble robustness, we reveal that a stochastic learning algorithm can
      generalize well as long as its sensitiveness to adversarial perturbations is bounded
      in average over training examples. Moreover, an algorithm may be sensitive to
      some adversarial examples (Goodfellow et al., 2015) but still generalize well. To
      support our claims, we provide extensive simulations for different deep learning
      algorithms and different network architectures exhibiting a strong correlation between
      ensemble robustness and the ability to generalize.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Robustness, Generalization, Deep Learning, Adversarial Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyKoKWbC-">
      <h4>
        <a href="https://openreview.net/forum?id=SyKoKWbC-">
          Distributional Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SyKoKWbC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ctli%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ctli@mit.edu">Chengtao Li</a>, <a href="https://openreview.net/profile?email=dalvmel%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dalvmel@mit.edu">David Alvarez-Melis</a>, <a href="https://openreview.net/profile?email=keyulu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="keyulu@mit.edu">Keyulu Xu</a>, <a href="https://openreview.net/profile?email=stefje%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefje@csail.mit.edu">Stefanie Jegelka</a>, <a href="https://openreview.net/profile?email=suvrit%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="suvrit@mit.edu">Suvrit Sra</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyKoKWbC--details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyKoKWbC--details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In most current formulations of adversarial training, the discriminators can be expressed as single-input operators, that is, the mapping they define is separable over observations. In this work, we argue that this property might help explain the infamous mode collapse phenomenon in adversarially-trained generative models. Inspired by discrepancy measures and two-sample tests between probability distributions, we propose distributional adversaries that operate on samples, i.e., on sets of multiple points drawn from a distribution, rather than on single observations. We show how they can be easily implemented on top of existing models. Various experimental results show that generators trained in combination with our distributional adversaries are much more stable and are remarkably less prone to mode collapse than traditional models trained with observation-wise prediction discriminators. In addition, the application of our framework to domain adaptation results in strong improvement over recent state-of-the-art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that the mode collapse problem in GANs may be explained by a lack of information sharing between observations in a training batch, and propose a distribution-based framework for globally sharing information between gradients that leads to more stable and effective adversarial training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial learning, generative model, domain adaptation, two-sample test</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkM3ibZRW">
      <h4>
        <a href="https://openreview.net/forum?id=BkM3ibZRW">
          Adversarially Regularized Autoencoders
        </a>
        
          <a href="https://openreview.net/pdf?id=BkM3ibZRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jakezhao%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jakezhao@cs.nyu.edu">Junbo (Jake) Zhao</a>, <a href="https://openreview.net/profile?email=yoonkim%40seas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoonkim@seas.harvard.edu">Yoon Kim</a>, <a href="https://openreview.net/profile?email=kz918%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kz918@nyu.edu">Kelly Zhang</a>, <a href="https://openreview.net/profile?email=srush%40seas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srush@seas.harvard.edu">Alexander M. Rush</a>, <a href="https://openreview.net/profile?email=yann%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann@cs.nyu.edu">Yann LeCun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkM3ibZRW-details-113" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkM3ibZRW-details-113"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While autoencoders are a key technique in representation learning for continuous structures, such as images or wave forms, developing general-purpose autoencoders for discrete structures, such as text sequence or discretized images, has proven to be more challenging. In particular, discrete inputs make it more difficult to learn a smooth encoder that preserves the complex local relationships in the input space. In this work, we propose an adversarially regularized autoencoder (ARAE) with the goal of learning more robust discrete-space representations. ARAE jointly trains both a rich discrete-space encoder, such as an RNN, and a simpler continuous space generator function, while using generative adversarial network (GAN) training to constrain the distributions to be similar. This method yields a smoother contracted code space that maps similar inputs to nearby codes, and also an implicit latent variable GAN model for generation. Experiments on text and discretized images demonstrate that the GAN model produces clean interpolations and captures the multimodality of the original space, and that the autoencoder produces improvements in semi-supervised learning as well as state-of-the-art results in unaligned text style transfer task using only a shared continuous-space representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adversarially Regularized Autoencoders learn smooth representations of discrete structures allowing for interesting results in text generation, such as unaligned style transfer, semi-supervised learning, and latent space interpolation and arithmetic.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, natural language generation, discrete structure modeling, adversarial training, unaligned text style-transfer</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skk3Jm96W">
      <h4>
        <a href="https://openreview.net/forum?id=Skk3Jm96W">
          Some Considerations on Learning to Explore via Meta-Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=Skk3Jm96W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bstadie%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bstadie@berkeley.edu">Bradly Stadie</a>, <a href="https://openreview.net/profile?email=yangge1987%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangge1987@gmail.com">Ge Yang</a>, <a href="https://openreview.net/profile?email=rein.hh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rein.hh@gmail.com">Rein Houthooft</a>, <a href="https://openreview.net/profile?email=adslcx%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adslcx@gmail.com">Xi Chen</a>, <a href="https://openreview.net/profile?email=dementrock%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dementrock@gmail.com">Yan Duan</a>, <a href="https://openreview.net/profile?email=ywu%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywu@cs.toronto.edu">Yuhuai Wu</a>, <a href="https://openreview.net/profile?email=pabbeel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@gmail.com">Pieter Abbeel</a>, <a href="https://openreview.net/profile?email=ilyasu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilyasu@openai.com">Ilya Sutskever</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skk3Jm96W-details-165" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skk3Jm96W-details-165"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of exploration in meta reinforcement learning. Two new meta reinforcement learning algorithms are suggested: E-MAML and ERL2. Results are presented on a novel environment we call 'Krazy World'  and a set of maze environments. We show E-MAML and ERL2 deliver better performance on tasks where exploration is important.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Modifications to MAML and RL2 that should allow for better exploration. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, rl, exploration, meta learning, meta reinforcement learning, curiosity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkA7gfZAb">
      <h4>
        <a href="https://openreview.net/forum?id=BkA7gfZAb">
          Stable Distribution Alignment Using the Dual of the Adversarial Distance
        </a>
        
          <a href="https://openreview.net/pdf?id=BkA7gfZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=usmn%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="usmn@bu.edu">Ben Usman</a>, <a href="https://openreview.net/profile?email=saenko%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saenko@bu.edu">Kate Saenko</a>, <a href="https://openreview.net/profile?email=bkulis%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bkulis@bu.edu">Brian Kulis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkA7gfZAb-details-845" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkA7gfZAb-details-845"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Methods that align distributions by minimizing an adversarial distance between them have recently achieved impressive results. However, these approaches are difficult to optimize with gradient descent and they often do not converge well without careful hyperparameter tuning and proper initialization. We investigate whether turning the adversarial min-max problem into an optimization problem by replacing the maximization part with its dual improves the quality of the resulting alignment and explore its connections to Maximum Mean Discrepancy. Our empirical results suggest that using the dual formulation for the restricted family of linear discriminators results in a more stable convergence to a desirable solution when compared with the performance of a primal min-max GAN-like objective and an MMD objective under the same restrictions. We test our hypothesis on the problem of aligning two synthetic point clouds on a plane and on a real-image domain adaptation problem on digits. In both cases, the dual formulation yields an iterative procedure that gives more stable and monotonic improvement over time.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> We propose a dual version of the logistic adversarial distance for feature alignment and show that it yields more stable gradient step iterations than the min-max objective.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">domain adaptation, adversarial networks, statistical distance, duality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H18WqugAb">
      <h4>
        <a href="https://openreview.net/forum?id=H18WqugAb">
          Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H18WqugAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=brenden%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="brenden@nyu.edu">Brenden Lake</a>, <a href="https://openreview.net/profile?email=marco.baroni%40unitn.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="marco.baroni@unitn.it">Marco Baroni</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H18WqugAb-details-1" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H18WqugAb-details-1"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Humans can understand and produce new utterances effortlessly, thanks to their systematic compositional skills. Once a person learns the meaning of a new verb "dax," he or she can immediately understand the meaning of "dax twice" or "sing and dax." In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can generalize well when the differences between training and test commands are small, so that they can apply "mix-and-match" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the "dax" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, supporting the conjecture that lack of systematicity is an important factor explaining why neural networks need very large training sets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using a simple language-driven navigation task, we study the compositional capabilities of modern seq2seq recurrent networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sequence-to-sequence recurrent networks, compositionality, systematicity, generalization, language-driven navigation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ3d2Ax0-">
      <h4>
        <a href="https://openreview.net/forum?id=HJ3d2Ax0-">
          Benefits of Depth for Long-Term Memory of Recurrent Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ3d2Ax0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yoavlevine%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoavlevine@cs.huji.ac.il">Yoav Levine</a>, <a href="https://openreview.net/profile?email=or.sharir%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="or.sharir@cs.huji.ac.il">Or Sharir</a>, <a href="https://openreview.net/profile?email=shashua%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shashua@cs.huji.ac.il">Amnon Shashua</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ3d2Ax0--details-999" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ3d2Ax0--details-999"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The key attribute that drives the unprecedented success of modern Recurrent Neural Networks (RNNs) on learning tasks which involve sequential data, is their ever-improving ability to model intricate long-term temporal dependencies. However, a well established measure of RNNs' long-term memory capacity is lacking, and thus formal understanding of their ability to correlate data throughout time is limited. Though depth efficiency in convolutional networks is well established by now, it does not suffice in order to account for the success of deep RNNs on inputs of varying lengths, and the need to address their 'time-series expressive power' arises. In this paper, we analyze the effect of depth on the ability of recurrent networks to express correlations ranging over long time-scales. To meet the above need, we introduce a measure of the information flow across time that can be supported by the network, referred to as the Start-End separation rank. Essentially, this measure reflects the distance of the function realized by the recurrent network from a function that models no interaction whatsoever between the beginning and end of the input sequence. We prove that deep recurrent networks support Start-End separation ranks which are exponentially higher than those supported by their shallow counterparts. Moreover, we show that the ability of deep recurrent networks to correlate different parts of the input sequence increases exponentially as the input sequence extends, while that of vanilla shallow recurrent networks does not adapt to the sequence length at all. Thus, we establish that depth brings forth an overwhelming advantage in the ability of recurrent networks to model long-term dependencies, and provide an exemplar of quantifying this key attribute which may be readily extended to other RNN architectures of interest, e.g. variants of LSTM networks. We obtain our results by considering a class of recurrent networks referred to as Recurrent Arithmetic Circuits (RACs), which merge the hidden state with the input via the Multiplicative Integration operation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a measure of long-term memory and prove that deep recurrent networks are much better fit to model long-term temporal dependencies than shallow ones.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, deep networks, correlations, long term memory, tensor networks, tensor analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryG6xZ-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryG6xZ-RZ">
          DLVM: A modern compiler infrastructure for deep learning systems
        </a>
        
          <a href="https://openreview.net/pdf?id=ryG6xZ-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xwei12%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xwei12@illinois.edu">Richard Wei</a>, <a href="https://openreview.net/profile?email=lanes%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lanes@illinois.edu">Lane Schwartz</a>, <a href="https://openreview.net/profile?email=vadve%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vadve@illinois.edu">Vikram Adve</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryG6xZ-RZ-details-386" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryG6xZ-RZ-details-386"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning software demands reliability and performance. However, many of the existing deep learning frameworks are software libraries that act as an unsafe DSL in Python and a computation graph interpreter. We present DLVM, a design and implementation of a compiler infrastructure with a linear algebra intermediate representation, algorithmic differentiation by adjoint code generation, domain- specific optimizations and a code generator targeting GPU via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM is more modular and more generic than existing deep learning compiler frameworks, and supports tensor DSLs with high expressivity. With our prototypical staged DSL embedded in Swift, we argue that the DLVM system enables a form of modular, safe and performant frameworks for deep learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a novel compiler infrastructure that addresses shortcomings of existing deep learning frameworks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, automatic differentiation, algorithmic differentiation, domain specific languages, neural networks, programming languages, DSLs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkGJUXb0-">
      <h4>
        <a href="https://openreview.net/forum?id=HkGJUXb0-">
          Learning Efficient Tensor Representations with Ring Structure Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HkGJUXb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=qibin.zhao%40riken.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="qibin.zhao@riken.jp">Qibin Zhao</a>, <a href="https://openreview.net/profile?email=sugi%40k.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="sugi@k.u-tokyo.ac.jp">Masashi Sugiyama</a>, <a href="https://openreview.net/profile?email=longhao.yuan%40riken.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="longhao.yuan@riken.jp">Longhao Yuan</a>, <a href="https://openreview.net/profile?email=a.cichocki%40riken.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.cichocki@riken.jp">Andrzej Cichocki</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkGJUXb0--details-106" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkGJUXb0--details-106"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">\emph{Tensor train (TT) decomposition} is a powerful representation for high-order tensors, which has been successfully applied to various machine learning tasks in recent years.  In this paper, we propose a more generalized tensor decomposition with ring structure network  by employing circular multilinear products over a sequence of lower-order core tensors, which is termed as TR representation. Several learning algorithms including blockwise ALS  with adaptive tensor ranks and  SGD  with high scalability are presented. Furthermore, the mathematical properties are investigated, which enables us to perform basic algebra operations in a computationally efficiently way by using TR representations. Experimental results on synthetic signals and real-world datasets demonstrate the effectiveness of TR model and the learning algorithms. In particular, we show that  the structure information and high-order correlations within a 2D image can be captured efficiently by employing tensorization and TR representation. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Tensor Decomposition, Tensor Networks, Stochastic Gradient Descent</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJypUGZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=BJypUGZ0Z">
          Accelerating Neural Architecture Search using Performance Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=BJypUGZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bowen%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bowen@mit.edu">Bowen Baker*</a>, <a href="https://openreview.net/profile?email=otkrist%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="otkrist@mit.edu">Otkrist Gupta*</a>, <a href="https://openreview.net/profile?email=raskar%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="raskar@mit.edu">Ramesh Raskar</a>, <a href="https://openreview.net/profile?email=naik%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="naik@mit.edu">Nikhil Naik</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJypUGZ0Z-details-323" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJypUGZ0Z-details-323"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Methods for neural network hyperparameter optimization and meta-modeling are computationally expensive due to the need to train a large number of model configurations. In this paper, we show that standard frequentist regression models can predict the final performance of partially trained model configurations using features based on network architectures, hyperparameters, and time series validation performance data. We empirically show that our performance prediction models are much more effective than prominent Bayesian counterparts, are simpler to implement, and are faster to train. Our models can predict final performance in both visual classification and language modeling domains, are effective for predicting performance of drastically varying model architectures, and can even generalize between model classes. Using these prediction models, we also propose an early stopping method for hyperparameter optimization and meta-modeling, which obtains a speedup of a factor up to 6x in both hyperparameter optimization and meta-modeling. Finally, we empirically show that our early stopping method can be seamlessly incorporated into both reinforcement learning-based architecture selection algorithms and bandit based search methods. Through extensive experimentation, we empirically show our performance prediction models and early stopping algorithm are state-of-the-art in terms of prediction accuracy and speedup achieved while still identifying the optimal model configurations.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkOb1Fl0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SkOb1Fl0Z">
          A Flexible Approach to Automated RNN Architecture Generation
        </a>
        
          <a href="https://openreview.net/pdf?id=SkOb1Fl0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=msch%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="msch@mit.edu">Martin Schrimpf</a>, <a href="https://openreview.net/profile?email=smerity%40smerity.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="smerity@smerity.com">Stephen Merity</a>, <a href="https://openreview.net/profile?email=james.bradbury%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.bradbury@salesforce.com">James Bradbury</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkOb1Fl0Z-details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkOb1Fl0Z-details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The process of designing neural architectures requires expert knowledge and extensive trial and error.
      While automated architecture search may simplify these requirements, the recurrent neural network (RNN) architectures generated by existing methods are limited in both flexibility and components.
      We propose a domain-specific language (DSL) for use in automated architecture search which can produce novel RNNs of arbitrary depth and width.
      The DSL is flexible enough to define standard architectures such as the Gated Recurrent Unit and Long Short Term Memory and allows the introduction of non-standard RNN components such as trigonometric curves and layer normalization.  Using two different candidate generation techniques, random search with a ranking function and reinforcement learning, 
      we explore the novel architectures produced by the RNN DSL for language modeling and machine translation domains.
      The resulting architectures do not follow human intuition yet perform well on their targeted tasks, suggesting the space of usable RNN architectures is far larger than previously assumed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We define a flexible DSL for RNN architecture generation that allows RNNs of varying size and complexity and propose a ranking function that represents RNNs as recursive neural networks, simulating their performance to decide on the most promising architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, architecture search, ranking function, recurrent neural networks, recursive neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SySaJ0xCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SySaJ0xCZ">
          Simple and efficient architecture search for Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SySaJ0xCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thomas.elsken%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.elsken@de.bosch.com">Thomas Elsken</a>, <a href="https://openreview.net/profile?email=janhendrik.metzen%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="janhendrik.metzen@de.bosch.com">Jan Hendrik Metzen</a>, <a href="https://openreview.net/profile?email=fh%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="fh@cs.uni-freiburg.de">Frank Hutter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SySaJ0xCZ-details-72" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SySaJ0xCZ-details-72"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks have recently had a lot of success for many tasks. However, neural
      network architectures that perform well are still typically designed manually
      by experts in a cumbersome trial-and-error process. We propose a new method
      to automatically search for well-performing CNN architectures based on a simple
      hill climbing procedure whose operators apply network morphisms, followed
      by short optimization runs by cosine annealing. Surprisingly, this simple method
      yields competitive results, despite only requiring resources in the same order of
      magnitude as training a single network. E.g., on CIFAR-10, our method designs
      and trains networks with an error rate below 6% in only 12 hours on a single GPU;
      training for one day reduces this error further, to almost 5%.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a simple and efficent method for architecture search for convolutional neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Hyperparameter Optimization, Architecture Search, Convolutional Neural Networks, Network Morphism, Network Transformation, SGDR, Cosine annealing, hill climbing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkCV_W-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=BkCV_W-AZ">
          Regret Minimization for Partially Observable Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BkCV_W-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=phj%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="phj@eecs.berkeley.edu">Peter H. Jin</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>, <a href="https://openreview.net/profile?email=keutzer%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="keutzer@berkeley.edu">Kurt Keutzer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkCV_W-AZ-details-51" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkCV_W-AZ-details-51"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategies from raw image pixels. However, algorithms that estimate state and state-action value functions typically assume a fully observed state and must compensate for partial or non-Markovian observations by using finite-length frame-history observations or recurrent networks. In this work, we propose a new deep reinforcement learning algorithm based on counterfactual regret minimization that iteratively updates an approximation to a cumulative clipped advantage function and is robust to partially observed state. We demonstrate that on several partially observed reinforcement learning tasks, this new class of algorithms can substantially outperform strong baseline methods: on Pong with single-frame observations, and on the challenging Doom (ViZDoom) and Minecraft (Malmö) first-person navigation benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Advantage-based regret minimization is a new deep reinforcement learning algorithm that is particularly effective on partially observable tasks, such as 1st person navigation in Doom and Minecraft.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkEfPeZRb">
      <h4>
        <a href="https://openreview.net/forum?id=rkEfPeZRb">
          Variance-based Gradient Compression for Efficient Distributed Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rkEfPeZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tsuzuku%40ms.k.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsuzuku@ms.k.u-tokyo.ac.jp">Yusuke Tsuzuku</a>, <a href="https://openreview.net/profile?email=imachi%40preferred.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="imachi@preferred.jp">Hiroto Imachi</a>, <a href="https://openreview.net/profile?email=akiba%40preferred.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="akiba@preferred.jp">Takuya Akiba</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkEfPeZRb-details-479" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkEfPeZRb-details-479"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Due to the substantial computational cost, training state-of-the-art deep neural networks for large-scale datasets often requires distributed training using multiple computation workers. However, by nature, workers need to frequently communicate gradients, causing severe bottlenecks, especially on lower bandwidth connections. A few methods have been proposed to compress gradient for efficient communication, but they either suffer a low compression ratio or significantly harm the resulting model accuracy, particularly when applied to convolutional neural networks. To address these issues, we propose a method to reduce the communication overhead of distributed deep learning. Our key observation is that gradient updates can be delayed until an unambiguous (high amplitude, low variance) gradient has been calculated. We also present an efficient algorithm to compute the variance and prove that it can be obtained with negligible additional cost. We experimentally show that our method can achieve very high compression ratio while maintaining the result model accuracy. We also analyze the efficiency using computation and communication cost models and provide the evidence that this method enables distributed deep learning for many scenarios with commodity environments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new algorithm to reduce the communication overhead of distributed deep learning by distinguishing ‘unambiguous’ gradients.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed deep learning, gradient compression, collective communication, data parallel distributed sgd, image classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyVOjfbRb">
      <h4>
        <a href="https://openreview.net/forum?id=SyVOjfbRb">
          LSH-SAMPLING BREAKS THE COMPUTATIONAL CHICKEN-AND-EGG LOOP IN ADAPTIVE STOCHASTIC GRADIENT ESTIMATION
        </a>
        
          <a href="https://openreview.net/pdf?id=SyVOjfbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=beidi.chen%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="beidi.chen@rice.edu">Beidi Chen</a>, <a href="https://openreview.net/profile?email=yingchen.xu%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yingchen.xu@rice.edu">Yingchen Xu</a>, <a href="https://openreview.net/profile?email=anshumali%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anshumali@rice.edu">Anshumali Shrivastava</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyVOjfbRb-details-190" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyVOjfbRb-details-190"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Stochastic Gradient Descent or SGD is the most popular optimization algorithm for large-scale problems. SGD estimates the gradient by uniform sampling with sample size one. There have been several other works that suggest faster epoch wise convergence by using weighted non-uniform sampling for better gradient estimates. Unfortunately, the per-iteration cost of maintaining this adaptive distribution for gradient estimation is more than calculating the full gradient. As a result, the false impression of faster convergence in iterations leads to slower convergence in time, which we call a chicken-and-egg loop. In this paper, we break this barrier by providing the first demonstration of a sampling scheme, which leads to superior gradient estimation, while keeping the sampling cost per iteration similar to that of the uniform sampling. Such an algorithm is possible due to the sampling view of Locality Sensitive Hashing (LSH), which came to light recently. As a consequence of superior and fast estimation, we reduce the running time of all existing gradient descent algorithms. We demonstrate the benefits of our proposal on both SGD and AdaGrad.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We improve the running of all existing gradient descent algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Stochastic Gradient Descent, Optimization, Sampling, Estimation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJjquybCW">
      <h4>
        <a href="https://openreview.net/forum?id=BJjquybCW">
          The loss surface and expressivity of deep convolutional neural networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJjquybCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=quynh%40cs.uni-saarland.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="quynh@cs.uni-saarland.de">Quynh Nguyen</a>, <a href="https://openreview.net/profile?email=hein%40cs.uni-saarland.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="hein@cs.uni-saarland.de">Matthias Hein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJjquybCW-details-322" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJjquybCW-details-322"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We analyze the expressiveness and loss surface of practical deep convolutional
      neural networks (CNNs) with shared weights and max pooling layers. We show
      that such CNNs produce linearly independent features at a “wide” layer which
      has more neurons than the number of training samples. This condition holds e.g.
      for the VGG network. Furthermore, we provide for such wide CNNs necessary
      and sufficient conditions for global minima with zero training error. For the case
      where the wide layer is followed by a fully connected layer we show that almost
      every critical point of the empirical loss is a global minimum with zero training
      error. Our analysis suggests that both depth and width are very important in deep
      learning. While depth brings more representational power and allows the network
      to learn high level features, width smoothes the optimization landscape of the
      loss function in the sense that a sufficiently wide network has a well-behaved loss
      surface with almost no bad local minima.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">convolutional neural networks, loss surface, expressivity, critical point, global minima, linear separability</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyfiiMZA-">
      <h4>
        <a href="https://openreview.net/forum?id=SyfiiMZA-">
          Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SyfiiMZA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cbschaff%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbschaff@ttic.edu">Charles Schaff</a>, <a href="https://openreview.net/profile?email=dyunis%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dyunis@uchicago.edu">David Yunis</a>, <a href="https://openreview.net/profile?email=ayan%40wustl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ayan@wustl.edu">Ayan Chakrabarti</a>, <a href="https://openreview.net/profile?email=mwalter%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mwalter@ttic.edu">Matthew R. Walter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyfiiMZA--details-84" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyfiiMZA--details-84"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The physical design of a robot and the policy that controls its motion are inherently coupled. However, existing approaches largely ignore this coupling, instead choosing to alternate between separate design and control phases, which requires expert intuition throughout and risks convergence to suboptimal designs. In this work, we propose a method that jointly optimizes over the physical design of a robot and the corresponding control policy in a model-free fashion, without any need for expert supervision. Given an arbitrary robot morphology, our method maintains a distribution over the design parameters and uses reinforcement learning to train a neural network controller. Throughout training, we refine the robot distribution to maximize the expected reward. This results in an assignment to the robot parameters and neural network policy that are jointly optimal. We evaluate our approach in the context of legged locomotion, and demonstrate that it discovers novel robot designs and walking gaits for several different morphologies, achieving performance comparable to or better than that of hand-crafted designs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Use deep reinforcement learning to design the physical attributes of a robot jointly with a control policy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">robot locomotion, reinforcement learning, policy gradients, physical design, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJZ2Mf-0-">
      <h4>
        <a href="https://openreview.net/forum?id=SJZ2Mf-0-">
          Adaptive Memory Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJZ2Mf-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=li.daniel%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="li.daniel@berkeley.edu">Daniel Li</a>, <a href="https://openreview.net/profile?email=asim%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="asim@nec-labs.com">Asim Kadav</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJZ2Mf-0--details-345" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJZ2Mf-0--details-345"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Real-world Question Answering (QA) tasks consist of thousands of words that often represent many facts and entities. Existing models based on LSTMs require a large number of parameters to support external memory and do not generalize well for long sequence inputs. Memory networks attempt to address these limitations by storing information to an external memory module but must examine all inputs in the memory. Hence, for longer sequence inputs the intermediate memory components proportionally scale in size resulting in poor inference times and high computation costs.
      
      In this paper, we present Adaptive Memory Networks (AMN) that process input question pairs to dynamically construct a network architecture optimized for lower inference times. During inference, AMN parses input text into entities within different memory slots. However, distinct from previous approaches, AMN is a dynamic network architecture that creates variable numbers of memory banks weighted by question relevance. Thus, the decoder can select a variable number of memory banks to construct an answer using fewer banks, creating a runtime trade-off between accuracy and speed. 
      
      AMN is enabled by first, a novel bank controller that makes discrete decisions with high accuracy and second, the capabilities of a dynamic framework (such as PyTorch) that allow for dynamic network sizing and efficient variable mini-batching. In our results, we demonstrate that our model learns to construct a varying number of memory banks based on task complexity and achieves faster inference times for standard bAbI tasks, and modified bAbI tasks. We achieve state of the art accuracy over these tasks with an average 48% lower entities are examined during inference.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Memory networks with faster inference</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Memory Networks, Dynamic Networks, Faster Inference, Reasoning, QA</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJyfrl-0b">
      <h4>
        <a href="https://openreview.net/forum?id=SJyfrl-0b">
          Fast Node Embeddings: Learning Ego-Centric Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=SJyfrl-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tpimentel%40dcc.ufmg.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="tpimentel@dcc.ufmg.br">Tiago Pimentel</a>, <a href="https://openreview.net/profile?email=adrianov%40dcc.ufmg.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="adrianov@dcc.ufmg.br">Adriano Veloso</a>, <a href="https://openreview.net/profile?email=nivio%40dcc.ufmg.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="nivio@dcc.ufmg.br">Nivio Ziviani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJyfrl-0b-details-992" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJyfrl-0b-details-992"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Representation learning is one of the foundations of Deep Learning and allowed important improvements on several Machine Learning tasks, such as Neural Machine Translation, Question Answering and Speech Recognition. Recent works have proposed new methods for learning representations for nodes and edges in graphs. Several of these methods are based on the SkipGram algorithm, and they usually process a large number of multi-hop neighbors in order to produce the context from which node representations are learned. In this paper, we propose an effective and also efficient method for generating node embeddings in graphs that employs a restricted number of permutations over the immediate neighborhood of a node as context to generate its representation, thus ego-centric representations. We present a thorough evaluation showing that our method outperforms state-of-the-art methods in six different datasets related to the problems of link prediction and node classification, being one to three orders of magnitude faster than baselines when generating node embeddings for very large graphs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A faster method for generating node embeddings that employs a number of permutations over a node's immediate neighborhood as context to generate its representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Graph, Node Embeddings, Distributed Representations, Learning Representations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1LXVnxRb">
      <h4>
        <a href="https://openreview.net/forum?id=S1LXVnxRb">
          Cross-Corpus Training with TreeLSTM for the Extraction of Biomedical Relationships from Text
        </a>
        
          <a href="https://openreview.net/pdf?id=S1LXVnxRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joel.legrand%40loria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="joel.legrand@loria.fr">Legrand Joël</a>, <a href="https://openreview.net/profile?email=yannick.toussaint%40loria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="yannick.toussaint@loria.fr">Yannick Toussaint</a>, <a href="https://openreview.net/profile?email=chedy.raissi%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="chedy.raissi@inria.fr">Chedy Raïssi</a>, <a href="https://openreview.net/profile?email=adrien.coulet%40loria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="adrien.coulet@loria.fr">Adrien Coulet</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1LXVnxRb-details-371" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1LXVnxRb-details-371"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A bottleneck problem in machine learning-based relationship extraction (RE) algorithms, and particularly of deep learning-based ones, is the availability of training data in the form of annotated corpora. For specific domains, such as biomedicine, the long time and high expertise required for the development of manually annotated corpora explain that most of the existing one are relatively small (i.e., hundreds of sentences). Beside, larger corpora focusing on general or domain-specific relationships (such as citizenship or drug-drug interactions) have been developed. In this paper, we study how large annotated corpora developed for alternative tasks may improve the performances on biomedicine related tasks, for which few annotated resources are available. We experiment two deep learning-based models to extract relationships from biomedical texts with high performance. The first one combine locally extracted features using a Convolutional Neural Network (CNN) model, while the second exploit the syntactic structure of sentences using a Recursive Neural Network (RNN) architecture. Our experiments show that, contrary to the former, the latter benefits from a cross-corpus learning strategy to improve the performance of relationship extraction tasks. Indeed our approach leads to the best published performances for two biomedical RE tasks, and to state-of-the-art results for two other biomedical RE tasks, for which few annotated resources are available (less than 400 manually annotated sentences). This may be particularly impactful in specialized domains in which training resources are scarce, because they would benefit from the training data of other domains for which large annotated corpora does exist. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Relationships Extraction, Deep Learning, TreeLSTM, NLP</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkaT3zWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkaT3zWCZ">
          Building Generalizable Agents with a Realistic and Rich 3D Environment
        </a>
        
          <a href="https://openreview.net/pdf?id=rkaT3zWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jxwuyi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jxwuyi@gmail.com">Yi Wu</a>, <a href="https://openreview.net/profile?email=ppwwyyxxc%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ppwwyyxxc@gmail.com">Yuxin Wu</a>, <a href="https://openreview.net/profile?email=georgia.gkioxari%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="georgia.gkioxari@gmail.com">Georgia Gkioxari</a>, <a href="https://openreview.net/profile?email=yuandong.tian%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuandong.tian@gmail.com">Yuandong Tian</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkaT3zWCZ-details-49" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkaT3zWCZ-details-49"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Teaching an agent to navigate in an unseen 3D environment is a challenging task, even in the event of simulated environments. To generalize to unseen environments, an agent needs to be robust to low-level variations (e.g. color, texture, object changes), and also high-level variations (e.g. layout changes of the environment). To improve overall generalization, all types of variations in the environment have to be taken under consideration via different level of data augmentation steps. To this end, we propose House3D, a rich, extensible and efficient environment that contains 45,622 human-designed 3D scenes of visually realistic houses, ranging from single-room studios to multi-storied houses, equipped with a diverse set of fully labeled 3D objects, textures and scene layouts, based on the SUNCG dataset (Song et al., 2017). The diversity in House3D opens the door towards scene-level augmentation, while the label-rich nature of House3D enables us to inject pixel- &amp; task-level augmentations such as domain randomization (Tobin et al., 2017) and multi-task training. Using a subset of houses in House3D, we show that reinforcement learning agents trained with an enhancement of different levels of augmentations perform much better in unseen environments than our baselines with raw RGB input by over 8% in terms of navigation success rate. House3D is publicly available at http://github.com/facebookresearch/House3D.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, generalization, navigation, 3D scenes</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
</ul>
</div>
    <div role="tabpanel" class="tab-pane fade  " id="rejected-papers">
      
    <ul class="list-unstyled submissions-list">
    <li class="note " data-id="HyXNCZbCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HyXNCZbCZ">
          Hierarchical Adversarially Learned Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=HyXNCZbCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ishmael.belghazi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ishmael.belghazi@gmail.com">Mohamed Ishmael Belghazi</a>, <a href="https://openreview.net/profile?email=rajsai24%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rajsai24@gmail.com">Sai Rajeswar</a>, <a href="https://openreview.net/profile?email=oli.mastro%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oli.mastro@gmail.com">Olivier Mastropietro</a>, <a href="https://openreview.net/profile?email=negar.rostamzadeh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="negar.rostamzadeh@gmail.com">Negar Rostamzadeh</a>, <a href="https://openreview.net/profile?email=jovana.mitrovic%40spc.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jovana.mitrovic@spc.ox.ac.uk">Jovana Mitrovic</a>, <a href="https://openreview.net/profile?email=aaron.courville%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaron.courville@gmail.com">Aaron Courville</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyXNCZbCZ-details-538" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyXNCZbCZ-details-538"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel hierarchical generative model with a simple Markovian structure and a corresponding inference model. Both the generative and inference model are trained using the adversarial learning paradigm. We demonstrate that the hierarchical structure supports the learning of progressively more abstract representations as well as providing semantically meaningful reconstructions with different levels of fidelity. Furthermore, we show that minimizing the Jensen-Shanon divergence between the generative and inference network is enough to minimize the reconstruction error.  The resulting semantically meaningful hierarchical latent structure discovery is exemplified on the CelebA dataset.  There, we show that the features learned by our model in an unsupervised way outperform the best handcrafted features. Furthermore, the extracted features remain competitive when compared to several recent deep supervised approaches on an attribute prediction task on CelebA. Finally, we leverage the model's inference network to achieve state-of-the-art performance on a semi-supervised variant of the MNIST digit classification task. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adversarially trained hierarchical generative model with robust and semantically learned latent representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative, hierarchical, unsupervised, semisupervised, latent, ALI, GAN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1CNpYg0-">
      <h4>
        <a href="https://openreview.net/forum?id=B1CNpYg0-">
          Learning to Compute Word Embeddings On the Fly
        </a>
        
          <a href="https://openreview.net/pdf?id=B1CNpYg0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dimabgv%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimabgv@gmail.com">Dzmitry Bahdanau</a>, <a href="https://openreview.net/profile?email=bosc.tom%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bosc.tom@gmail.com">Tom Bosc</a>, <a href="https://openreview.net/profile?email=staszek.jastrzebski%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="staszek.jastrzebski@gmail.com">Stanisław Jastrzębski</a>, <a href="https://openreview.net/profile?email=etg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="etg@google.com">Edward Grefenstette</a>, <a href="https://openreview.net/profile?email=pascal.vincent%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="pascal.vincent@umontreal.ca">Pascal Vincent</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1CNpYg0--details-82" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1CNpYg0--details-82"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Words in natural language follow a Zipfian distribution whereby some words are frequent but most are rare. Learning representations for words in the ``long tail'' of this distribution requires enormous amounts of data. 
      Representations of rare words trained directly on end tasks are usually poor, requiring us to pre-train embeddings on external data, or treat all rare words as out-of-vocabulary words with a unique representation. We provide a method for predicting embeddings of rare words on the fly from small amounts of auxiliary data with a network trained end-to-end for the downstream task. We show that this improves results against baselines where embeddings are trained on the end task for reading comprehension, recognizing textual entailment and language modeling.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a method to deal with rare words by computing their embedding from definitions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">NLU, word embeddings, representation learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJvu-GW0b">
      <h4>
        <a href="https://openreview.net/forum?id=SJvu-GW0b">
          Graph2Seq: Scalable Learning Dynamics for Graphs
        </a>
        
          <a href="https://openreview.net/pdf?id=SJvu-GW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bjjvnkt%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bjjvnkt@csail.mit.edu">Shaileshh Bojja Venkatakrishnan</a>, <a href="https://openreview.net/profile?email=alizadeh%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alizadeh@csail.mit.edu">Mohammad Alizadeh</a>, <a href="https://openreview.net/profile?email=pramodv%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pramodv@illinois.edu">Pramod Viswanath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJvu-GW0b-details-302" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJvu-GW0b-details-302"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks are increasingly used as a general purpose approach to learning algorithms over graph structured data. However, techniques for representing graphs as real-valued vectors are still in their infancy. Recent works have proposed several approaches (e.g., graph convolutional networks), but as we show in this paper, these methods have difficulty generalizing to large graphs. In this paper we propose Graph2Seq, an embedding framework that represents graphs as an infinite time-series. By not limiting the representation to a fixed dimension, Graph2Seq naturally scales to graphs of arbitrary size. Moreover, through analysis of a formal computational model we show that an unbounded sequence is necessary for scalability. Graph2Seq is also reversible, allowing full recovery of the graph structure from the sequence. Experimental evaluations of Graph2Seq on a variety of combinatorial optimization problems show strong generalization and strict improvement over state of the art. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJv4XWZA-">
      <h4>
        <a href="https://openreview.net/forum?id=rJv4XWZA-">
          Generating Differentially Private Datasets Using GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=rJv4XWZA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aleksei.triastcyn%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aleksei.triastcyn@epfl.ch">Aleksei Triastcyn</a>, <a href="https://openreview.net/profile?email=boi.faltings%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="boi.faltings@epfl.ch">Boi Faltings</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJv4XWZA--details-760" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJv4XWZA--details-760"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we present a technique for generating artificial datasets that retain statistical properties of the real data while providing differential privacy guarantees with respect to this data. We include a Gaussian noise layer in the discriminator of a generative adversarial network to make the output and the gradients differentially private with respect to the training data, and then use the generator component to synthesise privacy-preserving artificial dataset. Our experiments show that under a reasonably small privacy budget we are able to generate data of high quality and successfully train machine learning models on this artificial data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Train GANs with differential privacy to generate artificial privacy-preserving datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, differential privacy, synthetic data</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk7cHb-C-">
      <h4>
        <a href="https://openreview.net/forum?id=Sk7cHb-C-">
          Representing dynamically: An active process for describing sequential data
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk7cHb-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=j.s.olier.jauregui%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.s.olier.jauregui@tue.nl">Juan Sebastian Olier</a>, <a href="https://openreview.net/profile?email=e.i.barakova%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.i.barakova@tue.nl">Emilia Barakova</a>, <a href="https://openreview.net/profile?email=g.w.m.rauterberg%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="g.w.m.rauterberg@tue.nl">Matthias Rauterberg</a>, <a href="https://openreview.net/profile?email=carlo.regazzoni%40unige.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="carlo.regazzoni@unige.it">Carlo Regazzoni</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk7cHb-C--details-939" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk7cHb-C--details-939"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.
      The method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A method that build representations of sequential data and its dynamics through generative models with an active process</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Models, Latent representations, Predictive coding, Recurrent networks, Sequential data</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkS3fnl0W">
      <h4>
        <a href="https://openreview.net/forum?id=BkS3fnl0W">
          Semi-supervised Outlier Detection using Generative And Adversary Framework
        </a>
        
          <a href="https://openreview.net/pdf?id=BkS3fnl0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jindong.gu%40siemens.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jindong.gu@siemens.com">Jindong Gu</a>, <a href="https://openreview.net/profile?email=schubert%40dbs.ifi.lmu.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="schubert@dbs.ifi.lmu.de">Matthias Schubert</a>, <a href="https://openreview.net/profile?email=volker.tresp%40siemens.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="volker.tresp@siemens.com">Volker Tresp</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkS3fnl0W-details-438" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkS3fnl0W-details-438"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In a conventional binary/multi-class classification task, the decision boundary is supported by data from two or more classes. However, in one-class classification task, only data from one class are available. To build an robust outlier detector using only data from a positive class, we propose a corrupted GAN(CorGAN), a deep convolutional Generative Adversary Network requiring no convergence during training. In the adversarial process of training CorGAN, the Generator is supposed to generate outlier samples for negative class, and the Discriminator as an one-class classifier is trained to distinguish data from training datasets (i.e. positive class) and generated data from the Generator (i.e. negative class). To improve the performance of the Discriminator (one-class classifier), we also propose a lot of techniques to improve the performance of the model. The proposed model outperforms the traditional method PCA + PSVM and the solution based on Autoencoder.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Semi-supervised Learning, Generative And Adversary Framework, One-class classification, Outlier detection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkinqfbAb">
      <h4>
        <a href="https://openreview.net/forum?id=HkinqfbAb">
          Automatic Parameter Tying in Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HkinqfbAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yibo.yang%40utdallas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yibo.yang@utdallas.edu">Yibo Yang</a>, <a href="https://openreview.net/profile?email=nicholas.ruozzi%40utdallas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicholas.ruozzi@utdallas.edu">Nicholas Ruozzi</a>, <a href="https://openreview.net/profile?email=vgogate%40hlt.utdallas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vgogate@hlt.utdallas.edu">Vibhav Gogate</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkinqfbAb-details-338" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkinqfbAb-details-338"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recently, there has been growing interest in methods that perform neural network compression, namely techniques that attempt to substantially reduce the size of a neural network without significant reduction in performance. However, most existing methods are post-processing approaches in that they take a learned neural network as input and output a compressed network by either forcing several parameters to take the same value (parameter tying via quantization) or pruning irrelevant edges (pruning) or both. In this paper, we propose a novel algorithm that jointly learns and compresses a neural network. The key idea in our approach is to change the optimization criteria by adding $k$ independent Gaussian priors over the parameters and a sparsity penalty. We show that our approach is easy to implement using existing neural network libraries, generalizes L1 and L2 regularization and elegantly enforces parameter tying as well as pruning constraints. Experimentally, we demonstrate that our new algorithm yields state-of-the-art compression on several standard benchmarks with minimal loss in accuracy while requiring little to no hyperparameter tuning as compared with related, competing approaches. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A k-means prior combined with L1 regularization yields state-of-the-art compression results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural network, quantization, compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H15RufWAW">
      <h4>
        <a href="https://openreview.net/forum?id=H15RufWAW">
          GraphGAN: Generating Graphs via Random Walks
        </a>
        
          <a href="https://openreview.net/pdf?id=H15RufWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=a.bojchevski%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.bojchevski@in.tum.de">Aleksandar Bojchevski</a>, <a href="https://openreview.net/profile?email=shchur%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="shchur@in.tum.de">Oleksandr Shchur</a>, <a href="https://openreview.net/profile?email=daniel.zuegner%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.zuegner@gmail.com">Daniel Zügner</a>, <a href="https://openreview.net/profile?email=guennemann%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="guennemann@in.tum.de">Stephan Günnemann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H15RufWAW-details-224" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H15RufWAW-details-224"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose GraphGAN - the first implicit generative model for graphs that enables to mimic real-world networks.
      We pose the problem of graph generation as learning the distribution of biased random walks over a single input graph.
      Our model is based on a stochastic neural network that generates discrete output samples, and is trained using the Wasserstein GAN objective. GraphGAN enables us to generate sibling graphs, which have similar properties yet are not exact replicas of the original graph. Moreover, GraphGAN learns a semantic mapping from the latent input space to the generated graph's properties. We discover that sampling from certain regions of the latent space leads to varying properties of the output graphs, with smooth transitions between them. Strong generalization properties of GraphGAN are highlighted by its competitive performance in link prediction as well as promising results on node classification, even though not specifically trained for these tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using GANs to generate graphs via random walks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, graphs, random walks, implicit generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJiaRbk0-">
      <h4>
        <a href="https://openreview.net/forum?id=rJiaRbk0-">
          Towards Binary-Valued Gates for Robust LSTM Training 
        </a>
        
          <a href="https://openreview.net/pdf?id=rJiaRbk0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lizhuohan%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lizhuohan@pku.edu.cn">Zhuohan Li</a>, <a href="https://openreview.net/profile?email=di_he%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="di_he@pku.edu.cn">Di He</a>, <a href="https://openreview.net/profile?email=fetia%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fetia@microsoft.com">Fei Tian</a>, <a href="https://openreview.net/profile?email=wche%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wche@microsoft.com">Wei Chen</a>, <a href="https://openreview.net/profile?email=taoqin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taoqin@microsoft.com">Tao Qin</a>, <a href="https://openreview.net/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>, <a href="https://openreview.net/profile?email=tyliu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tyliu@microsoft.com">Tie-Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 31 May 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJiaRbk0--details-774" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJiaRbk0--details-774"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Long Short-Term Memory (LSTM) is one of the most widely used recurrent structures in sequence modeling. Its goal is to use gates to control the information flow (e.g., whether to skip some information/transformation or not) in the recurrent computations, although its practical implementation based on soft gates only partially achieves this goal and is easy to overfit. In this paper, we propose a new way for LSTM training, which pushes the values of the gates towards 0 or 1. By doing so, we can (1) better control the information flow: the gates are mostly open or closed, instead of in a middle state; and (2) avoid overfitting to certain extent: the gates operate at their flat regions, which is shown to correspond to better generalization ability. However, learning towards discrete values of the gates is generally difficult. To tackle this challenge, we leverage the recently developed Gumbel-Softmax trick from the field of variational methods, and make the model trainable with standard backpropagation. Experimental results on language modeling and machine translation show that (1) the values of the gates generated by our method are more reasonable and intuitively interpretable, and (2) our proposed method generalizes better and achieves better accuracy on test sets in all tasks. Moreover, the learnt models are not sensitive to low-precision approximation and low-rank approximation of the gate parameters due to the flat loss surface.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new algorithm for LSTM training by learning towards binary-valued gates which we shown has many nice properties.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural network, LSTM, long-short term memory network, machine translation, generalization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1h2DllAW">
      <h4>
        <a href="https://openreview.net/forum?id=r1h2DllAW">
          Discrete-Valued Neural Networks Using Variational Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=r1h2DllAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=roth%40tugraz.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="roth@tugraz.at">Wolfgang Roth</a>, <a href="https://openreview.net/profile?email=pernkopf%40tugraz.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="pernkopf@tugraz.at">Franz Pernkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1h2DllAW-details-530" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1h2DllAW-details-530"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The increasing demand for neural networks (NNs) being employed on embedded devices has led to plenty of research investigating methods for training low precision NNs. While most methods involve a quantization step, we propose a principled Bayesian approach where we first infer a distribution over a discrete weight space from which we subsequently derive hardware-friendly low precision NNs. To this end, we introduce a probabilistic forward pass to approximate the intractable variational objective that allows us to optimize over discrete-valued weight distributions for NNs with sign activation functions. In our experiments, we show that our model achieves state of the art performance on several real world data sets. In addition, the resulting models exhibit a substantial amount of sparsity that can be utilized to further reduce the computational costs for inference.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Variational Inference for infering a discrete distribution from which a low-precision neural network is derived</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">low-precision, neural networks, resource efficient, variational inference, Bayesian</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Y7OOlRZ">
      <h4>
        <a href="https://openreview.net/forum?id=S1Y7OOlRZ">
          Massively Parallel Hyperparameter Tuning
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Y7OOlRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lishal%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lishal@cs.ucla.edu">Lisha Li</a>, <a href="https://openreview.net/profile?email=jamieson%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamieson@cs.washington.edu">Kevin Jamieson</a>, <a href="https://openreview.net/profile?email=rostami%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rostami@google.com">Afshin Rostamizadeh</a>, <a href="https://openreview.net/profile?email=kgonina%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kgonina@google.com">Katya Gonina</a>, <a href="https://openreview.net/profile?email=hardt%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hardt@berkeley.edu">Moritz Hardt</a>, <a href="https://openreview.net/profile?email=brecht%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="brecht@berkeley.edu">Benjamin Recht</a>, <a href="https://openreview.net/profile?email=talwalkar%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="talwalkar@cmu.edu">Ameet Talwalkar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Y7OOlRZ-details-99" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Y7OOlRZ-details-99"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Modern machine learning models are characterized by large hyperparameter search spaces and prohibitively expensive training costs.  For such models, we cannot afford to train candidate models sequentially and wait months before finding a suitable hyperparameter configuration. Hence, we introduce the large-scale regime for parallel hyperparameter tuning, where we need to evaluate orders of magnitude more configurations than available parallel workers in a small multiple of the wall-clock time needed to train a single model.  We propose a novel hyperparameter tuning algorithm for this setting that exploits both parallelism and aggressive early-stopping techniques, building on the insights of the Hyperband algorithm.  Finally, we conduct a thorough empirical study of our algorithm on several benchmarks, including large-scale experiments with up to 500 workers.  Our results show that our proposed algorithm finds good hyperparameter settings nearly an order of magnitude faster than random search.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">parallel hyperparameter tuning, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyAbZb-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SyAbZb-0Z">
          Transfer Learning to Learn with Multitask Neural Model Search
        </a>
        
          <a href="https://openreview.net/pdf?id=SyAbZb-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=catwong%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="catwong@cs.stanford.edu">Catherine Wong</a>, <a href="https://openreview.net/profile?email=agesmundo%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="agesmundo@google.com">Andrea Gesmundo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyAbZb-0Z-details-873" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyAbZb-0Z-details-873"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning models require extensive architecture design exploration and hyperparameter optimization to perform well on a given task. The exploration of the model design space is often made by a human expert, and optimized using a combination of grid search and search heuristics over a large space of possible choices. Neural Architecture Search (NAS) is a Reinforcement Learning approach that has been proposed to automate architecture design. NAS has been successfully applied to generate Neural Networks that rival the best human-designed architectures. However, NAS requires sampling, constructing, and training hundreds to thousands of models to achieve well-performing architectures. This procedure needs to be executed from scratch for each new task. The application of NAS to a wide set of tasks currently lacks a way to transfer generalizable knowledge across tasks.
      In this paper, we present the Multitask Neural Model Search (MNMS) controller. Our goal is to learn a generalizable framework that can condition model construction on successful model searches for previously seen tasks, thus significantly speeding up the search for new tasks. We demonstrate that MNMS can conduct an automated architecture search for multiple tasks simultaneously while still learning well-performing, specialized models for each task. We then show that pre-trained MNMS controllers can transfer learning to new tasks. By leveraging knowledge from previous searches, we find that pre-trained MNMS models start from a better location in the search space and reduce search time on unseen tasks, while still discovering models that outperform published human-designed models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present Multitask Neural Model Search, a Meta-learner that can design models for multiple tasks simultaneously and transfer learning to unseen tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Learning to Learn, Meta learning, Reinforcement learning, Transfer learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyrGJYlRZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyrGJYlRZ">
          YellowFin and the Art of Momentum Tuning
        </a>
        
          <a href="https://openreview.net/pdf?id=SyrGJYlRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zjian%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zjian@cs.stanford.edu">Jian Zhang</a>, <a href="https://openreview.net/profile?email=ioannis%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ioannis@iro.umontreal.ca">Ioannis Mitliagkas</a>, <a href="https://openreview.net/profile?email=chrismre%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrismre@cs.stanford.edu">Christopher Re</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 21 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyrGJYlRZ-details-653" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyrGJYlRZ-details-653"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Hyperparameter tuning is one of the most time-consuming workloads in deep learning. State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam, reduce this labor by adaptively tuning an individual learning rate for each variable. Recently researchers have shown renewed interest in simpler methods like momentum SGD as they may yield better results. Motivated by this trend, we ask: can simple adaptive methods, based on SGD perform as well or better? We revisit the momentum SGD algorithm and show that hand-tuning a single learning rate and momentum makes it competitive with Adam. We then analyze its robustness to learning rate misspecification and objective curvature variation. Based on these insights, we design YellowFin, an automatic tuner for momentum and learning rate in SGD. YellowFin optionally uses a negative-feedback loop to compensate for the momentum dynamics in asynchronous settings on the fly. We empirically show YellowFin can converge in fewer iterations than Adam on ResNets and LSTMs for image recognition, language modeling and constituency parsing, with a speedup of up to $3.28$x in synchronous and up to $2.69$x in asynchronous settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">YellowFin is an SGD based optimizer with both momentum and learning rate adaptivity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adaptive optimizer, momentum, hyperparameter tuning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1bM1fZCW">
      <h4>
        <a href="https://openreview.net/forum?id=H1bM1fZCW">
          GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H1bM1fZCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zchen%40magicleap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zchen@magicleap.com">Zhao Chen</a>, <a href="https://openreview.net/profile?email=vbadrinarayanan%40magicleap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vbadrinarayanan@magicleap.com">Vijay Badrinarayanan</a>, <a href="https://openreview.net/profile?email=clee%40magicleap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="clee@magicleap.com">Chen-Yu Lee</a>, <a href="https://openreview.net/profile?email=arabinovich%40magicleap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arabinovich@magicleap.com">Andrew Rabinovich</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1bM1fZCW-details-825" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1bM1fZCW-details-825"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep multitask networks, in which one neural network produces multiple predictive outputs, are more scalable and often better regularized than their single-task counterparts. Such advantages can potentially lead to gains in both speed and performance, but multitask networks are also difficult to train without finding the right balance between tasks. We present a novel gradient normalization (GradNorm) technique which automatically balances the multitask loss function by directly tuning the gradients to equalize task training rates. We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting over single networks, static baselines, and other adaptive multitask loss balancing techniques. GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter $\alpha$. Thus, what was once a tedious search process which incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks. Ultimately, we hope to demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how you can boost performance in a multitask network by tuning an adaptive multitask loss function that is learned through directly balancing network gradients.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Multitask learning, computer vision, multitask loss function</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1OQukZ0-">
      <h4>
        <a href="https://openreview.net/forum?id=H1OQukZ0-">
          Online Hyper-Parameter Optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=H1OQukZ0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=damienv%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="damienv@google.com">Damien Vincent</a>, <a href="https://openreview.net/profile?email=sylvain.gelly%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sylvain.gelly@gmail.com">Sylvain Gelly</a>, <a href="https://openreview.net/profile?email=nicolas%40le-roux.name" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicolas@le-roux.name">Nicolas Le Roux</a>, <a href="https://openreview.net/profile?email=obousquet%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="obousquet@gmail.com">Olivier Bousquet</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1OQukZ0--details-165" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1OQukZ0--details-165"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose an efficient online hyperparameter optimization method which uses a joint dynamical system to evaluate the gradient with respect to the hyperparameters. While similar methods are usually limited to hyperparameters with a smooth impact on the model, we show how to apply it to the probability of dropout in neural networks. Finally, we show its effectiveness on two distinct tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An algorithm for optimizing regularization hyper-parameters during training</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hyper-parameters, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyjjD1WRb">
      <h4>
        <a href="https://openreview.net/forum?id=SyjjD1WRb">
          Evolutionary Expectation Maximization for Generative Models with Binary Latents
        </a>
        
          <a href="https://openreview.net/pdf?id=SyjjD1WRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=enrico.guiraud%40cern.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="enrico.guiraud@cern.ch">Enrico Guiraud</a>, <a href="https://openreview.net/profile?email=jakob.heinrich.drefs%40uni-oldenburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="jakob.heinrich.drefs@uni-oldenburg.de">Jakob Drefs</a>, <a href="https://openreview.net/profile?email=joerg.luecke%40uni-oldenburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="joerg.luecke@uni-oldenburg.de">Joerg Luecke</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyjjD1WRb-details-494" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyjjD1WRb-details-494"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We establish a theoretical link between evolutionary algorithms and variational parameter optimization of probabilistic generative models with binary hidden variables.
      While the novel approach is independent of the actual generative model, here we use two such models to investigate its applicability and scalability: a noisy-OR Bayes Net (as a standard example of binary data) and Binary Sparse Coding (as a model for continuous data).
      
      Learning of probabilistic generative models is first formulated as approximate maximum likelihood optimization using variational expectation maximization (EM).
      We choose truncated posteriors as variational distributions in which discrete latent states serve as variational parameters. In the variational E-step,
      the latent states are then  
      optimized according to a tractable free-energy objective. Given a data point, we can show that evolutionary algorithms can be used for the variational optimization loop by (A)~considering the bit-vectors of the latent states as genomes of individuals, and by (B)~defining the fitness of the
      individuals as the (log) joint probabilities given by the used generative model.
      
      As a proof of concept, we apply the novel evolutionary EM approach to the optimization of the parameters of noisy-OR Bayes nets and binary sparse coding on artificial and real data (natural image patches). Using point mutations and single-point cross-over for the evolutionary algorithm, we find that scalable variational EM algorithms are obtained which efficiently improve the data likelihood. In general we believe that, with the link established here, standard as well as recent results in the field of evolutionary optimization can be leveraged to address the difficult problem of parameter optimization in generative models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present Evolutionary EM as a novel algorithm for unsupervised training of generative models with binary latent variables that intimately connects variational EM with evolutionary optimization</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised, learning, evolutionary, sparse, coding, noisyOR, BSC, EM, expectation-maximization, variational EM, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1kP7vlRb">
      <h4>
        <a href="https://openreview.net/forum?id=r1kP7vlRb">
          Toward learning better metrics for sequence generation training with policy gradient
        </a>
        
          <a href="https://openreview.net/pdf?id=r1kP7vlRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=toyama%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="toyama@weblab.t.u-tokyo.ac.jp">Joji Toyama</a>, <a href="https://openreview.net/profile?email=iwasawa%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="iwasawa@weblab.t.u-tokyo.ac.jp">Yusuke Iwasawa</a>, <a href="https://openreview.net/profile?email=nakayama%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="nakayama@weblab.t.u-tokyo.ac.jp">Kotaro Nakayama</a>, <a href="https://openreview.net/profile?email=matsuo%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="matsuo@weblab.t.u-tokyo.ac.jp">Yutaka Matsuo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1kP7vlRb-details-224" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1kP7vlRb-details-224"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Designing a metric manually for unsupervised sequence generation tasks, such as text generation, is essentially difficult. In a such situation, learning a metric of a sequence from data is one possible solution. The previous study, SeqGAN, proposed the framework for unsupervised sequence generation, in which a metric is learned from data, and a generator is optimized with regard to the learned metric with policy gradient, inspired by generative adversarial nets (GANs) and reinforcement learning. In this paper, we make two proposals to learn better metric than SeqGAN's: partial reward function and expert-based reward function training. The partial reward function is a reward function for a partial sequence of a certain length. SeqGAN employs a reward function for completed sequence only. By combining long-scale and short-scale partial reward functions, we expect a learned metric to be able to evaluate a partial correctness as well as a coherence of a sequence, as a whole. In expert-based reward function training, a reward function is trained to discriminate between an expert (or true) sequence and a fake sequence that is produced by editing an expert sequence. Expert-based reward function training is not a kind of GAN frameworks. This makes the optimization of the generator easier. We examine the effect of the partial reward function and expert-based reward function training on synthetic data and real text data, and show improvements over SeqGAN and the model trained with MLE. Specifically, whereas SeqGAN gains 0.42 improvement of NLL over MLE on synthetic data, our best model gains 3.02 improvement, and whereas SeqGAN gains 0.029 improvement of BLEU over MLE, our best model gains 0.250 improvement.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sequence generation, reinforcement learning, unsupervised learning, RNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkdU7tCaZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkdU7tCaZ">
          Dynamic Evaluation of Neural Sequence Models
        </a>
        
          <a href="https://openreview.net/pdf?id=rkdU7tCaZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ben.krause%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ben.krause@ed.ac.uk">Ben Krause</a>, <a href="https://openreview.net/profile?email=e.kahembwe%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.kahembwe@ed.ac.uk">Emmanuel Kahembwe</a>, <a href="https://openreview.net/profile?email=i.murray%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="i.murray@ed.ac.uk">Iain Murray</a>, <a href="https://openreview.net/profile?email=s.renals%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.renals@ed.ac.uk">Steve Renals</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkdU7tCaZ-details-182" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkdU7tCaZ-details-182"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present methodology for using dynamic evaluation to improve neural sequence models. Models are adapted to recent history via a gradient descent based mechanism, causing them to assign higher probabilities to re-occurring sequential patterns. Dynamic evaluation outperforms existing adaptation approaches in our comparisons. Dynamic evaluation improves the state-of-the-art word-level perplexities on the Penn Treebank and WikiText-2 datasets to 51.1 and 44.3 respectively, and the state-of-the-art character-level cross-entropies on the text8 and Hutter Prize datasets to 1.19 bits/char and 1.08 bits/char respectively.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Paper presents dynamic evaluation methodology for adaptive sequence modelling</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sequence modelling, language, recurrent neural networks, adaptation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkYibHlRb">
      <h4>
        <a href="https://openreview.net/forum?id=SkYibHlRb">
          SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SkYibHlRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xuxiaojun1005%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuxiaojun1005@gmail.com">Xiaojun Xu</a>, <a href="https://openreview.net/profile?email=liuchang%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuchang@eecs.berkeley.edu">Chang Liu</a>, <a href="https://openreview.net/profile?email=dawnsong%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong@cs.berkeley.edu">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkYibHlRb-details-660" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkYibHlRb-details-660"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the "order-matters" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.
          
      In this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1nmx5l0W">
      <h4>
        <a href="https://openreview.net/forum?id=r1nmx5l0W">
          SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=r1nmx5l0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ccchuang%40datalab.cs.nthu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="ccchuang@datalab.cs.nthu.edu.tw">Chi-Chun Chuang</a>, <a href="https://openreview.net/profile?email=zxweng%40datalab.cs.nthu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="zxweng@datalab.cs.nthu.edu.tw">Zheng-Xin Weng</a>, <a href="https://openreview.net/profile?email=shwu%40cs.nthu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="shwu@cs.nthu.edu.tw">Shan-Hung Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1nmx5l0W-details-221" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1nmx5l0W-details-221"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Variational RNNs are proposed to output “creative” sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNNs, GANs, Variational RNNs, Sketch RNNs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkUDW_lCb">
      <h4>
        <a href="https://openreview.net/forum?id=BkUDW_lCb">
          Pointing Out SQL Queries From Text
        </a>
        
          <a href="https://openreview.net/pdf?id=BkUDW_lCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=clwang%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="clwang@cs.washington.edu">Chenglong Wang</a>, <a href="https://openreview.net/profile?email=mabrocks%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mabrocks@microsoft.com">Marc Brockschmidt</a>, <a href="https://openreview.net/profile?email=risin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="risin@microsoft.com">Rishabh Singh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkUDW_lCb-details-532" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkUDW_lCb-details-532"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The digitization of data has resulted in making datasets available to millions of users in the form of relational databases and spreadsheet tables. However, a majority of these users come from diverse backgrounds and lack the programming expertise to query and analyze such tables. We present a system that allows for querying data tables using natural language questions, where the system translates the question into an executable SQL query. We use a deep sequence to sequence model in wich the decoder uses a simple type system of SQL expressions to structure the output prediction. Based on the type, the decoder either copies an output token from the input question using an attention-based copying mechanism or generates it from a fixed vocabulary. We also introduce a value-based loss function that transforms a distribution over locations to copy from into a distribution over the set of input tokens to improve training of our model. We evaluate our model on the recently released WikiSQL dataset and show that our model trained using only supervised learning significantly outperforms the current state-of-the-art Seq2SQL model that uses reinforcement learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a type-based pointer network model together with a value-based loss method to effectively train a neural model to translate natural language to SQL.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Program Synthesis, Semantic Parsing, WikiTable, SQL, Pointer Network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyTrSegCb">
      <h4>
        <a href="https://openreview.net/forum?id=HyTrSegCb">
          Achieving morphological agreement with Concorde
        </a>
        
          <a href="https://openreview.net/pdf?id=HyTrSegCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daniil.polykovskiy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniil.polykovskiy@gmail.com">Daniil Polykovskiy</a>, <a href="https://openreview.net/profile?email=d.soloviev%40corp.mail.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.soloviev@corp.mail.ru">Dmitry Soloviev</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyTrSegCb-details-342" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyTrSegCb-details-342"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural conversational models are widely used in applications like personal assistants and chat bots. These models seem to give better performance when operating on word level. However, for fusion languages like French, Russian and Polish vocabulary size sometimes become infeasible since most of the words have lots of word forms. We propose a neural network architecture for transforming normalized text into a grammatically correct one. Our model efficiently employs correspondence between normalized and target words and significantly outperforms character-level models while being 2x faster in training and 20\% faster at evaluation. We also propose a new pipeline for building conversational models: first generate a normalized answer and then transform it into a grammatically correct one using our network. The proposed pipeline gives better performance than character-level conversational models according to assessor testing.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Proposed architecture to solve morphological agreement task</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">NLP, morphology, seq2seq</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ7RBNe0-">
      <h4>
        <a href="https://openreview.net/forum?id=rJ7RBNe0-">
          Generative Models for Alignment and Data Efficiency in Language
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ7RBNe0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dustin%40cs.columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dustin@cs.columbia.edu">Dustin Tran</a>, <a href="https://openreview.net/profile?email=yburda%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yburda@openai.com">Yura Burda</a>, <a href="https://openreview.net/profile?email=ilyasu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilyasu@openai.com">Ilya Sutskever</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ7RBNe0--details-380" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ7RBNe0--details-380"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We examine how learning from unaligned data can improve both the data efficiency of supervised tasks as well as enable alignments without any supervision. For example, consider unsupervised machine translation: the input is two corpora of English and French, and the task is to translate from one language to the other but without any pairs of English and French sentences. To address this, we develop feature-matching autoencoders (FMAEs). FMAEs ensure that the marginal distribution of feature layers are preserved across forward and inverse mappings between domains. We show that FMAEs achieve state of the art for data efficiency and alignment across three tasks: text decipherment, sentiment transfer, and neural machine translation for English-to-German and English-to-French. Most compellingly, FMAEs achieve state of the art for neural translation with limited supervision, with significant BLEU score differences of up to 5.7 and 6.3 over traditional supervised models. Furthermore, on English-to-German, they outperform last year's best fully supervised models such as ByteNet (Kalchbrenner et al., 2016) while using only half as many supervised examples.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1HNP0eCW">
      <h4>
        <a href="https://openreview.net/forum?id=r1HNP0eCW">
          Estimation of cross-lingual news similarities using text-mining methods
        </a>
        
          <a href="https://openreview.net/pdf?id=r1HNP0eCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wangzhouhao94%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangzhouhao94@gmail.com">Zhouhao Wang</a>, <a href="https://openreview.net/profile?email=m2015eliu%40socsim.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="m2015eliu@socsim.org">Enda Liu</a>, <a href="https://openreview.net/profile?email=sakaji%40sys.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="sakaji@sys.t.u-tokyo.ac.jp">Hiroki Sakaji</a>, <a href="https://openreview.net/profile?email=m2015titoh%40socsim.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="m2015titoh@socsim.org">Tomoki Ito</a>, <a href="https://openreview.net/profile?email=izumi%40sys.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="izumi@sys.t.u-tokyo.ac.jp">Kiyoshi Izumi</a>, <a href="https://openreview.net/profile?email=ktsubouc%40yahoo-corp.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="ktsubouc@yahoo-corp.jp">Kota Tsubouchi</a>, <a href="https://openreview.net/profile?email=tayamash%40yahoo-corp.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="tayamash@yahoo-corp.jp">Tatsuo Yamashita</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1HNP0eCW-details-31" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1HNP0eCW-details-31"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Every second, innumerable text data, including all kinds news, reports, messages, reviews, comments, and twits have been generated on the Internet,  which is written not only in English but also in other languages such as Chinese, Japanese, French and so on. Not only SNS sites but also worldwide news agency such as Thomson Reuters News provide news reported in more than 20 languages, reflecting the significance of the multilingual information.
      In this research, by taking advantage of multi-lingual text resources provided by the Thomson Reuters News, we developed a bidirectional LSTM based method to calculate cross-lingual semantic text similarity for long text and short text respectively. Thus, users could understand the situation comprehensively, by investigating similar and related cross-lingual articles, when there an important news comes in.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryacTMZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryacTMZRZ">
          Jiffy: A Convolutional Approach to Learning Time Series Similarity
        </a>
        
          <a href="https://openreview.net/pdf?id=ryacTMZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=divyas%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="divyas@mit.edu">Divya Shanmugam</a>, <a href="https://openreview.net/profile?email=dblalock%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dblalock@mit.edu">Davis Blalock</a>, <a href="https://openreview.net/profile?email=jguttag%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jguttag@mit.edu">John Guttag</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryacTMZRZ-details-837" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryacTMZRZ-details-837"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Computing distances between examples is at the core of many learning algorithms for time series. Consequently, a great deal of work has gone into designing effective time series distance measures. We present Jiffy, a simple and scalable distance metric for multivariate time series. Our approach is to reframe the task as a representation learning problem---rather than design an elaborate distance function, we use a CNN to learn an embedding such that the Euclidean distance is effective. By aggressively max-pooling and downsampling, we are able to construct this embedding using a highly compact neural network. Experiments on a diverse set of multivariate time series datasets show that our approach consistently outperforms existing methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Jiffy is a convolutional approach to learning a distance metric  for multivariate time series that outperforms existing methods in terms of nearest-neighbor classification accuracy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Time Series, Time Series Classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryj38zWRb">
      <h4>
        <a href="https://openreview.net/forum?id=ryj38zWRb">
          Optimizing the Latent Space of Generative Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ryj38zWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bojanowski%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bojanowski@fb.com">Piotr Bojanowski</a>, <a href="https://openreview.net/profile?email=ajoulin%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajoulin@fb.com">Armand Joulin</a>, <a href="https://openreview.net/profile?email=dlp%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlp@fb.com">David Lopez-Paz</a>, <a href="https://openreview.net/profile?email=aszlam%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aszlam@fb.com">Arthur Szlam</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryj38zWRb-details-725" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryj38zWRb-details-725"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images. In most applications, GAN models share two aspects in common. On the one hand, GANs training involves solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions. On the other hand, the generator and the discriminator are parametrized in terms of deep convolutional neural networks. The goal of this paper is to disentangle the contribution of these two factors to the success of GANs. In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators without using discriminators, thus avoiding the instability of adversarial optimization problems. Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: learning from large data, synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Are GANs successful because of adversarial training or the use of ConvNets? We show a ConvNet generator trained with a simple reconstruction loss and learnable noise vectors leads many of the desirable properties of a  GAN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative models, latent variable models, image generation, generative adversarial networks, convolutional neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1ZZTfZAW">
      <h4>
        <a href="https://openreview.net/forum?id=B1ZZTfZAW">
          Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=B1ZZTfZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=stephanie.hyland%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephanie.hyland@inf.ethz.ch">Stephanie Hyland</a>, <a href="https://openreview.net/profile?email=cr_est%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="cr_est@ethz.ch">Cristóbal Esteban</a>, <a href="https://openreview.net/profile?email=raetsch%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="raetsch@inf.ethz.ch">Gunnar Rätsch</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1ZZTfZAW-details-758" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1ZZTfZAW-details-758"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Conditional recurrent GANs for real-valued medical sequences generation, showing novel evaluation approaches and an empirical privacy analysis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, medical, records, time, series, generation, privacy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkfNU2e0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SkfNU2e0Z">
          Statestream: A toolbox to explore layerwise-parallel deep neural networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkfNU2e0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=volker.fischer%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="volker.fischer@de.bosch.com">Volker Fischer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkfNU2e0Z-details-875" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkfNU2e0Z-details-875"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Building deep neural networks to control autonomous agents which have to interact in real-time with the physical world, such as robots or automotive vehicles, requires a seamless integration of time into a network’s architecture. The central question of this work is, how the temporal nature of reality should be reflected in the execution of a deep neural network and its components. Most artificial deep neural networks are partitioned into a directed graph of connected modules or layers and the layers themselves consist of elemental building blocks, such as single units. For most deep neural networks, all units of a layer are processed synchronously and in parallel, but layers themselves are processed in a sequential manner. In contrast, all elements of a biological neural network are processed in parallel. In this paper, we define a class of networks between these two extreme cases. These networks are executed in a streaming or synchronous layerwise-parallel manner, unlocking the layers of such networks for parallel processing. Compared to the standard layerwise-sequential deep networks, these new layerwise-parallel networks show a fundamentally different temporal behavior and flow of information, especially for networks with skip or recurrent connections. We argue that layerwise-parallel deep networks are better suited for future challenges of deep neural network design, such as large functional modularized and/or recurrent architectures as well as networks allocating different network capacities dependent on current stimulus and/or task complexity. We layout basic properties and discuss major challenges for layerwise-parallel networks. Additionally, we provide a toolbox to design, train, evaluate, and online-interact with layerwise-parallel networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We define a concept of layerwise model-parallel deep neural networks, for which layers operate in parallel, and provide a toolbox to design, train, evaluate, and on-line interact with these networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">model-parallel, parallelization, software platform</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyIFzx-0b">
      <h4>
        <a href="https://openreview.net/forum?id=HyIFzx-0b">
          BinaryFlex: On-the-Fly Kernel Generation in Binary Convolutional Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyIFzx-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wt262%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wt262@cornell.edu">Vincent W.-S. Tseng</a>, <a href="https://openreview.net/profile?email=sourav.bhattacharya%40nokia-bell-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sourav.bhattacharya@nokia-bell-labs.com">Sourav Bhattachary</a>, <a href="https://openreview.net/profile?email=javier.fernandezmarques%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="javier.fernandezmarques@cs.ox.ac.uk">Javier Fernández Marqués</a>, <a href="https://openreview.net/profile?email=milad.alizadeh%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="milad.alizadeh@cs.ox.ac.uk">Milad Alizadeh</a>, <a href="https://openreview.net/profile?email=eu.tong%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="eu.tong@cs.ox.ac.uk">Catherine Tong</a>, <a href="https://openreview.net/profile?email=nicholas.lane%40cs.ox.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicholas.lane@cs.ox.uk">Nicholas Donald Lane</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyIFzx-0b-details-602" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyIFzx-0b-details-602"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work we present BinaryFlex, a neural network architecture that learns weighting coefficients of predefined orthogonal binary basis instead of the conventional approach of learning directly the convolutional filters. We have demonstrated the feasibility of our approach for complex computer vision datasets such as ImageNet. Our architecture trained on ImageNet is able to achieve top-5 accuracy of 65.7% while being around 2x smaller than binary networks capable of achieving similar accuracy levels. By using deterministic basis, that can be generated on-the-fly very efficiently, our architecture offers a great deal of flexibility in memory footprint when deploying in constrained microcontroller devices.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJtfOEn6-">
      <h4>
        <a href="https://openreview.net/forum?id=SJtfOEn6-">
          ResBinNet: Residual Binary Neural Network
        </a>
        
          <a href="https://openreview.net/pdf?id=SJtfOEn6-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mghasemzadeh%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mghasemzadeh@ucsd.edu">Mohammad Ghasemzadeh</a>, <a href="https://openreview.net/profile?email=msamragh%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="msamragh@ucsd.edu">Mohammad Samragh</a>, <a href="https://openreview.net/profile?email=farinaz%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="farinaz@ucsd.edu">Farinaz Koushanfar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJtfOEn6--details-677" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJtfOEn6--details-677"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent efforts on training light-weight binary neural networks offer promising execution/memory efficiency. This paper introduces ResBinNet, which is a composition of two interlinked methodologies aiming to address the slow convergence speed and limited accuracy of binary convolutional neural networks. The first method, called residual binarization, learns a multi-level binary representation for the features within a certain neural network layer. The second method, called temperature adjustment, gradually binarizes the weights of a particular layer. The two methods jointly learn a set of soft-binarized parameters that improve the convergence rate and accuracy of binary neural networks. We corroborate the applicability and scalability of ResBinNet by implementing a prototype hardware accelerator. The accelerator is reconfigurable in terms of the numerical precision of the binarized features, offering a trade-off between runtime and inference accuracy.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Residual Binary Neural Networks significantly improve the convergence rate and inference accuracy of the binary neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Binary Neural Networks, Residual Binarization, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyFaiGbCW">
      <h4>
        <a href="https://openreview.net/forum?id=HyFaiGbCW">
          Generalization of Learning using Reservoir Computing
        </a>
        
          <a href="https://openreview.net/pdf?id=HyFaiGbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sanjukta%40umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjukta@umd.edu">Sanjukta Krishnagopal</a>, <a href="https://openreview.net/profile?email=yiannis%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiannis@cs.umd.edu">Yiannis Aloimonos</a>, <a href="https://openreview.net/profile?email=girvan%40umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="girvan@umd.edu">Michelle Girvan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyFaiGbCW-details-385" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyFaiGbCW-details-385"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We investigate the methods by which a Reservoir Computing Network (RCN) learns concepts such as 'similar' and 'different' between pairs of images using a small training dataset and generalizes these concepts to previously unseen types of data. Specifically, we show that an RCN trained to identify relationships between image-pairs drawn from a subset of digits from the MNIST database or the depth maps of subset of visual scenes from a moving camera generalizes the learned transformations to images of digits unseen during training or depth maps of different visual scenes. We infer, using Principal Component Analysis, that the high dimensional reservoir states generated from an input image pair with a specific transformation converge over time to a unique relationship. Thus, as opposed to training the entire high dimensional reservoir state, the reservoir only needs to train on these unique relationships, allowing the reservoir to perform well with very few training examples. Thus, generalization of learning to unseen images is interpretable in terms of clustering of the reservoir state onto the attractor corresponding to the transformation in reservoir space. We find that RCNs can identify and generalize linear and non-linear transformations, and combinations of transformations, naturally and be a robust and effective image classifier. Additionally, RCNs perform significantly better than state of the art neural network classification techniques such as deep Siamese Neural Networks (SNNs) in generalization tasks both on the MNIST dataset and more complex depth maps of visual scenes from a moving camera. This work helps bridge the gap between explainable machine learning and biological learning through analogies using small datasets, and points to new directions in the investigation of learning processes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Generalization of the relationships learnt between pairs of images using a small training data to previously unseen types of images using an explainable dynamical systems model, Reservoir Computing, and a biologically plausible learning technique based on analogies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generalization, Reservoir Computing, dynamical system, Siamese Neural Network, image classification, similarity, dimensionality reduction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1vCXOe0b">
      <h4>
        <a href="https://openreview.net/forum?id=H1vCXOe0b">
          Interpreting Deep Classification Models With Bayesian Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=H1vCXOe0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eleyanh%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="eleyanh@nus.edu.sg">Hanshu Yan</a>, <a href="https://openreview.net/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1vCXOe0b-details-311" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1vCXOe0b-details-311"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a novel approach to interpret a well-trained classification model through systematically investigating effects of its hidden units on prediction making. We search for the core hidden units responsible for predicting inputs as the class of interest under the generative Bayesian inference framework. We model such a process of unit selection as an Indian Buffet Process, and derive a simplified objective function via the MAP asymptotic technique. The induced binary optimization problem is efficiently solved with a continuous relaxation method by attaching a Switch Gate layer to the hidden layers of interest. The resulted interpreter model is thus end-to-end optimized via standard gradient back-propagation. Experiments are conducted with two popular deep convolutional classifiers, respectively well-trained on the MNIST dataset and the CI- FAR10 dataset. The results demonstrate that the proposed interpreter successfully finds the core hidden units most responsible for prediction making. The modified model, only with the selected units activated, can hold correct predictions at a high rate. Besides, this interpreter model is also able to extract the most informative pixels in the images by connecting a Switch Gate layer to the input layer.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ1HFlZAb">
      <h4>
        <a href="https://openreview.net/forum?id=HJ1HFlZAb">
          Evaluation of generative networks through their data augmentation capacity
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ1HFlZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=t.lesort%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="t.lesort@gmail.com">Timothée Lesort</a>, <a href="https://openreview.net/profile?email=florian.bordes%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="florian.bordes@umontreal.ca">Florian Bordes</a>, <a href="https://openreview.net/profile?email=jean-francois.goudou%40thalesgroup.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jean-francois.goudou@thalesgroup.com">Jean-Francois Goudou</a>, <a href="https://openreview.net/profile?email=david.filliat%40ensta-paristech.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.filliat@ensta-paristech.fr">David Filliat</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ1HFlZAb-details-538" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ1HFlZAb-details-538"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative networks are known to be difficult to assess. Recent works on generative models, especially on generative adversarial networks, produce nice samples of varied categories of images. But the validation of their quality is highly dependent on the method used. A good generator should generate data which contain meaningful and varied information and that fit the distribution of a dataset. This paper presents a new method to assess a generator. Our approach is based on training a classifier with a mixture of real and generated samples. We train a generative model over a labeled training set, then we use this generative model to sample new data points that we mix with the original training data. This mixture of real and generated data is thus used to train a classifier which is afterwards tested on a given labeled test dataset. We compare this result with the score of the same classifier trained on the real training data mixed with noise. By computing the classifier's accuracy with different ratios of samples from both distributions (real and generated) we are able to estimate if the generator successfully fits and is able to generalize the distribution of the dataset. Our experiments compare the result of different generators from the VAE and GAN framework on MNIST and fashion MNIST dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Evaluating generative networks through their data augmentation capacity on discrimative models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative models, Evaluation of generative models, Data Augmentation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1RQdCg0W">
      <h4>
        <a href="https://openreview.net/forum?id=r1RQdCg0W">
          MACH: Embarrassingly parallel $K$-class classification in $O(d\log{K})$ memory and $O(K\log{K} + d\log{K})$ time, instead of $O(Kd)$
        </a>
        
          <a href="https://openreview.net/pdf?id=r1RQdCg0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=qh5%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qh5@rice.edu">Qixuan Huang</a>, <a href="https://openreview.net/profile?email=anshumali%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anshumali@rice.edu">Anshumali Shrivastava</a>, <a href="https://openreview.net/profile?email=yiqiu.wang%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiqiu.wang@rice.edu">Yiqiu Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1RQdCg0W-details-332" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1RQdCg0W-details-332"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Merged-Averaged Classifiers via Hashing (MACH) for $K$-classification with large $K$. Compared to traditional one-vs-all classifiers that require $O(Kd)$ memory and inference cost, MACH only need $O(d\log{K})$ memory while only requiring $O(K\log{K} + d\log{K})$ operation for inference. MACH is the first generic $K$-classification algorithm, with provably theoretical guarantees, which requires $O(\log{K})$ memory without any assumption on the relationship between classes. MACH uses universal hashing to reduce classification with a large number of classes to few independent classification task with very small (constant) number of classes. We provide theoretical quantification of accuracy-memory tradeoff by showing the first connection between extreme classification and heavy hitters. With MACH we can train ODP dataset with 100,000 classes and 400,000 features on a single Titan X GPU (12GB), with the classification accuracy of 19.28\%, which is the best-reported accuracy on this dataset. Before this work, the best performing baseline is a one-vs-all classifier that requires 40 billion parameters (320 GB model size) and achieves 9\% accuracy.  In contrast, MACH can achieve 9\% accuracy with 480x reduction in the model size (of mere 0.6GB). With MACH, we also demonstrate complete training of fine-grained imagenet dataset (compressed size 104GB), with 21,000 classes, on a single GPU.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">How to Training 100,000 classes on a single GPU</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Extreme Classification, Large-scale learning, hashing, GPU, High Performance Computing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1AoGNlC-">
      <h4>
        <a href="https://openreview.net/forum?id=r1AoGNlC-">
          Code Synthesis with Priority Queue Training
        </a>
        
          <a href="https://openreview.net/pdf?id=r1AoGNlC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=danabo%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danabo@google.com">Daniel A. Abolafia</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>, <a href="https://openreview.net/profile?email=mnorouzi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mnorouzi@google.com">Mohammad Norouzi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1AoGNlC--details-254" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1AoGNlC--details-254"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the task of program synthesis in the presence of a reward function over the output of programs, where the goal is to find programs with maximal rewards. We introduce a novel iterative optimization scheme, where we train an RNN on a dataset of K best programs from a priority queue of the generated programs so far. Then, we synthesize new programs and add them to the priority queue by sampling from the RNN. We benchmark our algorithm called priority queue training (PQT) against genetic algorithm and reinforcement learning baselines on a simple but expressive Turing complete programming language called BF. Our experimental results show that our deceptively simple PQT algorithm significantly outperforms the baselines. By adding a program length penalty to the reward function, we are able to synthesize short, human readable programs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use a simple search algorithm involving an RNN and priority queue to find solutions to coding tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">code synthesis, program synthesis, genetic algorithm, reinforcement learning, policy gradient, reinforce, priority queue, topk buffer, bf, code golf, rnn</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r154_g-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=r154_g-Rb">
          Composable Planning with Attributes
        </a>
        
          <a href="https://openreview.net/pdf?id=r154_g-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amyzhang%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amyzhang@fb.com">Amy Zhang</a>, <a href="https://openreview.net/profile?email=alerer%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alerer@fb.com">Adam Lerer</a>, <a href="https://openreview.net/profile?email=sainbar%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sainbar@cs.nyu.edu">Sainbayar Sukhbaatar</a>, <a href="https://openreview.net/profile?email=fergus%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fergus@cs.nyu.edu">Rob Fergus</a>, <a href="https://openreview.net/profile?email=aszlam%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aszlam@fb.com">Arthur Szlam</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r154_g-Rb-details-253" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r154_g-Rb-details-253"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The tasks that an agent will need to solve often aren’t known during training. However, if the agent knows which properties of the environment we consider im- portant, then after learning how its actions affect those properties the agent may be able to use this knowledge to solve complex tasks without training specifi- cally for them. Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest. We propose a model that learns a policy for transitioning between “nearby” sets of attributes, and maintains a graph of possible transitions. Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan. We show in grid-world games and 3D block stacking that our model is able to generalize to longer, more complex tasks at test time even when it only sees short, simple tasks at train time.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Compositional attribute-based planning that generalizes to long test tasks, despite being trained on short &amp; simple tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Planning, Compositionality, Attributes, Reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1NOXfWR-">
      <h4>
        <a href="https://openreview.net/forum?id=B1NOXfWR-">
          Neural Task Graph Execution
        </a>
        
          <a href="https://openreview.net/pdf?id=B1NOXfWR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=srsohn%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srsohn@umich.edu">Sungryull Sohn</a>, <a href="https://openreview.net/profile?email=junhyuk%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junhyuk@umich.edu">Junhyuk Oh</a>, <a href="https://openreview.net/profile?email=honglak%40eecs.umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@eecs.umich.edu">Honglak Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1NOXfWR--details-430" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1NOXfWR--details-430"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In order to develop a scalable multi-task reinforcement learning (RL) agent that is able to execute many complex tasks, this paper introduces a new RL problem where the agent is required to execute a given task graph which describes a set of subtasks and dependencies among them. Unlike existing approaches which explicitly describe what the agent should do, our problem only describes properties of subtasks and relationships between them, which requires the agent to perform a complex reasoning to find the optimal subtask to execute. To solve this problem, we propose a neural task graph solver (NTS) which encodes the task graph using a recursive neural network. To overcome the difficulty of training, we propose a novel non-parametric gradient-based policy that performs back-propagation over a differentiable form of the task graph to compute the influence of each subtask on the other subtasks. Our NTS is pre-trained to approximate the proposed gradient-based policy and fine-tuned through actor-critic method. The experimental results on a 2D visual domain show that our method to pre-train from the gradient-based policy significantly improves the performance of NTS. We also demonstrate that our agent can perform a complex reasoning to find the optimal way of executing the task graph and generalize well to unseen task graphs. In addition, we compare our agent with a Monte-Carlo Tree Search (MCTS) method showing that our method is much more efficient than MCTS, and the performance of our agent can be further improved by combining with MCTS. The demo video is available at https://youtu.be/e_ZXVS5VutM.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, task execution, instruction execution</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By3VrbbAb">
      <h4>
        <a href="https://openreview.net/forum?id=By3VrbbAb">
          Realtime query completion via deep language models
        </a>
        
          <a href="https://openreview.net/pdf?id=By3VrbbAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=poweiw%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="poweiw@cs.cmu.edu">Po-Wei Wang</a>, <a href="https://openreview.net/profile?email=zkolter%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkolter@cs.cmu.edu">J. Zico Kolter</a>, <a href="https://openreview.net/profile?email=vijaim%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vijaim@amazon.com">Vijai Mohan</a>, <a href="https://openreview.net/profile?email=isd%40a9.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="isd@a9.com">Inderjit S. Dhillon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By3VrbbAb-details-416" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By3VrbbAb-details-416"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Search engine users nowadays heavily depend on query completion and correction to shape their queries.  Typically, the completion is done by database lookup which does not understand the context and cannot generalize to prefixes not in the database. In the paper, we propose to use unsupervised deep language models to complete and correct the queries given an arbitrary prefix.  We show how to address two main challenges that renders this method practical for large-scale deployment: 1) we propose a method for integrating error correction into the language model completion via a edit-distance potential and a variant of beam search that can exploit these potential functions; and 2) we show how to efficiently perform CPU-based computation to complete the queries, with error correction, in real time (generating top 10 completions within 16 ms). Experiments show that the method substantially increases hit rate over standard approaches, and is capable of handling tail queries.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">realtime search query completion using character-level LSTM language models</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">query completion, realtime, error correction, recurrent network, beam search</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ4prNx0W">
      <h4>
        <a href="https://openreview.net/forum?id=BJ4prNx0W">
          Learning what to learn in a neural program
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ4prNx0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ricshin%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ricshin@berkeley.edu">Richard Shin</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ4prNx0W-details-815" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ4prNx0W-details-815"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryZElGZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=ryZElGZ0Z">
          Discovery of Predictive Representations With a Network of General Value Functions
        </a>
        
          <a href="https://openreview.net/pdf?id=ryZElGZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mkschleg%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkschleg@ualberta.ca">Matthew Schlegel</a>, <a href="https://openreview.net/profile?email=andnpatt%40indiana.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="andnpatt@indiana.edu">Andrew Patterson</a>, <a href="https://openreview.net/profile?email=amw8%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="amw8@ualberta.ca">Adam White</a>, <a href="https://openreview.net/profile?email=whitem%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="whitem@ualberta.ca">Martha White</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryZElGZ0Z-details-342" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryZElGZ0Z-details-342"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The ability of an agent to {\em discover} its own learning objectives has long been considered a key ingredient for artificial general intelligence. Breakthroughs in autonomous decision making and reinforcement learning have primarily been in domains where the agent's goal is outlined and clear: such as playing a game to win, or driving safely. Several studies have demonstrated that learning extramural sub-tasks and auxiliary predictions can improve (1) single human-specified task learning, (2) transfer of learning, (3) and the agent's learned representation of the world. In all these examples, the agent was instructed what to learn about. We investigate a framework for discovery: curating a large collection of predictions, which are used to construct the agent's representation of the world. Specifically, our system maintains a large collection of predictions, continually pruning and replacing predictions. We highlight the importance of considering stability rather than convergence for such a system, and develop an adaptive, regularized algorithm towards that aim. We provide several experiments in computational micro-worlds demonstrating that this simple approach can be effective for discovering useful predictions autonomously.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate a framework for discovery: curating a large collection of predictions, which are used to construct the agent’s representation in partially observable domains.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, General Value Functions, Predictive Representations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyvCD-b0W">
      <h4>
        <a href="https://openreview.net/forum?id=SyvCD-b0W">
          Autostacker: an Automatic Evolutionary Hierarchical  Machine Learning System
        </a>
        
          <a href="https://openreview.net/pdf?id=SyvCD-b0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=boyuan.chen%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="boyuan.chen@columbia.edu">Boyuan Chen</a>, <a href="https://openreview.net/profile?email=warrenmo%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="warrenmo@uchicago.edu">Warren Mo</a>, <a href="https://openreview.net/profile?email=ishanu%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ishanu@uchicago.edu">Ishanu Chattopadhyay</a>, <a href="https://openreview.net/profile?email=hod.lipson%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hod.lipson@columbia.edu">Hod Lipson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyvCD-b0W-details-781" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyvCD-b0W-details-781"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This work provides an automatic machine learning (AutoML) modelling architecture called Autostacker. Autostacker improves the prediction accuracy of machine learning baselines by utilizing an innovative hierarchical stacking architecture and an efficient parameter search algorithm. Neither prior domain knowledge about the data nor feature preprocessing is needed. We significantly reduce the time of AutoML with a naturally inspired algorithm - Parallel Hill Climbing (PHC). By parallelizing PHC, Autostacker can provide candidate pipelines with sufficient prediction accuracy within a short amount of time. These pipelines can be used as is or as a starting point for human experts to build on. By focusing on the modelling process, Autostacker breaks the tradition of following fixed order pipelines by exploring not only single model pipeline but also innovative combinations and structures. As we will show in the experiment section, Autostacker achieves significantly better performance both in terms of test accuracy and time cost comparing with human initial trials and recent popular AutoML system.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Automate machine learning system with efficient search algorithm and innovative structure to provide better model baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Machine Learning, AutoML</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1Ww66x0-">
      <h4>
        <a href="https://openreview.net/forum?id=H1Ww66x0-">
          Lifelong Learning with Output Kernels
        </a>
        
          <a href="https://openreview.net/pdf?id=H1Ww66x0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kmuruges%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kmuruges@cs.cmu.edu">Keerthiram Murugesan</a>, <a href="https://openreview.net/profile?email=jgc%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgc@cs.cmu.edu">Jaime Carbonell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1Ww66x0--details-127" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1Ww66x0--details-127"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">a novel approach for online lifelong learning using output kernels.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multitask learning, lifelong learning, online learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkFvV0yC-">
      <h4>
        <a href="https://openreview.net/forum?id=SkFvV0yC-">
          Network Iterative Learning for Dynamic Deep Neural Networks via Morphism
        </a>
        
          <a href="https://openreview.net/pdf?id=SkFvV0yC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=taowei%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="taowei@buffalo.edu">Tao Wei</a>, <a href="https://openreview.net/profile?email=wangchanghu%40toutiao.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangchanghu@toutiao.com">Changhu Wang</a>, <a href="https://openreview.net/profile?email=chencw%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chencw@buffalo.edu">Chang Wen Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkFvV0yC--details-126" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkFvV0yC--details-126"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this research, we present a novel learning scheme called network iterative learning for deep neural networks. Different from traditional optimization algorithms that usually optimize directly on a static objective function, we propose in this work to optimize a dynamic objective function in an iterative fashion capable of adapting its function form when being optimized. The optimization is implemented as a series of intermediate neural net functions that is able to dynamically grow into the targeted neural net objective function. This is done via network morphism so that the network knowledge is fully preserved with each network growth. Experimental results demonstrate that the proposed network iterative learning scheme is able to significantly alleviate the degradation problem. Its effectiveness is verified on diverse benchmark datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Network Iterative Learning, Morphism</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJQO7UJCW">
      <h4>
        <a href="https://openreview.net/forum?id=SJQO7UJCW">
          Adversarial Learning for Semi-Supervised Semantic Segmentation
        </a>
        
          <a href="https://openreview.net/pdf?id=SJQO7UJCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=whung8%40ucmerced.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="whung8@ucmerced.edu">Wei-Chih Hung</a>, <a href="https://openreview.net/profile?email=ytsai%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ytsai@nec-labs.com">Yi-Hsuan Tsai</a>, <a href="https://openreview.net/profile?email=lyt%40csie.ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="lyt@csie.ntu.edu.tw">Yan-Ting Liou</a>, <a href="https://openreview.net/profile?email=yylin%40citi.sinica.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="yylin@citi.sinica.edu.tw">Yen-Yu Lin</a>, <a href="https://openreview.net/profile?email=mhyang%40ucmerced.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhyang@ucmerced.edu">Ming-Hsuan Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJQO7UJCW-details-752" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJQO7UJCW-details-752"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a method for semi-supervised semantic segmentation using the adversarial network. While most existing discriminators are trained to classify input images as real or fake on the image level, we design a discriminator in a fully convolutional manner to differentiate the predicted probability maps from the ground truth segmentation distribution with the consideration of the spatial resolution. We show that the proposed discriminator can be used to improve the performance on semantic segmentation by coupling the adversarial loss with the standard cross entropy loss on the segmentation network. In addition, the fully convolutional discriminator enables the semi-supervised learning through discovering the trustworthy regions in prediction results of unlabeled images, providing additional supervisory signals. In contrast to existing methods that utilize weakly-labeled images, our method leverages unlabeled images without any annotation to enhance the segmentation model. Experimental results on both the PASCAL VOC 2012 dataset and the Cityscapes dataset demonstrate the effectiveness of our algorithm.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">semantic segmentation, adversarial learning, semi-supervised learning, self-taught learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyVVXngRW">
      <h4>
        <a href="https://openreview.net/forum?id=SyVVXngRW">
          Deep Asymmetric Multi-task Feature Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SyVVXngRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hblee%40unist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="hblee@unist.ac.kr">Hae Beom Lee</a>, <a href="https://openreview.net/profile?email=yangeh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangeh@gmail.com">Eunho Yang</a>, <a href="https://openreview.net/profile?email=sjhwang%40unist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang@unist.ac.kr">Sung Ju Hwang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyVVXngRW-details-855" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyVVXngRW-details-855"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can learn deep representations shared across multiple tasks while effectively preventing negative transfer that may happen in the feature sharing process. Specifically, we introduce an asymmetric autoencoder term that allows reliable predictors for the easy tasks to have high contribution to the feature learning while suppressing the influences of unreliable predictors for more difficult tasks. This allows the learning of less noisy representations, and enables unreliable predictors to exploit knowledge from the reliable predictors via the shared latent features. Such asymmetric knowledge transfer through shared features is also more scalable and efficient than inter-task asymmetric transfer. We validate our Deep-AMTFL model on multiple benchmark datasets for multitask learning and image classification, on which it significantly outperforms existing symmetric and asymmetric multitask learning models, by effectively preventing negative transfer in deep feature learning.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy_o3x-0b">
      <h4>
        <a href="https://openreview.net/forum?id=Hy_o3x-0b">
          Feature Map Variational Auto-Encoders
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy_o3x-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=larsma%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="larsma@dtu.dk">Lars Maaløe</a>, <a href="https://openreview.net/profile?email=olwi%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="olwi@dtu.dk">Ole Winther</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>23 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy_o3x-0b-details-459" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy_o3x-0b-details-459"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a generative model that proves state-of-the-art results on gray-scale and natural images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, representation learning, variational auto-encoders, variational inference, generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJIhGXWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJIhGXWCZ">
          Prediction Under Uncertainty with Error Encoding Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJIhGXWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mbh305%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbh305@nyu.edu">Mikael Henaff</a>, <a href="https://openreview.net/profile?email=j.zhao%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.zhao@nyu.edu">Junbo Zhao</a>, <a href="https://openreview.net/profile?email=yann%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann@cs.nyu.edu">Yann Lecun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJIhGXWCZ-details-504" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJIhGXWCZ-details-504"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work we introduce a new framework for performing temporal predictions
      in the presence of uncertainty. It is based on a simple idea of disentangling com-
      ponents of the future state which are predictable from those which are inherently
      unpredictable, and encoding the unpredictable components into a low-dimensional
      latent variable which is fed into the forward model. Our method uses a simple su-
      pervised training objective which is fast and easy to train. We evaluate it in the
      context of video prediction on multiple datasets and show that it is able to consi-
      tently generate diverse predictions without the need for alternating minimization
      over a latent space or adversarial training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simple and easy to train method for multimodal prediction in time series. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJa90ceAb">
      <h4>
        <a href="https://openreview.net/forum?id=rJa90ceAb">
          Learning to Generate Filters for Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJa90ceAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shenwei%40cn.fujitsu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shenwei@cn.fujitsu.com">Wei Shen</a>, <a href="https://openreview.net/profile?email=rjliu%40cn.fujitsu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rjliu@cn.fujitsu.com">Rujie Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJa90ceAb-details-138" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJa90ceAb-details-138"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Conventionally, convolutional neural networks (CNNs) process different images with the same set of filters. However, the variations in images pose a challenge to this fashion. In this paper, we propose to generate sample-specific filters for convolutional layers in the forward pass. Since the filters are generated on-the-fly, the model becomes more flexible and can better fit the training data compared to traditional CNNs. In order to obtain sample-specific features, we extract the intermediate feature maps from an autoencoder. As filters are usually high dimensional, we propose to learn a set of coefficients instead of a set of filters. These coefficients are used to linearly combine the base filters from a filter repository to generate the final filters for a CNN. The proposed method is evaluated on MNIST, MTFL and CIFAR10 datasets. Experiment results demonstrate that the classification accuracy of the baseline model can be improved by using the proposed filter generation method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">dynamically generate filters conditioned on the input image for CNNs in each forward pass </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">filter generation, meta-learning, filter repository, image classification, dynamic generation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkCvZXbC-">
      <h4>
        <a href="https://openreview.net/forum?id=HkCvZXbC-">
          3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY
        </a>
        
          <a href="https://openreview.net/pdf?id=HkCvZXbC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ycharn%40cs.unc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ycharn@cs.unc.edu">Yeu-Chern Harn</a>, <a href="https://openreview.net/profile?email=vjojic%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vjojic@gmail.com">Vladimir Jojic</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkCvZXbC--details-327" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkCvZXbC--details-327"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present 3C-GAN: a novel multiple generators structures, that contains one conditional generator that generates a semantic part of an image conditional on its input label, and one context generator generates the rest of an image. Compared to original GAN model, this model has multiple generators and gives control over what its generators should generate. Unlike previous multi-generator models use a subsequent generation process, that one layer is generated given the previous layer, our model uses a process of generating different part of the images together. This way the model contains fewer parameters and the generation speed is faster. Speciﬁcally, the model leverages the label information to separate the object from the image correctly. Since the model conditional on the label information does not restrict to generate other parts of an image, we proposed a cost function that encourages the model to generate only the succinct part of an image in terms of label discrimination. We also found an exclusive prior on the mask of the model help separate the object. The experiments on MNIST, SVHN, and CelebA datasets show 3C-GAN can generate different objects with different generators simultaneously, according to the labels given to each generator.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkQsMCJCb">
      <h4>
        <a href="https://openreview.net/forum?id=rkQsMCJCb">
          Generative Adversarial Networks using Adaptive Convolution
        </a>
        
          <a href="https://openreview.net/pdf?id=rkQsMCJCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nmnguyen%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="nmnguyen@ualberta.ca">Nhat M. Nguyen</a>, <a href="https://openreview.net/profile?email=nray1%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="nray1@ualberta.ca">Nilanjan Ray</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkQsMCJCb-details-981" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkQsMCJCb-details-981"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Most existing GANs architectures that generate images use transposed convolution or resize-convolution as their upsampling algorithm from lower to higher resolution feature maps in the generator. We argue that this kind of fixed operation is problematic for GANs to model objects that have very different visual appearances. We propose a novel adaptive convolution method that learns the upsampling algorithm based on the local context at each location to address this problem. We modify a baseline GANs architecture by replacing normal convolutions with adaptive convolutions in the generator. Experiments on CIFAR-10 dataset show that our modified models improve the baseline model by a large margin. Furthermore, our models achieve state-of-the-art performance on CIFAR-10 and STL-10 datasets in the unsupervised setting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We replace normal convolutions with adaptive convolutions to improve GANs generator.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, Unsupervised Learning, GANs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJrJpzZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJrJpzZRZ">
          Self-Supervised Learning of Object Motion Through Adversarial Video Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=HJrJpzZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rich.zhang%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rich.zhang@eecs.berkeley.edu">Alex X. Lee</a>, <a href="https://openreview.net/profile?email=febert%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="febert@berkeley.edu">Frederik Ebert</a>, <a href="https://openreview.net/profile?email=cbfinn%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbfinn@eecs.berkeley.edu">Richard Zhang</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Chelsea Finn</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Pieter Abbeel</a>, Sergey Levine
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJrJpzZRZ-details-816" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJrJpzZRZ-details-816"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Can we build models that automatically learn about object motion from raw, unlabeled videos? In this paper, we study the problem of multi-step video prediction, where the goal is to predict a sequence of future frames conditioned on a short context. We focus specifically on two aspects of video prediction: accurately modeling object motion, and producing naturalistic image predictions. Our model is based on a flow-based generator network with a discriminator used to improve prediction quality. The implicit flow in the generator can be examined to determine its accuracy, and the predicted images can be evaluated for image quality. We argue that these two metrics are critical for understanding whether the model has effectively learned object motion, and propose a novel evaluation benchmark based on ground truth object flow. Our network achieves state-of-the-art results in terms of both the realism of the predicted images, as determined by human judges, and the accuracy of the predicted flow. Videos and full results can be viewed on the supplementary website: \url{https://sites.google.com/site/omvideoprediction}.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial, video prediction, flow</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy8hkYeRb">
      <h4>
        <a href="https://openreview.net/forum?id=Hy8hkYeRb">
          A Deep Predictive Coding Network for Learning Latent Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy8hkYeRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shirin.dora%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shirin.dora@gmail.com">Shirin Dora</a>, <a href="https://openreview.net/profile?email=c.m.a.pennartz%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="c.m.a.pennartz@uva.nl">Cyriel Pennartz</a>, <a href="https://openreview.net/profile?email=s.m.bohte%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.m.bohte@cwi.nl">Sander Bohte</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy8hkYeRb-details-891" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy8hkYeRb-details-891"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It has been argued that the brain is a prediction machine that continuously learns how to make better predictions about the stimuli received from the external environment. For this purpose, it builds a model of the world around us and uses this model to infer the external stimulus. Predictive coding has been proposed as a mechanism through which the brain might be able to build such a model of the external environment. However, it is not clear how predictive coding can be used to build deep neural network models of the brain while complying with the architectural constraints imposed by the brain. In this paper, we describe an algorithm to build a deep generative model using predictive coding that can be used to infer latent representations about the stimuli received from external environment. Specifically, we used predictive coding to train a deep neural network on real-world images in a unsupervised learning paradigm. To understand the capacity of the network with regards to modeling the external environment, we studied the latent representations generated by the model on images of objects that are never presented to the model during training. Despite the novel features of these objects the model is able to infer the latent representations for them. Furthermore, the reconstructions of the original images obtained from these latent representations preserve the important details of these objects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A predictive coding based learning algorithm for building deep neural network models of the brain</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Predictive coding, deep neural network, generative model, unsupervised learning, learning latent representations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry4S90l0b">
      <h4>
        <a href="https://openreview.net/forum?id=ry4S90l0b">
          A Self-Training Method for Semi-Supervised GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=ry4S90l0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alan.do-omri%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="alan.do-omri@mail.mcgill.ca">Alan Do-Omri</a>, <a href="https://openreview.net/profile?email=daleiwu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daleiwu@gmail.com">Dalei Wu</a>, <a href="https://openreview.net/profile?email=liuxiaohua3%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuxiaohua3@huawei.com">Xiaohua Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry4S90l0b-details-39" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry4S90l0b-details-39"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Since the creation of Generative Adversarial Networks (GANs), much work has been done to improve their training stability, their generated image quality, their range of application but nearly none of them explored their self-training potential. Self-training has been used before the advent of deep learning in order to allow training on limited labelled training data and has shown impressive results in semi-supervised learning. In this work, we combine these two ideas and make GANs self-trainable for semi-supervised learning tasks by exploiting their infinite data generation potential. Results show that using even the simplest form of self-training yields an improvement. We also show results for a more complex self-training scheme that performs at least as well as the basic self-training scheme but with significantly less data augmentation. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">self-training, generative adversarial networks, semi-supervised</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJg4YGWRb">
      <h4>
        <a href="https://openreview.net/forum?id=rJg4YGWRb">
          Attention-based Graph Neural Network for Semi-supervised Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rJg4YGWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kirankoshy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kirankoshy@gmail.com">Kiran K. Thekumparampil</a>, <a href="https://openreview.net/profile?email=sewoong79%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sewoong79@gmail.com">Sewoong Oh</a>, <a href="https://openreview.net/profile?email=chongw%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongw@google.com">Chong Wang</a>, <a href="https://openreview.net/profile?email=lijiali%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lijiali@cs.stanford.edu">Li-Jia Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJg4YGWRb-details-996" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJg4YGWRb-details-996"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recently popularized graph neural networks achieve the state-of-the-art accuracy on a number of standard benchmark datasets for graph-based semi-supervised learning, improving significantly over existing approaches. These architectures alternate between a propagation layer that aggregates the hidden states of the local neighborhood and a fully-connected layer. Perhaps surprisingly, we show that a linear model, that removes all the intermediate fully-connected layers, is still able to achieve a performance comparable to the state-of-the-art models. This significantly reduces the number of parameters, which is critical for semi-supervised learning where number of labeled examples are small. This in turn allows a room for designing more innovative propagation layers. Based on this insight, we propose a novel graph neural network that removes all the intermediate fully-connected layers, and replaces the propagation layers with attention mechanisms that respect the structure of the graph. The attention mechanism allows us to learn a dynamic and adaptive local summary of the neighborhood to achieve more accurate predictions. In a number of experiments on benchmark citation networks datasets, we demonstrate that our approach outperforms competing methods. By examining the attention weights among neighbors, we show that our model provides some interesting insights on how neighbors influence each other.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel attention-based interpretable Graph Neural Network architecture which outperforms the current state-of-the-art Graph Neural Networks in standard benchmark datasets</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Graph Neural Network, Attention, Semi-supervised Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJRV1ZZAW">
      <h4>
        <a href="https://openreview.net/forum?id=HJRV1ZZAW">
          FAST READING COMPREHENSION WITH CONVNETS
        </a>
        
          <a href="https://openreview.net/pdf?id=HJRV1ZZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=fw245%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fw245@cornell.edu">Felix Wu</a>, <a href="https://openreview.net/profile?email=nlao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nlao@google.com">Ni Lao</a>, <a href="https://openreview.net/profile?email=blitzer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="blitzer@google.com">John Blitzer</a>, <a href="https://openreview.net/profile?email=gy46%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gy46@cornell.edu">Guandao Yang</a>, <a href="https://openreview.net/profile?email=kqw4%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kqw4@cornell.edu">Kilian Weinberger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJRV1ZZAW-details-639" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJRV1ZZAW-details-639"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">State-of-the-art deep reading comprehension models are dominated by recurrent
      neural nets. Their sequential nature is a natural fit for language, but it also precludes
      parallelization within an instances and often becomes the bottleneck for
      deploying such models to latency critical scenarios. This is particularly problematic
      for longer texts. Here we present a convolutional architecture as an alternative
      to these recurrent architectures. Using simple dilated convolutional units in place
      of recurrent ones, we achieve results comparable to the state of the art on two
      question answering tasks, while at the same time achieving up to two orders of
      magnitude speedups for question answering.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reading comprehension, question answering, CNN, ConvNet, Inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJMuY-gRW">
      <h4>
        <a href="https://openreview.net/forum?id=BJMuY-gRW">
          Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs
        </a>
        
          <a href="https://openreview.net/pdf?id=BJMuY-gRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jean%40maillard.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="jean@maillard.it">Jean Maillard</a>, <a href="https://openreview.net/profile?email=sc609%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sc609@cam.ac.uk">Stephen Clark</a>, <a href="https://openreview.net/profile?email=dyogatama%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dyogatama@google.com">Dani Yogatama</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJMuY-gRW-details-678" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJMuY-gRW-details-678"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a neural network that represents sentences by composing their words according to induced binary parse trees. We use Tree-LSTM as our composition function, applied along a tree structure found by a fully differentiable natural language chart parser. Our model simultaneously optimises both the composition function and the parser, thus eliminating the need for externally-provided parse trees which are normally required for Tree-LSTM. It can therefore be seen as a tree-based RNN that is unsupervised with respect to the parse trees. As it is fully differentiable, our model is easily trained with an off-the-shelf gradient descent method and backpropagation. We demonstrate that it achieves better performance compared to various supervised Tree-LSTM architectures on a textual entailment task and a reverse dictionary task. Finally, we show how performance can be improved with an attention mechanism which fully exploits the parse chart, by attending over all possible subspans of the sentence.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Represent sentences by composing them with Tree-LSTMs according to automatically induced parse trees.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hierarchical, tree-lstm, treelstm, syntax, composition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1kIr-WRb">
      <h4>
        <a href="https://openreview.net/forum?id=B1kIr-WRb">
          LEARNING SEMANTIC WORD RESPRESENTATIONS VIA TENSOR FACTORIZATION
        </a>
        
          <a href="https://openreview.net/pdf?id=B1kIr-WRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=popcorncolonel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="popcorncolonel@gmail.com">Eric Bailey</a>, <a href="https://openreview.net/profile?email=cmey63%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cmey63@gmail.com">Charles Meyer</a>, <a href="https://openreview.net/profile?email=shuchin%40ece.tufts.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shuchin@ece.tufts.edu">Shuchin Aeron</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1kIr-WRb-details-226" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1kIr-WRb-details-226"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many state-of-the-art word embedding techniques involve factorization of a cooccurrence
      based matrix. We aim to extend this approach by studying word embedding
      techniques that involve factorization of co-occurrence based tensors (N-
      way arrays). We present two new word embedding techniques based on tensor
      factorization and show that they outperform common methods on several semantic
      NLP tasks when given the same data. To train one of the embeddings, we present
      a new joint tensor factorization problem and an approach for solving it. Furthermore,
      we modify the performance metrics for the Outlier Detection Camacho-
      Collados &amp; Navigli (2016) task to measure the quality of higher-order relationships
      that a word embedding captures. Our tensor-based methods significantly
      outperform existing methods at this task when using our new metric. Finally, we
      demonstrate that vectors in our embeddings can be composed multiplicatively to
      create different vector representations for each meaning of a polysemous word.
      We show that this property stems from the higher order information that the vectors
      contain, and thus is unique to our tensor based embeddings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Word Embeddings, Tensor Factorization, Natural Language Processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H113pWZRb">
      <h4>
        <a href="https://openreview.net/forum?id=H113pWZRb">
          Topology Adaptive Graph Convolutional  Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=H113pWZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jiand%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiand@andrew.cmu.edu">Jian Du</a>, <a href="https://openreview.net/profile?email=shanghaz%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shanghaz@andrew.cmu.edu">Shanghang Zhang</a>, <a href="https://openreview.net/profile?email=guanhanw%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guanhanw@andrew.cmu.edu">Guanhang Wu</a>, <a href="https://openreview.net/profile?email=moura%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="moura@andrew.cmu.edu">José M. F. Moura</a>, <a href="https://openreview.net/profile?email=soummyak%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="soummyak@andrew.cmu.edu">Soummya Kar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H113pWZRb-details-792" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H113pWZRb-details-792"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolution acts as a local feature extractor in convolutional neural networks (CNNs). However, the convolution operation is not applicable when the input data is supported on an irregular graph such as with social networks, citation networks, or knowledge graphs. This paper proposes the topology adaptive graph convolutional network (TAGCN), a novel graph convolutional network that generalizes CNN architectures to graph-structured data and provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution, replacing the square filter for the grid-structured data in traditional CNNs. The outputs are the weighted sum of these filters’ outputs, extraction of both vertex features and strength of correlation between vertices. It
      can be used with both directed and undirected graphs. The proposed TAGCN not only inherits the properties of convolutions in CNN for grid-structured data, but it is also consistent with convolution as defined in graph signal processing. Further, as no approximation to the convolution is needed, TAGCN exhibits better performance than existing graph-convolution-approximation methods on a number
      of data sets. As only the polynomials of degree two of the adjacency matrix are used, TAGCN is also computationally simpler than other recent methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Low computational complexity graph CNN (without approximation) with better classification accuracy</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph convolutional neural networks, graph-structured data, semi-classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylejExC-">
      <h4>
        <a href="https://openreview.net/forum?id=rylejExC-">
          Stochastic Training of Graph Convolutional Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rylejExC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chenjian14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenjian14@mails.tsinghua.edu.cn">Jianfei Chen</a>, <a href="https://openreview.net/profile?email=dcszj%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@mail.tsinghua.edu.cn">Jun Zhu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rylejExC--details-70" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylejExC--details-70"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Graph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes nodes' representation recursively from their neighbors, making the receptive field size grow exponentially with the number of layers.  Previous attempts on reducing the receptive field size by subsampling neighbors do not have any convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop a preprocessing strategy and two control variate based algorithms to further reduce the receptive field size. Our algorithms are guaranteed to converge to GCN's local optimum regardless of the neighbor sampling size. Empirical results show that our algorithms have a similar convergence speed per epoch with the exact algorithm even using only two neighbors per node. The time consumption of our algorithm on the Reddit dataset is only one fifth of previous neighbor sampling algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A control variate based stochastic training algorithm for graph convolutional networks that the receptive field can be only two neighbors per node.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Graph convolutional networks, stochastic gradient descent, variance reduction, control variate</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkJKHMW0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SkJKHMW0Z">
          Recurrent Relational Networks for complex relational reasoning
        </a>
        
          <a href="https://openreview.net/pdf?id=SkJKHMW0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rasmusbergpalm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rasmusbergpalm@gmail.com">Rasmus Berg Palm</a>, <a href="https://openreview.net/profile?email=upaq%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="upaq@google.com">Ulrich Paquet</a>, <a href="https://openreview.net/profile?email=olwi%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="olwi@dtu.dk">Ole Winther</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkJKHMW0Z-details-634" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkJKHMW0Z-details-634"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Humans possess an ability to abstractly reason about objects and their interactions, an ability not shared with state-of-the-art deep learning models. Relational networks, introduced by Santoro et al. (2017), add the capacity for relational reasoning to deep neural networks, but are limited in the complexity of the reasoning tasks they can address. We introduce recurrent relational networks which increase the suite of solvable tasks to those that require an order of magnitude more steps of relational reasoning. We use recurrent relational networks to solve Sudoku puzzles and achieve state-of-the-art results by solving 96.6% of the hardest Sudoku puzzles, where relational networks fail to solve any. We also apply our model to the BaBi textual QA dataset solving 19/20 tasks which is competitive with state-of-the-art sparse differentiable neural computers. The recurrent relational network is a general purpose module that can augment any neural network model with the capacity to do many-step relational reasoning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce Recurrent Relational Networks, a powerful and general neural network module for relational reasoning, and use it to solve 96.6% of the hardest Sudokus and 19/20 BaBi tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">relational reasoning, graph neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByquB-WC-">
      <h4>
        <a href="https://openreview.net/forum?id=ByquB-WC-">
          Finding ReMO (Related Memory Object): A Simple neural architecture for Text based Reasoning
        </a>
        
          <a href="https://openreview.net/pdf?id=ByquB-WC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jhmoon%40dm.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jhmoon@dm.snu.ac.kr">Jihyung Moon</a>, <a href="https://openreview.net/profile?email=hyochang%40dm.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyochang@dm.snu.ac.kr">Hyochang Yang</a>, <a href="https://openreview.net/profile?email=zoon%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="zoon@snu.ac.kr">Sungzoon Cho</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByquB-WC--details-537" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByquB-WC--details-537"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Memory Network based models have shown a remarkable progress on the task of relational reasoning.
      Recently, a simpler yet powerful neural network module called Relation Network (RN) has been introduced. 
      Despite its architectural simplicity, the time complexity of relation network grows quadratically with data, hence limiting its application to tasks with a large-scaled memory.
      We introduce Related Memory Network, an end-to-end neural network architecture exploiting both memory network and relation network structures. 
      We follow memory network's four components while each component operates similar to the relation network without taking a pair of objects. 
      As a result, our model is as simple as RN but the computational complexity is reduced to linear time.
      It achieves the state-of-the-art results in jointly trained bAbI-10k story-based question answering and  bAbI dialog dataset. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simple reasoning architecture based on the memory network (MemNN) and relation network (RN), reducing the time complexity compared to the RN and achieving state-of-the-are result on bAbI story based QA and bAbI dialog.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Natural Language Processing, Deep Learning, Reasoning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJBwoM-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=rJBwoM-Cb">
          Neural Tree Transducers for Tree to Tree Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rJBwoM-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joao%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="joao@cis.upenn.edu">João Sedoc</a>, <a href="https://openreview.net/profile?email=dean%40foster.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="dean@foster.net">Dean Foster</a>, <a href="https://openreview.net/profile?email=ungar%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ungar@cis.upenn.edu">Lyle Ungar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJBwoM-Cb-details-618" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJBwoM-Cb-details-618"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a novel approach to tree-to-tree learning, the neural tree transducer (NTT), a top-down depth first context-sensitive tree decoder, which is paired with recursive neural encoders. Our method works purely on tree-to-tree manipulations rather than sequence-to-tree or tree-to-sequence and is able to encode and decode multiple depth trees. We compare our method to sequence-to-sequence models applied to serializations of the trees and show that our method outperforms previous methods for tree-to-tree transduction. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, tree transduction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1sRrN-CW">
      <h4>
        <a href="https://openreview.net/forum?id=S1sRrN-CW">
          Revisiting Knowledge Base Embedding as Tensor Decomposition
        </a>
        
          <a href="https://openreview.net/pdf?id=S1sRrN-CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xptree%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xptree@gmail.com">Jiezhong Qiu</a>, <a href="https://openreview.net/profile?email=haoma%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haoma@microsoft.com">Hao Ma</a>, <a href="https://openreview.net/profile?email=yuxdong%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuxdong@microsoft.com">Yuxiao Dong</a>, <a href="https://openreview.net/profile?email=kuansanw%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kuansanw@microsoft.com">Kuansan Wang</a>, <a href="https://openreview.net/profile?email=jietang%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jietang@tsinghua.edu.cn">Jie Tang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1sRrN-CW-details-12" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1sRrN-CW-details-12"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the problem of knowledge base (KB) embedding, which is usually addressed through two frameworks---neural KB embedding and tensor decomposition. In this work, we theoretically analyze the neural embedding framework and subsequently connect it with tensor based embedding. Specifically, we show that in neural KB embedding the two commonly adopted optimization solutions---margin-based and negative sampling losses---are closely related to each other. We also reach the closed-form tensor that is implicitly approximated by popular neural KB approaches, revealing the underlying connection between neural and tensor based KB embedding models. Grounded in the theoretical results, we further present a tensor decomposition based framework KBTD to directly approximate the derived closed form tensor. Under this framework, the neural KB embedding models, such as NTN, TransE, Bilinear, and DISTMULT, are unified into a general tensor optimization architecture. Finally, we conduct experiments on the link prediction task in WordNet and Freebase, empirically demonstrating the effectiveness of the KBTD framework. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Knowledge base embedding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ71VXZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJ71VXZAZ">
          Learning To Generate Reviews and Discovering Sentiment
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ71VXZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alec%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alec@openai.com">Alec Radford</a>, <a href="https://openreview.net/profile?email=rafal%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rafal@openai.com">Rafal Jozefowicz</a>, <a href="https://openreview.net/profile?email=ilya%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilya@openai.com">Ilya Sutskever</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ71VXZAZ-details-892" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ71VXZAZ-details-892"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We explore the properties of byte-level recurrent language models. When given sufficient amounts of capacity, training data, and compute time, the representations learned by these models include disentangled features corresponding to high-level concepts. Specifically, we find a single unit which performs sentiment analysis. These representations, learned in an unsupervised manner, achieve state of the art on the binary subset of the Stanford Sentiment Treebank. They are also very data efficient. When using only a handful of labeled examples, our approach matches the performance of strong baselines trained on full datasets. We also demonstrate the sentiment unit has a direct influence on the generative process of the model. Simply fixing its value to be positive or negative generates samples with the corresponding positive or negative sentiment.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Byte-level recurrent language models learn high-quality domain specific representations of text.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, representation learning, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1XXq6lRW">
      <h4>
        <a href="https://openreview.net/forum?id=S1XXq6lRW">
          Zero-shot Cross Language Text Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=S1XXq6lRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dsve%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="dsve@dtu.dk">Dan Svenstrup</a>, <a href="https://openreview.net/profile?email=jonas%40meinertz.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonas@meinertz.org">Jonas Meinertz Hansen</a>, <a href="https://openreview.net/profile?email=olwi%40dtu.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="olwi@dtu.dk">Ole Winther</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1XXq6lRW-details-630" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1XXq6lRW-details-630"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Labeled text classification datasets are typically only available in a few select languages. In order to train a model for e.g news categorization in a language $L_t$ without a suitable text classification dataset there are two options. The first option is to create a new labeled dataset by hand, and the second option is to transfer label information from an existing labeled dataset in a source language $L_s$ to the target language $L_t$. In this paper we propose a method for sharing label information across languages by means of a language independent text encoder. The encoder will give almost identical representations to multilingual versions of the same text. This means that labeled data in one language can be used to train a classifier that works for the rest of the languages. The encoder is trained independently of any concrete classification task and can therefore subsequently be used for any classification task.  We show that it is possible to obtain good performance even in the case where only a comparable corpus of texts is available. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Cross Language Text Classification by universal encoding</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Cross Language Text Classification, Neural Networks, Machine Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkM27IxR-">
      <h4>
        <a href="https://openreview.net/forum?id=BkM27IxR-">
          Learning to Optimize Neural Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=BkM27IxR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ke.li%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ke.li@eecs.berkeley.edu">Ke Li</a>, <a href="https://openreview.net/profile?email=jitendram%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jitendram@google.com">Jitendra Malik</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkM27IxR--details-339" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkM27IxR--details-339"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning to Optimize is a recently proposed framework for learning optimization algorithms using reinforcement learning. In this paper, we explore learning an optimization algorithm for training shallow neural nets. Such high-dimensional stochastic optimization problems present interesting challenges for existing reinforcement learning algorithms. We develop an extension that is suited to learning optimization algorithms in this setting and demonstrate that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture. More specifically, we show that an optimization algorithm trained with the proposed method on the problem of training a neural net on MNIST generalizes to the problems of training neural nets on the Toronto Faces Dataset, CIFAR-10 and CIFAR-100. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We learn an optimization algorithm that generalizes to unseen tasks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Learning to learn, meta-learning, reinforcement learning, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByuP8yZRb">
      <h4>
        <a href="https://openreview.net/forum?id=ByuP8yZRb">
          Censoring Representations with Multiple-Adversaries over Random Subspaces
        </a>
        
          <a href="https://openreview.net/pdf?id=ByuP8yZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=iwasawa%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="iwasawa@weblab.t.u-tokyo.ac.jp">Yusuke Iwasawa</a>, <a href="https://openreview.net/profile?email=nakayama%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="nakayama@weblab.t.u-tokyo.ac.jp">Kotaro Nakayama</a>, <a href="https://openreview.net/profile?email=matsuo%40weblab.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="matsuo@weblab.t.u-tokyo.ac.jp">Yutaka Matsuo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByuP8yZRb-details-528" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByuP8yZRb-details-528"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Adversarial feature learning (AFL) is one of the promising ways for explicitly constrains neural networks to learn desired representations; for example, AFL could help to learn anonymized representations so as to avoid privacy issues. AFL learn such a representations by training the networks to deceive the adversary that predict the sensitive information from the network, and therefore, the success of the AFL heavily relies on the choice of the adversary. This paper proposes a novel design of the adversary, {\em multiple adversaries over random subspaces} (MARS) that instantiate the concept of the {\em volunerableness}. The proposed method is motivated by an assumption that deceiving an adversary could fail to give meaningful information if the adversary is easily fooled, and adversary rely on single classifier suffer from this issues. 
      In contrast, the proposed method is designed to be less vulnerable, by utilizing the ensemble of independent classifiers where each classifier tries to predict sensitive variables from a different {\em subset} of the representations. 
      The empirical validations on three user-anonymization tasks show that our proposed method achieves state-of-the-art performances in all three datasets without significantly harming the utility of data. 
      This is significant because it gives new implications about designing the adversary, which is important to improve the performance of AFL. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper improves the quality of the recently proposed adversarial feature leaning (AFL) approach for incorporating explicit constrains to representations, by introducing the concept of the {\em vulnerableness} of the adversary. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Training, Privacy Protection, Random Subspace</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJzMATlAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJzMATlAZ">
          Deep Continuous Clustering
        </a>
        
          <a href="https://openreview.net/pdf?id=SJzMATlAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sohilas%40umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sohilas@umd.edu">Sohil Atul Shah</a>, <a href="https://openreview.net/profile?email=vkoltun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkoltun@gmail.com">Vladlen Koltun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJzMATlAZ-details-929" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJzMATlAZ-details-929"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Clustering high-dimensional datasets is hard because interpoint distances become less informative in high-dimensional spaces. We present a clustering algorithm that performs nonlinear dimensionality reduction and clustering jointly. The data is embedded into a lower-dimensional space by a deep autoencoder. The autoencoder is optimized as part of the clustering process. The resulting network produces clustered data. The presented approach does not rely on prior knowledge of the number of ground-truth clusters. Joint nonlinear dimensionality reduction and clustering are formulated as optimization of a global continuous objective. We thus avoid discrete reconfigurations of the objective that characterize prior clustering algorithms. Experiments on datasets from multiple domains demonstrate that the presented algorithm outperforms state-of-the-art clustering schemes, including recent methods that use deep networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A clustering algorithm that performs joint nonlinear dimensionality reduction and clustering by optimizing a global continuous objective.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">clustering, dimensionality reduction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryjw_eAaZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryjw_eAaZ">
          Unsupervised Deep Structure Learning by Recursive Dependency Analysis
        </a>
        
          <a href="https://openreview.net/pdf?id=ryjw_eAaZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=raanan.y.yehezkel.rohekar%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raanan.y.yehezkel.rohekar@intel.com">Raanan Y. Yehezkel Rohekar</a>, <a href="https://openreview.net/profile?email=guy.koren%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="guy.koren@intel.com">Guy Koren</a>, <a href="https://openreview.net/profile?email=shami.nisimov%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shami.nisimov@intel.com">Shami Nisimov</a>, <a href="https://openreview.net/profile?email=gal.novik%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gal.novik@intel.com">Gal Novik</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryjw_eAaZ-details-336" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryjw_eAaZ-details-336"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce an unsupervised structure learning algorithm for deep, feed-forward, neural networks. We propose a new interpretation for depth and inter-layer connectivity where a hierarchy of independencies in the input distribution is encoded in the network structure. This results in structures allowing neurons to connect to neurons in any deeper layer skipping intermediate layers. Moreover, neurons in deeper layers encode low-order (small condition sets) independencies and have a wide scope of the input, whereas neurons in the first layers encode higher-order (larger condition sets) independencies and have a narrower scope. Thus, the depth of the network is automatically determined---equal to the maximal order of independence in the input distribution, which is the recursion-depth of the algorithm. The proposed algorithm constructs two main graphical models: 1) a generative latent graph (a deep belief network) learned from data and 2) a deep discriminative graph constructed from the generative latent graph. We prove that conditional dependencies between the nodes in the learned generative latent graph are preserved in the class-conditional discriminative graph. Finally, a deep neural network structure is constructed based on the discriminative graph. We demonstrate on image classification benchmarks that the algorithm replaces the deepest layers (convolutional and dense layers) of common convolutional networks, achieving high classification accuracy, while constructing significantly smaller structures. The proposed structure learning algorithm requires a small computational cost and runs efficiently on a standard desktop CPU.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A principled approach for structure learning of deep neural networks with a new interpretation for depth and inter-layer connectivity. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, structure learning, deep belief networks, probabilistic graphical models, Bayesian networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk9kKMZ0-">
      <h4>
        <a href="https://openreview.net/forum?id=rk9kKMZ0-">
          LEAP: Learning Embeddings for Adaptive Pace
        </a>
        
          <a href="https://openreview.net/pdf?id=rk9kKMZ0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vthangar%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="vthangar@uoguelph.ca">Vithursan Thangarasa</a>, <a href="https://openreview.net/profile?email=gwtaylor%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gwtaylor@uoguelph.ca">Graham W. Taylor</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk9kKMZ0--details-875" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk9kKMZ0--details-875"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Determining the optimal order in which data examples are presented to Deep Neural Networks during training is a non-trivial problem. However, choosing a non-trivial scheduling method may drastically improve convergence. In this paper, we propose a Self-Paced Learning (SPL)-fused Deep Metric Learning (DML) framework, which we call Learning Embeddings for Adaptive Pace (LEAP). Our method parameterizes mini-batches dynamically based on the \textit{easiness} and \textit{true diverseness} of the sample within a salient feature representation space. In LEAP, we train an \textit{embedding} Convolutional Neural Network (CNN) to learn an expressive representation space by adaptive density discrimination using the Magnet Loss. The \textit{student} CNN classifier dynamically selects samples to form a mini-batch based on the \textit{easiness} from cross-entropy losses and \textit{true diverseness} of examples from the representation space sculpted by the \textit{embedding} CNN. We evaluate LEAP using deep CNN architectures for the task of supervised image classification on MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and SVHN. We show that the LEAP framework converges faster with respect to the number of mini-batch updates required to achieve a comparable or better test performance on each of the datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">LEAP combines the strength of adaptive sampling with that of mini-batch online learning and adaptive representation learning to formulate a representative self-paced strategy in an end-to-end DNN training protocol. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep metric learning, self-paced learning, representation learning, cnn</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkFEGHx0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SkFEGHx0Z">
          Nearest Neighbour Radial Basis Function Solvers for Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkFEGHx0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=benjamin.meyer%40monash.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="benjamin.meyer@monash.edu">Benjamin J. Meyer</a>, <a href="https://openreview.net/profile?email=ben.harwood%40monash.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ben.harwood@monash.edu">Ben Harwood</a>, <a href="https://openreview.net/profile?email=tom.drummond%40monash.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom.drummond@monash.edu">Tom Drummond</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkFEGHx0Z-details-61" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkFEGHx0Z-details-61"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a radial basis function solver for convolutional neural networks that can be directly applied to both distance metric learning and classification problems. Our method treats all training features from a deep neural network as radial basis function centres and computes loss by summing the influence of a feature's nearby centres in the embedding space. Having a radial basis function centred on each training feature is made scalable by treating it as an approximate nearest neighbour search problem. End-to-end learning of the network and solver is carried out, mapping high dimensional features into clusters of the same class. This results in a well formed embedding space, where semantically related instances are likely to be located near one another, regardless of whether or not the network was trained on those classes. The same loss function is used for both the metric learning and classification problems. We show that our radial basis function solver outperforms state-of-the-art embedding approaches on the Stanford Cars196 and CUB-200-2011 datasets. Additionally, we show that when used as a classifier, our method outperforms a conventional softmax classifier on the CUB-200-2011, Stanford Cars196, Oxford 102 Flowers and Leafsnap fine-grained classification datasets.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ695PxRW">
      <h4>
        <a href="https://openreview.net/forum?id=rJ695PxRW">
          Discovering Order in Unordered Datasets: Generative Markov Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ695PxRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yaohungt%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaohungt@cs.cmu.edu">Yao-Hung Hubert Tsai</a>, <a href="https://openreview.net/profile?email=han.zhao%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="han.zhao@cs.cmu.edu">Han Zhao</a>, <a href="https://openreview.net/profile?email=jojic%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jojic@microsoft.com">Nebojsa Jojic</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ695PxRW-details-101" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ695PxRW-details-101"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The assumption that data samples are independently identically distributed is the backbone of many learning algorithms. Nevertheless, datasets often exhibit rich structures in practice, and we argue that there exist some unknown orders within the data instances. Aiming to find such orders, we introduce a novel Generative Markov Network (GMN) which we use to extract the order of data instances automatically. Specifically, we assume that the instances are sampled from a Markov chain. Our goal is to learn the transitional operator of the chain as well as the generation order by maximizing the generation probability under all possible data permutations. One of our key ideas is to use neural networks as a soft lookup table for approximating the possibly huge, but discrete transition matrix. This strategy allows us to amortize the space complexity with a single model and make the transitional operator generalizable to unseen instances. To ensure the learned Markov chain is ergodic, we propose a greedy batch-wise permutation scheme that allows fast training.  Empirically, we evaluate the learned Markov chain by showing that GMNs are able to discover orders among data instances and also perform comparably well to state-of-the-art methods on the one-shot recognition benchmark task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Propose to observe implicit orders in datasets in a generative model viewpoint.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Markov chain, discovering orders, generative model, one-shot</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyuWNMZ0W">
      <h4>
        <a href="https://openreview.net/forum?id=SyuWNMZ0W">
          Directing Generative Networks with Weighted Maximum Mean Discrepancy
        </a>
        
          <a href="https://openreview.net/pdf?id=SyuWNMZ0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=momod%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="momod@utexas.edu">Maurice Diesendruck</a>, <a href="https://openreview.net/profile?email=guywcole%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guywcole@utexas.edu">Guy W. Cole</a>, <a href="https://openreview.net/profile?email=sinead.williamson%40mccombs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sinead.williamson@mccombs.utexas.edu">Sinead Williamson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyuWNMZ0W-details-188" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyuWNMZ0W-details-188"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The maximum mean discrepancy (MMD) between two probability measures P
      and Q is a metric that is zero if and only if all moments of the two measures
      are equal, making it an appealing statistic for two-sample tests. Given i.i.d. samples
      from P and Q, Gretton et al. (2012) show that we can construct an unbiased
      estimator for the square of the MMD between the two distributions. If P is a
      distribution of interest and Q is the distribution implied by a generative neural
      network with stochastic inputs, we can use this estimator to train our neural network.
      However, in practice we do not always have i.i.d. samples from our target
      of interest. Data sets often exhibit biases—for example, under-representation of
      certain demographics—and if we ignore this fact our machine learning algorithms
      will propagate these biases. Alternatively, it may be useful to assume our data has
      been gathered via a biased sample selection mechanism in order to manipulate
      properties of the estimating distribution Q.
      In this paper, we construct an estimator for the MMD between P and Q when we
      only have access to P via some biased sample selection mechanism, and suggest
      methods for estimating this sample selection mechanism when it is not already
      known. We show that this estimator can be used to train generative neural networks
      on a biased data sample, to give a simulator that reverses the effect of that
      bias.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an estimator for the maximum mean discrepancy, appropriate when a target distribution is only accessible via a biased sample selection procedure, and show that it can be used in a generative network to correct for this bias.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative networks, two sample tests, bias correction, maximum mean discrepancy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HydnA1WCb">
      <h4>
        <a href="https://openreview.net/forum?id=HydnA1WCb">
          Gaussian Prototypical Networks for Few-Shot Learning on Omniglot
        </a>
        
          <a href="https://openreview.net/pdf?id=HydnA1WCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sfort1%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sfort1@stanford.edu">Stanislav Fort</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HydnA1WCb-details-876" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HydnA1WCb-details-876"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel architecture for k-shot classification on the Omniglot dataset. Building on prototypical networks, we extend their architecture to what we call Gaussian prototypical networks. Prototypical networks learn a map between images and embedding vectors, and use their clustering for classification. In our model, a part of the encoder output is interpreted as a confidence region estimate about the embedding point, and expressed as a Gaussian covariance matrix. Our network then constructs a direction and class dependent distance metric on the embedding space, using uncertainties of individual data points as weights. We show that Gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent number of parameters. We report results consistent with state-of-the-art performance in 1-shot and 5-shot classification both in 5-way and 20-way regime on the Omniglot dataset. We explore artificially down-sampling a fraction of images in the training set, which improves our performance. Our experiments therefore lead us to hypothesize that Gaussian prototypical networks might perform better in less homogeneous, noisier datasets, which are commonplace in real world applications.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel architecture for few-shot classification capable of dealing with uncertainty.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">one-shot learning, few-shot learning, Omniglot</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryH_bShhW">
      <h4>
        <a href="https://openreview.net/forum?id=ryH_bShhW">
          DOUBLY STOCHASTIC ADVERSARIAL AUTOENCODER
        </a>
        
          <a href="https://openreview.net/pdf?id=ryH_bShhW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mazarafrooz%40cylance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mazarafrooz@cylance.com">Mahdi Azarafrooz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryH_bShhW-details-795" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryH_bShhW-details-795"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Any autoencoder network can be turned into a generative model by imposing an arbitrary prior distribution on its hidden code vector. Variational Autoencoder uses a KL divergence penalty to impose the prior, whereas Adversarial Autoencoder uses generative adversarial networks.  A straightforward modification of Adversarial Autoencoder can be achieved by replacing the adversarial network with maximum mean discrepancy (MMD) network. This replacement leads to a new set of probabilistic autoencoder which is also discussed in our paper.
      
      However, an essential challenge remains in both of these probabilistic autoencoders, namely that the only source of randomness at the output of encoder, is the training data itself.  Lack of enough stochasticity can make the optimization problem non-trivial. As a result, they can lead to degenerate solutions where the generator collapses into sampling only a few modes.
      
      Our proposal is to replace the adversary of the adversarial autoencoder by a space of {\it stochastic} functions. This replacement introduces a a new source of randomness which can be considered as a continuous control for encouraging {\it explorations}. This prevents the adversary from fitting too closely to the generator and therefore leads to more diverse set of generated samples. Consequently, the decoder serves as a better generative network which unlike MMD nets scales linearly with the amount of data. We provide mathematical and empirical evidence on how this replacement outperforms the pre-existing architectures.   </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative adversarial Networks, Deep Generative models, Kernel Methods</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk6qdGgCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rk6qdGgCZ">
          Fixing Weight Decay Regularization in Adam
        </a>
        
          <a href="https://openreview.net/pdf?id=rk6qdGgCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ilya.loshchilov%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilya.loshchilov@gmail.com">Ilya Loshchilov</a>, <a href="https://openreview.net/profile?email=fh%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="fh@cs.uni-freiburg.de">Frank Hutter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>23 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk6qdGgCZ-details-150" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk6qdGgCZ-details-150"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We note that common implementations of adaptive gradient algorithms, such as Adam, limit the potential benefit of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an additive constant factor. 
      We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) 
      decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam, and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter).
      We also demonstrate that longer optimization runs require smaller weight decay values for optimal results and introduce a normalized variant of weight decay to reduce this dependence. Finally, we propose a version of Adam with warm restarts (AdamWR) that has strong anytime performance while achieving state-of-the-art results on CIFAR-10 and ImageNet32x32. 
      Our source code will become available after the review process.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Fixing weight decay regularization in adaptive gradient methods such as Adam</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adam, Adaptive Gradient Methods, weight decay, L2 regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJaU__eCZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJaU__eCZ">
          Hallucinating brains with artificial brains
        </a>
        
          <a href="https://openreview.net/pdf?id=BJaU__eCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=py_zhuang%40bupt.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="py_zhuang@bupt.edu.cn">Peiye Zhuang</a>, <a href="https://openreview.net/profile?email=aschwing%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aschwing@illinois.edu">Alexander G. Schwing</a>, <a href="https://openreview.net/profile?email=sanmi%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanmi@illinois.edu">Oluwasanmi Koyejo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJaU__eCZ-details-802" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJaU__eCZ-details-802"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Human brain function as measured by functional magnetic resonance imaging
      (fMRI), exhibits a rich diversity. In response, understanding the individual variability
      of brain function and its association with behavior has become one of the
      major concerns in modern cognitive neuroscience. Our work is motivated by the
      view that generative models provide a useful tool for understanding this variability.
      To this end, this manuscript presents two novel generative models trained
      on real neuroimaging data which synthesize task-dependent functional brain images.
      Brain images are high dimensional tensors which exhibit structured spatial
      correlations. Thus, both models are 3D conditional Generative Adversarial networks
      (GANs) which apply Convolutional Neural Networks (CNNs) to learn an
      abstraction of brain image representations. Our results show that the generated
      brain images are diverse, yet task dependent. In addition to qualitative evaluation,
      we utilize the generated synthetic brain volumes as additional training data to improve
      downstream fMRI classifiers (also known as decoding, or brain reading).
      Our approach achieves significant improvements for a variety of datasets, classifi-
      cation tasks and evaluation scores. Our classification results provide a quantitative
      evaluation of the quality of the generated images, and also serve as an additional
      contribution of this manuscript.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Two novel GANs are constructed to generate high-quality 3D fMRI brain images and synthetic brain images greatly help to improve downstream classification tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">3D fMRI data, Deep Learning, Generative Adversarial Network, Classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy1f0e-R-">
      <h4>
        <a href="https://openreview.net/forum?id=Sy1f0e-R-">
          An empirical study on evaluation metrics of generative adversarial networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy1f0e-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gh349%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gh349@cornell.edu">Gao Huang</a>, <a href="https://openreview.net/profile?email=yy528%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yy528@cornell.edu">Yang Yuan</a>, <a href="https://openreview.net/profile?email=qx57%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qx57@cornell.edu">Qiantong Xu</a>, <a href="https://openreview.net/profile?email=cg563%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cg563@cornell.edu">Chuan Guo</a>, <a href="https://openreview.net/profile?email=yusun%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yusun@berkeley.edu">Yu Sun</a>, <a href="https://openreview.net/profile?email=fw245%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fw245@cornell.edu">Felix Wu</a>, <a href="https://openreview.net/profile?email=kqw4%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kqw4@cornell.edu">Kilian Weinberger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy1f0e-R--details-131" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy1f0e-R--details-131"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite the widespread interest in generative adversarial networks (GANs), few works have studied the metrics that quantitatively evaluate GANs' performance. In this paper, we revisit several representative sample-based evaluation metrics for GANs, and address the important problem of \emph{how to evaluate the evaluation metrics}. We start with a few necessary conditions for metrics to produce meaningful scores, such as distinguishing real from generated samples, identifying mode dropping and mode collapsing, and detecting overfitting. Then with a series of carefully designed experiments,  we are able to comprehensively investigate existing sample-based metrics and identify their strengths and limitations in practical settings. Based on these results, we observe that kernel Maximum Mean Discrepancy (MMD) and the 1-Nearest-Neighbour (1-NN) two-sample test seem to satisfy most of the desirable properties, provided that the distances between samples are computed in a suitable feature space. Our experiments also unveil interesting properties about the behavior of several popular GAN models, such as whether they are memorizing training samples, and how far these state-of-the-art GANs are from perfect.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, evaluation metric</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syjha0gAZ">
      <h4>
        <a href="https://openreview.net/forum?id=Syjha0gAZ">
          Loss Functions for Multiset Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=Syjha0gAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wellecks%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wellecks@nyu.edu">Sean Welleck</a>, <a href="https://openreview.net/profile?email=zy566%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zy566@nyu.edu">Zixin Yao</a>, <a href="https://openreview.net/profile?email=yg1246%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yg1246@nyu.edu">Yu Gai</a>, <a href="https://openreview.net/profile?email=jm5830%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jm5830@nyu.edu">Jialin Mao</a>, <a href="https://openreview.net/profile?email=zz%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zz@nyu.edu">Zheng Zhang</a>, <a href="https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syjha0gAZ-details-796" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syjha0gAZ-details-796"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We study the problem of multiset prediction and propose a novel multiset loss function, providing analysis and empirical evidence that demonstrates its effectiveness.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine learning, deep learning, structured prediction, sequential prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJme6-ZR-">
      <h4>
        <a href="https://openreview.net/forum?id=SJme6-ZR-">
          A Deep Learning Approach for Survival Clustering without End-of-life Signals
        </a>
        
          <a href="https://openreview.net/pdf?id=SJme6-ZR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chandr%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chandr@purdue.edu">S Chandra Mouli</a>, <a href="https://openreview.net/profile?email=ribeiro%40cs.purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ribeiro@cs.purdue.edu">Bruno Ribeiro</a>, <a href="https://openreview.net/profile?email=neville%40cs.purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="neville@cs.purdue.edu">Jennifer Neville</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJme6-ZR--details-875" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJme6-ZR--details-875"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The goal of survival clustering is to map subjects (e.g., users in a social network, patients in a medical study) to $K$ clusters ranging from low-risk to high-risk. Existing survival methods assume the presence of clear \textit{end-of-life} signals or introduce them artificially using a pre-defined timeout. In this paper, we forego this assumption and introduce a loss function that differentiates between the empirical lifetime distributions of the clusters using a modified Kuiper statistic. We learn a deep neural network by optimizing this loss, that performs a soft clustering of users into survival groups. We apply our method to a social network dataset with over 1M subjects, and show significant improvement in C-index compared to alternatives.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The goal of survival clustering is to map subjects into clusters. Without end-of-life signals, this is a challenging task. To address this task we propose a new loss function by modifying the Kuiper statistics.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Survival Analysis, Kuiper statistics, model-free</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bys_NzbC-">
      <h4>
        <a href="https://openreview.net/forum?id=Bys_NzbC-">
          Achieving Strong Regularization for Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Bys_NzbC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pdhvip%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pdhvip@gmail.com">Dae Hoon Park</a>, <a href="https://openreview.net/profile?email=chiuman100%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chiuman100@gmail.com">Chiu Man Ho</a>, <a href="https://openreview.net/profile?email=yi.chang%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yi.chang@huawei.com">Yi Chang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bys_NzbC--details-976" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bys_NzbC--details-976"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">L1 and L2 regularizers are critical tools in machine learning due to their ability to simplify solutions. However, imposing strong L1 or L2 regularization with gradient descent method easily fails, and this limits the generalization ability of the underlying neural networks. To understand this phenomenon, we investigate how and why training fails for strong regularization. Specifically, we examine how gradients change over time for different regularization strengths and provide an analysis why the gradients diminish so fast. We find that there exists a tolerance level of regularization strength, where the learning completely fails if the regularization strength goes beyond it. We propose a simple but novel method, Delayed Strong Regularization, in order to moderate the tolerance level. Experiment results show that our proposed approach indeed achieves strong regularization for both L1 and L2 regularizers and improves both accuracy and sparsity on public data sets. Our source code is published.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We investigate how and why strong L1/L2 regularization fails and propose a method than can achieve strong regularization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkOhuyA6-">
      <h4>
        <a href="https://openreview.net/forum?id=HkOhuyA6-">
          Graph Classification with 2D Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HkOhuyA6-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=antoine.tixier-1%40colorado.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoine.tixier-1@colorado.edu">Antoine J.-P. Tixier</a>, <a href="https://openreview.net/profile?email=giannisnik%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="giannisnik@hotmail.com">Giannis Nikolentzos</a>, <a href="https://openreview.net/profile?email=p.meladianos%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="p.meladianos@gmail.com">Polykarpos Meladianos</a>, <a href="https://openreview.net/profile?email=mvazirg%40lix.polytechnique.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="mvazirg@lix.polytechnique.fr">Michalis Vazirgiannis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkOhuyA6--details-124" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkOhuyA6--details-124"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Graph classification is currently dominated by graph kernels, which, while powerful, suffer some significant limitations. Convolutional Neural Networks (CNNs) offer a very appealing alternative. However, processing graphs with CNNs is not trivial. To address this challenge, many sophisticated extensions of CNNs have recently been proposed. In this paper, we reverse the problem: rather than proposing yet another graph CNN model, we introduce a novel way to represent graphs as multi-channel image-like structures that allows them to be handled by vanilla 2D CNNs. Despite its simplicity, our method proves very competitive to state-of-the-art graph kernels and graph CNNs, and outperforms them by a wide margin on some datasets. It is also preferable to graph kernels in terms of time complexity. Code and data are publicly available.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a novel way to represent graphs as multi-channel image-like structures that allows them to be handled by vanilla 2D CNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph classification, convolutional neural networks, 2D CNN, representation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyW4Gjg0W">
      <h4>
        <a href="https://openreview.net/forum?id=SyW4Gjg0W">
          Kernel Graph Convolutional Neural Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=SyW4Gjg0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=giannisnik%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="giannisnik@hotmail.com">Giannis Nikolentzos</a>, <a href="https://openreview.net/profile?email=pmeladianos%40aueb.gr" class="profile-link" data-toggle="tooltip" data-placement="top" title="pmeladianos@aueb.gr">Polykarpos Meladianos</a>, <a href="https://openreview.net/profile?email=antoine.tixier-1%40colorado.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoine.tixier-1@colorado.edu">Antoine J-P Tixier</a>, <a href="https://openreview.net/profile?email=kskianis%40lix.polytechnique.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kskianis@lix.polytechnique.fr">Konstantinos Skianis</a>, <a href="https://openreview.net/profile?email=mvazirg%40lix.polytechnique.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="mvazirg@lix.polytechnique.fr">Michalis Vazirgiannis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyW4Gjg0W-details-146" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyW4Gjg0W-details-146"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Graph kernels have been successfully applied to many graph classification problems. Typically, a kernel is first designed, and then an SVM classifier is trained based on the features defined implicitly by this kernel. This two-stage approach decouples data representation from learning, which is suboptimal. On the other hand, Convolutional Neural Networks (CNNs) have the capability to learn their own features directly from the raw data during training. Unfortunately, they cannot handle irregular data such as graphs. We address this challenge by using graph kernels to embed meaningful local neighborhoods of the graphs in a continuous vector space. A set of filters is then convolved with these patches, pooled, and the output is then passed to a feedforward network. With limited parameter tuning, our approach outperforms strong baselines on 7 out of 10 benchmark datasets, and reaches comparable performance elsewhere. Code and data are publicly available.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkVsWbbAW">
      <h4>
        <a href="https://openreview.net/forum?id=BkVsWbbAW">
          Deep Generative Dual Memory Network for Continual Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BkVsWbbAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nkamra%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nkamra@usc.edu">Nitin Kamra</a>, <a href="https://openreview.net/profile?email=umanggup%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="umanggup@usc.edu">Umang Gupta</a>, <a href="https://openreview.net/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkVsWbbAW-details-102" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkVsWbbAW-details-102"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite advances in deep learning, artificial neural networks do not learn the same way as humans do. Today, neural networks can learn multiple tasks when trained on them jointly, but cannot maintain performance on learnt tasks when tasks are presented one at a time -- this phenomenon called catastrophic forgetting is a fundamental challenge to overcome before neural networks can learn continually from incoming data. In this work, we derive inspiration from human memory to develop an architecture capable of learning continuously from sequentially incoming tasks, while averting catastrophic forgetting. Specifically, our model consists of a dual memory architecture to emulate the complementary learning systems (hippocampus and the neocortex) in the human brain and maintains a consolidated long-term memory via generative replay of past experiences. We (i) substantiate our claim that replay should be generative, (ii) show the benefits of generative replay and dual memory via experiments, and (iii) demonstrate improved performance retention even for small models with low capacity. Our architecture displays many important characteristics of the human memory and provides insights on the connection between sleep and learning in humans.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A dual memory architecture inspired from human brain to learn sequentially incoming tasks, while averting catastrophic forgetting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Continual Learning, Catastrophic Forgetting, Sequential Multitask Learning, Deep Generative Models, Dual Memory Networks, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ5AUm-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJ5AUm-CZ">
          The Variational Homoencoder: Learning to Infer High-Capacity Generative Models from Few Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ5AUm-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lbh%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbh@mit.edu">Luke Hewitt</a>, <a href="https://openreview.net/profile?email=agane%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="agane@mit.edu">Andrea Gane</a>, <a href="https://openreview.net/profile?email=tommi%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tommi@csail.mit.edu">Tommi Jaakkola</a>, <a href="https://openreview.net/profile?email=jbt%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbt@mit.edu">Joshua B. Tenenbaum</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ5AUm-CZ-details-221" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ5AUm-CZ-details-221"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Hierarchical Bayesian methods have the potential to unify many related tasks (e.g. k-shot classification, conditional, and unconditional generation) by framing each as inference within a single generative model. We show that existing approaches for learning such models can fail on expressive generative networks such as PixelCNNs, by describing the global distribution with little reliance on latent variables. To address this, we develop a modification of the Variational Autoencoder in which encoded observations are decoded to new elements from the same class; the result, which we call a Variational Homoencoder (VHE), may be understood as training a hierarchical latent variable model which better utilises latent variables in these cases. Using this framework enables us to train a hierarchical PixelCNN for the Omniglot dataset, outperforming all existing models on test set likelihood. With a single model we achieve both strong one-shot generation and near human-level classification, competitive with state-of-the-art discriminative classifiers. The VHE objective extends naturally to richer dataset structures such as factorial or hierarchical categories, as we illustrate by training models to separate character content from simple variations in drawing style, and to generalise the style of an alphabet to new characters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Technique for learning deep generative models with shared latent variables, applied to Omniglot with a PixelCNN decoder.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative models, one-shot learning, metalearning, pixelcnn, hierarchical bayesian, omniglot</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkp3uhxCW">
      <h4>
        <a href="https://openreview.net/forum?id=Hkp3uhxCW">
          Revisiting Bayes by Backprop
        </a>
        
          <a href="https://openreview.net/pdf?id=Hkp3uhxCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=meirefortunato%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="meirefortunato@google.com">Meire Fortunato</a>, <a href="https://openreview.net/profile?email=cblundell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cblundell@google.com">Charles Blundell</a>, <a href="https://openreview.net/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hkp3uhxCW-details-75" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkp3uhxCW-details-75"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work we explore a straightforward variational Bayes scheme for Recurrent Neural Networks.
      Firstly, we show that a simple adaptation of truncated backpropagation through time can yield good quality uncertainty estimates and superior regularisation at only a small extra computational cost during training, also reducing the amount of parameters by 80\%.
      Secondly, we demonstrate how a novel kind of posterior approximation yields further improvements to the performance of Bayesian RNNs. We incorporate local gradient information into the approximate posterior to sharpen it around the current batch statistics. We show how this technique is not exclusive to recurrent neural networks and can be applied more widely to train Bayesian neural networks.
      We also empirically demonstrate how Bayesian RNNs are superior to traditional RNNs on a language modelling benchmark and an image captioning task, as well as showing how each of these methods improve our model over a variety of other schemes for training them. We also introduce a new benchmark for studying uncertainty for language models so future methods can be easily compared.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> Variational Bayes scheme for Recurrent Neural Networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Bayesian, Deep Learning, Recurrent Neural Networks, LSTM</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1fduCl0b">
      <h4>
        <a href="https://openreview.net/forum?id=S1fduCl0b">
          Lifelong Generative Modeling
        </a>
        
          <a href="https://openreview.net/pdf?id=S1fduCl0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jason.ramapuram%40etu.unige.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="jason.ramapuram@etu.unige.ch">Jason Ramapuram</a>, <a href="https://openreview.net/profile?email=magda.gregorova%40unige.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="magda.gregorova@unige.ch">Magda Gregorova</a>, <a href="https://openreview.net/profile?email=alexandros.kalousis%40hesge.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexandros.kalousis@hesge.ch">Alexandros Kalousis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1fduCl0b-details-976" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1fduCl0b-details-976"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Lifelong learning is the problem of learning multiple consecutive tasks in a sequential manner where knowledge gained from previous tasks is retained and used for future learning. It is essential towards the development of intelligent machines that can adapt to their surroundings. In this work we focus on a lifelong learning approach to generative modeling where we continuously incorporate newly observed streaming distributions into our learnt model. We do so through a student-teacher architecture which allows us to learn and preserve all the distributions seen so far without the need to retain the past data nor the past models. Through the introduction of a novel cross-model regularizer, the student model leverages the information learnt by the teacher, which acts as a summary of everything seen till now. The regularizer has the additional benefit of reducing the effect of catastrophic interference that appears when we learn over streaming data. We demonstrate its efficacy on streaming distributions as well as its ability to learn a common latent representation across a complex transfer learning scenario.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Lifelong distributional learning through a student-teacher architecture coupled with a cross model posterior regularizer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Lifelong, Generative Modeling, Variational Autoencoder, VAE, Catastrophic Interference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkDB51WR-">
      <h4>
        <a href="https://openreview.net/forum?id=BkDB51WR-">
          Learning temporal evolution of probability distribution with Recurrent Neural Network
        </a>
        
          <a href="https://openreview.net/pdf?id=BkDB51WR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kyeo%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyeo@us.ibm.com">Kyongmin Yeo</a>, <a href="https://openreview.net/profile?email=igor.melnyk%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="igor.melnyk@ibm.com">Igor Melnyk</a>, <a href="https://openreview.net/profile?email=nnguyen%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nnguyen@us.ibm.com">Nam Nguyen</a>, <a href="https://openreview.net/profile?email=eunkyung.lee%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eunkyung.lee@us.ibm.com">Eun Kyung Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkDB51WR--details-785" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkDB51WR--details-785"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose to tackle a time series regression problem by computing temporal evolution of a probability density function to provide a probabilistic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of a probability density function. We use a softmax layer for a numerical discretization of a smooth probability density functions, which transforms a function approximation problem to a classification task. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A Monte Carlo procedure to compute the temporal evolution of the distribution for a multiple-step forecast is presented. The evaluation of the proposed algorithm on three synthetic and two real data sets shows advantage over the compared baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Proposed RNN-based algorithm to estimate predictive distribution in one- and multi-step forecasts in time series prediction problems</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">predictive distribution estimation, probabilistic RNN, uncertainty in time series prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1nLkl-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=B1nLkl-0Z">
          Learning Gaussian Policies from Smoothed Action Value Functions
        </a>
        
          <a href="https://openreview.net/pdf?id=B1nLkl-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ofirnachum%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ofirnachum@google.com">Ofir Nachum</a>, <a href="https://openreview.net/profile?email=mnorouzi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mnorouzi@google.com">Mohammad Norouzi</a>, <a href="https://openreview.net/profile?email=gjt%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gjt@google.com">George Tucker</a>, <a href="https://openreview.net/profile?email=schuurmans%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schuurmans@google.com">Dale Schuurmans</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1nLkl-0Z-details-765" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1nLkl-0Z-details-765"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">State-action value functions (i.e., Q-values) are ubiquitous in reinforcement learning (RL), giving rise to popular algorithms such as SARSA and Q-learning. We propose a new notion of action value defined by a Gaussian smoothed version of the expected Q-value used in SARSA. We show that such smoothed Q-values still satisfy a Bellman equation, making them naturally learnable from experience sampled from an environment. Moreover, the gradients of expected reward with respect to the mean and covariance of a parameterized Gaussian policy can be recovered from the gradient and Hessian of the smoothed Q-value function. Based on these relationships we develop new algorithms for training a Gaussian policy directly from a learned Q-value approximator. The approach is also amenable to proximal optimization techniques by augmenting the objective with a penalty on KL-divergence from a previous policy. We find that the ability to learn both a mean and covariance during training allows this approach to achieve strong results on standard continuous control benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new Q-value function that enables better learning of Gaussian policies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SySisz-CW">
      <h4>
        <a href="https://openreview.net/forum?id=SySisz-CW">
          On the difference between building and extracting patterns: a causal analysis of deep generative models.
        </a>
        
          <a href="https://openreview.net/pdf?id=SySisz-CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=michel.besserve%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="michel.besserve@tuebingen.mpg.de">Michel Besserve</a>, <a href="https://openreview.net/profile?email=dominik.janzing%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="dominik.janzing@tuebingen.mpg.de">Dominik Janzing</a>, <a href="https://openreview.net/profile?email=bs%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tuebingen.mpg.de">Bernhard Schoelkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SySisz-CW-details-9" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SySisz-CW-details-9"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative models are important tools to capture and investigate the properties of complex empirical data. Recent developments such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) use two very similar, but \textit{reverse}, deep convolutional architectures, one to generate and one to extract information from data. Does learning the parameters of both architectures obey the same rules? We exploit the causality principle of independence of mechanisms to quantify how the weights of successive layers adapt to each other. Using the recently introduced Spectral Independence Criterion, we quantify the dependencies between the kernels of successive convolutional layers and show that those are more independent for the generative process than for information extraction, in line with results from the field of causal inference. In addition, our experiments on generation of human faces suggest that more independence between successive layers of generators results in improved performance of these architectures.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use causal inference to characterise the architecture of generative models</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, VAE, causality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkcya1ZAW">
      <h4>
        <a href="https://openreview.net/forum?id=rkcya1ZAW">
          Continuous-Time Flows for Efficient Inference and Density Estimation
        </a>
        
          <a href="https://openreview.net/pdf?id=rkcya1ZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cchangyou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cchangyou@gmail.com">Changyou Chen</a>, <a href="https://openreview.net/profile?email=chunyuan.li%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chunyuan.li@duke.edu">Chunyuan Li</a>, <a href="https://openreview.net/profile?email=lc267%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lc267@duke.edu">Liqun Chen</a>, <a href="https://openreview.net/profile?email=wenlin.wang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenlin.wang@duke.edu">Wenlin Wang</a>, <a href="https://openreview.net/profile?email=yunchen.pu%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yunchen.pu@duke.edu">Yunchen Pu</a>, <a href="https://openreview.net/profile?email=lcarin%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcarin@duke.edu">Lawrence Carin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkcya1ZAW-details-478" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkcya1ZAW-details-478"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Two fundamental problems in unsupervised learning are efficient inference for latent-variable models and robust density estimation based on large amounts of unlabeled data. For efficient inference, normalizing flows have been recently developed to approximate a target distribution arbitrarily well. In practice, however, normalizing flows only consist of a finite number of deterministic transformations, and thus they possess no guarantee on the approximation accuracy. For density estimation, the generative adversarial network (GAN) has been advanced as an appealing model, due to its often excellent performance in generating samples. In this paper, we propose the concept of {\em continuous-time flows} (CTFs), a family of diffusion-based methods that are able to asymptotically approach a target distribution. Distinct from normalizing flows and GANs, CTFs can be adopted to achieve the above two goals in one framework, with theoretical guarantees. Our framework includes distilling knowledge from a CTF for efficient inference, and learning an explicit  energy-based distribution with CTFs for density estimation. Experiments on various tasks demonstrate promising performance of the proposed CTF framework, compared to related techniques.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">continuous-time flows, efficient inference, density estimation, deep generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJLTTe-0W">
      <h4>
        <a href="https://openreview.net/forum?id=rJLTTe-0W">
          Bayesian Time Series Forecasting with Change Point and Anomaly Detection
        </a>
        
          <a href="https://openreview.net/pdf?id=rJLTTe-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ye.zhang%40yale.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ye.zhang@yale.edu">Anderson Y. Zhang</a>, <a href="https://openreview.net/profile?email=mlu%40oath.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mlu@oath.com">Miao Lu</a>, <a href="https://openreview.net/profile?email=dkong%40oath.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkong@oath.com">Deguang Kong</a>, <a href="https://openreview.net/profile?email=jianyang%40oath.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianyang@oath.com">Jimmy Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJLTTe-0W-details-268" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJLTTe-0W-details-268"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Time series forecasting plays a crucial role in marketing, finance and many other quantitative fields. A large amount of methodologies has been developed on this topic, including ARIMA, Holt–Winters, etc. However, their performance is easily undermined by the existence of change points and anomaly points, two structures commonly observed in real data, but rarely considered in the aforementioned methods. In this paper, we propose a novel state space time series model, with the capability to capture the structure of change points and anomaly points, as well as trend and seasonality. To infer all the hidden variables, we develop a Bayesian framework, which is able to obtain distributions and forecasting intervals for time series forecasting, with provable theoretical properties. For implementation, an iterative algorithm with Markov chain Monte Carlo (MCMC), Kalman filter and Kalman smoothing is proposed. In both synthetic data and real data applications, our methodology yields a better performance in time series forecasting compared with existing methods, along with more accurate change point detection and anomaly detection.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel state space time series model with the capability to capture the structure of change points and anomaly points, so that it has a better forecasting performance when there exist change points and anomalies in the time series.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Time Series Forecasting, Change Point Detection, Anomaly Detection, State Space Model, Bayesian</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1drp-WCZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1drp-WCZ">
          State Space LSTM Models with Particle MCMC Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=r1drp-WCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xunzheng90%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xunzheng90@gmail.com">Xun Zheng</a>, <a href="https://openreview.net/profile?email=manzil%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="manzil@cmu.edu">Manzil Zaheer</a>, <a href="https://openreview.net/profile?email=amra%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amra@google.com">Amr Ahmed</a>, <a href="https://openreview.net/profile?email=yuanwang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanwang@google.com">Yuan Wang</a>, <a href="https://openreview.net/profile?email=epxing%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="epxing@cs.cmu.edu">Eric P. Xing</a>, <a href="https://openreview.net/profile?email=alex%40smola.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="alex@smola.org">Alex Smola</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1drp-WCZ-details-119" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1drp-WCZ-details-119"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Long Short-Term Memory (LSTM) is one of the most powerful sequence models. Despite the strong performance, however, it lacks the nice interpretability as in state space models. In this paper, we present a way to combine the best of both worlds by introducing State Space LSTM (SSL), which generalizes the earlier work \cite{zaheer2017latent} of combining topic models with LSTM. However, unlike \cite{zaheer2017latent}, we do not make any factorization assumptions in our inference algorithm. We present an efficient sampler based on sequential Monte Carlo (SMC) method that draws from the joint posterior directly. Experimental results confirms the superiority and stability of this SMC inference algorithm on a variety of domains.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present State Space LSTM models, a combination of state space models and LSTMs, and propose an inference algorithm based on sequential Monte Carlo. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, state space models, sequential Monte Carlo</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1tWRJ-R-">
      <h4>
        <a href="https://openreview.net/forum?id=S1tWRJ-R-">
          Joint autoencoders: a flexible meta-learning framework
        </a>
        
          <a href="https://openreview.net/pdf?id=S1tWRJ-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=baruch.epstein%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="baruch.epstein@gmail.com">Baruch Epstein</a>, <a href="https://openreview.net/profile?email=rmeir%40ee.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="rmeir@ee.technion.ac.il">Ron Meir</a>, <a href="https://openreview.net/profile?email=tomer.m%40ee.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomer.m@ee.technion.ac.il">Tomer Michaeli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1tWRJ-R--details-501" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1tWRJ-R--details-501"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The incorporation of prior knowledge into learning is essential in achieving good performance based on small noisy samples. Such knowledge is often incorporated through the availability of related data arising from domains and tasks similar to the one of current interest. Ideally one would like to allow both the data for the current task and for previous related tasks to self-organize the learning system in such a way that commonalities and differences between the tasks are learned in a data-driven fashion. We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches, dealing with the common features of all tasks, and private branches, learning the specific unique aspects of each task. Once an appropriate weight sharing architecture has been established, learning takes place through standard algorithms for feedforward networks, e.g., stochastic gradient descent and its variations. The method deals with meta-learning (such as domain adaptation, transfer and multi-task learning) in a unified fashion, and can easily deal with data arising from different types of sources. Numerical experiments demonstrate the effectiveness of learning in domain adaptation and transfer learning setups, and provide evidence for the flexible and task-oriented representations arising in the network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A generic framework for handling transfer and multi-task learning using pairs of autoencoders with task-specific and shared weights.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">transfer learning, domain adaptation, unsupervised learning, autoencoders, multi-task learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkbJTYyAb">
      <h4>
        <a href="https://openreview.net/forum?id=HkbJTYyAb">
          Convolutional Normalizing Flows
        </a>
        
          <a href="https://openreview.net/pdf?id=HkbJTYyAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gzheng%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gzheng@cs.cmu.edu">Guoqing Zheng</a>, <a href="https://openreview.net/profile?email=yiming%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiming@cs.cmu.edu">Yiming Yang</a>, <a href="https://openreview.net/profile?email=jgc%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgc@cs.cmu.edu">Jaime Carbonell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkbJTYyAb-details-115" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkbJTYyAb-details-115"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Bayesian posterior inference is prevalent in various machine learning problems. Variational inference provides one way to approximate the posterior distribution, however its expressive power is limited and so is the accuracy of resulting approximation. Recently, there has a trend of using neural networks to approximate the variational posterior distribution due to the flexibility of neural network architecture. One way to construct flexible variational distribution is to warp a simple density into a complex by normalizing flows, where the resulting density can be analytically evaluated. However, there is a trade-off between the flexibility of normalizing flow and computation cost for efficient transformation. In this paper, we propose a simple yet effective architecture of normalizing flows, ConvFlow, based on convolution over the dimensions of random input vector. Experiments on synthetic and real world posterior inference problems demonstrate the effectiveness and efficiency of the proposed method.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkhCSO4T-">
      <h4>
        <a href="https://openreview.net/forum?id=rkhCSO4T-">
          Distributed non-parametric deep and wide networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rkhCSO4T-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=biswasengupta%40yahoo.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="biswasengupta@yahoo.com">Biswa Sengupta</a>, <a href="https://openreview.net/profile?email=yu.qian%40cortexica.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yu.qian@cortexica.com">Yu Qian</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkhCSO4T--details-796" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkhCSO4T--details-796"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In recent work, it was shown that combining multi-kernel based support vector machines (SVMs) can lead to near state-of-the-art performance on an action recognition dataset (HMDB-51 dataset). In the present work, we show that combining distributed Gaussian Processes with multi-stream deep convolutional neural networks (CNN) alleviate the need to augment a neural network with hand-crafted features. In contrast to prior work, we treat each deep neural convolutional network as an expert wherein the individual predictions (and their respective uncertainties) are combined into a Product of Experts (PoE) framework.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJjePwx0-">
      <h4>
        <a href="https://openreview.net/forum?id=HJjePwx0-">
          Better Generalization by Efficient Trust Region Method
        </a>
        
          <a href="https://openreview.net/pdf?id=HJjePwx0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xqliu%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xqliu@ucdavis.edu">Xuanqing Liu</a>, <a href="https://openreview.net/profile?email=jasondlee88%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jasondlee88@gmail.com">Jason D. Lee</a>, <a href="https://openreview.net/profile?email=chohsieh%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@ucdavis.edu">Cho-Jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJjePwx0--details-769" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJjePwx0--details-769"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we develop a trust region method for training deep neural networks. At each iteration, trust region method computes the search direction by solving a non-convex subproblem. Solving this subproblem is non-trivial---existing methods have only sub-linear convergence rate. In the first part, we show that a simple modification of gradient descent algorithm can converge to a global minimizer of the subproblem with an asymptotic linear convergence rate. Moreover, our method only requires Hessian-vector products, which can be computed efficiently by back-propagation in neural networks. In the second part, we apply our algorithm to train large-scale convolutional neural networks, such as VGG and MobileNets. Although trust region method is about 3 times slower than SGD in terms of running time, we observe it finds a model that has lower generalization (test) error than SGD, and this difference is even more significant in large batch training. 
      We conduct several interesting experiments to support our conjecture that the trust region method can avoid sharp local minimas.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byk4My-RZ">
      <h4>
        <a href="https://openreview.net/forum?id=Byk4My-RZ">
          Flexible Prior Distributions for Deep Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=Byk4My-RZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yannic.kilcher%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="yannic.kilcher@inf.ethz.ch">Yannic Kilcher</a>, <a href="https://openreview.net/profile?email=aurelien.lucchi%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aurelien.lucchi@inf.ethz.ch">Aurelien Lucchi</a>, <a href="https://openreview.net/profile?email=thomas.hofmann%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.hofmann@inf.ethz.ch">Thomas Hofmann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Byk4My-RZ-details-38" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byk4My-RZ-details-38"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of training generative models with deep neural networks as generators, i.e. to map latent codes to data points. Whereas the dominant paradigm combines simple priors over codes with complex deterministic models,
      we argue that it might be advantageous to use more flexible code distributions. We demonstrate how these distributions can be induced directly from the data. The benefits include: more powerful generative models, better modeling of latent
      structure and explicit control of the degree of generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Generative Models, GANs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1rRWl-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=H1rRWl-Cb">
          An information-theoretic analysis of deep latent-variable models
        </a>
        
          <a href="https://openreview.net/pdf?id=H1rRWl-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alemi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alemi@google.com">Alex Alemi</a>, <a href="https://openreview.net/profile?email=poole%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="poole@cs.stanford.edu">Ben Poole</a>, <a href="https://openreview.net/profile?email=iansf%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iansf@google.com">Ian Fischer</a>, <a href="https://openreview.net/profile?email=jvdillon%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jvdillon@google.com">Josh Dillon</a>, <a href="https://openreview.net/profile?email=rif%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rif@google.com">Rif A. Saurus</a>, <a href="https://openreview.net/profile?email=kpmurphy%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kpmurphy@google.com">Kevin Murphy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1rRWl-Cb-details-588" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1rRWl-Cb-details-588"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present an information-theoretic framework for understanding trade-offs in unsupervised learning of deep latent-variables models using variational inference. This framework emphasizes the need to consider latent-variable models along two dimensions: the ability to reconstruct inputs (distortion) and the communication cost (rate). We derive the optimal frontier of generative models in the two-dimensional rate-distortion plane, and show how the standard evidence lower bound objective is insufficient to select between points along this frontier. However, by performing targeted optimization to learn generative models with different rates, we are able to learn many models that can achieve similar generative performance but make vastly different trade-offs in terms of the usage of the latent variable. Through experiments on MNIST and Omniglot with a variety of architectures, we show how our framework sheds light on many recent proposed extensions to the variational autoencoder family.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We provide an information theoretic and experimental analysis of state-of-the-art variational autoencoders.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">information theory, generative models, latent variable models, variational autoencoders</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkMt1bWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkMt1bWAZ">
          Bias-Variance Decomposition for Boltzmann Machines
        </a>
        
          <a href="https://openreview.net/pdf?id=rkMt1bWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mahito%40nii.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="mahito@nii.ac.jp">Mahito Sugiyama</a>, <a href="https://openreview.net/profile?email=tsuda%40k.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsuda@k.u-tokyo.ac.jp">Koji Tsuda</a>, <a href="https://openreview.net/profile?email=hiro%40brain.riken.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="hiro@brain.riken.jp">Hiroyuki Nakahara</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkMt1bWAZ-details-797" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkMt1bWAZ-details-797"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We achieve bias-variance decomposition for Boltzmann machines using an information geometric formulation. Our decomposition leads to an interesting phenomenon that the variance does not necessarily increase when more parameters are included in Boltzmann machines, while the bias always decreases. Our result gives a theoretical evidence of the generalization ability of deep learning architectures because it provides the possibility of increasing the representation power with avoiding the variance inflation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We achieve bias-variance decomposition for Boltzmann machines using an information geometric formulation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Boltzmann machine, bias-variance decomposition, information geometry</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJOl4DlCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJOl4DlCZ">
          Classifier-to-Generator Attack: Estimation of Training Data Distribution from Classifier
        </a>
        
          <a href="https://openreview.net/pdf?id=SJOl4DlCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cocuh%40mdl.cs.tsukuba.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="cocuh@mdl.cs.tsukuba.ac.jp">Kosuke Kusano</a>, <a href="https://openreview.net/profile?email=jun%40cs.tsukuba.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="jun@cs.tsukuba.ac.jp">Jun Sakuma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJOl4DlCZ-details-232" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJOl4DlCZ-details-232"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Suppose a deep classification model is trained with samples that need to be kept private for privacy or confidentiality reasons. In this setting, can an adversary obtain the private samples if the classification model is given to the adversary? We call this reverse engineering against the classification model the Classifier-to-Generator (C2G) Attack. This situation arises when the classification model is embedded into mobile devices for offline prediction (e.g., object recognition for the automatic driving car and face recognition for mobile phone authentication).
      For C2G attack, we introduce a novel GAN, PreImageGAN. In PreImageGAN, the generator is designed to estimate the the sample distribution conditioned by the preimage of classification model $f$, $P(X|f(X)=y)$, where $X$ is the random variable on the sample space and $y$ is the probability vector representing the target label arbitrary specified by the adversary. In experiments, we demonstrate PreImageGAN works successfully with hand-written character recognition and face recognition. In character recognition, we show that, given a recognition model of hand-written digits, PreImageGAN allows the adversary to extract alphabet letter images without knowing that the model is built for alphabet letter images. In face recognition, we show that, when an adversary obtains a face recognition model for a set of individuals, PreImageGAN allows the adversary to extract face images of specific individuals contained in the set, even when the adversary has no knowledge of the face of the individuals.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Estimation of training data distribution from trained classifier using GAN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Security, Privacy, Model Publication, Generative Adversarial Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByuI-mW0W">
      <h4>
        <a href="https://openreview.net/forum?id=ByuI-mW0W">
          Towards a Testable Notion of Generalization for Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ByuI-mW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rcornish%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="rcornish@robots.ox.ac.uk">Robert Cornish</a>, <a href="https://openreview.net/profile?email=hongseok.yang%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongseok.yang@cs.ox.ac.uk">Hongseok Yang</a>, <a href="https://openreview.net/profile?email=fwood%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="fwood@robots.ox.ac.uk">Frank Wood</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByuI-mW0W-details-636" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByuI-mW0W-details-636"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the question of how to assess generative adversarial networks, in particular with respect to whether or not they generalise beyond memorising the training data. We propose a simple procedure for assessing generative adversarial network performance based on a principled consideration of what the actual goal of generalisation is. Our approach involves using a test set to estimate the Wasserstein distance between the generative distribution produced by our procedure, and the underlying data distribution. We use this procedure to assess the performance of several modern generative adversarial network architectures. We find that this procedure is sensitive to the choice of ground metric on the underlying data space, and suggest a choice of ground metric that substantially improves performance.  We finally suggest that attending to the ground metric used in Wasserstein generative adversarial network training may be fruitful, and outline a concrete pathway towards doing so.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Assess whether or not your GAN is actually doing something other than memorizing the training data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, Wasserstein, GAN, generalization, theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1EwLkW0W">
      <h4>
        <a href="https://openreview.net/forum?id=S1EwLkW0W">
          Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients
        </a>
        
          <a href="https://openreview.net/pdf?id=S1EwLkW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lukas.balles%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukas.balles@tuebingen.mpg.de">Lukas Balles</a>, <a href="https://openreview.net/profile?email=ph%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="ph@tue.mpg.de">Philipp Hennig</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1EwLkW0W-details-303" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1EwLkW0W-details-303"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The ADAM optimizer is exceedingly popular in the deep learning community. Often it works very well, sometimes it doesn’t. Why? We interpret ADAM as a combination of two aspects: for each weight, the update direction is determined by the sign of the stochastic gradient, whereas the update magnitude is solely determined by an estimate of its relative variance. We  disentangle these two aspects and analyze them in isolation, shedding light on ADAM ’s inner workings. Transferring the "variance adaptation” to momentum- SGD gives rise to a novel method, completing the practitioner’s toolbox for problems where ADAM fails.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Analyzing the popular Adam optimizer</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Stochastic Optimization, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJYoqzbC-">
      <h4>
        <a href="https://openreview.net/forum?id=HJYoqzbC-">
          A comparison of second-order methods for deep convolutional neural networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJYoqzbC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=phpchen%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="phpchen@ucdavis.edu">Patrick H. Chen</a>, <a href="https://openreview.net/profile?email=chohsieh%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@ucdavis.edu">Cho-jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJYoqzbC--details-418" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJYoqzbC--details-418"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite many second-order methods have been proposed to train neural networks, most of the results were done on smaller single layer fully connected networks, so we still cannot conclude whether it's useful in training deep convolutional networks. In this study, we conduct extensive experiments to answer the question "whether second-order method is useful for deep learning?". In our analysis, we find out although currently second-order methods are too slow to be applied in practice, it can reduce training loss in fewer number of iterations compared with SGD. In addition, we have the following interesting findings: (1) When using a large batch size, inexact-Newton methods will converge much faster than SGD. Therefore inexact-Newton method could be a better choice in distributed training of deep networks. (2) Quasi-newton methods are competitive with SGD even when using ReLu activation function (which has no curvature) on residual networks. However, current methods are too sensitive to parameters and not easy to tune for different settings. Therefore, quasi-newton methods with more self-adjusting mechanisms might be more useful than SGD in training deeper networks. 
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByJDAIe0b">
      <h4>
        <a href="https://openreview.net/forum?id=ByJDAIe0b">
          Integrating Episodic Memory into a Reinforcement Learning Agent Using Reservoir Sampling
        </a>
        
          <a href="https://openreview.net/pdf?id=ByJDAIe0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kjyoung%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="kjyoung@ualberta.ca">Kenny J. Young</a>, <a href="https://openreview.net/profile?email=rsutton%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsutton@ualberta.ca">Shuo Yang</a>, <a href="https://openreview.net/profile?email=s-yan14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="s-yan14@mails.tsinghua.edu.cn">Richard S. Sutton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByJDAIe0b-details-80" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByJDAIe0b-details-80"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Episodic memory is a psychology term which refers to the ability to recall specific events from the past. We suggest one advantage of this particular type of memory is the ability to easily assign credit to a specific state when remembered information is found to be useful. Inspired by this idea, and the increasing popularity of external memory mechanisms to handle long-term dependencies in deep learning systems, we propose a novel algorithm which uses a reservoir sampling procedure to maintain an external memory consisting of a fixed number of past states. The algorithm allows a deep reinforcement learning agent to learn online to preferentially remember those states which are found to be useful to recall later on. Critically this method allows for efficient online computation of gradient estimates with respect to the write process of the external memory. Thus unlike most prior mechanisms for external memory it is feasible to use in an online reinforcement learning setting.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">External memory for online reinforcement learning based on estimating gradients over a novel reservoir sampling technique.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, external memory, deep learning, policy gradient, online learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H13WofbAb">
      <h4>
        <a href="https://openreview.net/forum?id=H13WofbAb">
          Faster Distributed Synchronous SGD with Weak Synchronization
        </a>
        
          <a href="https://openreview.net/pdf?id=H13WofbAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cx2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cx2@illinois.edu">Cong Xie</a>, <a href="https://openreview.net/profile?email=sanmi%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanmi@illinois.edu">Oluwasanmi O. Koyejo</a>, <a href="https://openreview.net/profile?email=indy%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="indy@illinois.edu">Indranil Gupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H13WofbAb-details-111" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H13WofbAb-details-111"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Distributed training of deep learning is widely conducted with large neural networks and large datasets. Besides asynchronous stochastic gradient descent~(SGD), synchronous SGD is a reasonable alternative with better convergence guarantees. However, synchronous SGD suffers from stragglers. To make things worse, although there are some strategies dealing with slow workers, the issue of slow servers is commonly ignored. In this paper, we propose a new parameter server~(PS) framework dealing with not only slow workers, but also slow servers by weakening the synchronization criterion. The empirical results show good performance when there are stragglers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed, deep learning, straggler</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJLmN8xRW">
      <h4>
        <a href="https://openreview.net/forum?id=BJLmN8xRW">
          Character Level Based Detection of DGA Domain Names
        </a>
        
          <a href="https://openreview.net/pdf?id=BJLmN8xRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=biny%40infoblox.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="biny@infoblox.com">Bin Yu</a>, <a href="https://openreview.net/profile?email=jiep%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiep@uw.edu">Jie Pan</a>, <a href="https://openreview.net/profile?email=huj22%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huj22@uw.edu">Jiaming Hu</a>, <a href="https://openreview.net/profile?email=andclay%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="andclay@uw.edu">Anderson Nascimento</a>, <a href="https://openreview.net/profile?email=mdecock%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mdecock@uw.edu">Martine De Cock</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJLmN8xRW-details-648" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJLmN8xRW-details-648"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recently several different deep learning architectures have been proposed that take a string of characters as the raw input signal and automatically derive features for text classification. Little studies are available that compare the effectiveness of these approaches for character based text classification with each other. In this paper we perform such an empirical comparison for the important cybersecurity problem of DGA detection: classifying domain names as either benign vs. produced by malware (i.e., by a Domain Generation Algorithm). Training and evaluating on a dataset with 2M domain names shows that there is surprisingly little difference between various convolutional neural network (CNN) and recurrent neural network (RNN) based architectures in terms of accuracy, prompting a preference for the simpler architectures, since they are faster to train and less prone to overfitting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep neural networks, short text classification, cybersecurity, domain generation algorithms, malicious domain names</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkrWCJWAW">
      <h4>
        <a href="https://openreview.net/forum?id=rkrWCJWAW">
          Unbiasing Truncated Backpropagation Through Time
        </a>
        
          <a href="https://openreview.net/pdf?id=rkrWCJWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=corentin.tallec%40polytechnique.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="corentin.tallec@polytechnique.edu">Corentin Tallec</a>, <a href="https://openreview.net/profile?email=yann%40yann-ollivier.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann@yann-ollivier.org">Yann Ollivier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkrWCJWAW-details-539" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkrWCJWAW-details-539"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">\emph{Truncated Backpropagation Through Time} (truncated BPTT, \cite{jaeger2002tutorial}) is a widespread method for learning recurrent computational graphs. Truncated BPTT keeps the computational benefits of \emph{Backpropagation Through Time} (BPTT \cite{werbos:bptt}) while relieving the need for a complete backtrack through the whole data sequence at every step.  However, truncation favors short-term dependencies: the gradient estimate of truncated BPTT is biased, so that it does not benefit from the convergence guarantees from stochastic gradient theory. We introduce \emph{Anticipated Reweighted Truncated Backpropagation} (ARTBP), an algorithm that keeps the computational benefits of truncated BPTT, while providing unbiasedness. ARTBP works by using variable truncation lengths together with carefully chosen compensation factors in the backpropagation equation. We check the viability of ARTBP on two tasks. First, a simple synthetic task where careful balancing of temporal dependencies at different scales is needed: truncated BPTT displays unreliable performance, and in worst case scenarios, divergence, while ARTBP converges reliably. Second, on Penn Treebank character-level language modelling \cite{ptb_proc}, ARTBP slightly outperforms truncated BPTT.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Provides an unbiased version of truncated backpropagation by sampling truncation lengths and reweighting accordingly.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJJzTyWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJJzTyWCZ">
          Large-scale Cloze Test Dataset Designed by Teachers
        </a>
        
          <a href="https://openreview.net/pdf?id=rJJzTyWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=qizhex%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qizhex@gmail.com">Qizhe Xie</a>, <a href="https://openreview.net/profile?email=guokun%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guokun@cs.cmu.edu">Guokun Lai</a>, <a href="https://openreview.net/profile?email=zander.dai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zander.dai@gmail.com">Zihang Dai</a>, <a href="https://openreview.net/profile?email=hovy%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hovy@cs.cmu.edu">Eduard Hovy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJJzTyWCZ-details-145" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJJzTyWCZ-details-145"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Cloze test is widely adopted in language exams to evaluate students' language proficiency. In this paper, we propose the first large-scale human-designed cloze test dataset CLOTH in which the questions were used in middle-school and high-school language exams. With the missing blanks carefully created by teachers and candidate choices purposely designed to be confusing, CLOTH requires a deeper language understanding and a wider attention span than previous automatically generated cloze datasets. We show humans outperform dedicated designed baseline models by a significant margin, even when the model is trained on sufficiently large external data. We investigate the source of the performance gap, trace model deficiencies to some distinct properties of CLOTH, and identify the limited ability of comprehending a long-term context to be the key bottleneck. In addition, we find that human-designed data leads to a larger gap between the model's performance and human performance when compared to automatically generated data. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A cloze test dataset designed by teachers to assess language proficiency</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">dataset, human-designed, language understanding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk346Ok0W">
      <h4>
        <a href="https://openreview.net/forum?id=Bk346Ok0W">
          Sensor Transformation Attention Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk346Ok0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=brauns%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="brauns@ethz.ch">Stefan Braun</a>, <a href="https://openreview.net/profile?email=daniel.l.neil%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.l.neil@gmail.com">Daniel Neil</a>, <a href="https://openreview.net/profile?email=enea.ceolini%40ini.uzh.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="enea.ceolini@ini.uzh.ch">Enea Ceolini</a>, <a href="https://openreview.net/profile?email=anumula%40ini.uzh.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="anumula@ini.uzh.ch">Jithendar Anumula</a>, <a href="https://openreview.net/profile?email=shih%40ini.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="shih@ini.ethz.ch">Shih-Chii Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk346Ok0W-details-782" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk346Ok0W-details-782"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent work on encoder-decoder models for sequence-to-sequence mapping has shown that integrating both temporal and spatial attentional mechanisms into neural networks increases the performance of the system substantially. We report on a new modular network architecture that applies an attentional mechanism not on temporal and spatial regions of the input, but on sensor selection for multi-sensor setups. This network called the sensor transformation attention network (STAN) is evaluated in scenarios which include the presence of natural noise or synthetic dynamic noise. We demonstrate how the attentional signal responds dynamically to changing noise levels and sensor-specific noise, leading to reduced word error rates (WERs) on both audio and visual tasks using TIDIGITS and GRID; and also on CHiME-3, a multi-microphone real-world noisy dataset. The improvement grows as more channels are corrupted as demonstrated on the CHiME-3 dataset. Moreover, the proposed STAN architecture naturally introduces a number of advantages including ease of removing sensors from existing architectures, attentional interpretability, and increased robustness to a variety of noise environments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a modular multi-sensor network architecture with an attentional mechanism that enables dynamic sensor selection on real-world noisy data from CHiME-3.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">attention, sensor-selection, multi-sensor, natural noise</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkNQeiRpb">
      <h4>
        <a href="https://openreview.net/forum?id=SkNQeiRpb">
          Training Deep AutoEncoders for Recommender Systems
        </a>
        
          <a href="https://openreview.net/pdf?id=SkNQeiRpb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kuchaev%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kuchaev@gmail.com">Oleksii Kuchaiev</a>, <a href="https://openreview.net/profile?email=boris.ginsburg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boris.ginsburg@gmail.com">Boris Ginsburg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkNQeiRpb-details-191" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkNQeiRpb-details-191"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper proposes a new model for the rating prediction task in recommender systems which significantly outperforms previous state-of-the art models on a time-split Netflix data set. Our model is based on deep autoencoder with 6 layers and is trained end-to-end without any layer-wise pre-training. We empirically demonstrate that: a) deep autoencoder models generalize much better than the shallow ones, b) non-linear activation functions with negative parts are crucial for training deep models, and c) heavy use of regularization techniques such as dropout is necessary to prevent over-fitting. We also propose a new training algorithm based on iterative output re-feeding to overcome natural sparseness of collaborate filtering. The new algorithm significantly speeds up training and improves model performance. Our code is publicly available.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper demonstrates how to train deep autoencoders end-to-end to achieve SoA results on time-split Netflix data set.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">autoencoder, recommendations, collaborative filtering, selu</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1DGha1CZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1DGha1CZ">
          Enhancing Batch Normalized Convolutional Networks using Displaced Rectifier Linear Units: A Systematic Comparative Study
        </a>
        
          <a href="https://openreview.net/pdf?id=H1DGha1CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dlm%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlm@cin.ufpe.br">David Macêdo</a>, <a href="https://openreview.net/profile?email=cz%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="cz@cin.ufpe.br">Cleber Zanchettin</a>, <a href="https://openreview.net/profile?email=alio%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="alio@cin.ufpe.br">Adriano L. I. Oliveira</a>, <a href="https://openreview.net/profile?email=tbl%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="tbl@cin.ufpe.br">Teresa Ludermir</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1DGha1CZ-details-534" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1DGha1CZ-details-534"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we turn our attention to the interworking between the activation functions and the batch normalization, which is a virtually mandatory technique to train deep networks currently. We propose the activation function Displaced Rectifier Linear Unit (DReLU) by conjecturing that extending the identity function of ReLU to the third quadrant enhances compatibility with batch normalization. Moreover, we used statistical tests to compare the impact of using distinct activation functions (ReLU, LReLU, PReLU, ELU, and DReLU) on the learning speed and test accuracy performance of standardized VGG and Residual Networks state-of-the-art models. These convolutional neural networks were trained on CIFAR-100 and CIFAR-10, the most commonly used deep learning computer vision datasets. The results showed DReLU speeded up learning in all models and datasets. Besides, statistical significant performance assessments (p&lt;0.05) showed DReLU enhanced the test accuracy presented by ReLU in all scenarios. Furthermore, DReLU showed better test accuracy than any other tested activation function in all experiments with one exception, in which case it presented the second best performance. Therefore, this work demonstrates that it is possible to increase performance replacing ReLU by an enhanced activation function.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new activation function called Displaced Rectifier Linear Unit is proposed. It is showed to enhance the training and inference performance of batch normalized convolutional neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Batch Normalized, Convolutional Neural Networks, Displaced Rectifier Linear Unit, Comparative Study</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryY4RhkCZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryY4RhkCZ">
          DEEP DENSITY NETWORKS AND UNCERTAINTY IN RECOMMENDER SYSTEMS
        </a>
        
          <a href="https://openreview.net/pdf?id=ryY4RhkCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yoel.z%40taboola.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoel.z@taboola.com">Yoel Zeldes</a>, <a href="https://openreview.net/profile?email=sth%40deeplab.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="sth@deeplab.ai">Stavros Theodorakis</a>, <a href="https://openreview.net/profile?email=efrat.s%40taboola.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="efrat.s@taboola.com">Efrat Solodnik</a>, <a href="https://openreview.net/profile?email=aviv.r%40taboola.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aviv.r@taboola.com">Aviv Rotman</a>, <a href="https://openreview.net/profile?email=gil.c%40taboola.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gil.c@taboola.com">Gil Chamiel</a>, <a href="https://openreview.net/profile?email=dan.f%40taboola.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dan.f@taboola.com">Dan Friedman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryY4RhkCZ-details-417" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryY4RhkCZ-details-417"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Building robust online content recommendation systems requires learning com- plex interactions between user preferences and content features. The field has evolved rapidly in recent years from traditional multi-arm bandit and collabora- tive filtering techniques, with new methods integrating Deep Learning models that enable to capture non-linear feature interactions. Despite progress, the dynamic nature of online recommendations still poses great challenges, such as finding the delicate balance between exploration and exploitation. In this paper we provide a novel method, Deep Density Networks (DDN) which deconvolves measurement and data uncertainty and predicts probability densities of CTR, enabling us to perform more efficient exploration of the feature space. We show the usefulness of using DDN online in a real world content recommendation system that serves billions of recommendations per day, and present online and offline results to eval- uate the benefit of using DDN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We have introduced Deep Density Network, a unified DNN model to estimate uncertainty for exploration/exploitation in recommendation systems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, recommendation system, uncertainty, context-based and collaborative filtering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkfbLilAb">
      <h4>
        <a href="https://openreview.net/forum?id=rkfbLilAb">
          Improving Search Through A3C Reinforcement Learning Based Conversational Agent
        </a>
        
          <a href="https://openreview.net/pdf?id=rkfbLilAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=milan.ag1994%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="milan.ag1994@gmail.com">Milan Aggarwal</a>, <a href="https://openreview.net/profile?email=aarushi.arora043%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aarushi.arora043@gmail.com">Aarushi Arora</a>, <a href="https://openreview.net/profile?email=sshagunsodhani%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sshagunsodhani@gmail.com">Shagun Sodhani</a>, <a href="https://openreview.net/profile?email=kbalaji%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kbalaji@adobe.com">Balaji Krishnamurthy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkfbLilAb-details-585" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkfbLilAb-details-585"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We develop a reinforcement learning based search assistant which can assist users through a set of actions and sequence of interactions to enable them realize their intent. Our approach caters to subjective search where the user is seeking digital assets such as images which is fundamentally different from the tasks which have objective and limited search modalities. Labeled conversational data is generally not available in such search tasks and training the agent through human interactions can be time consuming. We propose a stochastic virtual user which impersonates a real user and can be used to sample user behavior efficiently to train the agent which accelerates the bootstrapping of the agent. We develop A3C algorithm based context preserving architecture which enables the agent to provide contextual assistance to the user. We compare the A3C agent with Q-learning and evaluate its performance on average rewards and state values it obtains with the virtual user in validation episodes. Our experiments show that the agent learns to achieve higher rewards and better states.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A Reinforcement Learning based conversational search assistant which provides contextual assistance in subjective search (like digital assets).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Subjective search, Reinforcement Learning, Conversational Agent, Virtual user model, A3C, Context aggregation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJVruWZRW">
      <h4>
        <a href="https://openreview.net/forum?id=rJVruWZRW">
          Dense Recurrent Neural Network with Attention Gate
        </a>
        
          <a href="https://openreview.net/pdf?id=rJVruWZRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yhyoo%40rit.kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="yhyoo@rit.kaist.ac.kr">Yong-Ho Yoo</a>, <a href="https://openreview.net/profile?email=khan%40rit.kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="khan@rit.kaist.ac.kr">Kook Han</a>, <a href="https://openreview.net/profile?email=scho%40rit.kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="scho@rit.kaist.ac.kr">Sanghyun Cho</a>, <a href="https://openreview.net/profile?email=kckoh%40rit.kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kckoh@rit.kaist.ac.kr">Kyoung-Chul Koh</a>, <a href="https://openreview.net/profile?email=johkim%40rit.kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="johkim@rit.kaist.ac.kr">Jong-Hwan Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJVruWZRW-details-667" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJVruWZRW-details-667"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose the dense RNN, which has the fully connections from each hidden state to multiple preceding hidden states of all layers directly. As the density of the connection increases, the number of paths through which the gradient flows can be increased. It increases the magnitude of gradients, which help to prevent the vanishing gradient problem in time. Larger gradients, however, can also cause exploding gradient problem. To complement the trade-off between two problems, we propose an attention gate, which controls the amounts of gradient flows. We describe the relation between the attention gate and the gradient flows by approximation. The experiment on the language modeling using Penn Treebank corpus shows dense connections with the attention gate improve the model’s performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Dense RNN that has fully connections from each hidden state to multiple preceding hidden states of all layers directly.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural network, language modeling, dense connection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkYXvCR6W">
      <h4>
        <a href="https://openreview.net/forum?id=SkYXvCR6W">
          Compact Encoding of Words for Efficient Character-level Convolutional Neural Networks Text Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=SkYXvCR6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wemerson_marinho%40id.uff.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="wemerson_marinho@id.uff.br">Wemerson Marinho</a>, <a href="https://openreview.net/profile?email=lmarti%40ic.uff.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="lmarti@ic.uff.br">Luis Marti</a>, <a href="https://openreview.net/profile?email=nayat%40ime.uerj.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="nayat@ime.uerj.br">Nayat Sanchez-pi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkYXvCR6W-details-42" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkYXvCR6W-details-42"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper puts forward a new text to tensor representation that relies on information compression techniques to assign shorter codes to the most frequently used characters. This representation is language-independent with no need of pretraining and produces an encoding with no information loss. It provides an adequate description of the morphology of text, as it is able to represent prefixes, declensions, and inflections with similar vectors and are able to represent even unseen words on the training dataset. Similarly, as it is compact yet sparse, is ideal for speed up training times using tensor processing libraries. As part of this paper, we show that this technique is especially effective when coupled with convolutional neural networks (CNNs) for text classification at character-level. We apply two variants of CNN coupled with it. Experimental results show that it drastically reduces the number of parameters to be optimized, resulting in competitive classification accuracy values in only a fraction of the time spent by one-hot encoding representations, thus enabling training in commodity hardware.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using Compressing tecniques to Encoding of Words is a possibility for faster training of CNN and dimensionality reduction of representation</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Character Level Convolutional Networks, Text Classification, Word Compressing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy5OAyZC-">
      <h4>
        <a href="https://openreview.net/forum?id=Sy5OAyZC-">
          On the Use of Word Embeddings Alone to Represent Natural Language Sequences
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy5OAyZC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dinghan.shen%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dinghan.shen@duke.edu">Dinghan Shen</a>, <a href="https://openreview.net/profile?email=guoyin.wang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guoyin.wang@duke.edu">Guoyin Wang</a>, <a href="https://openreview.net/profile?email=wenlin.wang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenlin.wang@duke.edu">Wenlin Wang</a>, <a href="https://openreview.net/profile?email=renqiang%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="renqiang@nec-labs.com">Martin Renqiang Min</a>, <a href="https://openreview.net/profile?email=qinliang.su%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qinliang.su@duke.edu">Qinliang Su</a>, <a href="https://openreview.net/profile?email=yizhe.zhang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yizhe.zhang@duke.edu">Yizhe Zhang</a>, <a href="https://openreview.net/profile?email=ricardo.henao%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ricardo.henao@duke.edu">Ricardo Henao</a>, <a href="https://openreview.net/profile?email=lcarin%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcarin@duke.edu">Lawrence Carin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy5OAyZC--details-911" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy5OAyZC--details-911"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">To construct representations for natural language sequences, information from two main sources needs to be captured: (i) semantic meaning of individual words, and (ii) their compositionality. These two types of information are usually represented in the form of word embeddings and compositional functions, respectively. For the latter, Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) have been considered. There has not been a rigorous evaluation regarding the relative importance of each component to different text-representation-based tasks; i.e., how important is the modeling capacity of word embeddings alone, relative to the added value of a compositional function? In this paper, we conduct an extensive comparative study between Simple Word Embeddings-based Models (SWEMs), with no compositional parameters, relative to employing word embeddings within RNN/CNN-based models. Surprisingly, SWEMs exhibit comparable or even superior performance in the majority of cases considered. Moreover, in a new SWEM setup, we propose to employ a max-pooling operation over the learned word-embedding matrix of a given sentence. This approach is demonstrated to extract complementary features relative to the averaging operation standard to SWEMs, while endowing our model with better interpretability. To further validate our observations, we examine the information utilized by different models to make predictions, revealing interesting properties of word embeddings.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Natural Language Processing, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byht0GbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=Byht0GbRZ">
          STRUCTURED ALIGNMENT NETWORKS
        </a>
        
          <a href="https://openreview.net/pdf?id=Byht0GbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yang.liu2%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yang.liu2@ed.ac.uk">Yang Liu</a>, <a href="https://openreview.net/profile?email=mattg%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="mattg@allenai.org">Matt Gardner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Byht0GbRZ-details-566" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byht0GbRZ-details-566"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> Many tasks in natural language processing involve comparing two sentences to compute some notion of relevance, entailment, or similarity. Typically this comparison is done either at the word level or at the sentence level, with no attempt to leverage the inherent structure of the sentence. When sentence structure is used for comparison, it is obtained during a non-differentiable pre-processing step, leading to propagation of errors. We introduce a model of structured alignments between sentences, showing how to compare two sentences by matching their latent structures. Using a structured attention mechanism, our model matches possible spans in the first sentence to possible spans in the second sentence, simultaneously discovering the tree structure of each sentence and performing a comparison, in a model that is fully differentiable and is trained only on the comparison objective. We evaluate this model on two sentence comparison tasks: the Stanford natural language inference dataset and the TREC-QA dataset. We find that comparing spans results in superior performance to comparing words individually, and that the learned trees are consistent with actual linguistic structures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Matching sentences by learning the latent constituency tree structures with a variant of the inside-outside algorithm embedded as a neural network layer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">structured attention, sentence matching</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJZsR7kCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJZsR7kCZ">
          Iterative Deep Compression : Compressing Deep Networks for Classification and Semantic Segmentation
        </a>
        
          <a href="https://openreview.net/pdf?id=SJZsR7kCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sugandhadoda672%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sugandhadoda672@gmail.com">Sugandha Doda</a>, <a href="https://openreview.net/profile?email=vitor.fortes%40dfki.uni-kl.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitor.fortes@dfki.uni-kl.de">Vitor Fortes Rey</a>, <a href="https://openreview.net/profile?email=nadereh.hatamimazinani%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nadereh.hatamimazinani@de.bosch.com">Dr. Nadereh Hatami</a>, Prof. Dr. Paul Lukowicz
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJZsR7kCZ-details-298" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJZsR7kCZ-details-298"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Machine learning and in particular deep learning approaches have outperformed many traditional techniques in accomplishing complex tasks such as
      image classfication, natural language processing or speech recognition. Most of the state-of-the art deep networks have complex architecture and use a vast number of parameters to reach this superior performance. Though these networks use a large number of learnable parameters, those parameters present significant redundancy. Therefore, it is possible to compress the network without much affecting its accuracy by eliminating those redundant and unimportant parameters.
      In this work, we propose a three stage compression pipeline, which consists of pruning, weight sharing and quantization to compress deep neural networks.
      Our novel pruning technique combines magnitude based ones with dense sparse dense ideas and iteratively finds for each layer its achievable sparsity instead of selecting a single threshold for the whole network.
      Unlike previous works, where compression is only applied on networks performing classification, we evaluate and perform compression on networks for classification as well as semantic segmentation, which is greatly useful for understanding scenes in autonomous driving.
      We tested our method on LeNet-5 and FCNs, performing classification and semantic segmentation, respectively. With LeNet-5 on MNIST, pruning reduces the number of parameters by 15.3 times and storage requirement from 1.7 MB to 0.006 MB with accuracy loss of 0.03%. With FCN8 on Cityscapes, we decrease the number of parameters by 8 times and reduce the storage requirement from 537.47 MB to 18.23 MB with class-wise intersection-over-union (IoU) loss of 4.93% on the validation data.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkQCGzZ0-">
      <h4>
        <a href="https://openreview.net/forum?id=BkQCGzZ0-">
          Discrete Autoencoders for Sequence Models
        </a>
        
          <a href="https://openreview.net/pdf?id=BkQCGzZ0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lukaszkaiser%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukaszkaiser@google.com">Lukasz Kaiser</a>, <a href="https://openreview.net/profile?email=bengio%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengio@google.com">Samy Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkQCGzZ0--details-536" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkQCGzZ0--details-536"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent models for sequences have been recently successful at many tasks, especially for language modeling
      and machine translation. Nevertheless, it remains challenging to extract good representations from
      these models. For instance, even though language has a clear hierarchical structure going from characters
      through words to sentences, it is not apparent in current language models.
      We propose to improve the representation in sequence models by
      augmenting current approaches with an autoencoder that is forced to compress
      the sequence through an intermediate discrete latent space. In order to propagate gradients
      though this discrete representation we introduce an improved semantic hashing technique.
      We show that this technique performs well on a newly proposed quantitative efficiency measure.
      We also analyze latent codes produced by the model showing how they correspond to
      words and phrases. Finally, we present an application of the autoencoder-augmented
      model to generating diverse translations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Autoencoders for text with a new method for using discrete latent space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">autoencoders, sequence models, discrete representations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkl1uWb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=Bkl1uWb0Z">
          Inducing Grammars with and for Neural Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=Bkl1uWb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ketranmanh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ketranmanh@gmail.com">Ke Tran</a>, <a href="https://openreview.net/profile?email=ybisk%40yonatanbisk.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ybisk@yonatanbisk.com">Yonatan Bisk</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bkl1uWb0Z-details-513" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkl1uWb0Z-details-513"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Previous work has demonstrated the benefits of incorporating additional linguistic annotations such as syntactic trees into neural machine translation. However the cost of obtaining those syntactic annotations is expensive for many languages and the quality of unsupervised learning linguistic structures is too poor to be helpful. In this work, we aim to improve neural machine translation via source side dependency syntax but without explicit annotation. We propose a set of models that learn to induce dependency trees on the source side and learn to use that information on the target side. Importantly, we also show that our dependency trees capture important syntactic features of language and improve translation quality on two language pairs En-De and En-Ru.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">improve NMT with latent trees</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">structured attention, neural machine translation, grammar induction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syx6bz-Ab">
      <h4>
        <a href="https://openreview.net/forum?id=Syx6bz-Ab">
          Seq2SQL: Generating Structured Queries From Natural Language Using Reinforcement Learning 
        </a>
        
          <a href="https://openreview.net/pdf?id=Syx6bz-Ab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=victor%40victorzhong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="victor@victorzhong.com">Victor Zhong</a>, <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syx6bz-Ab-details-556" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syx6bz-Ab-details-556"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Relational databases store a significant amount of the worlds data. However, accessing this data currently requires users to understand a query language such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model uses rewards from in the loop query execution over the database to learn a policy to generate the query, which contains unordered parts that are less suitable for optimization via cross entropy loss. Moreover, Seq2SQL leverages the structure of SQL to prune the space of generated queries and significantly simplify the generation problem. In addition to the model, we release WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables fromWikipedia that is an order of magnitude larger than comparable datasets. By applying policy based reinforcement learning with a query execution environment to WikiSQL, Seq2SQL outperforms a state-of-the-art semantic parser, improving execution accuracy from 35.9% to 59.4% and logical form accuracy from 23.4% to 48.3%.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce Seq2SQL, which translates questions to SQL queries using rewards from online query execution, and WikiSQL, a SQL table/question/query dataset orders of magnitude larger than existing datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, reinforcement learning, dataset, natural language processing, natural language interface, sql</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJInMmWC-">
      <h4>
        <a href="https://openreview.net/forum?id=BJInMmWC-">
          Generative Entity Networks: Disentangling Entitites and Attributes in Visual Scenes using Partial Natural Language Descriptions
        </a>
        
          <a href="https://openreview.net/pdf?id=BJInMmWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=charlie.nash%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="charlie.nash@ed.ac.uk">Charlie Nash</a>, <a href="https://openreview.net/profile?email=sebastian.nowozin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.nowozin@microsoft.com">Sebastian Nowozin</a>, <a href="https://openreview.net/profile?email=nate%40kushman.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="nate@kushman.org">Nate Kushman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJInMmWC--details-710" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJInMmWC--details-710"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative image models have made significant progress in the last few years, and are now able to generate low-resolution images which sometimes look realistic. However the state-of-the-art models utilize fully entangled latent representations where small changes to a single neuron can effect every output pixel in relatively arbitrary ways, and different neurons have possibly arbitrary relationships with each other. This limits the ability of such models to generalize to new combinations or orientations of objects as well as their ability to connect with more structured representations such as natural language, without explicit strong supervision. In this work explore the synergistic effect of using partial natural language scene descriptions to help disentangle the latent entities visible an image. We present a novel neural network architecture called Generative Entity Networks, which jointly generates both the natural language descriptions and the images from a set of latent entities. Our model is based on the variational autoencoder framework and makes use of visual attention to identify and characterise the visual attributes of each entity. Using the Shapeworld dataset, we show that our representation both enables a better generative model of images, leading to higher quality image samples, as well as creating more semantically useful representations that improve performance over purely dicriminative models on a simple natural language yes/no question answering task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">VAE, Generative Model, Vision, Natural Language</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1Zi2Mb0-">
      <h4>
        <a href="https://openreview.net/forum?id=r1Zi2Mb0-">
          EXPLORING NEURAL ARCHITECTURE SEARCH FOR LANGUAGE TASKS
        </a>
        
          <a href="https://openreview.net/pdf?id=r1Zi2Mb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=luong.m.thang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="luong.m.thang@gmail.com">Minh-Thang Luong</a>, <a href="https://openreview.net/profile?email=ddohan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddohan@google.com">David Dohan</a>, <a href="https://openreview.net/profile?email=adamsyuwei%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adamsyuwei@gmail.com">Adams Wei Yu</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>, <a href="https://openreview.net/profile?email=barretzoph%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="barretzoph@google.com">Barret Zoph</a>, <a href="https://openreview.net/profile?email=vrv%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vrv@google.com">Vijay Vasudevan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1Zi2Mb0--details-812" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1Zi2Mb0--details-812"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural architecture search (NAS), the task of finding neural architectures automatically, has recently emerged as a promising approach for unveiling better models over human-designed ones. However, most success stories are for vision tasks and have been quite limited for text, except for a small language modeling setup. In this paper, we explore NAS for text sequences at scale, by first focusing on the task of language translation and later extending to reading comprehension. From a standard sequence-to-sequence models for translation, we conduct extensive searches over the recurrent cells and attention similarity functions across two translation tasks, IWSLT English-Vietnamese and WMT German-English. We report challenges in performing cell searches as well as demonstrate initial success on attention searches with translation improvements over strong baselines. In addition, we show that results on attention searches are transferable to reading comprehension on the SQuAD dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We explore neural architecture search for language tasks. Recurrent cell search is challenging for NMT, but attention mechanism search works. The result of attention search on translation is transferable to reading comprehension.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural architecture search, language tasks, neural machine translation, reading comprehension, SQuAD</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1347ot3b">
      <h4>
        <a href="https://openreview.net/forum?id=S1347ot3b">
          Exploring Sentence Vectors Through Automatic Summarization
        </a>
        
          <a href="https://openreview.net/pdf?id=S1347ot3b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=at7%40williams.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="at7@williams.edu">Adly Templeton</a>, <a href="https://openreview.net/profile?email=jkalita%40uccs.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jkalita@uccs.edu">Jugal Kalita</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1347ot3b-details-946" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1347ot3b-details-946"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Vector semantics, especially sentence vectors, have recently been used successfully in many areas of natural language processing. However, relatively little work has explored the internal structure and properties of spaces of sentence vectors. In this paper, we will explore the properties of sentence vectors by studying a particular real-world application: Automatic Summarization. In particular, we show that cosine similarity between sentence vectors and document vectors is strongly correlated with sentence importance and that vector semantics can identify and correct gaps between the sentences chosen so far and the document. In addition, we identify specific dimensions which are linked to effective summaries. To our knowledge, this is the first time specific dimensions of sentence embeddings have been connected to sentence properties. We also compare the features of different methods of sentence embeddings. Many of these insights have applications in uses of sentence embeddings far beyond summarization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A comparison and detailed analysis of various sentence embedding models through the real-world task of automatic summarization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Sentence Vectors, Vector Semantics, Automatic Summarization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJDEbngCZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJDEbngCZ">
          Global Convergence of Policy Gradient Methods for Linearized  Control Problems
        </a>
        
          <a href="https://openreview.net/pdf?id=BJDEbngCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mfazel%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mfazel@uw.edu">Maryam Fazel</a>, <a href="https://openreview.net/profile?email=rongge%40cs.duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rongge@cs.duke.edu">Rong Ge</a>, <a href="https://openreview.net/profile?email=sham%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sham@cs.washington.edu">Sham M. Kakade</a>, <a href="https://openreview.net/profile?email=mesbahi%40aa.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mesbahi@aa.washington.edu">Mehran Mesbahi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJDEbngCZ-details-799" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJDEbngCZ-details-799"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Direct policy gradient methods for reinforcement learning and continuous control problems are a popular
      approach for a variety of reasons: 
      1) they are easy to implement without explicit knowledge of the underlying model;
      2) they are an "end-to-end" approach, directly optimizing the performance metric of interest;
      3) they inherently allow for richly parameterized policies.
      A notable drawback is that even in the most basic continuous control problem (that of linear quadratic regulators), these methods must solve a non-convex optimization problem, where little is understood about their efficiency from both computational and statistical perspectives. In contrast, system identification and model based planning in optimal control theory have a much more solid theoretical footing, where much is known with regards to their computational and statistical properties.  This work bridges this gap showing that (model free) policy gradient methods globally converge to the optimal solution and are efficient (polynomially so in relevant problem dependent quantities) with regards to their sample and computational complexities. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper shows that model-free policy gradient methods can converge to the global optimal solution for non-convex linearized control problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">linear quadratic regulator, policy gradient, natural gradient, reinforcement learning, non-convex optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJICXeWAb">
      <h4>
        <a href="https://openreview.net/forum?id=SJICXeWAb">
          Depth separation and weight-width trade-offs for sigmoidal neural networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJICXeWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amitdesh%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amitdesh@microsoft.com">Amit Deshpande</a>, <a href="https://openreview.net/profile?email=navingo%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="navingo@microsoft.com">Navin Goyal</a>, <a href="https://openreview.net/profile?email=sushrutk%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sushrutk@cs.utexas.edu">Sushrut Karmalkar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJICXeWAb-details-69" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJICXeWAb-details-69"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Some recent work has shown separation between the expressive power of depth-2 and depth-3 neural networks. These separation results are shown by constructing functions and input distributions, so that the function is well-approximable by a depth-3 neural network of polynomial size but it cannot be well-approximated under the chosen input distribution by any depth-2 neural network of polynomial size. These results are not robust and require carefully chosen functions as well as input distributions.
      
      We show a similar separation between the expressive power of depth-2 and depth-3 sigmoidal neural networks over a large class of input distributions, as long as the weights are polynomially bounded. While doing so, we also show that depth-2 sigmoidal neural networks with small width and small weights can be well-approximated by low-degree multivariate polynomials.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">depth-2-vs-3 separation for sigmoidal neural networks over general distributions</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">depth separation, neural networks, weights-width trade-off</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJR2ylbRb">
      <h4>
        <a href="https://openreview.net/forum?id=rJR2ylbRb">
          Spectral Graph Wavelets for Structural Role Similarity in Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJR2ylbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cdonnat%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdonnat@stanford.edu">Claire Donnat</a>, <a href="https://openreview.net/profile?email=marinka%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="marinka@cs.stanford.edu">Marinka Zitnik</a>, <a href="https://openreview.net/profile?email=hallac%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hallac@stanford.edu">David Hallac</a>, <a href="https://openreview.net/profile?email=jure%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jure@cs.stanford.edu">Jure Leskovec</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJR2ylbRb-details-914" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJR2ylbRb-details-914"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Nodes residing in different parts of a graph can have similar structural roles within their local network topology. The identification of such roles provides key insight into the organization of networks and can also be used to inform machine learning on graphs. However, learning structural representations of nodes is a challenging unsupervised-learning task, which typically involves manually specifying and tailoring topological features for each node. Here we develop GraphWave, a method that represents each node’s local network neighborhood via a low-dimensional embedding by leveraging spectral graph wavelet diffusion patterns. We prove that nodes with similar local network neighborhoods will have similar GraphWave embeddings even though these nodes may reside in very different parts of the network. Our method scales linearly with the number of edges and does not require any hand-tailoring of topological features. We evaluate performance on both synthetic and real-world datasets, obtaining improvements of up to 71% over state-of-the-art baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We develop a method for learning structural signatures in networks based on the diffusion of spectral graph wavelets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Graphs, Structural Similarities, Spectral Graph Wavelets, Graph Signal Processing, Unsupervised Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1CE9GWR-">
      <h4>
        <a href="https://openreview.net/forum?id=r1CE9GWR-">
          Understanding GANs: the LQG Setting
        </a>
        
          <a href="https://openreview.net/pdf?id=r1CE9GWR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sfeizi%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sfeizi@stanford.edu">Soheil Feizi</a>, <a href="https://openreview.net/profile?email=chsuh%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="chsuh@kaist.ac.kr">Changho Suh</a>, <a href="https://openreview.net/profile?email=feixia%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="feixia@stanford.edu">Fei Xia</a>, <a href="https://openreview.net/profile?email=dntse%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dntse@stanford.edu">David Tse</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1CE9GWR--details-775" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1CE9GWR--details-775"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative Adversarial Networks (GANs) have become a popular method to learn a probability model from data. Many GAN architectures with different optimization metrics have been introduced recently. Instead of proposing yet another architecture, this  paper aims to provide an understanding of some of the basic issues surrounding GANs. First, we propose a natural way of specifying the loss function for GANs by drawing a connection with supervised learning. Second, we shed light on the statistical performance of GANs through the analysis of a simple LQG setting: the generator is linear, the loss function is quadratic and the data is drawn from a Gaussian distribution. We show that  in this setting: 1) the optimal GAN solution converges to population Principal Component Analysis (PCA) as the number of training samples increases; 2) the number of samples required scales exponentially with the dimension of the data; 3) the number of samples scales almost linearly if the discriminator is constrained to be quadratic. Moreover, under this quadratic constraint on the discriminator, the optimal finite-sample GAN performs simply empirical PCA.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Networks, Wasserstein, Generalization, PCA</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyY0Ff-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=HyY0Ff-AZ">
          Representing Entropy : A short proof of the equivalence between soft Q-learning and policy gradients
        </a>
        
          <a href="https://openreview.net/pdf?id=HyY0Ff-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=phr17%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="phr17@imperial.ac.uk">Pierre H. Richemond</a>, <a href="https://openreview.net/profile?email=b.maginnis%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="b.maginnis@imperial.ac.uk">Brendan Maginnis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyY0Ff-AZ-details-48" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyY0Ff-AZ-details-48"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Two main families of reinforcement learning algorithms, Q-learning and policy gradients, have recently been proven to be equivalent when using a softmax relaxation on one part, and an entropic regularization on the other. We relate this result to the well-known convex duality of Shannon entropy and the softmax function. Such a result is also known as the Donsker-Varadhan formula. This provides a short proof of the equivalence. We then interpret this duality further, and use ideas of convex analysis to prove a new policy inequality relative to soft Q-learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A short proof of the equivalence of soft Q-learning and policy gradients.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">soft Q-learning, policy gradients, entropy, Legendre transformation, duality, convex analysis, Donsker-Varadhan</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJcAWaeCW">
      <h4>
        <a href="https://openreview.net/forum?id=BJcAWaeCW">
          Graph Topological Features via GAN
        </a>
        
          <a href="https://openreview.net/pdf?id=BJcAWaeCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=weiyiliu%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weiyiliu@us.ibm.com">Weiyi Liu</a>, <a href="https://openreview.net/profile?email=hal.cooper%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hal.cooper@columbia.edu">Hal Cooper</a>, <a href="https://openreview.net/profile?email=m.oh%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.oh@columbia.edu">Min-Hwan Oh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJcAWaeCW-details-964" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJcAWaeCW-details-964"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Inspired by the success of generative adversarial networks (GANs) in image domains, we introduce a novel hierarchical architecture for learning characteristic topological features from a single arbitrary input graph via GANs. The hierarchical architecture consisting of multiple GANs preserves both local and global topological features, and automatically partitions the input graph into representative stages for feature learning. The stages facilitate reconstruction and can be used as indicators of the importance of the associated topological structures. Experiments show that our method produces subgraphs retaining a wide range of topological features, even in early reconstruction stages. This paper contains original research on combining the use of GANs and graph topological analysis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A GAN based method to learn important topological features of an arbitrary input graph.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph topology, GAN, network science, hierarchical learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyEi7bWR-">
      <h4>
        <a href="https://openreview.net/forum?id=HyEi7bWR-">
          Orthogonal Recurrent Neural Networks with Scaled Cayley Transform
        </a>
        
          <a href="https://openreview.net/pdf?id=HyEi7bWR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kyle.helfrich%40uky.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyle.helfrich@uky.edu">Kyle Helfrich</a>, <a href="https://openreview.net/profile?email=devin.willmott%40uky.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="devin.willmott@uky.edu">Devin Willmott</a>, <a href="https://openreview.net/profile?email=qiang.ye%40uky.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiang.ye@uky.edu">Qiang Ye</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyEi7bWR--details-157" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyEi7bWR--details-157"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent Neural Networks (RNNs) are designed to handle sequential data but suffer from vanishing or exploding gradients.  Recent work on Unitary Recurrent Neural Networks (uRNNs) have been used to address this issue and in some cases, exceed the capabilities of Long Short-Term Memory networks (LSTMs).  We propose a simpler and novel update scheme to maintain orthogonal recurrent weight matrices without using complex valued matrices. This is done by parametrizing with a skew-symmetric matrix using the Cayley transform. Such a parametrization is unable to represent matrices with negative one eigenvalues, but this limitation is overcome by scaling the recurrent weight matrix by a diagonal matrix consisting of ones and negative ones.  The proposed training scheme involves a straightforward gradient calculation and update step. In several experiments, the proposed scaled Cayley orthogonal recurrent neural network (scoRNN) achieves superior results with fewer trainable parameters than other unitary RNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel approach to maintain orthogonal recurrent weight matrices in a RNN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, vanishing gradients, exploding gradients, orthogonal, unitary, long term dependencies, uRNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1EPYJ-C-">
      <h4>
        <a href="https://openreview.net/forum?id=B1EPYJ-C-">
          Federated Learning: Strategies for Improving Communication Efficiency
        </a>
        
          <a href="https://openreview.net/pdf?id=B1EPYJ-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=konkey%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="konkey@google.com">Jakub Konečný</a>, <a href="https://openreview.net/profile?email=mcmahan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcmahan@google.com">H. Brendan McMahan</a>, <a href="https://openreview.net/profile?email=felixyu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="felixyu@google.com">Felix X. Yu</a>, <a href="https://openreview.net/profile?email=theertha%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="theertha@google.com">Ananda Theertha Suresh</a>, <a href="https://openreview.net/profile?email=dabacon%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dabacon@google.com">Dave Bacon</a>, <a href="https://openreview.net/profile?email=peter.richtarik%40kaust.edu.sa" class="profile-link" data-toggle="tooltip" data-placement="top" title="peter.richtarik@kaust.edu.sa">Peter Richtárik</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1EPYJ-C--details-416" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1EPYJ-C--details-416"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections.  We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model.  The typical clients in this setting are mobile phones, and communication efficiency is of the utmost importance. 
      
      In this paper, we propose two ways to reduce the uplink communication costs: structured updates, where we directly learn an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, where we learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling before sending it to the server. Experiments on both convolutional and recurrent networks show that the proposed methods can reduce the communication cost by two orders of magnitude.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1SuFjkRW">
      <h4>
        <a href="https://openreview.net/forum?id=r1SuFjkRW">
          Discrete Sequential Prediction of Continuous Actions for Deep RL
        </a>
        
          <a href="https://openreview.net/pdf?id=r1SuFjkRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lmetz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lmetz@google.com">Luke Metz</a>, <a href="https://openreview.net/profile?email=julianibarz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="julianibarz@google.com">Julian Ibarz</a>, <a href="https://openreview.net/profile?email=njaitly%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="njaitly@google.com">Navdeep Jaitly</a>, <a href="https://openreview.net/profile?email=jcdavidson%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jcdavidson@google.com">James Davidson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1SuFjkRW-details-415" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1SuFjkRW-details-415"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It has long been assumed that high dimensional continuous control problems cannot be solved effectively by discretizing individual dimensions of the action space due to the exponentially large number of bins over which policies would have to be learned. In this paper, we draw inspiration from the recent success of sequence-to-sequence models for structured prediction problems to develop policies over discretized spaces. Central to this method is the realization that complex functions over high dimensional spaces can be modeled by neural networks that predict one dimension at a time. Specifically, we show how Q-values and policies over continuous spaces can be modeled using a next step prediction model over discretized dimensions. With this parameterization, it is possible to both leverage the compositional structure of action spaces during learning, as well as compute maxima over action spaces (approximately). On a simple example task we demonstrate empirically that our method can perform global search, which effectively gets around the local optimization issues that plague DDPG. We apply the technique to off-policy (Q-learning) methods and show that our method can achieve the state-of-the-art for off-policy methods on several continuous control tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A method to do Q-learning on continuous action spaces by predicting a sequence of discretized 1-D actions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning, continuous control, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyXBcYg0b">
      <h4>
        <a href="https://openreview.net/forum?id=HyXBcYg0b">
          Residual Gated Graph ConvNets
        </a>
        
          <a href="https://openreview.net/pdf?id=HyXBcYg0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xbresson%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="xbresson@ntu.edu.sg">Xavier Bresson</a>, <a href="https://openreview.net/profile?email=tlaurent%40lmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tlaurent@lmu.edu">Thomas Laurent</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyXBcYg0b-details-364" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyXBcYg0b-details-364"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Graph-structured data such as social networks, functional brain networks, gene regulatory networks, communications networks have brought the interest in generalizing deep learning techniques to graph domains. In this paper, we are interested to design neural networks for graphs with variable length in order to solve learning problems such as vertex classification, graph classification, graph regression, and graph generative tasks. Most existing works have focused on recurrent neural networks (RNNs) to learn meaningful representations of graphs, and more recently new convolutional neural networks (ConvNets) have been introduced. In this work, we want to compare rigorously these two fundamental families of architectures to solve graph learning tasks. We review existing graph RNN and ConvNet architectures, and propose natural extension of LSTM and ConvNet to graphs with arbitrary size. Then, we design a set of analytically controlled experiments on two basic graph problems, i.e. subgraph matching and graph clustering, to test the different architectures.  Numerical results show that the proposed graph ConvNets are 3-17% more accurate and 1.5-4x faster than graph RNNs. Graph ConvNets are also 36% more accurate than variational (non-learning) techniques. Finally, the most effective graph ConvNet architecture uses gated edges and residuality. Residuality plays an essential role to learn multi-layer architectures as they provide a 10% gain of performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We compare graph RNNs and graph ConvNets, and we consider the most generic class of graph ConvNets with residuality.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph neural networks, ConvNets, RNNs, pattern matching, semi-supervised clustering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyI5ro0pW">
      <h4>
        <a href="https://openreview.net/forum?id=HyI5ro0pW">
          Neural Networks with Block Diagonal Inner Product Layers
        </a>
        
          <a href="https://openreview.net/pdf?id=HyI5ro0pW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anesky%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anesky@umich.edu">Amy Nesky</a>, <a href="https://openreview.net/profile?email=qstout%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qstout@umich.edu">Quentin Stout</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyI5ro0pW-details-617" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyI5ro0pW-details-617"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Artificial neural networks have opened up a world of possibilities in data science and artificial intelligence, but neural networks are cumbersome tools that grow with the complexity of the learning problem. We make contributions to this issue by considering a modified version of the fully connected layer we call a block diagonal inner product layer. These modified layers have weight matrices that are block diagonal, turning a single fully connected layer into a set of densely connected neuron groups. This idea is a natural extension of group, or depthwise separable, convolutional layers applied to the fully connected layers. Block diagonal inner product layers can be achieved by either initializing a purely block diagonal weight matrix or by iteratively pruning off diagonal block entries. This method condenses network storage and speeds up the run time without significant adverse effect on the testing accuracy, thus offering a new approach to improve network computation efficiency.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We look at neural networks with block diagonal inner product layers for efficiency.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ1fQYlCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJ1fQYlCZ">
          Training with Growing Sets: A Simple Alternative to Curriculum Learning and Self Paced Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ1fQYlCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=melike.mermer%40izu.edu.tr" class="profile-link" data-toggle="tooltip" data-placement="top" title="melike.mermer@izu.edu.tr">Melike Nur Mermer</a>, <a href="https://openreview.net/profile?email=mfatih%40ce.yildiz.edu.tr" class="profile-link" data-toggle="tooltip" data-placement="top" title="mfatih@ce.yildiz.edu.tr">Mehmet Fatih Amasyali</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ1fQYlCZ-details-262" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ1fQYlCZ-details-262"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Curriculum learning and Self paced learning are popular topics in the machine learning that suggest to put the training samples in order by considering their difficulty levels. Studies in these topics show that starting with a small training set and adding new samples according to difficulty levels improves the learning performance. In this paper we experimented that we can also obtain good results by adding the samples randomly without a meaningful order. We compared our method with classical training, Curriculum learning, Self paced learning and their reverse ordered versions. Results of the statistical tests show that the proposed method is better than classical method and similar with the others. These results point a new training regime that removes the process of difficulty level determination in Curriculum and Self paced learning and as successful as these methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose that training with growing sets stage-by-stage provides an optimization for neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural networks, Curriculum learning, Self paced learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJaE2alRW">
      <h4>
        <a href="https://openreview.net/forum?id=rJaE2alRW">
          Autoregressive Convolutional Neural Networks for Asynchronous Time Series
        </a>
        
          <a href="https://openreview.net/pdf?id=rJaE2alRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mikbinkowski%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mikbinkowski@gmail.com">Mikolaj Binkowski</a>, <a href="https://openreview.net/profile?email=gautier.marti%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gautier.marti@gmail.com">Gautier Marti</a>, <a href="https://openreview.net/profile?email=pdonnat%40helleborecapital.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pdonnat@helleborecapital.com">Philippe Donnat</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJaE2alRW-details-345" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJaE2alRW-details-345"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose Significance-Offset Convolutional Neural Network, a deep convolutional network architecture for regression of multivariate asynchronous time series.  The model is inspired by standard autoregressive (AR) models and gating mechanisms used in recurrent neural networks.  It involves an AR-like weighting system, where the final predictor is obtained as a weighted sum of adjusted regressors, while the weights are data-dependent functions learnt through a convolutional network. The architecture was designed for applications on asynchronous time series and is evaluated on such datasets: a hedge fund proprietary dataset of over 2 million quotes for a credit derivative index, an artificially generated noisy autoregressive  series  and  household  electricity  consumption  dataset.   The  pro-posed architecture achieves promising results as compared to convolutional and recurrent neural networks. The code for the numerical experiments and the architecture implementation will be shared online to make the research reproducible.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Convolutional architecture for learning data-dependent weights for autoregressive forecasting of time series.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural networks, convolutional neural networks, time series, asynchronous data, regression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1KFAGWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1KFAGWAZ">
          Revisiting The Master-Slave Architecture In Multi-Agent Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B1KFAGWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kxyzc1992%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kxyzc1992@gmail.com">Xiangyu Kong</a>, <a href="https://openreview.net/profile?email=liufangchen%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liufangchen@pku.edu.cn">Fangchen Liu</a>, <a href="https://openreview.net/profile?email=boxin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boxin@microsoft.com">Bo Xin</a>, <a href="https://openreview.net/profile?email=yizhou.wang%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yizhou.wang@pku.edu.cn">Yizhou Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1KFAGWAZ-details-202" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1KFAGWAZ-details-202"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many tasks in artificial intelligence require the collaboration of multiple agents. We exam deep reinforcement learning for multi-agent domains. Recent research efforts often take the form of two seemingly conflicting perspectives, the decentralized perspective, where each agent is supposed to have its own controller; and the centralized perspective, where one assumes there is a larger model controlling all agents. In this regard, we revisit the idea of the master-slave architecture by incorporating both perspectives within one framework. Such a hierarchical structure naturally leverages advantages from one another. The idea of combining both perspective is intuitive and can be well motivated from many real world systems, however, out of a variety of possible realizations, we highlights three key ingredients, i.e. composed action representation, learnable communication and independent reasoning. With network designs to facilitate these explicitly, our proposal consistently outperforms latest competing methods both in synthetics experiments and when applied to challenging StarCraft  micromanagement tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We revisit the idea of the master-slave architecture in multi-agent deep reinforcement learning and outperforms state-of-the-arts.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning, Multi-Agent Reinforcement Learning, StarCraft Micromanagement Tasks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1q_Cz-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=S1q_Cz-Cb">
          Training Neural Machines with Partial Traces
        </a>
        
          <a href="https://openreview.net/pdf?id=S1q_Cz-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=matthew.mirman%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.mirman@inf.ethz.ch">Matthew Mirman</a>, <a href="https://openreview.net/profile?email=dpavle%40student.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="dpavle@student.ethz.ch">Dimitar Dimitrov</a>, <a href="https://openreview.net/profile?email=dimitar.dimitrov%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimitar.dimitrov@inf.ethz.ch">Pavle Djordjevich</a>, <a href="https://openreview.net/profile?email=timon.gehr%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="timon.gehr@inf.ethz.ch">Timon Gehr</a>, <a href="https://openreview.net/profile?email=martin.vechev%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.vechev@inf.ethz.ch">Martin Vechev</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1q_Cz-Cb-details-452" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1q_Cz-Cb-details-452"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a novel approach for training neural abstract architectures which in- corporates (partial) supervision over the machine’s interpretable components. To cleanly capture the set of neural architectures to which our method applies, we introduce the concept of a differential neural computational machine (∂NCM) and show that several existing architectures (e.g., NTMs, NRAMs) can be instantiated as a ∂NCM and can thus benefit from any amount of additional supervision over their interpretable components. Based on our method, we performed a detailed experimental evaluation with both, the NTM and NRAM architectures, and showed that the approach leads to significantly better convergence and generalization capabilities of the learning phase than when training using only input-output examples.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We increase the amount of trace supervision possible to utilize when training fully differentiable neural machine architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Abstract Machines, Neural Turing Machines, Neural Random Access Machines, Program Synthesis, Program Induction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkMCybx0-">
      <h4>
        <a href="https://openreview.net/forum?id=HkMCybx0-">
          Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs)
        </a>
        
          <a href="https://openreview.net/pdf?id=HkMCybx0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bradcarlile%40yahoo.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bradcarlile@yahoo.com">Brad Carlile</a>, <a href="https://openreview.net/profile?email=info%40aiperf.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="info@aiperf.com">Guy Delamarter</a>, Paul Kinney, Akiko Marti, Brian Whitney
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkMCybx0--details-735" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkMCybx0--details-735"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce the “inverse square root linear unit” (ISRLU) to speed up learning in deep neural networks. ISRLU has better performance than ELU but has many of the same benefits. ISRLU and ELU have similar curves and characteristics. Both have negative values, allowing them to push mean unit activation closer to zero, and bring the normal gradient closer to the unit natural gradient, ensuring a noise- robust deactivation state, lessening the over fitting risk. The significant performance advantage of ISRLU on traditional CPUs also carry over to more efficient HW implementations on HW/SW codesign for CNNs/RNNs. In experiments with TensorFlow, ISRLU leads to faster learning and better generalization than ReLU on CNNs. This work also suggests a computationally efficient variant called the “inverse square root unit” (ISRU) which can be used for RNNs. Many RNNs use either long short-term memory (LSTM) and gated recurrent units (GRU) which are implemented with tanh and sigmoid activation functions. ISRU has less computational complexity but still has a similar curve to tanh and sigmoid.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the ISRLU activation function which is continuously differentiable and faster than ELU. The related ISRU replaces tanh &amp; sigmoid.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, Theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxE3jlA-">
      <h4>
        <a href="https://openreview.net/forum?id=SJxE3jlA-">
          Now I Remember! Episodic Memory For Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SJxE3jlA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=riloynd%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="riloynd@microsoft.com">Ricky Loynd</a>, <a href="https://openreview.net/profile?email=mahauskn%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mahauskn@microsoft.com">Matthew Hausknecht</a>, <a href="https://openreview.net/profile?email=lihongli.cs%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lihongli.cs@gmail.com">Lihong Li</a>, <a href="https://openreview.net/profile?email=l.deng%40ieee.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="l.deng@ieee.org">Li Deng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJxE3jlA--details-606" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxE3jlA--details-606"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Humans rely on episodic memory constantly, in remembering the name of someone they met 10 minutes ago, the plot of a movie as it unfolds, or where they parked the car. Endowing reinforcement learning agents with episodic memory is a key step on the path toward replicating human-like general intelligence. We analyze why standard RL agents lack episodic memory today, and why existing RL tasks don't require it. We design a new form of external memory called Masked Experience Memory, or MEM, modeled after key features of human episodic memory. To evaluate episodic memory we define an RL task based on the common children's game of Concentration. We find that a MEM RL agent leverages episodic memory effectively to master Concentration, unlike the baseline agents we tested.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Implementing and evaluating episodic memory for RL.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning, Deep learning, Episodic memory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk1NTfZAb">
      <h4>
        <a href="https://openreview.net/forum?id=Sk1NTfZAb">
          Key Protected Classification for GAN Attack Resilient Collaborative Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk1NTfZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mbsariyildiz%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbsariyildiz@gmail.com">Mert Bülent Sarıyıldız</a>, <a href="https://openreview.net/profile?email=gokberkcinbis%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gokberkcinbis@gmail.com">Ramazan Gökberk Cinbiş</a>, <a href="https://openreview.net/profile?email=erman%40cs.bilkent.edu.tr" class="profile-link" data-toggle="tooltip" data-placement="top" title="erman@cs.bilkent.edu.tr">Erman Ayday</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk1NTfZAb-details-738" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk1NTfZAb-details-738"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Large-scale publicly available datasets play a fundamental role in training deep learning models. However, large-scale
      datasets are difficult to collect in problems that involve processing of sensitive information.
      Collaborative learning techniques provide a privacy-preserving solution in such cases, by enabling
      training over a number of private datasets that are not shared by their owners.
      Existing collaborative learning
      techniques, combined with differential privacy, are shown to be resilient against a passive
      adversary which tries to infer the training data only from the model parameters. However, recently, it has
      been shown that the existing collaborative learning techniques are vulnerable to an active adversary that runs a GAN
      attack during the learning phase. In this work, we propose a novel key-based collaborative learning technique that is
      resilient against such GAN attacks. For this purpose, we present a collaborative learning formulation in which class scores 
      are protected by class-specific keys, and therefore, prevents a GAN attack. We also show that
      very high dimensional class-specific keys can be utilized to improve robustness against attacks, without increasing the model complexity. 
      Our experimental results on two popular datasets, MNIST and AT&amp;T Olivetti Faces, demonstrate the effectiveness of the proposed technique
      against the GAN attack. To the best of our knowledge, the proposed approach is the first collaborative learning
      formulation that effectively tackles an active adversary, and, unlike model corruption or differential privacy formulations,
      our approach does not inherently feature a trade-off between model accuracy and data privacy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">privacy preserving deep learning, collaborative learning, adversarial attack</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk_fs6gA-">
      <h4>
        <a href="https://openreview.net/forum?id=Bk_fs6gA-">
          Long Term Memory Network for Combinatorial Optimization Problems
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk_fs6gA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hazemahmed%40alexu.edu.eg" class="profile-link" data-toggle="tooltip" data-placement="top" title="hazemahmed@alexu.edu.eg">Hazem A. A. Nomer</a>, <a href="https://openreview.net/profile?email=abdallah_aboutahoun%40alexu.edu.eg" class="profile-link" data-toggle="tooltip" data-placement="top" title="abdallah_aboutahoun@alexu.edu.eg">Abdallah Aboutahoun</a>, <a href="https://openreview.net/profile?email=ashraf.elsayed%40alexu.edu.eg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashraf.elsayed@alexu.edu.eg">Ashraf Elsayed</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk_fs6gA--details-110" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk_fs6gA--details-110"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces a framework for solving combinatorial optimization problems by learning from input-output examples of optimization problems. We introduce a new memory augmented neural model in which the memory is not resettable (i.e the information stored in the memory after processing an input example is kept for the next seen examples). We used deep reinforcement learning to train a memory controller agent to store useful memories. Our model was able to outperform hand-crafted solver on Binary Linear Programming (Binary LP). The proposed model is tested on different Binary LP instances with large number of variables (up to 1000 variables) and constrains (up to 700 constrains).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a memory network model to solve Binary LP instances where the memory information is perseved for long-term use. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Memory Networks, Combinatorial Optimization, Binary LP</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r17Q6WWA-">
      <h4>
        <a href="https://openreview.net/forum?id=r17Q6WWA-">
          Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection
        </a>
        
          <a href="https://openreview.net/pdf?id=r17Q6WWA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ludovic.trottier.1%40ulaval.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludovic.trottier.1@ulaval.ca">Ludovic Trottier</a>, <a href="https://openreview.net/profile?email=philippe.giguere%40ift.ulaval.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="philippe.giguere@ift.ulaval.ca">Philippe Giguère</a>, <a href="https://openreview.net/profile?email=brahim.chaib-draa%40ift.ulaval.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="brahim.chaib-draa@ift.ulaval.ca">Brahim Chaib-draa</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r17Q6WWA--details-421" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r17Q6WWA--details-421"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-task learning, soft parameter sharing, facial landmark detection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJCPLLpaW">
      <h4>
        <a href="https://openreview.net/forum?id=SJCPLLpaW">
          Exploring the Hidden Dimension in Accelerating Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJCPLLpaW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhihao%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhihao@cs.stanford.edu">Zhihao Jia</a>, <a href="https://openreview.net/profile?email=silin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="silin@microsoft.com">Sina Lin</a>, <a href="https://openreview.net/profile?email=rqi%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rqi@stanford.edu">Charles R. Qi</a>, <a href="https://openreview.net/profile?email=aiken%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aiken@cs.stanford.edu">Alex Aiken</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJCPLLpaW-details-724" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJCPLLpaW-details-724"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">DeePa is a deep learning framework that explores parallelism in all parallelizable dimensions to accelerate the training process of convolutional neural networks. DeePa optimizes parallelism at the granularity of each individual layer in the network. We present an elimination-based algorithm that finds an optimal parallelism configuration for every layer. Our evaluation shows that DeePa achieves up to 6.5× speedup compared to state-of-the-art deep learning frameworks and reduces data transfers by up to 23×.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">To the best of our knowledge, DeePa is the first deep learning framework that controls and optimizes the parallelism of CNNs in all parallelizable dimensions at the granularity of each layer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Parallelism of Convolutional Neural Networks, Accelerating Convolutional Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1srNebAZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1srNebAZ">
          Discovering the mechanics of hidden neurons
        </a>
        
          <a href="https://openreview.net/pdf?id=H1srNebAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=simon.carbonnelle%40uclouvain.be" class="profile-link" data-toggle="tooltip" data-placement="top" title="simon.carbonnelle@uclouvain.be">Simon Carbonnelle</a>, <a href="https://openreview.net/profile?email=christophe.devleeschouwer%40uclouvain.be" class="profile-link" data-toggle="tooltip" data-placement="top" title="christophe.devleeschouwer@uclouvain.be">Christophe De Vleeschouwer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1srNebAZ-details-583" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1srNebAZ-details-583"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks trained through stochastic gradient descent (SGD) have been around for more than 30 years, but they still escape our understanding. This paper takes an experimental approach, with a divide-and-conquer strategy in mind: we start by studying what happens in single neurons. While being the core building block of deep neural networks, the way they encode information about the inputs and how such encodings emerge is still unknown. We report experiments providing strong evidence that hidden neurons behave like binary classifiers during training and testing. During training, analysis of the gradients reveals that a neuron separates two categories of inputs, which are impressively constant across training. During testing, we show that the fuzzy, binary partition described above embeds the core information used by the network for its prediction. These observations bring to light some of the core internal mechanics of deep neural networks, and have the potential to guide the next theoretical and practical developments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We report experiments providing strong evidence that a neuron behaves like a binary classifier during training and testing</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, experimental analysis, hidden neurons</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r16Vyf-0-">
      <h4>
        <a href="https://openreview.net/forum?id=r16Vyf-0-">
          Image Transformer
        </a>
        
          <a href="https://openreview.net/pdf?id=r16Vyf-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=avaswani%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avaswani@google.com">Ashish Vaswani</a>, <a href="https://openreview.net/profile?email=nikip%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikip@google.com">Niki Parmar</a>, <a href="https://openreview.net/profile?email=uszkoreit%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="uszkoreit@google.com">Jakob Uszkoreit</a>, <a href="https://openreview.net/profile?email=noam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="noam@google.com">Noam Shazeer</a>, <a href="https://openreview.net/profile?email=lukaszkaiser%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukaszkaiser@google.com">Lukasz Kaiser</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r16Vyf-0--details-336" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r16Vyf-0--details-336"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Image generation has been successfully cast as an autoregressive sequence generation
      or transformation problem. Recent work has shown that self-attention is
      an effective way of modeling textual sequences. In this work, we generalize a
      recently proposed model architecture based on self-attention, the Transformer, to
      a sequence modeling formulation of image generation with a tractable likelihood.
      By restricting the self-attention mechanism to attend to local neighborhoods we
      significantly increase the size of images the model can process in practice, despite
      maintaining significantly larger receptive fields per layer than typical convolutional
      neural networks. We propose another extension of self-attention allowing it
      to efficiently take advantage of the two-dimensional nature of images.
      While conceptually simple, our generative models trained on two image data sets
      are competitive with or significantly outperform the current state of the art in autoregressive
      image generation on two different data sets, CIFAR-10 and ImageNet.
      We also present results on image super-resolution with a large magnification ratio,
      applying an encoder-decoder configuration of our architecture. In a human
      evaluation study, we show that our super-resolution models improve significantly
      over previously published autoregressive super-resolution models. Images they
      generate fool human observers three times more often than the previous state of
      the art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">image generation, super-resolution, self-attention, transformer</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklpCzC6-">
      <h4>
        <a href="https://openreview.net/forum?id=HklpCzC6-">
          Image Segmentation by Iterative Inference from Conditional Score Estimation
        </a>
        
          <a href="https://openreview.net/pdf?id=HklpCzC6-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=adriana.romsor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adriana.romsor@gmail.com">Adriana Romero</a>, <a href="https://openreview.net/profile?email=michal.drozdzal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michal.drozdzal@gmail.com">Michal Drozdzal</a>, <a href="https://openreview.net/profile?email=akram.er-raqabi%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="akram.er-raqabi@umontreal.ca">Akram Erraqabi</a>, <a href="https://openreview.net/profile?email=simon.jegou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="simon.jegou@gmail.com">Simon Jégou</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HklpCzC6--details-223" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklpCzC6--details-223"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Inspired by the combination of feedforward and iterative computations in the visual cortex, and taking advantage of the ability of denoising autoencoders to estimate the score of a joint distribution, we propose a novel approach to iterative inference for capturing and exploiting the complex joint distribution of output variables conditioned on some input variables. This approach is applied to image pixel-wise segmentation, with the estimated conditional score used to perform gradient ascent towards a mode of the estimated conditional distribution. This extends previous work on score estimation by denoising autoencoders to the case of a conditional distribution, with a novel use of a corrupted feedforward predictor replacing Gaussian corruption. An advantage of this approach over more classical ways to perform iterative inference for structured outputs, like conditional random fields (CRFs), is that it is not any more necessary to define an explicit energy function linking the output variables. To keep computations tractable, such energy function parametrizations are typically fairly constrained, involving only a few neighbors of each of the output variables in each clique. We experimentally find that the proposed iterative inference from conditional score estimation by conditional denoising autoencoders performs better than comparable models based on CRFs or those not using any explicit modeling of the conditional joint distribution of outputs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Refining segmentation proposals by performing iterative inference with conditional denoising autoencoders.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">semantic segmentation, conditional denoising autoencoders, iterative inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkymMAxAb">
      <h4>
        <a href="https://openreview.net/forum?id=SkymMAxAb">
          AirNet: a machine learning dataset for air quality forecasting
        </a>
        
          <a href="https://openreview.net/pdf?id=SkymMAxAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gfgkmn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gfgkmn@gmail.com">Songgang Zhao</a>, <a href="https://openreview.net/profile?email=yuan%40caiyunapp.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuan@caiyunapp.com">Xingyuan Yuan</a>, <a href="https://openreview.net/profile?email=xiaoda99%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoda99@gmail.com">Da Xiao</a>, <a href="https://openreview.net/profile?email=littletree%40caiyunapp.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="littletree@caiyunapp.com">Jianyuan Zhang</a>, <a href="https://openreview.net/profile?email=joeyzhouyuanli%40caiyunapp.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joeyzhouyuanli@caiyunapp.com">Zhouyuan Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkymMAxAb-details-996" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkymMAxAb-details-996"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In the past decade, many urban areas in China have suffered from serious air pollution problems, making air quality forecast a hot spot. Conventional approaches rely on numerical methods to estimate the pollutant concentration and require lots of computing power. To solve this problem, we applied the widely used deep learning methods. Deep learning requires large-scale datasets to train an effective model. In this paper, we introduced a new dataset, entitled as AirNet, containing the 0.25 degree resolution grid map of mainland China, with more than two years of continued air quality measurement and meteorological data. We published this dataset as an open resource for machine learning researches and set up a baseline of a 5-day air pollution forecast. The results of experiments demonstrated that this dataset could facilitate the development of new algorithms on the air quality forecast.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1nzLmWAb">
      <h4>
        <a href="https://openreview.net/forum?id=r1nzLmWAb">
          Video Action Segmentation with Hybrid Temporal Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1nzLmWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=liding%40rochester.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liding@rochester.edu">Li Ding</a>, <a href="https://openreview.net/profile?email=chenliang.xu%40rochester.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenliang.xu@rochester.edu">Chenliang Xu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1nzLmWAb-details-721" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1nzLmWAb-details-721"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Action segmentation as a milestone towards building automatic systems to understand untrimmed videos has received considerable attention in the recent years. It is typically being modeled as a sequence labeling problem but contains intrinsic and sufficient differences than text parsing or speech processing. In this paper, we introduce a novel hybrid temporal convolutional and recurrent network (TricorNet), which has an encoder-decoder architecture: the encoder consists of a hierarchy of temporal convolutional kernels that capture the local motion changes of different actions; the decoder is a hierarchy of recurrent neural networks that are able to learn and memorize long-term action dependencies after the encoding stage. Our model is simple but extremely effective in terms of video sequence labeling. The experimental results on three public action segmentation datasets have shown that the proposed model achieves superior performance over the state of the art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new hybrid temporal network that achieves state-of-the-art performance on video action segmentation on three public datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">action segmentation, video labeling, temporal networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByZmGjkA-">
      <h4>
        <a href="https://openreview.net/forum?id=ByZmGjkA-">
          Understanding Grounded Language Learning Agents
        </a>
        
          <a href="https://openreview.net/pdf?id=ByZmGjkA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=felixhill%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="felixhill@google.com">Felix Hill</a>, <a href="https://openreview.net/profile?email=kmh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kmh@google.com">Karl Moritz Hermann</a>, <a href="https://openreview.net/profile?email=pblunsom%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pblunsom@google.com">Phil Blunsom</a>, <a href="https://openreview.net/profile?email=clarkstephen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="clarkstephen@google.com">Stephen Clark</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByZmGjkA--details-73" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByZmGjkA--details-73"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural network-based systems can now learn to locate the referents of words and phrases in images, answer questions about visual scenes, and even execute symbolic instructions as first-person actors in partially-observable worlds. To achieve this so-called grounded language learning, models must overcome certain well-studied learning challenges that are also fundamental to infants learning their first words. While it is notable that models with no meaningful prior knowledge overcome these learning obstacles, AI researchers and practitioners currently lack a clear understanding of exactly how they do so. Here we address this question as a way of achieving a clearer general understanding of grounded language learning, both to inform future research and to improve confidence in model predictions. For maximum control and generality, we focus on a simple neural network-based language learning agent trained via policy-gradient methods to interpret synthetic linguistic instructions in a simulated 3D world. We apply experimental paradigms from developmental psychology to this agent, exploring the conditions under which established human biases and learning effects emerge. We further propose a novel way to visualise and analyse semantic representation in grounded language learning agents that yields a plausible computational account of the observed effects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Analysing and understanding how neural network agents learn to understand simple grounded language</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Language AI Learning Reinforcement Deep</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkBcLugC-">
      <h4>
        <a href="https://openreview.net/forum?id=SkBcLugC-">
          Fast and Accurate Inference with Adaptive Ensemble Prediction for Deep Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkBcLugC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=inouehrs%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="inouehrs@jp.ibm.com">Hiroshi Inoue</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkBcLugC--details-407" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkBcLugC--details-407"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Ensembling multiple predictions is a widely-used technique to improve the accuracy of various machine learning tasks. In image classification tasks, for example, averaging the predictions for multiple patches extracted from the input image significantly improves accuracy. Using multiple networks trained independently to make predictions improves accuracy further. One obvious drawback of the ensembling technique is its higher execution cost during inference.% If we average 100 local predictions, the execution cost will be 100 times as high as the cost without the ensemble. This higher cost limits the real-world use of ensembling. In this paper, we first describe our insights on relationship between the probability of the prediction and the effect of ensembling with current deep neural networks; ensembling does not help mispredictions for inputs predicted with a high probability, i.e. the output from the softmax. This finding motivates us to develop a new technique called adaptive ensemble prediction, which achieves the benefits of ensembling with much smaller additional execution costs. Hence, we calculate the confidence level of the prediction for each input from the probabilities of the local predictions during the ensembling computation. If the prediction for an input reaches a high enough probability on the basis of the confidence level, we stop ensembling for this input to avoid wasting computation power. We evaluated the adaptive ensembling by using various datasets and showed that it reduces the computation cost significantly while achieving similar accuracy to the naive ensembling. We also showed that our statistically rigorous confidence-level-based termination condition reduces the burden of the task-dependent parameter tuning compared to the naive termination based on the pre-defined threshold in addition to yielding a better accuracy with the same cost.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">ensemble, confidence level</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJe7FW-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=rJe7FW-Cb">
          A Painless Attention Mechanism for Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJe7FW-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pau.rodriguez%40cvc.uab.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="pau.rodriguez@cvc.uab.es">Pau Rodríguez</a>, <a href="https://openreview.net/profile?email=gcucurull%40cvc.uab.cat" class="profile-link" data-toggle="tooltip" data-placement="top" title="gcucurull@cvc.uab.cat">Guillem Cucurull</a>, <a href="https://openreview.net/profile?email=poal%40cvc.uab.cat" class="profile-link" data-toggle="tooltip" data-placement="top" title="poal@cvc.uab.cat">Jordi Gonzàlez</a>, <a href="https://openreview.net/profile?email=xavir%40cvc.uab.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="xavir@cvc.uab.es">Josep M. Gonfaus</a>, Xavier Roca
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJe7FW-Cb-details-222" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJe7FW-Cb-details-222"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. The proposed mechanism reuses CNN feature activations to find the most informative parts of the image at different depths with the help of gating mechanisms and without part annotations. Thus, it can be used to augment any layer of a CNN to extract low- and high-level local information to be more discriminative. 
      
      Differently, from other approaches, the mechanism we propose just needs a single pass through the input and it can be trained end-to-end through SGD. As a consequence, the proposed mechanism is modular, architecture-independent, easy to implement, and faster than iterative approaches.
      
      Experiments show that, when augmented with our approach, Wide Residual Networks systematically achieve superior performance on each of five different fine-grained recognition datasets: the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100, obtaining competitive and state-of-the-art scores.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We enhance CNNs with a novel attention mechanism for fine-grained recognition. Superior performance is obtained on 5 datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">computer vision, deep learning, convolutional neural networks, attention</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkiIkBJ0b">
      <h4>
        <a href="https://openreview.net/forum?id=BkiIkBJ0b">
          Do Deep Reinforcement Learning Algorithms really Learn to Navigate?
        </a>
        
          <a href="https://openreview.net/pdf?id=BkiIkBJ0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shurjo%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shurjo@umich.edu">Shurjo Banerjee</a>, <a href="https://openreview.net/profile?email=dhiman%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhiman@umich.edu">Vikas Dhiman</a>, <a href="https://openreview.net/profile?email=griffb%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="griffb@umich.edu">Brent Griffin</a>, <a href="https://openreview.net/profile?email=jjcorso%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjcorso@umich.edu">Jason J. Corso</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkiIkBJ0b-details-918" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkiIkBJ0b-details-918"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning (DRL) algorithms have demonstrated progress in learning to find a goal in challenging environments. As the title of the paper by Mirowski et al. (2016) suggests, one might assume that DRL-based algorithms are able to “learn to navigate” and are thus ready to replace classical mapping and path-planning algorithms, at least in simulated environments. Yet, from experiments and analysis in this earlier work, it is not clear what strategies are used by these algorithms in navigating the mazes and finding the goal. In this paper, we pose and study this underlying question: are DRL algorithms doing some form of mapping and/or path-planning? Our experiments show that the algorithms are not memorizing the maps of mazes at the testing stage but, rather, at the training stage. Hence, the DRL algorithms fall short of qualifying as mapping or path-planning algorithms with any reasonable definition of mapping. We extend the experiments in Mirowski et al. (2016) by separating the set of training and testing maps and by a more ablative coverage of the space of experiments. Our systematic experiments show that the NavA3C-D1-D2-L algorithm, when trained and tested on the same maps, is able to choose the shorter paths to the goal. However, when tested on unseen maps the algorithm utilizes a wall-following strategy to find the goal without doing any mapping or path planning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We quantitatively and qualitatively evaluate deep reinforcement learning based navigation methods under a variety of conditions to answer the question of how close they are to replacing classical path planners and mapping algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, navigation, path-planning, mapping</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJPSN3gRW">
      <h4>
        <a href="https://openreview.net/forum?id=HJPSN3gRW">
          Learning to navigate by distilling visual information and natural language instructions
        </a>
        
          <a href="https://openreview.net/pdf?id=HJPSN3gRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=abhsinha%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhsinha@adobe.com">Abhishek Sinha</a>, <a href="https://openreview.net/profile?email=akb%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akb@adobe.com">Akilesh B</a>, <a href="https://openreview.net/profile?email=msarkar%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="msarkar@adobe.com">Mausoom Sarkar</a>, <a href="https://openreview.net/profile?email=kbalaji%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kbalaji@adobe.com">Balaji Krishnamurthy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJPSN3gRW-details-47" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJPSN3gRW-details-47"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work, we focus on the problem of grounding language by training an agent
      to follow a set of natural language instructions and navigate to a target object
      in a 2D grid environment. The agent receives visual information through raw
      pixels and a natural language instruction telling what task needs to be achieved.
      Other than these two sources of information, our model does not have any prior
      information of both the visual and textual modalities and is end-to-end trainable.
      We develop an attention mechanism for multi-modal fusion of visual and textual
      modalities that allows the agent to learn to complete the navigation tasks and also
      achieve language grounding. Our experimental results show that our attention
      mechanism outperforms the existing multi-modal fusion mechanisms proposed in
      order to solve the above mentioned navigation task. We demonstrate through the
      visualization of attention weights that our model learns to correlate attributes of
      the object referred in the instruction with visual representations and also show
      that the learnt textual representations are semantically meaningful as they follow
      vector arithmetic and are also consistent enough to induce translation between instructions
      in different natural languages. We also show that our model generalizes
      effectively to unseen scenarios and exhibit zero-shot generalization capabilities.
      In order to simulate the above described challenges, we introduce a new 2D environment
      for an agent to jointly learn visual and textual modalities</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Attention based architecture for language grounding via reinforcement learning in a new customizable 2D grid environment  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep reinforcement learning, Computer Vision, Multi-modal fusion, Language Grounding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJNGGmZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=HJNGGmZ0Z">
          What is image captioning made of?
        </a>
        
          <a href="https://openreview.net/pdf?id=HJNGGmZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=p.madhyastha%40sheffield.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="p.madhyastha@sheffield.ac.uk">Pranava Madhyastha</a>, <a href="https://openreview.net/profile?email=j.k.wang%40sheffield.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.k.wang@sheffield.ac.uk">Josiah Wang</a>, <a href="https://openreview.net/profile?email=l.specia%40sheffield.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="l.specia@sheffield.ac.uk">Lucia Specia</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJNGGmZ0Z-details-235" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJNGGmZ0Z-details-235"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We hypothesize that end-to-end neural image captioning systems work seemingly well because they exploit and learn ‘distributional similarity’ in a multimodal feature space, by mapping a test image to similar training images in this space and generating a caption from the same space. To validate our hypothesis, we focus on the ‘image’ side of image captioning, and vary the input image representation but keep the RNN text generation model of a CNN-RNN constant. We propose a sparse bag-of-objects vector as an interpretable representation to investigate our distributional similarity hypothesis. We found that image captioning models (i) are capable of separating structure from noisy input representations; (ii) experience virtually no significant performance loss when a high dimensional representation is compressed to a lower dimensional space; (iii) cluster images with similar visual and linguistic information together; (iv) are heavily reliant on test sets with a similar distribution as the training set; (v) repeatedly generate the same captions by matching images and ‘retrieving’ a caption in the joint visual-textual space. Our experiments all point to one fact: that our distributional similarity hypothesis holds. We conclude that, regardless of the image representation, image captioning systems seem to match images and generate captions in a learned joint image-text semantic subspace.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper presents an empirical analysis on the role of different types of image representations and probes the properties of these representations for the task of image captioning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">image captioning, representation learning, interpretability, rnn, multimodal, vision to language</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkWN3g-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkWN3g-AZ">
          XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings
        </a>
        
          <a href="https://openreview.net/pdf?id=rkWN3g-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aroyer%40ist.ac.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="aroyer@ist.ac.at">Amelie Royer</a>, <a href="https://openreview.net/profile?email=konstantinos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="konstantinos@google.com">Konstantinos Bousmalis</a>, <a href="https://openreview.net/profile?email=sgouws%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgouws@google.com">Stephan Gouws</a>, <a href="https://openreview.net/profile?email=fredbertsch%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fredbertsch@google.com">Fred Bertsch</a>, <a href="https://openreview.net/profile?email=inbarm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="inbarm@google.com">Inbar Mosseri</a>, <a href="https://openreview.net/profile?email=fcole%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fcole@google.com">Forrester Cole</a>, <a href="https://openreview.net/profile?email=kpmurphy%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kpmurphy@google.com">Kevin Murphy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkWN3g-AZ-details-620" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkWN3g-AZ-details-620"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Style transfer usually refers to the task of applying color and texture information from a specific style image to a given content image while preserving the structure of the latter. Here we tackle the more generic problem of semantic style transfer: given two unpaired collections of images, we aim to learn a mapping between the corpus-level style of each collection, while preserving semantic content shared across the two domains. We introduce XGAN ("Cross-GAN"), a dual adversarial autoencoder, which captures a shared representation of the common domain semantic content in an unsupervised way, while jointly learning the domain-to-domain image translations in both directions.  We exploit ideas from the domain adaptation literature and define a semantic consistency loss which encourages the model to preserve semantics in the learned embedding space. We report promising qualitative results for the task of face-to-cartoon translation. The cartoon dataset we collected for this purpose will also be released as a new benchmark for semantic style transfer.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">XGAN is an unsupervised model for feature-level image-to-image translation applied to semantic style transfer problems such as the face-to-cartoon task, for which we introduce a new dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised, gan, domain adaptation, style transfer, semantic, image translation, dataset</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJDH5M-AW">
      <h4>
        <a href="https://openreview.net/forum?id=BJDH5M-AW">
          Synthesizing Robust Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=BJDH5M-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aathalye%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aathalye@mit.edu">Anish Athalye</a>, <a href="https://openreview.net/profile?email=engstrom%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="engstrom@mit.edu">Logan Engstrom</a>, <a href="https://openreview.net/profile?email=ailyas%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ailyas@mit.edu">Andrew Ilyas</a>, <a href="https://openreview.net/profile?email=kevink16%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevink16@gmail.com">Kevin Kwok</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJDH5M-AW-details-637" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJDH5M-AW-details-637"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural network-based classifiers parallel or exceed human-level accuracy on many common tasks and are used in practical systems. Yet, neural networks are susceptible to adversarial examples, carefully perturbed inputs that cause networks to misbehave in arbitrarily chosen ways. When generated with standard methods, these examples do not consistently fool a classifier in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations. Adversarial examples generated using standard techniques require complete control over direct input to the classifier, which is impossible in many real-world systems.
      
      We introduce the first method for constructing real-world 3D objects that consistently fool a neural network across a wide distribution of angles and viewpoints. We present a general-purpose algorithm for generating adversarial examples that are robust across any chosen distribution of transformations. We demonstrate its application in two dimensions, producing adversarial images that are robust to noise, distortion, and affine transformation. Finally, we apply the algorithm to produce arbitrary physical 3D-printed adversarial objects, demonstrating that our approach works end-to-end in the real world. Our results show that adversarial examples are a practical concern for real-world systems.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a new method for synthesizing adversarial examples robust in the physical world and use it to fabricate the first 3D adversarial objects.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1680_1Rb">
      <h4>
        <a href="https://openreview.net/forum?id=S1680_1Rb">
          CAYLEYNETS: SPECTRAL GRAPH CNNS WITH COMPLEX RATIONAL FILTERS
        </a>
        
          <a href="https://openreview.net/pdf?id=S1680_1Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ronlevie%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronlevie@gmail.com">Ron Levie</a>, <a href="https://openreview.net/profile?email=federico.monti%40usi.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="federico.monti@usi.ch">Federico Monti</a>, <a href="https://openreview.net/profile?email=xavier.bresson%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xavier.bresson@gmail.com">Xavier Bresson</a>, <a href="https://openreview.net/profile?email=michael.bronstein%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.bronstein@gmail.com">Michael M. Bronstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1680_1Rb-details-515" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1680_1Rb-details-515"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. 
      In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest. Our model generates rich spectral filters that are localized in space, scales linearly with the size of the input data for sparsely-connected graphs, and can handle different constructions of Laplacian operators. Extensive experimental results show the superior performance of our approach on spectral image classification, community detection, vertex classification and matrix completion tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A spectral graph convolutional neural network with spectral zoom properties.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Spectral Graph Convolutional Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkaPsfZ0W">
      <h4>
        <a href="https://openreview.net/forum?id=SkaPsfZ0W">
          Network of Graph Convolutional Networks Trained on Random Walks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkaPsfZ0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=haija%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haija@google.com">Sami Abu-El-Haija</a>, <a href="https://openreview.net/profile?email=ajk2227%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajk2227@columbia.edu">Amol Kapoor</a>, <a href="https://openreview.net/profile?email=bperozzi%40acm.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="bperozzi@acm.org">Bryan Perozzi</a>, <a href="https://openreview.net/profile?email=joonseok%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joonseok@google.com">Joonseok Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkaPsfZ0W-details-877" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkaPsfZ0W-details-877"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Graph Convolutional Networks (GCNs) are a recently proposed architecture which has had success in semi-supervised learning on graph-structured data. At the same time, unsupervised learning of graph embeddings has benefited from the information contained in random walks. In this paper we propose a model, Network of GCNs (N-GCN), which marries these two lines of work. At its core, N-GCN trains multiple instances of GCNs over node pairs discovered at different distances in random walks, and learns a combination of the instance outputs which optimizes the classification objective. Our experiments show that our proposed N-GCN model achieves state-of-the-art performance on all of the challenging node classification tasks we consider: Cora, Citeseer, Pubmed, and PPI. In addition, our proposed method has other desirable properties, including generalization to recently proposed semi-supervised learning methods such as GraphSAGE, allowing us to propose N-SAGE, and resilience to adversarial input perturbations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We make a network of Graph Convolution Networks, feeding each a different power of the adjacency matrix, combining all their representation into a classification sub-network, achieving state-of-the-art on semi-supervised node classification.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Graph Convolution, Deep Learning, Network of Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyBBgXWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyBBgXWAZ">
          Optimal transport maps for distribution preserving operations on latent spaces of Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SyBBgXWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aeirikur%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="aeirikur@vision.ee.ethz.ch">Eirikur Agustsson</a>, <a href="https://openreview.net/profile?email=sagea%40student.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="sagea@student.ethz.ch">Alexander Sage</a>, <a href="https://openreview.net/profile?email=radu.timofte%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="radu.timofte@vision.ee.ethz.ch">Radu Timofte</a>, <a href="https://openreview.net/profile?email=vangool%40vision.ee.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="vangool@vision.ee.ethz.ch">Luc Van Gool</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyBBgXWAZ-details-44" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyBBgXWAZ-details-44"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative models such as Variational Auto Encoders (VAEs) and Generative Adversarial Networks (GANs) are typically trained for a fixed prior distribution in the latent space, such as uniform or Gaussian.
      After a trained model is obtained, one can sample the Generator in various forms for exploration and understanding, such as interpolating between two samples, sampling in the vicinity of a sample or exploring differences between a pair of samples applied to a third sample.
      In this paper, we show that the latent space operations used in the literature so far induce a distribution mismatch between the resulting outputs and the prior distribution the model was trained on. To address this, we propose to use distribution matching transport maps to ensure that such  latent space operations preserve the prior distribution, while minimally modifying the original operation. 
      Our experimental results validate that the proposed operations give higher quality samples compared to the original operations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Operations in the GAN latent space can induce a distribution mismatch compared to the training distribution, and we address this using optimal transport to match the distributions. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Models, GANs, latent space operations, optimal transport</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H139Q_gAW">
      <h4>
        <a href="https://openreview.net/forum?id=H139Q_gAW">
          Learning Graph Convolution Filters from Data Manifold
        </a>
        
          <a href="https://openreview.net/pdf?id=H139Q_gAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=guokun%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guokun@cs.cmu.edu">Guokun Lai</a>, <a href="https://openreview.net/profile?email=hanxiaol%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanxiaol@cs.cmu.edu">Hanxiao Liu</a>, <a href="https://openreview.net/profile?email=yiming%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiming@cs.cmu.edu">Yiming Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H139Q_gAW-details-332" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H139Q_gAW-details-332"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolution Neural Network (CNN) has gained tremendous success in computer vision tasks with its outstanding ability to capture the local latent features. Recently, there has been an increasing interest in extending CNNs to the general spatial domain. Although various types of graph convolution and geometric convolution methods have been proposed, their connections to traditional 2D-convolution are not well-understood. In this paper, we show that depthwise separable convolution is a path to unify the two kinds of convolution methods in one mathematical view, based on which we derive a novel Depthwise Separable Graph Convolution that subsumes existing graph convolution methods as special cases of our formulation. Experiments show that the proposed approach consistently outperforms other graph convolution and geometric convolution baselines on benchmark datasets in multiple domains.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We devise a novel Depthwise Separable Graph Convolution (DSGC) for the generic spatial domain data, which is highly compatible with depthwise separable convolution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Label Propagation, Depthwise separable convolution, Graph and geometric convolution</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyjsLqxR-">
      <h4>
        <a href="https://openreview.net/forum?id=SyjsLqxR-">
          Universality, Robustness, and Detectability of Adversarial Perturbations under Adversarial Training
        </a>
        
          <a href="https://openreview.net/pdf?id=SyjsLqxR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=janhendrik.metzen%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="janhendrik.metzen@de.bosch.com">Jan Hendrik Metzen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyjsLqxR--details-544" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyjsLqxR--details-544"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Classifiers such as deep neural networks have been shown to be vulnerable against adversarial perturbations on problems with high-dimensional input space. While adversarial training improves the robustness of classifiers against such adversarial perturbations, it leaves classifiers sensitive to them on a non-negligible fraction of the inputs. We argue that there are two different kinds of adversarial perturbations: shared perturbations which fool a classifier on many inputs and singular perturbations which only fool the classifier on a small fraction of the data. We find that adversarial training increases the robustness of classifiers against shared perturbations. Moreover, it is particularly effective in removing universal perturbations, which can be seen as an extreme form of shared perturbations. Unfortunately, adversarial training does not consistently increase the robustness against singular perturbations on unseen inputs. However, we find that adversarial training decreases robustness of the remaining perturbations against image transformations such as changes to contrast and brightness or  Gaussian blurring. It thus makes successful attacks on the classifier in the physical world less likely. Finally, we show that even singular perturbations can be easily detected and must thus exhibit generalizable patterns even though the perturbations are specific for certain inputs. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We empirically show that adversarial training is effective for removing universal perturbations, makes adversarial examples less robust to image transformations, and leaves them detectable for a detection approach.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, adversarial training, universal perturbations, safety, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hki-ZlbA-">
      <h4>
        <a href="https://openreview.net/forum?id=Hki-ZlbA-">
          Ground-Truth Adversarial Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=Hki-ZlbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nicholas%40carlini.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicholas@carlini.com">Nicholas Carlini</a>, <a href="https://openreview.net/profile?email=katz911%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="katz911@gmail.com">Guy Katz</a>, <a href="https://openreview.net/profile?email=barrett%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="barrett@cs.stanford.edu">Clark Barrett</a>, <a href="https://openreview.net/profile?email=dill%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dill@cs.stanford.edu">David L. Dill</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hki-ZlbA--details-346" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hki-ZlbA--details-346"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The ability to deploy neural networks in real-world, safety-critical systems is severely limited by the presence of adversarial examples: slightly perturbed inputs that are misclassified by the network. In recent years, several techniques have been proposed for training networks that are robust to such examples; and each time stronger attacks have been devised, demonstrating the shortcomings of existing defenses. This highlights a key difficulty in designing an effective defense: the inability to assess a network's robustness against future attacks. We propose to address this difficulty through formal verification techniques. We construct ground truths: adversarial examples with a provably-minimal distance from a given input point. We demonstrate how ground truths can serve to assess the effectiveness of attack techniques, by comparing the adversarial examples produced by those attacks to the ground truths; and also of defense techniques, by computing the distance to the ground truths before and after the defense is applied, and measuring the improvement. We use this technique to assess recently suggested attack and defense techniques.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use formal verification to assess the effectiveness of techniques for finding adversarial examples or for defending against adversarial examples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, neural networks, formal verification, ground truths</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyqAPeWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyqAPeWAZ">
          CNNs as Inverse Problem Solvers and Double Network Superresolution
        </a>
        
          <a href="https://openreview.net/pdf?id=SyqAPeWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cemtarhan%40aselsan.com.tr" class="profile-link" data-toggle="tooltip" data-placement="top" title="cemtarhan@aselsan.com.tr">Cem TARHAN</a>, <a href="https://openreview.net/profile?email=bozdagi%40metu.edu.tr" class="profile-link" data-toggle="tooltip" data-placement="top" title="bozdagi@metu.edu.tr">Gözde BOZDAĞI AKAR</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyqAPeWAZ-details-114" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyqAPeWAZ-details-114"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In recent years Convolutional Neural Networks (CNN) have been used extensively for Superresolution (SR). In this paper, we use inverse problem and sparse representation solutions to form a mathematical basis for CNN operations. We show how a single neuron is able to provide the optimum solution for inverse problem, given a low resolution image dictionary as an operator. Introducing a new concept called Representation Dictionary Duality, we show that CNN elements (filters) are trained to be representation vectors and then, during reconstruction, used as dictionaries. In the light of theoretical work, we propose a new algorithm which uses two networks with different structures that are separately trained with low and high coherency image patches and show that it performs faster compared to the state-of-the-art algorithms while not sacrificing from performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">After proving that a neuron acts as an inverse problem solver for superresolution and a network of neurons is guarantied to provide a solution, we proposed a double network architecture that performs faster than state-of-the-art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">superresolution, convolutional neural network, sparse representation, inverse problem</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklZOfW0W">
      <h4>
        <a href="https://openreview.net/forum?id=HklZOfW0W">
          UPS: optimizing Undirected Positive Sparse graph for neural graph filtering
        </a>
        
          <a href="https://openreview.net/pdf?id=HklZOfW0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=moonfolk%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="moonfolk@umich.edu">Mikhail Yurochkin</a>, <a href="https://openreview.net/profile?email=dthai%40iesl.cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dthai@iesl.cs.umass.edu">Dung Thai</a>, <a href="https://openreview.net/profile?email=bui.h.hung%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bui.h.hung@gmail.com">Hung Hai Bui</a>, <a href="https://openreview.net/profile?email=xuanlong%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuanlong@umich.edu">XuanLong Nguyen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HklZOfW0W-details-280" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklZOfW0W-details-280"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work we propose a novel approach for learning graph representation of the data using gradients obtained via backpropagation. Next we build a neural network architecture compatible with our optimization approach and motivated by graph filtering in the vertex domain. We demonstrate that the learned graph has richer structure than often used nearest neighbors graphs constructed based on features similarity. Our experiments demonstrate that we can improve prediction quality for several convolution on graphs architectures, while others appeared to be insensitive to the input graph.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Graph Optimization with signal filtering in the vertex domain.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H11lAfbCW">
      <h4>
        <a href="https://openreview.net/forum?id=H11lAfbCW">
          On Characterizing the Capacity of Neural Networks Using Algebraic Topology
        </a>
        
          <a href="https://openreview.net/pdf?id=H11lAfbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wguss%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wguss@cs.cmu.edu">William H. Guss</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H11lAfbCW-details-94" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H11lAfbCW-details-94"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The learnability of different neural architectures can be characterized directly by computable measures of data complexity. In this paper, we reframe the problem of architecture selection as understanding how data determines the most expressive and generalizable architectures suited to that data, beyond inductive bias. After suggesting algebraic topology as a measure for data complexity, we show that the power of a network to express the topological complexity of a dataset in its decision boundary is a strictly limiting factor in its ability to generalize. We then provide the first empirical characterization of the topological capacity of neural networks. Our empirical analysis shows that at every level of dataset complexity, neural networks exhibit topological phase transitions and stratification. This observation allowed us to connect existing theory to empirically driven conjectures on the choice of architectures for a single hidden layer neural networks. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that the learnability of different neural architectures can be characterized directly by computable measures of data complexity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning theory, architecture selection, algebraic topology</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk7wvW-C-">
      <h4>
        <a href="https://openreview.net/forum?id=Bk7wvW-C-">
          Exploring Asymmetric Encoder-Decoder Structure for Context-based Sentence Representation Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk7wvW-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shuaitang93%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shuaitang93@ucsd.edu">Shuai Tang</a>, <a href="https://openreview.net/profile?email=hljin%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hljin@adobe.com">Hailin Jin</a>, <a href="https://openreview.net/profile?email=cfang%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cfang@adobe.com">Chen Fang</a>, <a href="https://openreview.net/profile?email=zhawang%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhawang@adobe.com">Zhaowen Wang</a>, <a href="https://openreview.net/profile?email=desa%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="desa@ucsd.edu">Virginia R. de Sa</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk7wvW-C--details-803" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk7wvW-C--details-803"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Context information plays an important role in human language understanding, and it is also useful for machines to learn vector representations of language. In this paper, we explore an asymmetric encoder-decoder structure for unsupervised context-based sentence representation learning. As a result, we build an encoder-decoder architecture with an RNN encoder and a CNN decoder, and we show that neither an autoregressive decoder nor an RNN decoder is required.  We further combine a suite of effective designs to significantly improve model efficiency while also achieving better performance. Our model is trained on two different large unlabeled corpora, and in both cases transferability is evaluated on a set of downstream language understanding tasks. We empirically show that our model is simple and fast while producing rich sentence representations that excel in downstream tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We proposed an RNN-CNN encoder-decoder model for fast unsupervised sentence representation learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">asymmetric structure, RNN-CNN, fast, unsupervised, representation, sentence</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryHM_fbA-">
      <h4>
        <a href="https://openreview.net/forum?id=ryHM_fbA-">
          Learning Document Embeddings With CNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=ryHM_fbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shunan%40layer6.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="shunan@layer6.ai">Shunan Zhao</a>, <a href="https://openreview.net/profile?email=chundi%40layer6.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="chundi@layer6.ai">Chundi Lui</a>, <a href="https://openreview.net/profile?email=maksims.volkovs%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maksims.volkovs@gmail.com">Maksims Volkovs</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryHM_fbA--details-857" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryHM_fbA--details-857"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper proposes a new model for document embedding. Existing approaches either require complex inference or use recurrent neural networks that are difficult to parallelize. We take a different route and use recent advances in language modeling to develop a convolutional neural network embedding model. This allows us to train deeper architectures that are fully parallelizable. Stacking layers together increases the receptive filed allowing each successive layer to model increasingly longer range semantic dependences within the document. Empirically we demonstrate superior results on two publicly available benchmarks. Full code will be released with the final version of this paper.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Convolutional neural network model for unsupervised document embedding.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised embedding, convolutional neural network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByUEelW0-">
      <h4>
        <a href="https://openreview.net/forum?id=ByUEelW0-">
          Modifying memories in a Recurrent Neural Network Unit
        </a>
        
          <a href="https://openreview.net/pdf?id=ByUEelW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vsv1g12%40soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="vsv1g12@soton.ac.uk">Vlad Velici</a>, <a href="https://openreview.net/profile?email=apb%40soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="apb@soton.ac.uk">Adam Prügel-Bennett</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByUEelW0--details-333" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByUEelW0--details-333"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Long Short-Term Memory (LSTM) units have the ability to memorise and use long-term dependencies between inputs to generate predictions on time series data. We introduce the concept of modifying the cell state (memory) of LSTMs using rotation matrices parametrised by a new set of trainable weights. This addition shows significant increases of performance on some of the tasks from the bAbI dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adding a new set of weights to the LSTM that rotate the cell memory improves performance on some bAbI tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">LSTM, RNN, rotation matrix, long-term memory, natural language processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syt0r4bRZ">
      <h4>
        <a href="https://openreview.net/forum?id=Syt0r4bRZ">
          Tree2Tree Learning with Memory Unit
        </a>
        
          <a href="https://openreview.net/pdf?id=Syt0r4bRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=miaoning%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="miaoning@pku.edu.cn">Ning Miao</a>, <a href="https://openreview.net/profile?email=wanghl%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanghl@pku.edu.cn">Hengliang Wang</a>, <a href="https://openreview.net/profile?email=leran%40buaa.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="leran@buaa.edu.cn">Ran Le</a>, <a href="https://openreview.net/profile?email=chongyangtao%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongyangtao@pku.edu.cn">Chongyang Tao</a>, <a href="https://openreview.net/profile?email=shangmy%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="shangmy@pku.edu.cn">Mingyue Shang</a>, <a href="https://openreview.net/profile?email=ruiyan%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruiyan@pku.edu.cn">Rui Yan</a>, <a href="https://openreview.net/profile?email=zhaody%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaody@pku.edu.cn">Dongyan Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syt0r4bRZ-details-217" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syt0r4bRZ-details-217"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Traditional recurrent neural network (RNN) or convolutional neural net- work (CNN) based sequence-to-sequence model can not handle tree structural data well. To alleviate this problem, in this paper, we propose a tree-to-tree model with specially designed encoder unit and decoder unit, which recursively encodes tree inputs into highly folded tree embeddings and decodes the embeddings into tree outputs. Our model could represent the complex information of a tree while also restore a tree from embeddings.
      We evaluate our model in random tree recovery task and neural machine translation task. Experiments show that our model outperforms the baseline model.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk2MHt-3-">
      <h4>
        <a href="https://openreview.net/forum?id=Hk2MHt-3-">
          Coupled Ensembles of Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk2MHt-3-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anuvabh.dutt%40univ-grenoble-alpes.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="anuvabh.dutt@univ-grenoble-alpes.fr">Anuvabh Dutt</a>, <a href="https://openreview.net/profile?email=denis.pellerin%40gipsa-lab.grenoble-inp.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="denis.pellerin@gipsa-lab.grenoble-inp.fr">Denis Pellerin</a>, <a href="https://openreview.net/profile?email=georges.quenot%40imag.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="georges.quenot@imag.fr">Georges Quénot</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk2MHt-3--details-51" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk2MHt-3--details-51"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We investigate in this paper the architecture of deep convolutional networks. Building on existing state of the art models, we propose a reconfiguration of the model parameters into several parallel branches at the global network level, with each branch being a standalone CNN. We show that this arrangement is an efficient way to significantly reduce the number of parameters while at the same time improving the performance. The use of branches brings an additional form of regularization. In addition to splitting the parameters into parallel branches, we propose a tighter coupling of these branches by averaging their log-probabilities. The tighter coupling favours the learning of better representations, even at the level of the individual branches, as compared to when each branch is trained independently. We refer to this branched architecture as "coupled ensembles". The approach is very generic and can be applied with almost any neural network architecture. With coupled ensembles of DenseNet-BC and parameter budget of 25M, we obtain error rates of 2.92%, 15.68% and 1.50% respectively on CIFAR-10, CIFAR-100 and SVHN tasks. For the same parameter budget, DenseNet-BC has an error rate of 3.46%, 17.18%, and 1.8% respectively.  With ensembles of coupled ensembles, of DenseNet-BC networks, with 50M total parameters, we obtain error rates of 2.72%, 15.13% and 1.42% respectively on these tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that splitting a neural network into parallel branches improves performance and that proper coupling of the branches improves performance even further.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Ensemble learning, neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJLy_SxC-">
      <h4>
        <a href="https://openreview.net/forum?id=SJLy_SxC-">
          Log-DenseNet: How to Sparsify a DenseNet
        </a>
        
          <a href="https://openreview.net/pdf?id=SJLy_SxC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hanzhang%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanzhang@cs.cmu.edu">Hanzhang Hu</a>, <a href="https://openreview.net/profile?email=dedey%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dedey@microsoft.com">Debadeepta Dey</a>, <a href="https://openreview.net/profile?email=adelgior%40ri.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="adelgior@ri.cmu.edu">Allie Del Giorno</a>, <a href="https://openreview.net/profile?email=hebert%40ri.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hebert@ri.cmu.edu">Martial Hebert</a>, <a href="https://openreview.net/profile?email=dbagnell%40ri.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbagnell@ri.cmu.edu">J. Andrew Bagnell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJLy_SxC--details-10" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJLy_SxC--details-10"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Skip connections are increasingly utilized by deep neural networks to improve accuracy and cost-efficiency. In particular, the recent DenseNet is efficient in computation and parameters, and achieves state-of-the-art predictions by directly connecting each feature layer to all previous ones. However, DenseNet's extreme connectivity pattern may hinder its scalability to high depths, and in applications like fully convolutional networks, full DenseNet connections are prohibitively expensive. 
      This work first experimentally shows that one key advantage of skip connections is to have short distances among feature layers during backpropagation. Specifically, using a fixed number of skip connections, the connection patterns with shorter backpropagation distance among layers have more accurate predictions. Following this insight, we propose a connection template, Log-DenseNet, which, in comparison to DenseNet,  only slightly increases the backpropagation distances among layers from 1 to  ($1 + \log_2 L$), but uses only $L\log_2 L$ total connections instead of $O(L^2)$. Hence, \logdenses are easier to scale than DenseNets, and no longer require careful GPU memory management. We demonstrate the effectiveness of our design principle by showing better performance than DenseNets on tabula rasa semantic segmentation, and competitive results on visual recognition.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show shortcut connections should be placed in patterns that minimize between-layer distances during backpropagation, and design networks that achieve log L distances using L log(L) connections.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">DenseNet, sparse shortcut connections, network architecture, scene parsing, image classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HknbyQbC-">
      <h4>
        <a href="https://openreview.net/forum?id=HknbyQbC-">
          Generating Adversarial Examples with Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HknbyQbC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaocw%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaocw@umich.edu">Chaowei Xiao</a>, <a href="https://openreview.net/profile?email=lxbosky%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxbosky@gmail.com">Bo Li</a>, <a href="https://openreview.net/profile?email=junyanz%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junyanz@berkeley.edu">Jun-Yan Zhu</a>, <a href="https://openreview.net/profile?email=_w%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="_w@eecs.berkeley.edu">Warren He</a>, <a href="https://openreview.net/profile?email=mingyan%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingyan@umich.edu">Mingyan Liu</a>, <a href="https://openreview.net/profile?email=dawnsong.travel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong.travel@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HknbyQbC--details-736" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HknbyQbC--details-736"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks (DNNs) have been found to be vulnerable to adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results.
      Different attack strategies have been proposed to generate adversarial examples, but how to produce them with high perceptual quality and more efficiently requires more research efforts. 
      In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and approximate the distribution of original instances. 
      For AdvGAN, once the generator is trained, it can generate adversarial perturbations efficiently for any instance, so as to potentially accelerate adversarial training as defenses.  
      We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In black-box attacks, we dynamically train a distilled model for the black-box model and optimize the generator accordingly.
      Adversarial examples generated by AdvGAN on different target models have high attack success rate under state-of-the-art defenses compared to other attacks. Our attack  has placed the first with 92.76% accuracy on a public MNIST black-box attack challenge. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial examples, generative adversarial network, black-box attack</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkA1f3NpZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkA1f3NpZ">
          Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rkA1f3NpZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thilo.strauss%40etas.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thilo.strauss@etas.com">Thilo Strauss</a>, <a href="https://openreview.net/profile?email=markus.hanselmann%40etas.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="markus.hanselmann@etas.com">Markus Hanselmann</a>, <a href="https://openreview.net/profile?email=andrej.junginger%40etas.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrej.junginger@etas.com">Andrej Junginger</a>, <a href="https://openreview.net/profile?email=holger.ulmer%40etas.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="holger.ulmer@etas.com">Holger Ulmer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkA1f3NpZ-details-549" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkA1f3NpZ-details-549"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning has become the state of the art approach in many machine learning problems such as classification. It has recently been shown that deep learning is highly vulnerable to adversarial perturbations. Taking the camera systems of self-driving cars as an example, small adversarial perturbations can cause the system to  make errors in important tasks, such as classifying traffic signs or detecting pedestrians. Hence, in order to use deep learning without safety concerns a proper defense strategy is required. We propose to use ensemble methods as a defense strategy against adversarial perturbations. We find that an attack leading one model to misclassify does not imply the same for other networks performing the same task. This makes ensemble methods an attractive defense strategy against adversarial attacks. We empirically show for the MNIST and the CIFAR-10 data sets that ensemble methods not only improve the accuracy of neural networks on test data but also increase their robustness against adversarial perturbations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using ensemble methods as a defense to adversarial perturbations against deep neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Ensemble Method, Adversarial Perturbations, Deep Neural Networks, Defense, Attack</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkeJVllRW">
      <h4>
        <a href="https://openreview.net/forum?id=HkeJVllRW">
          Sparse-Complementary Convolution for Efficient Model Utilization on CNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=HkeJVllRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chenrich%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenrich@us.ibm.com">Chun-Fu (Richard) Chen</a>, <a href="https://openreview.net/profile?email=ohj%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ohj@us.ibm.com">Jinwook Oh</a>, <a href="https://openreview.net/profile?email=qfan%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qfan@us.ibm.com">Quanfu Fan</a>, <a href="https://openreview.net/profile?email=pistoia%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pistoia@us.ibm.com">Marco Pistoia</a>, <a href="https://openreview.net/profile?email=clee%40mail.ncku.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="clee@mail.ncku.edu.tw">Gwo Giun (Chris) Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkeJVllRW-details-699" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkeJVllRW-details-699"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">TL;DR</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce an efficient way to increase the accuracy of convolution neural networks (CNNs) based on high model utilization without increasing any computational complexity.
      The proposed sparse-complementary convolution replaces regular convolution with sparse and complementary shapes of kernels, covering the same receptive field. 
      By the nature of deep learning, high model utilization of a CNN can be achieved with more simpler kernels rather than fewer complex kernels.
      This simple but insightful model reuses of recent network architectures, ResNet and DenseNet, can provide better accuracy for most classification tasks (CIFAR-10/100 and ImageNet) compared to their baseline models. By simply replacing the convolution of a CNN with our sparse-complementary convolution, at the same FLOPs and parameters, we can improve top-1 accuracy on ImageNet by 0.33% and 0.18% for ResNet-101 and ResNet-152, respectively. A similar accuracy improvement could be gained by increasing the number of layers in those networks by ~1.5x.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">CNN, sparse convolution, sparse kernel, sparsity, model utilization, image classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByqFhGZCW">
      <h4>
        <a href="https://openreview.net/forum?id=ByqFhGZCW">
          MACHINE VS MACHINE: MINIMAX-OPTIMAL DEFENSE AGAINST ADVERSARIAL EXAMPLES
        </a>
        
          <a href="https://openreview.net/pdf?id=ByqFhGZCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hammj%40cse.ohio-state.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hammj@cse.ohio-state.edu">Jihun Hamm</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByqFhGZCW-details-155" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByqFhGZCW-details-155"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recently, researchers have discovered that the state-of-the-art object classifiers can be fooled easily by small perturbations in the input unnoticeable to human eyes.  It is known that an attacker can generate strong adversarial examples if she knows the classifier parameters. Conversely, a defender can robustify the classifier by retraining if she has the adversarial examples. 
      The cat-and-mouse game nature of attacks and defenses raises the question of the presence of equilibria in the dynamics.
      In this paper, we present a neural-network based attack class to approximate a larger but intractable class of attacks, and 
      formulate the attacker-defender interaction as a zero-sum leader-follower game. We present sensitivity-penalized optimization algorithms to find minimax solutions, which are the best worst-case defenses against whitebox attacks. Advantages of the learning-based attacks and defenses compared to gradient-based attacks and defenses are demonstrated with MNIST and CIFAR-10.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A game-theoretic solution to adversarial attacks and defenses.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryvxcPeAb">
      <h4>
        <a href="https://openreview.net/forum?id=ryvxcPeAb">
          Enhancing the Transferability of Adversarial Examples with Noise Reduced Gradient
        </a>
        
          <a href="https://openreview.net/pdf?id=ryvxcPeAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=leiwu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="leiwu@pku.edu.cn">Lei Wu</a>, <a href="https://openreview.net/profile?email=zhanxing.zhu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanxing.zhu@pku.edu.cn">Zhanxing Zhu</a>, <a href="https://openreview.net/profile?email=chengt%40math.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chengt@math.princeton.edu">Cheng Tai</a>, <a href="https://openreview.net/profile?email=weinan%40math.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="weinan@math.princeton.edu">Weinan E</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryvxcPeAb-details-142" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryvxcPeAb-details-142"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks provide state-of-the-art performance for many applications of interest. Unfortunately they are known to be vulnerable to adversarial examples, formed by applying small but malicious perturbations to the original inputs. Moreover, the perturbations can transfer across models: adversarial examples generated for a specific model will often mislead other unseen models. Consequently  the adversary can leverage it to attack against the deployed black-box systems. 
      In this work, we demonstrate that the adversarial perturbation can be decomposed into two components: model-specific and data-dependent one, and it is the latter that mainly contributes to the transferability. Motivated by this understanding, we propose to craft adversarial examples by utilizing the noise reduced gradient (NRG) which approximates the data-dependent component. Experiments on various classification models trained on ImageNet demonstrates that the new approach enhances the transferability dramatically. We also find that low-capacity models have more powerful attack capability than high-capacity counterparts, under the condition that they have comparable test performance.  These insights give rise to a principled manner to construct adversarial examples with high success rates and could potentially provide us guidance for designing effective defense approaches against black-box attacks. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new method for enhancing the transferability of adversarial examples by using the noise-reduced gradient.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">black-box attack, adversarial example, deep learning, transferability</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJdXGy1RW">
      <h4>
        <a href="https://openreview.net/forum?id=HJdXGy1RW">
          CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble Behavior
        </a>
        
          <a href="https://openreview.net/pdf?id=HJdXGy1RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xzhang7%40clemson.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xzhang7@clemson.edu">Xiang Zhang</a>, <a href="https://openreview.net/profile?email=nvishwa%40clemson.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nvishwa@clemson.edu">Nishant Vishwamitra</a>, <a href="https://openreview.net/profile?email=luofeng%40clemson.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="luofeng@clemson.edu">Hongxin Hu</a>, <a href="https://openreview.net/profile?email=hongxih%40clemson.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongxih@clemson.edu">Feng Luo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJdXGy1RW-details-909" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJdXGy1RW-details-909"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a new deep convolutional neural network, CrescendoNet, by stacking simple building blocks without residual connections. Each Crescendo block contains independent convolution paths with increased depths. The numbers of convolution layers and parameters are only increased linearly in Crescendo blocks. In experiments, CrescendoNet with only 15 layers outperforms almost all networks without residual connections on benchmark datasets, CIFAR10, CIFAR100, and SVHN. Given sufficient amount of data as in SVHN dataset, CrescendoNet with 15 layers and 4.1M parameters can match the performance of DenseNet-BC with 250 layers and 15.3M parameters. CrescendoNet provides a new way to construct high performance deep convolutional neural networks without residual connections. Moreover, through investigating the behavior and performance of subnetworks in CrescendoNet, we note that the high performance of CrescendoNet may come from its implicit ensemble behavior, which differs from the FractalNet that is also a deep convolutional neural network without residual connections. Furthermore, the independence between paths in CrescendoNet allows us to introduce a new path-wise training procedure, which can reduce the memory needed for training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce CrescendoNet, a deep CNN architecture by stacking simple building blocks without residual connections.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">CNN, ensemble, image recognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byj54-bAW">
      <h4>
        <a href="https://openreview.net/forum?id=Byj54-bAW">
          A Tensor Analysis on Dense Connectivity via Convolutional Arithmetic Circuits
        </a>
        
          <a href="https://openreview.net/pdf?id=Byj54-bAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=emilio.balda%40ti.rwth-aachen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="emilio.balda@ti.rwth-aachen.de">Emilio Rafael Balda</a>, <a href="https://openreview.net/profile?email=arash.behboodi%40ti.rwth-aachen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="arash.behboodi@ti.rwth-aachen.de">Arash Behboodi</a>, <a href="https://openreview.net/profile?email=mathar%40ti.rwth-aachen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mathar@ti.rwth-aachen.de">Rudolf Mathar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Byj54-bAW-details-223" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byj54-bAW-details-223"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Several state of the art convolutional networks rely on inter-connecting different layers to ease the flow of information and gradient between their input and output layers. These techniques have enabled practitioners to successfully train deep convolutional networks with hundreds of layers. Particularly, a novel way of interconnecting layers was introduced as the Dense Convolutional Network (DenseNet) and has achieved state of the art performance on relevant image recognition tasks. Despite their notable empirical success, their theoretical understanding is still limited. In this work, we address this problem by analyzing the effect of layer interconnection on the overall expressive power of a convolutional network. In particular, the  connections used in DenseNet are compared with other types of inter-layer connectivity. We carry out a tensor analysis on the expressive power inter-connections on convolutional arithmetic circuits (ConvACs) and relate our results to standard convolutional networks. The analysis leads to performance bounds and practical guidelines for design of ConvACs. The generalization of these results are discussed for other kinds of convolutional networks via generalized tensor decompositions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We analyze the expressive power of the connections used in DenseNets via tensor decompositions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">DenseNets, Tensor Analysis, Convolutional Arithmetic Circuits</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B16_iGWCW">
      <h4>
        <a href="https://openreview.net/forum?id=B16_iGWCW">
          Deep Boosting of Diverse Experts
        </a>
        
          <a href="https://openreview.net/pdf?id=B16_iGWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=weizh%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="weizh@fudan.edu.cn">Wei Zhang</a>, <a href="https://openreview.net/profile?email=qchen12%40uncc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qchen12@uncc.edu">Qiuyu Chen</a>, <a href="https://openreview.net/profile?email=yujun%40hdu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yujun@hdu.edu.cn">Jun Yu</a>, <a href="https://openreview.net/profile?email=jfan%40uncc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfan@uncc.edu">Jianping Fan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B16_iGWCW-details-494" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B16_iGWCW-details-494"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, a deep boosting algorithm is developed to
      learn more discriminative ensemble classifier by seamlessly combining a set of base deep CNNs (base experts)
      with diverse capabilities, e.g., these base deep CNNs are
      sequentially trained to recognize a set of 
      object classes in an easy-to-hard way according to their
      learning complexities. Our experimental results have demonstrated
      that our deep boosting algorithm can significantly improve the
      accuracy rates on large-scale visual recognition.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> A deep boosting algorithm is developed to learn more discriminative ensemble classifier by seamlessly combining a set of base deep CNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">boosting learning, deep learning, neural network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkmtTJZCb">
      <h4>
        <a href="https://openreview.net/forum?id=rkmtTJZCb">
          Unsupervised Hierarchical Video Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=rkmtTJZCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wichersn%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wichersn@google.com">Nevan Wichers</a>, <a href="https://openreview.net/profile?email=dumitru%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dumitru@google.com">Dumitru Erhan</a>, <a href="https://openreview.net/profile?email=honglak%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@google.com">Honglak Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkmtTJZCb-details-778" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkmtTJZCb-details-778"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Much recent research has been devoted to video prediction and generation,  but mostly for short-scale time horizons. The hierarchical video prediction method by Villegas et al. (2017) is an example of a state of the art method for long term video prediction.  However, their method has limited applicability in practical settings as it requires a ground truth pose (e.g.,  poses of joints of a human) at training time.   This paper presents a long term hierarchical video prediction model that does not have such a restriction. We show that the network learns its own higher-level structure (e.g., pose equivalent hidden variables) that works better in cases where the ground truth pose does not fully capture all of the information needed to  predict  the  next  frame.   This  method  gives  sharper  results  than  other  video prediction methods which do not require a ground truth pose, and its efficiency is shown on the Humans 3.6M and Robot Pushing datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show ways to train a hierarchical video prediction model without needing pose labels.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">video prediction, visual analogy network, unsupervised, hierarchical</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hk-FlMbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=Hk-FlMbAZ">
          The Manifold Assumption and Defenses Against Adversarial Perturbations
        </a>
        
          <a href="https://openreview.net/pdf?id=Hk-FlMbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiwu%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiwu@cs.wisc.edu">Xi Wu</a>, <a href="https://openreview.net/profile?email=wjang%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wjang@cs.wisc.edu">Uyeong Jang</a>, <a href="https://openreview.net/profile?email=lchen%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lchen@cs.wisc.edu">Lingjiao Chen</a>, <a href="https://openreview.net/profile?email=jha%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jha@cs.wisc.edu">Somesh Jha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hk-FlMbAZ-details-188" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hk-FlMbAZ-details-188"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In the adversarial-perturbation problem of neural networks, an adversary starts with a neural network model $F$ and a point $\bfx$ that $F$ classifies correctly, and applies a \emph{small perturbation} to  $\bfx$ to produce another point $\bfx'$ that $F$ classifies \emph{incorrectly}.  In this paper, we propose taking into account \emph{the inherent confidence information} produced by models when studying adversarial perturbations, where a natural measure of ``confidence'' is \|F(\bfx)\|_\infty$ (i.e. how confident $F$ is about its prediction?). Motivated by a thought experiment based on the manifold assumption, we propose a ``goodness property'' of models which states that \emph{confident regions of a good model should be well separated}. We give formalizations of this property and examine existing robust training objectives in view of them. Interestingly, we find that a recent objective by Madry et al. encourages training a model that satisfies well our formal version of the goodness property, but has a weak control of points that are wrong but with low confidence. However, if Madry et al.'s model is indeed a good solution to their objective, then good and bad points are now distinguishable and we can try to embed uncertain points back to the closest confident region to get (hopefully) correct predictions. We thus propose embedding objectives and algorithms, and perform an empirical study using this method. Our experimental results are encouraging: Madry et al.'s model wrapped with our embedding procedure achieves almost perfect success rate in defending against attacks that the base model fails on, while retaining good generalization behavior.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Defending against adversarial perturbations of neural networks from manifold assumption </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">the manifold assumption, adversarial perturbation, neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJbs5gbRW">
      <h4>
        <a href="https://openreview.net/forum?id=rJbs5gbRW">
          On the Generalization Effects of DenseNet Model Structures 
        </a>
        
          <a href="https://openreview.net/pdf?id=rJbs5gbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=liuyin14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuyin14@mails.tsinghua.edu.cn">Yin Liu</a>, <a href="https://openreview.net/profile?email=389091983%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="389091983@qq.com">Vincent Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJbs5gbRW-details-312" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJbs5gbRW-details-312"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Modern neural network architectures take advantage of increasingly deeper layers, and various advances in their structure to achieve better performance. While traditional explicit regularization techniques like dropout, weight decay, and data augmentation are still being used in these new models, little about the regularization and generalization effects of these new structures have been studied. 
      Besides being deeper than their predecessors, could newer architectures like ResNet and DenseNet also benefit from their structures' implicit regularization properties? 
      In this work, we investigate the skip connection's effect on network's generalization features. Through experiments, we show that certain neural network architectures contribute to their generalization abilities. Specifically, we study the effect that low-level features have on generalization performance when they are introduced to deeper layers in DenseNet, ResNet as well as networks with 'skip connections'. We show that these low-level representations do help with generalization in multiple settings when both the quality and quantity of training data is decreased. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Our paper analyses the tremendous representational power of networks especially with 'skip connections', which may be used as a method  for better generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Skip connection, generalization, gegularization, deep network, representation.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJCq_fZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SJCq_fZ0Z">
          Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJCq_fZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rosemary.nan.ke%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rosemary.nan.ke@gmail.com">Nan Rosemary Ke</a>, <a href="https://openreview.net/profile?email=anirudhgoyal9119%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anirudhgoyal9119@gmail.com">Anirudh Goyal</a>, <a href="https://openreview.net/profile?email=obilaniu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="obilaniu@gmail.com">Olexa Bilaniuk</a>, <a href="https://openreview.net/profile?email=jbinas%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbinas@gmail.com">Jonathan Binas</a>, <a href="https://openreview.net/profile?email=lcharlin%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcharlin@gmail.com">Laurent Charlin</a>, <a href="https://openreview.net/profile?email=chris.j.pal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chris.j.pal@gmail.com">Chris Pal</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJCq_fZ0Z-details-745" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJCq_fZ0Z-details-745"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A major drawback of backpropagation through time (BPTT) is the difficulty of learning long-term dependencies, coming from having to propagate credit information backwards through every single step of the forward computation. This makes BPTT both computationally impractical and biologically implausible. For this reason, full backpropagation through time is rarely used on long sequences, and truncated backpropagation through time is used as a heuristic.  However, this usually leads to biased estimates of the gradient in which longer term dependencies are ignored.  Addressing this issue, we propose an alternative algorithm, Sparse Attentive Backtracking, which might also be related to principles used by brains to learn long-term dependencies. Sparse Attentive Backtracking learns an attention mechanism over the hidden states of the past and selectively backpropagates through paths with high attention weights.  This allows the model to learn long term dependencies while only backtracking for a small number of time steps, not just from the recent past but also from attended relevant past states.   </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Towards Efficient Credit Assignment in Recurrent Networks without Backpropagation Through Time</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, long-term dependencies, back-propagation through time, truncated back-propagation, biological inspiration, self-attention</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJMN-xWC-">
      <h4>
        <a href="https://openreview.net/forum?id=HJMN-xWC-">
          Learning Parsimonious Deep Feed-forward Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJMN-xWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zchenbb%40cse.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="zchenbb@cse.ust.hk">Zhourong Chen</a>, <a href="https://openreview.net/profile?email=xlibo%40cse.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="xlibo@cse.ust.hk">Xiaopeng Li</a>, <a href="https://openreview.net/profile?email=lzhang%40cse.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="lzhang@cse.ust.hk">Nevin L. Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJMN-xWC--details-49" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJMN-xWC--details-49"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks and recurrent neural networks are designed with network structures well suited to the nature of spacial and sequential data respectively. However, the structure of standard feed-forward neural networks (FNNs) is simply a stack of fully connected layers, regardless of the feature correlations in data. In addition, the number of layers and the number of neurons are manually tuned on validation data, which is time-consuming and may lead to suboptimal networks. In this paper, we propose an unsupervised structure learning method for learning parsimonious deep FNNs. Our method determines the number of layers, the number of neurons at each layer, and the sparse connectivity between adjacent layers automatically from data. The resulting models are called Backbone-Skippath Neural Networks (BSNNs). Experiments on 17 tasks show that, in comparison with FNNs,  BSNNs can achieve better or comparable classification performance with much fewer parameters. The interpretability of BSNNs is also shown to be better than that of FNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An unsupervised structure learning method for Parsimonious Deep Feed-forward Networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Parsimonious Deep Feed-forward Networks, structure learning, classification, overfitting, fewer parameters, high interpretability</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyp3i2xRb">
      <h4>
        <a href="https://openreview.net/forum?id=Hyp3i2xRb">
          Overcoming the vanishing gradient problem in plain recurrent networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Hyp3i2xRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yuhuang.hu%40ini.uzh.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuhuang.hu@ini.uzh.ch">Yuhuang Hu</a>, <a href="https://openreview.net/profile?email=huberad%40ini.uzh.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="huberad@ini.uzh.ch">Adrian Huber</a>, <a href="https://openreview.net/profile?email=shih%40ini.uzh.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="shih@ini.uzh.ch">Shih-Chii Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hyp3i2xRb-details-783" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyp3i2xRb-details-783"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Plain recurrent networks greatly suffer from the vanishing gradient problem while Gated Neural Networks (GNNs) such as Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU) deliver promising results in many sequence learning tasks through sophisticated network designs. This paper shows how we can address this problem in a plain recurrent network by analyzing the gating mechanisms in GNNs. We propose a novel network called the Recurrent Identity Network (RIN) which allows a plain recurrent network to overcome the vanishing gradient problem while training very deep models without the use of gates. We compare this model with IRNNs and LSTMs on multiple sequence modeling benchmarks. The RINs demonstrate competitive performance and converge faster in all tasks. Notably, small RIN models produce 12%–67% higher accuracy on the Sequential and Permuted MNIST datasets and reach state-of-the-art performance on the bAbI question answering dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel network called the Recurrent Identity Network (RIN) which allows a plain recurrent network to overcome the vanishing gradient problem while training very deep models without the use of gates.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">vanishing gradient descent, recurrent neural networks, identity mapping</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ78bJZCZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJ78bJZCZ">
          Efficiently applying attention to sequential data with the Recurrent Discounted Attention unit
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ78bJZCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=brendan.maginnis%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="brendan.maginnis@gmail.com">Brendan Maginnis</a>, <a href="https://openreview.net/profile?email=pierre.richemond%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pierre.richemond@gmail.com">Pierre Richemond</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ78bJZCZ-details-139" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ78bJZCZ-details-139"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent Neural Networks architectures excel at processing sequences by
      modelling dependencies over different timescales. The recently introduced
      Recurrent Weighted Average (RWA) unit captures long term dependencies
      far better than an LSTM on several challenging tasks. The RWA achieves
      this by applying attention to each input and computing a weighted average
      over the full history of its computations. Unfortunately, the RWA cannot
      change the attention it has assigned to previous timesteps, and so struggles
      with carrying out consecutive tasks or tasks with changing requirements.
      We present the Recurrent Discounted Attention (RDA) unit that builds on
      the RWA by additionally allowing the discounting of the past.
      We empirically compare our model to RWA, LSTM and GRU units on
      several challenging tasks. On tasks with a single output the RWA, RDA and
      GRU units learn much quicker than the LSTM and with better performance.
      On the multiple sequence copy task our RDA unit learns the task three
      times as quickly as the LSTM or GRU units while the RWA fails to learn at
      all. On the Wikipedia character prediction task the LSTM performs best
      but it followed closely by our RDA unit. Overall our RDA unit performs
      well and is sample efficient on a large variety of sequence tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce the Recurrent Discounted Unit which applies attention to any length sequence in linear time</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNNs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ8W1Q-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=HJ8W1Q-0Z">
          GATED FAST WEIGHTS FOR ASSOCIATIVE RETRIEVAL
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ8W1Q-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=imanol%40idsia.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="imanol@idsia.ch">Imanol Schlag</a>, <a href="https://openreview.net/profile?email=juergen%40idsia.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="juergen@idsia.ch">Jürgen Schmidhuber</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ8W1Q-0Z-details-56" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ8W1Q-0Z-details-56"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We improve previous end-to-end differentiable neural networks (NNs) with fast
      weight memories. A gate mechanism updates fast weights at every time step of
      a sequence through two separate outer-product-based matrices generated by slow
      parts of the net. The system is trained on a complex sequence to sequence variation
      of the Associative Retrieval Problem with roughly 70 times more temporal
      memory (i.e. time-varying variables) than similar-sized standard recurrent NNs
      (RNNs). In terms of accuracy and number of parameters, our architecture outperforms
      a variety of RNNs, including Long Short-Term Memory, Hypernetworks,
      and related fast weight architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An improved Fast Weight network which shows better results on a general toy task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">fast weights, RNN, associative retrieval, time-varying variables</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ1RPJWAW">
      <h4>
        <a href="https://openreview.net/forum?id=rJ1RPJWAW">
          Learnability of Learned Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ1RPJWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=t-rahsha%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="t-rahsha@microsoft.com">Rahul Anand Sharma</a>, <a href="https://openreview.net/profile?email=navingo%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="navingo@microsoft.com">Navin Goyal</a>, <a href="https://openreview.net/profile?email=monojitc%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="monojitc@microsoft.com">Monojit Choudhury</a>, <a href="https://openreview.net/profile?email=praneeth%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="praneeth@microsoft.com">Praneeth Netrapalli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ1RPJWAW-details-546" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ1RPJWAW-details-546"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability.
      This work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks. Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Exploring the Learnability of Learned Neural Networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Learnability, Generalizability, Understanding Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HylgYB3pZ">
      <h4>
        <a href="https://openreview.net/forum?id=HylgYB3pZ">
          Linearly Constrained Weights: Resolving the Vanishing Gradient Problem by Reducing Angle Bias
        </a>
        
          <a href="https://openreview.net/pdf?id=HylgYB3pZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kutsuna%40mosk.tytlabs.co.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="kutsuna@mosk.tytlabs.co.jp">Takuro Kutsuna</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 07 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HylgYB3pZ-details-684" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HylgYB3pZ-details-684"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we first identify \textit{angle bias}, a simple but remarkable phenomenon that causes the vanishing gradient problem in a multilayer perceptron (MLP) with sigmoid activation functions. We then propose \textit{linearly constrained weights (LCW)} to reduce the angle bias in a neural network, so as to train the network under the constraints that the sum of the elements of each weight vector is zero. A reparameterization technique is presented to efficiently train a model with LCW by embedding the constraints on weight vectors into the structure of the network. Interestingly, batch normalization (Ioffe &amp; Szegedy, 2015) can be viewed as a mechanism to correct angle bias. Preliminary experiments show that LCW helps train a 100-layered MLP more efficiently than does batch normalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We identify angle bias that causes the vanishing gradient problem in deep nets and propose an efficient method to reduce the bias.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">vanishing gradient problem, multilayer perceptron, angle bias</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkHkeixAW">
      <h4>
        <a href="https://openreview.net/forum?id=SkHkeixAW">
          Regularization for Deep Learning: A Taxonomy
        </a>
        
          <a href="https://openreview.net/pdf?id=SkHkeixAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jan.kukacka%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="jan.kukacka@tum.de">Jan Kukačka</a>, <a href="https://openreview.net/profile?email=vladimir.golkov%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="vladimir.golkov@tum.de">Vladimir Golkov</a>, <a href="https://openreview.net/profile?email=cremers%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="cremers@tum.de">Daniel Cremers</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkHkeixAW-details-277" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkHkeixAW-details-277"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a novel, systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We identify the atomic building blocks of existing methods, and decouple the assumptions they enforce from the mathematical tools they rely on. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Systematic categorization of regularization methods for deep learning, revealing their similarities.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural networks, deep learning, regularization, data augmentation, network architecture, loss function, dropout, residual learning, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r111KtCp-">
      <h4>
        <a href="https://openreview.net/forum?id=r111KtCp-">
          Taking Apart Autoencoders: How do They Encode Geometric Shapes ?
        </a>
        
          <a href="https://openreview.net/pdf?id=r111KtCp-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alasdairnewson%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alasdairnewson@gmail.com">Alasdair Newson</a>, <a href="https://openreview.net/profile?email=andres.almansa%40parisdescartes.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="andres.almansa@parisdescartes.fr">Andres Almansa</a>, <a href="https://openreview.net/profile?email=yann.gousseau%40telecom-paristech.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann.gousseau@telecom-paristech.fr">Yann Gousseau</a>, <a href="https://openreview.net/profile?email=said.ladjal%40telecom-paristech.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="said.ladjal@telecom-paristech.fr">Said Ladjal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r111KtCp--details-747" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r111KtCp--details-747"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the precise mechanisms which allow autoencoders to encode and decode a simple geometric shape, the disk. In this carefully controlled setting, we are able to describe the specific form of the optimal solution to the minimisation problem of the training step. We show that the autoencoder indeed approximates this solution during training. Secondly, we identify a clear failure in the generalisation capacity of the autoencoder, namely its inability to interpolate data. Finally, we explore several regularisation schemes to resolve the generalisation problem. Given the great attention that has been recently given to the generative capacity of neural networks, we believe that studying in depth simple geometric cases sheds some light on the generation process and can provide a minimal requirement experimental setup for more complex architectures. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We study the functioning of autoencoders in a simple setting and advise new strategies for their regularisation in order to obtain bettre generalisation with latent interpolation in mind for image sythesis. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">autoencoders, CNN, image synthesis, latent space</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkhxwltab">
      <h4>
        <a href="https://openreview.net/forum?id=rkhxwltab">
          AANN: Absolute Artificial Neural Network
        </a>
        
          <a href="https://openreview.net/pdf?id=rkhxwltab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=animeshsk3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animeshsk3@gmail.com">Animesh Karnewar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkhxwltab-details-788" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkhxwltab-details-788"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This research paper describes a simplistic architecture named as AANN: Absolute Artificial Neural Network, which can be used to create highly interpretable representations of the input data. These representations are generated by penalizing the learning of the network in such a way that those learned representations correspond to the respective labels present in the labelled dataset used for supervised training; thereby, simultaneously giving the network the ability to classify the input data. The network can be used in the reverse direction to generate data that closely resembles the input by feeding in representation vectors as required. This research paper also explores the use of mathematical abs (absolute valued) functions as activation functions which constitutes the core part of this neural network architecture. Finally the results obtained on the MNIST dataset by using this technique are presented and discussed in brief.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Tied weights auto-encoder with abs function as activation function, learns to do classification in the forward direction and regression in the backward direction due to specially defined cost function.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Network architecture, Learned representation space, absolute valued function, bidirectional neuron</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyp-JJJRW">
      <h4>
        <a href="https://openreview.net/forum?id=Hyp-JJJRW">
          Style Memory: Making a Classifier Network Generative
        </a>
        
          <a href="https://openreview.net/pdf?id=Hyp-JJJRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rrwiyatn%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="rrwiyatn@uwaterloo.ca">Rey Wiyatno</a>, <a href="https://openreview.net/profile?email=jorchard%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jorchard@uwaterloo.ca">Jeff Orchard</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hyp-JJJRW-details-652" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyp-JJJRW-details-652"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep networks have shown great performance in classification tasks. However, the parameters learned by the classifier networks usually discard stylistic information of the input, in favour of information strictly relevant to classification. We introduce a network that has the capacity to do both classification and reconstruction by adding a "style memory" to the output layer of the network. We also show how to train such a neural network as a deep multi-layer autoencoder, jointly minimizing both classification and reconstruction losses. The generative capacity of our network demonstrates that the combination of style-memory neurons with the classifier neurons yield good reconstructions of the inputs when the classification is correct. We further investigate the nature of the style memory, and how it relates to composing digits and letters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Augmenting the top layer of a classifier network with a style memory enables it to be generative.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural networks, autoencoder, generative, feed-back</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By0ANxbRW">
      <h4>
        <a href="https://openreview.net/forum?id=By0ANxbRW">
          DNN Model Compression Under Accuracy Constraints
        </a>
        
          <a href="https://openreview.net/pdf?id=By0ANxbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=khoram%40wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="khoram@wisc.edu">Soroosh Khoram</a>, <a href="https://openreview.net/profile?email=jli%40ece.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jli@ece.wisc.edu">Jing Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By0ANxbRW-details-53" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By0ANxbRW-details-53"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The growing interest to implement Deep Neural Networks (DNNs) on resource-bound hardware has motivated innovation of compression algorithms. Using these algorithms, DNN model sizes can be substantially reduced, with little to no accuracy degradation. This is achieved by either eliminating components from the model, or penalizing complexity during training. While both approaches demonstrate considerable compressions, the former often ignores the loss function during compression while the later produces unpredictable compressions. In this paper, we propose a technique that directly minimizes both the model complexity and the changes in the loss function. In this technique, we formulate compression as a constrained optimization problem, and then present a solution for it. We will show that using this technique, we can achieve competitive results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Compressing trained DNN models by minimizing their complexity while constraining their loss.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">DNN Compression, Weigh-sharing, Model Compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkiCjzNTZ">
      <h4>
        <a href="https://openreview.net/forum?id=SkiCjzNTZ">
          Spontaneous Symmetry Breaking in Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkiCjzNTZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ricky.fok3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ricky.fok3@gmail.com">Ricky Fok</a>, Aijun An, Xiaogang Wang
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkiCjzNTZ-details-406" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkiCjzNTZ-details-406"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a framework to understand the unprecedented performance and robustness of deep neural networks using field theory. Correlations between the weights within the same layer can be described by symmetries in that layer, and networks generalize better if such symmetries are broken to reduce the redundancies of the weights. Using a two parameter field theory, we find that the network can break such symmetries itself towards the end of training in a process commonly known in physics as spontaneous symmetry breaking. This corresponds to a network generalizing itself without any user input layers to break the symmetry, but by communication with adjacent layers. In the layer decoupling limit applicable to residual networks (He et al., 2015), we show that the remnant symmetries that survive the non-linear layers are spontaneously broken based on empirical results. The Lagrangian for the non-linear and weight layers together has striking similarities with the one in quantum field theory of a scalar. Using results from quantum field theory we show that our framework is able to explain many experimentally observed phenomena, such as training on random labels with zero error (Zhang et al., 2017), the information bottleneck and the phase transition out of it (Shwartz-Ziv &amp; Tishby, 2017), shattered gradients (Balduzzi et al., 2017), and many more.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Closed form results for deep learning in the layer decoupling limit applicable to Residual Networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, physics, field theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJa1Nk10b">
      <h4>
        <a href="https://openreview.net/forum?id=SJa1Nk10b">
          Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy
        </a>
        
          <a href="https://openreview.net/pdf?id=SJa1Nk10b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hanzhang%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanzhang@cs.cmu.edu">Hanzhang Hu</a>, <a href="https://openreview.net/profile?email=dedey%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dedey@microsoft.com">Debadeepta Dey</a>, <a href="https://openreview.net/profile?email=hebert%40ri.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hebert@ri.cmu.edu">Martial Hebert</a>, <a href="https://openreview.net/profile?email=dbagnell%40ri.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbagnell@ri.cmu.edu">J. Andrew Bagnell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJa1Nk10b-details-889" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJa1Nk10b-details-889"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present an approach for anytime predictions in deep neural networks (DNNs). For each test sample, an anytime predictor produces a coarse result quickly, and then continues to refine it until the test-time computational budget is depleted. Such predictors can address the growing computational problem of DNNs by automatically adjusting to varying test-time budgets. In this work, we study a \emph{general} augmentation to feed-forward networks to form anytime neural networks (ANNs) via auxiliary predictions and losses. Specifically, we point out a blind-spot in recent studies in such ANNs: the importance of high final accuracy. In fact, we show on multiple recognition data-sets and architectures that by having near-optimal final predictions in small anytime models, we can effectively double the speed of large ones to reach corresponding accuracy level. We achieve such speed-up with simple weighting of anytime losses that oscillate during training. We also assemble a sequence of exponentially deepening ANNs, to achieve both theoretically and practically near-optimal anytime results at any budget, at the cost of a constant fraction of additional consumed budget.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">anytime, neural network, adaptive prediction, budgeted prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1spAqUp-">
      <h4>
        <a href="https://openreview.net/forum?id=B1spAqUp-">
          Pixel Deconvolutional Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=B1spAqUp-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hongyang.gao%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongyang.gao@wsu.edu">Hongyang Gao</a>, <a href="https://openreview.net/profile?email=hao.yuan%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hao.yuan@wsu.edu">Hao Yuan</a>, <a href="https://openreview.net/profile?email=zwang6%40eecs.wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zwang6@eecs.wsu.edu">Zhengyang Wang</a>, <a href="https://openreview.net/profile?email=sji%40eecs.wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sji@eecs.wsu.edu">Shuiwang Ji</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1spAqUp--details-250" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1spAqUp--details-250"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deconvolutional layers have been widely used in a variety of deep
      models for up-sampling, including encoder-decoder networks for
      semantic segmentation and deep generative models for unsupervised
      learning. One of the key limitations of deconvolutional operations
      is that they result in the so-called checkerboard problem. This is
      caused by the fact that no direct relationship exists among adjacent
      pixels on the output feature map. To address this problem, we
      propose the pixel deconvolutional layer (PixelDCL) to establish
      direct relationships among adjacent pixels on the up-sampled feature
      map. Our method is based on a fresh interpretation of the regular
      deconvolution operation. The resulting PixelDCL can be used to
      replace any deconvolutional layer in a plug-and-play manner without
      compromising the fully trainable capabilities of original models.
      The proposed PixelDCL may result in slight decrease in efficiency,
      but this can be overcome by an implementation trick. Experimental
      results on semantic segmentation demonstrate that PixelDCL can
      consider spatial features such as edges and shapes and yields more
      accurate segmentation outputs than deconvolutional layers. When used
      in image generation tasks, our PixelDCL can largely overcome the
      checkerboard problem suffered by regular deconvolution operations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Solve checkerboard problem in Deconvolutional layer by building dependencies between pixels</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Deconvolutional Layer, Pixel CNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryzm6BATZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryzm6BATZ">
          Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ryzm6BATZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=michaelvertolli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michaelvertolli@gmail.com">Michael O. Vertolli</a>, <a href="https://openreview.net/profile?email=jim%40jimdavies.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="jim@jimdavies.org">Jim Davies</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryzm6BATZ-details-37" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryzm6BATZ-details-37"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a new, multi-component energy function for energy-based Generative Adversarial Networks (GANs) based on methods from the image quality assessment literature. Our approach expands on the Boundary Equilibrium Generative Adversarial Network (BEGAN) by outlining some of the short-comings of the original energy and loss functions. We address these short-comings by incorporating an l1 score, the Gradient Magnitude Similarity score, and a chrominance score into the new energy function. We then provide a set of systematic experiments that explore its hyper-parameters. We show that each of the energy function's components is able to represent a slightly different set of features, which require their own evaluation criteria to assess whether they have been adequately learned. We show that models using the new energy function are able to produce better image representations than the BEGAN model in predicted ways.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, gans, deep learning, image modeling, image generation, energy based models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJjBnN9a-">
      <h4>
        <a href="https://openreview.net/forum?id=BJjBnN9a-">
          Continuous Convolutional Neural Networks for Image Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=BJjBnN9a-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vitor.guizilini%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitor.guizilini@sydney.edu.au">Vitor Guizilini</a>, <a href="https://openreview.net/profile?email=fabio.ramos%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="fabio.ramos@sydney.edu.au">Fabio Ramos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJjBnN9a--details-127" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJjBnN9a--details-127"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces the concept of continuous convolution to neural networks and deep learning applications in general. Rather than directly using discretized information, input data is first projected into a high-dimensional Reproducing Kernel Hilbert Space (RKHS), where it can be modeled as a continuous function using a series of kernel bases. We then proceed to derive a closed-form solution to the continuous convolution operation between two arbitrary functions operating in different RKHS. Within this framework, convolutional filters also take the form of continuous functions, and the training procedure involves learning the RKHS to which each of these filters is projected, alongside their weight parameters. This results in much more expressive filters, that do not require spatial discretization and benefit from properties such as adaptive support and non-stationarity. Experiments on image classification are performed, using classical datasets, with results indicating that the proposed continuous convolutional neural network is able to achieve competitive accuracy rates with far fewer parameters and a faster convergence rate.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper proposes a novel convolutional layer that operates in a continuous Reproducing Kernel Hilbert Space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">convolutional neural networks, image classification, deep learning, feature representation, hilbert maps, reproducing kernel hilbert space</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkQu4Wb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rkQu4Wb0Z">
          DNN Representations as Codewords: Manipulating Statistical Properties via Penalty Regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=rkQu4Wb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=choid%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="choid@snu.ac.kr">Daeyoung Choi</a>, <a href="https://openreview.net/profile?email=ch.shin%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ch.shin@snu.ac.kr">Changho Shin</a>, <a href="https://openreview.net/profile?email=webofthink%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="webofthink@snu.ac.kr">Hyunghun Cho</a>, <a href="https://openreview.net/profile?email=wrhee%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="wrhee@snu.ac.kr">Wonjong Rhee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkQu4Wb0Z-details-241" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkQu4Wb0Z-details-241"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Performance of Deep Neural Network (DNN) heavily depends on the characteristics of hidden layer representations. Unlike the codewords of channel coding, however, the representations of learning cannot be directly designed or controlled. Therefore, we develop a family of penalty regularizers where each one aims to affect one of representation's statistical properties such as sparsity, variance, or covariance. The regularizers are extended to perform class-wise regularization, and the extension is found to provide an outstanding shaping capability. A variety of statistical properties are investigated for 10 different regularization strategies including dropout and batch normalization, and several interesting findings are reported. Using the family of regularizers, performance improvements are confirmed for MNIST, CIFAR-100, and CIFAR-10 classification problems. But more importantly, our results suggest that understanding how to manipulate statistical properties of representations can be an important step toward understanding DNN and that the role and effect of DNN regularizers need to be reconsidered.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">DNN representation, penalty regularization, channel coding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkMhoDITb">
      <h4>
        <a href="https://openreview.net/forum?id=HkMhoDITb">
          Reinforcement Learning via Replica Stacking of Quantum Measurements for the Training of Quantum Boltzmann Machines
        </a>
        
          <a href="https://openreview.net/pdf?id=HkMhoDITb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anna.levit%401qbit.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anna.levit@1qbit.com">Anna Levit</a>, <a href="https://openreview.net/profile?email=daniel.crawford%401qbit.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.crawford@1qbit.com"> Daniel Crawford</a>, <a href="https://openreview.net/profile?email=navid.ghadermarzy%401qbit.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="navid.ghadermarzy@1qbit.com">Navid Ghadermarzy</a>, <a href="https://openreview.net/profile?email=jaspreet.oberoi%401qbit.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaspreet.oberoi@1qbit.com">Jaspreet S. Oberoi</a>, <a href="https://openreview.net/profile?email=ehsan.zahedinejad%401qbit.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ehsan.zahedinejad@1qbit.com">Ehsan Zahedinejad</a>, <a href="https://openreview.net/profile?email=pooya.ronagh%401qbit.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pooya.ronagh@1qbit.com">Pooya Ronagh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkMhoDITb-details-439" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkMhoDITb-details-439"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent theoretical and experimental results suggest the possibility of using current and near-future quantum hardware in challenging sampling tasks. In this paper, we introduce free-energy-based reinforcement learning (FERL) as an application of quantum hardware. We propose a method for processing a quantum annealer’s measured qubit spin configurations in approximating the free energy of a quantum Boltzmann machine (QBM). We then apply this method to perform reinforcement learning on the grid-world problem using the D-Wave 2000Q quantum annealer. The experimental results show that our technique is a promising method for harnessing the power of quantum sampling in reinforcement learning tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train Quantum Boltzmann Machines using a replica stacking method and a quantum annealer to perform a reinforcement learning task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Quantum Annealing, Reinforcement Learning, Boltzmann Machines, Markov Chain Monte Carlo</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SksY3deAW">
      <h4>
        <a href="https://openreview.net/forum?id=SksY3deAW">
          Learning Deep ResNet Blocks Sequentially using Boosting Theory
        </a>
        
          <a href="https://openreview.net/pdf?id=SksY3deAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=furongh%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="furongh@cs.umd.edu">Furong Huang</a>, <a href="https://openreview.net/profile?email=jordantash%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jordantash@gmail.com">Jordan T. Ash</a>, <a href="https://openreview.net/profile?email=jcl%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jcl@microsoft.com">John Langford</a>, <a href="https://openreview.net/profile?email=schapire%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schapire@microsoft.com">Robert E. Schapire</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SksY3deAW-details-914" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SksY3deAW-details-914"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We prove a multiclass boosting theory for the ResNet architectures which simultaneously creates a new technique for multiclass boosting and provides a new algorithm for ResNet-style architectures.  Our proposed training algorithm, BoostResNet, is particularly suitable in non-differentiable architectures.  Our method only requires the relatively inexpensive sequential training of T "shallow ResNets". We prove that the training error decays exponentially with the depth T if the weak module classifiers that we train perform slightly better than some weak baseline.  In other words, we propose a weak learning condition and prove a boosting theory for ResNet under the weak learning condition.  A generalization error bound based on margin theory is proved and suggests that ResNet could be resistant to overfitting using a network with l_1 norm bounded weights.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove a multiclass boosting theory for the ResNet architectures which simultaneously creates a new technique for multiclass boosting and provides a new algorithm for ResNet-style architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">residual network, boosting theory, training error guarantee</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgPCveAW">
      <h4>
        <a href="https://openreview.net/forum?id=BJgPCveAW">
          Characterizing Sparse Connectivity Patterns in Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJgPCveAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=souryade%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="souryade@usc.edu">Sourya Dey</a>, <a href="https://openreview.net/profile?email=kuanwenh%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kuanwenh@usc.edu">Kuan-Wen Huang</a>, <a href="https://openreview.net/profile?email=pabeerel%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabeerel@usc.edu">Peter A. Beerel</a>, <a href="https://openreview.net/profile?email=chugg%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chugg@usc.edu">Keith M. Chugg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJgPCveAW-details-584" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgPCveAW-details-584"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel way of reducing the number of parameters in the storage-hungry fully connected layers of a neural network by using pre-defined sparsity, where the majority of connections are absent prior to starting training. Our results indicate that convolutional neural networks can operate without any loss of accuracy at less than 0.5% classification layer connection density, or less than 5% overall network connection density. We also investigate the effects of pre-defining the sparsity of networks with only fully connected layers. Based on our sparsifying technique, we introduce the `scatter' metric to characterize the quality of a particular connection pattern. As proof of concept, we show results on CIFAR, MNIST and a new dataset on classifying Morse code symbols, which highlights some interesting trends and limits of sparse connection patterns.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Neural networks can be pre-defined to have sparse connectivity without performance degradation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Machine learning, Neural networks, Sparse neural networks, Pre-defined sparsity, Scatter, Connectivity patterns, Adjacency matrix, Parameter Reduction, Morse code</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1fHmlbCW">
      <h4>
        <a href="https://openreview.net/forum?id=S1fHmlbCW">
          Neural Networks for irregularly observed continuous-time Stochastic Processes
        </a>
        
          <a href="https://openreview.net/pdf?id=S1fHmlbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=francois.belletti%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="francois.belletti@berkeley.edu">Francois W. Belletti</a>, <a href="https://openreview.net/profile?email=alexku%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexku@berkeley.edu">Alexander Ku</a>, <a href="https://openreview.net/profile?email=jegonzal%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jegonzal@berkeley.edu">Joseph E. Gonzalez</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1fHmlbCW-details-636" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1fHmlbCW-details-636"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Designing neural networks for continuous-time stochastic processes is challenging, especially when observations are made irregularly. In this article, we analyze neural networks from a frame theoretic perspective to identify the sufficient conditions that enable smoothly recoverable representations of signals in L^2(R). Moreover, we show that, under certain assumptions, these properties hold even when signals are irregularly observed. As we converge to the family of (convolutional) neural networks that satisfy these conditions, we show that we can optimize our convolution filters while constraining them so that they effectively compute a Discrete Wavelet Transform. Such a neural network can efficiently divide the time-axis of a signal into orthogonal sub-spaces of different temporal scale and localization. We evaluate the resulting neural network on an assortment of synthetic and real-world tasks: parsimonious auto-encoding, video classification, and financial forecasting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Neural architectures providing representations of irregularly observed signals that provably enable signal reconstruction.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Stochastic Processes, Time Series Analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkrHeXbCW">
      <h4>
        <a href="https://openreview.net/forum?id=SkrHeXbCW">
          Learning Representations for Faster Similarity Search
        </a>
        
          <a href="https://openreview.net/pdf?id=SkrHeXbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ludwigs%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludwigs@mit.edu">Ludwig Schmidt</a>, <a href="https://openreview.net/profile?email=kunal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunal@google.com">Kunal Talwar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkrHeXbCW-details-627" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkrHeXbCW-details-627"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In high dimensions, the performance of nearest neighbor algorithms depends crucially on structure in the data.
      While traditional nearest neighbor datasets consisted mostly of hand-crafted feature vectors, an increasing number of datasets comes from representations learned with neural networks.
      We study the interaction between nearest neighbor algorithms and neural networks in more detail.
      We find that the network architecture can significantly influence the efficacy of nearest neighbor algorithms even when the classification accuracy is unchanged.
      Based on our experiments, we propose a number of training modifications that lead to significantly better datasets for nearest neighbor algorithms.
      Our modifications lead to learned representations that can accelerate nearest neighbor queries by 5x.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how to get good representations from the point of view of Simiarity Search.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1mAkPxCZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1mAkPxCZ">
          VOCABULARY-INFORMED VISUAL FEATURE AUGMENTATION FOR ONE-SHOT LEARNING
        </a>
        
          <a href="https://openreview.net/pdf?id=B1mAkPxCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=14302010017%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="14302010017@fudan.edu.cn">jianqi ma</a>, <a href="https://openreview.net/profile?email=16210240036%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="16210240036@fudan.edu.cn">hangyu lin</a>, <a href="https://openreview.net/profile?email=yindaz%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yindaz@cs.princeton.edu">yinda zhang</a>, <a href="https://openreview.net/profile?email=y.fu%40qmul.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.fu@qmul.ac.uk">yanwei fu</a>, xiangyang xue
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1mAkPxCZ-details-790" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1mAkPxCZ-details-790"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A natural solution for one-shot learning is to augment training data to handle the data deficiency problem. However, directly augmenting in the image domain may not necessarily generate training data that sufficiently explore the intra-class space for one-shot classification. Inspired by the recent vocabulary-informed learning, we propose to generate synthetic training data with the guide of the semantic word space. Essentially, we train an auto-encoder as a bridge to enable the transformation between the image feature space and the semantic space. Besides directly augmenting image features, we transform the image features to semantic space using the encoder and perform the data augmentation. The decoder then synthesizes the image features for the augmented instances from the semantic space. Experiments on three datasets show that our data augmentation method effectively improves the performance of one-shot classification. An extensive study shows that data augmented from semantic space are complementary with those from the image space, and thus boost the classification accuracy dramatically. Source code and dataset will be available. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">vocabulary-informed learning, data augmentation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HymYLebCb">
      <h4>
        <a href="https://openreview.net/forum?id=HymYLebCb">
          Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=HymYLebCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hegdek2%40rpi.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hegdek2@rpi.edu">Kshiteesh Hegde</a>, <a href="https://openreview.net/profile?email=magdon%40rpi.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="magdon@rpi.edu">Malik Magdon-Ismail</a>, <a href="https://openreview.net/profile?email=ram%40gotenna.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ram@gotenna.com">Ram Ramanathan</a>, <a href="https://openreview.net/profile?email=bishal.thapa%40raytheon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bishal.thapa@raytheon.com">Bishal Thapa</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HymYLebCb-details-479" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HymYLebCb-details-479"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that
      1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,
      2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, transfer learning, adjacency matrices, image feature representation, Caffe, graph classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skvd-myR-">
      <h4>
        <a href="https://openreview.net/forum?id=Skvd-myR-">
          Learning Non-Metric Visual Similarity for Image Retrieval
        </a>
        
          <a href="https://openreview.net/pdf?id=Skvd-myR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=garciadn%40aston.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="garciadn@aston.ac.uk">Noa Garcia</a>, <a href="https://openreview.net/profile?email=g.vogiatzis%40aston.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="g.vogiatzis@aston.ac.uk">George Vogiatzis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skvd-myR--details-821" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skvd-myR--details-821"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Measuring visual (dis)similarity between two or more instances within a data distribution is a fundamental task in many applications, specially in image retrieval. Theoretically, non-metric distances are able to generate a more complex and accurate similarity model than metric distances, provided that the non-linear data distribution is precisely captured by the similarity model. In this work, we analyze a simple approach for deep learning networks to be used as an approximation of non-metric similarity functions and we study how these models generalize across different image retrieval datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Similarity network to learn a non-metric visual similarity estimation between a pair of images</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">image retrieval, visual similarity, non-metric learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJw03ceRW">
      <h4>
        <a href="https://openreview.net/forum?id=SJw03ceRW">
          GENERATIVE LOW-SHOT NETWORK EXPANSION
        </a>
        
          <a href="https://openreview.net/pdf?id=SJw03ceRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=adi.hayat3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adi.hayat3@gmail.com">Adi Hayat</a>, <a href="https://openreview.net/profile?email=mark.kliger%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mark.kliger@gmail.com">Mark Kliger</a>, <a href="https://openreview.net/profile?email=shacharfl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shacharfl@gmail.com">Shachar Fleishman</a>, <a href="https://openreview.net/profile?email=cohenor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cohenor@gmail.com">Daniel Cohen-Or</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJw03ceRW-details-639" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJw03ceRW-details-639"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Conventional deep learning classifiers are static in the sense that they are trained on
      a predefined set of classes and learning to classify a novel class typically requires
      re-training. In this work, we address the problem of Low-shot network-expansion
      learning. We introduce a learning framework which enables expanding a pre-trained
      (base) deep network to classify novel classes when the number of examples for the
      novel classes is particularly small. We present a simple yet powerful distillation
      method where the base network is augmented with additional weights to classify
      the novel classes, while keeping the weights of the base network unchanged. We
      term this learning hard distillation, since we preserve the response of the network
      on the old classes to be equal in both the base and the expanded network. We
      show that since only a small number of weights needs to be trained, the hard
      distillation excels for low-shot training scenarios. Furthermore, hard distillation
      avoids detriment to classification performance on the base classes. Finally, we
      show that low-shot network expansion can be done with a very small memory
      footprint by using a compact generative model of the base classes training data
      with only a negligible degradation relative to learning with the full training set.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> In this paper, we address the problem of Low-shot network-expansion learning</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Low-Shot Learning, class incremental learning, Network expansion, Generative model, Distillation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJluxbWC-">
      <h4>
        <a href="https://openreview.net/forum?id=BJluxbWC-">
          Unseen Class Discovery in Open-world Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=BJluxbWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lshu3%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lshu3@uic.edu">Lei Shu</a>, <a href="https://openreview.net/profile?email=hxu48%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hxu48@uic.edu">Hu Xu</a>, <a href="https://openreview.net/profile?email=liub%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liub@uic.edu">Bing Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJluxbWC--details-522" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJluxbWC--details-522"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper concerns open-world classification, where the classifier not only needs to classify test examples into seen classes that have appeared in training but also reject examples from unseen or novel classes that have not appeared in training. Specifically, this paper focuses on discovering the hidden unseen classes of the rejected examples. Clearly, without prior knowledge this is difficult. However, we do have the data from the seen training classes, which can tell us what kind of similarity/difference is expected for examples from the same class or from different classes. It is reasonable to assume that this knowledge can be transferred to the rejected examples and used to discover the hidden unseen classes in them. This paper aims to solve this problem. It first proposes a joint open classification model with a sub-model for classifying whether a pair of examples belongs to the same or different classes. This sub-model can serve as a distance function for clustering to discover the hidden classes of the rejected examples. Experimental results show that the proposed model is highly promising.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJr4QJ26W">
      <h4>
        <a href="https://openreview.net/forum?id=HJr4QJ26W">
          Improving image generative models with human interactions
        </a>
        
          <a href="https://openreview.net/pdf?id=HJr4QJ26W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lampinen%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lampinen@stanford.edu">Andrew Kyle Lampinen</a>, <a href="https://openreview.net/profile?email=davidso%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidso@google.com">David So</a>, <a href="https://openreview.net/profile?email=deck%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="deck@google.com">Douglas Eck</a>, <a href="https://openreview.net/profile?email=fredbertsch%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fredbertsch@google.com">Fred Bertsch</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJr4QJ26W-details-483" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJr4QJ26W-details-483"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">GANs provide a framework for training generative models which mimic a data distribution. However, in many cases we wish to train a generative model to optimize some auxiliary objective function within the data it generates, such as making more aesthetically pleasing images. In some cases, these objective functions are difficult to evaluate, e.g. they may require human interaction. Here, we develop a system for efficiently training a GAN to increase a generic rate of positive user interactions, for example aesthetic ratings. To do this, we build a model of human behavior in the targeted domain from a relatively small set of interactions, and then use this behavioral model as an auxiliary loss function to improve the generative model. As a proof of concept, we demonstrate that this system is successful at improving positive interaction rates simulated from a variety of objectives, and characterize s</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe how to improve an image generative model according to a slow- or difficult-to-evaluate objective, such as human feedback, which could have many applications, like making more aesthetic images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">human in the loop, GANs, generative adversarial networks, image generative models, computer vision</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJVHY9lCb">
      <h4>
        <a href="https://openreview.net/forum?id=SJVHY9lCb">
          Learning to Select: Problem, Solution, and Applications
        </a>
        
          <a href="https://openreview.net/pdf?id=SJVHY9lCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rhc93%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="rhc93@kaist.ac.kr">Heechang Ryu</a>, <a href="https://openreview.net/profile?email=dhk618%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhk618@kaist.ac.kr">Donghyun Kim</a>, <a href="https://openreview.net/profile?email=hyshin%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyshin@kaist.ac.kr">Hayong Shin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJVHY9lCb-details-333" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJVHY9lCb-details-333"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a "Learning to Select" problem that selects the best among the flexible size candidates. This makes decisions based not only on the properties of the candidate, but also on the environment in which they belong to. For example, job dispatching in the manufacturing factory is a typical "Learning to Select" problem. We propose Variable-Length CNN which combines the classification power using hidden features from CNN and the idea of flexible input from Learning to Rank algorithms. This not only can handles flexible candidates using Dynamic Computation Graph, but also is computationally efficient because it only builds a network with the necessary sizes to fit the situation. We applied the algorithm to the job dispatching problem which uses the dispatching log data obtained from the virtual fine-tuned factory. Our proposed algorithm shows considerably better performance than other comparable algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Selection Problem, Job Dispatching, Convolution Neural Network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJDUjKeA-">
      <h4>
        <a href="https://openreview.net/forum?id=HJDUjKeA-">
          Learning objects from pixels
        </a>
        
          <a href="https://openreview.net/pdf?id=HJDUjKeA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=saxton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saxton@google.com">David Saxton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJDUjKeA--details-125" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJDUjKeA--details-125"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We show how discrete objects can be learnt in an unsupervised fashion from pixels, and how to perform reinforcement learning using this object representation.
      
      More precisely, we construct a differentiable mapping from an image to a discrete tabular list of objects, where each object consists of a differentiable position, feature vector, and scalar presence value that allows the representation to be learnt using an attention mechanism.
      
      Applying this mapping to Atari games, together with an interaction net-style architecture for calculating quantities from objects, we construct agents that can play Atari games using objects learnt in an unsupervised fashion. During training, many natural objects emerge, such as the ball and paddles in Pong, and the submarine and fish in Seaquest.
      
      This gives the first reinforcement learning agent for Atari with an interpretable object representation, and opens the avenue for agents that can conduct object-based exploration and generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show how discrete objects can be learnt in an unsupervised fashion from pixels, and how to perform reinforcement learning using this object representation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">objects, unsupervised, reinforcement learning, atari</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkAK2jg0b">
      <h4>
        <a href="https://openreview.net/forum?id=SkAK2jg0b">
          An Out-of-the-box Full-network Embedding for Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkAK2jg0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dario.garcia%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="dario.garcia@bsc.es">Dario Garcia-Gasulla</a>, <a href="https://openreview.net/profile?email=armand.vilalta%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="armand.vilalta@bsc.es">Armand Vilalta</a>, <a href="https://openreview.net/profile?email=ferran.pares%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="ferran.pares@bsc.es">Ferran Parés</a>, <a href="https://openreview.net/profile?email=jonatan.moreno%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonatan.moreno@bsc.es">Jonatan Moreno</a>, <a href="https://openreview.net/profile?email=eduard.ayguade%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="eduard.ayguade@bsc.es">Eduard Ayguadé</a>, <a href="https://openreview.net/profile?email=jesus.labarta%40bsc.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="jesus.labarta@bsc.es">Jesús Labarta</a>, <a href="https://openreview.net/profile?email=ia%40cs.upc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ia@cs.upc.edu">Ulises Cortés</a>, <a href="https://openreview.net/profile?email=suzumurat%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="suzumurat@gmail.com">Toyotaro Suzumura</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkAK2jg0b-details-517" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkAK2jg0b-details-517"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Embedding spaces, feature extraction, transfer learning.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkoCeqgR-">
      <h4>
        <a href="https://openreview.net/forum?id=BkoCeqgR-">
          On the Construction and Evaluation of Color Invariant Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BkoCeqgR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=konrad.groh%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="konrad.groh@de.bosch.com">Konrad Groh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkoCeqgR--details-604" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkoCeqgR--details-604"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This is an empirical paper which constructs color invariant networks and evaluates their performances on a realistic data set. The paper studies the simplest possible case of color invariance: invariance under pixel-wise permutation of the color channels. Thus the network is aware not of the specific color object, but its colorfulness. The data set introduced in the paper consists of images showing crashed cars from which ten classes were extracted. An additional annotation was done which labeled whether the car shown was red or non-red.  The networks were evaluated by their performance on the classification task. With the color annotation we altered the color ratios  in the training data and analyzed the generalization capabilities of the networks on the unaltered test data. We further split the test data in red and non-red cars and did a similar evaluation. It is shown in the paper that an pixel-wise ordering of the rgb-values of the images performs better or at least similarly for small deviations from the true color ratios. The limits of these networks are also discussed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We construct and evaluate color invariant neural nets on a novel realistic data set</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, invariance, data set, evaluation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bym0cU1CZ">
      <h4>
        <a href="https://openreview.net/forum?id=Bym0cU1CZ">
          Towards Interpretable Chit-chat: Open Domain Dialogue Generation with Dialogue Acts
        </a>
        
          <a href="https://openreview.net/pdf?id=Bym0cU1CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wuwei%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuwei@microsoft.com">Wei Wu</a>, <a href="https://openreview.net/profile?email=can.xu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="can.xu@microsoft.com">Can Xu</a>, <a href="https://openreview.net/profile?email=wumark%40126.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wumark@126.com">Yu Wu</a>, <a href="https://openreview.net/profile?email=lizj%40buaa.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lizj@buaa.edu.cn">Zhoujun Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bym0cU1CZ-details-211" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bym0cU1CZ-details-211"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Conventional methods model open domain dialogue generation as a black box through end-to-end learning from large scale conversation data. In this work, we make the first step to open the black box by introducing dialogue acts into open domain dialogue generation. The dialogue acts are generally designed and reveal how people engage in social chat. Inspired by analysis on real data, we propose jointly modeling dialogue act selection and response generation, and perform learning with human-human conversations tagged with a dialogue act classifier and a reinforcement approach to further optimizing the model for long-term conversation. With the dialogue acts, we not only achieve significant improvement over state-of-the-art methods on response quality for given contexts and long-term conversation in both machine-machine simulation and human-machine conversation, but also are capable of explaining why such achievements can be made.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">open domain dialogue generation with dialogue acts</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">dialogue generation, dialogue acts, open domain conversation, supervised learning, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bki1Ct1AW">
      <h4>
        <a href="https://openreview.net/forum?id=Bki1Ct1AW">
          Baseline-corrected space-by-time non-negative matrix factorization for decoding single trial population spike trains
        </a>
        
          <a href="https://openreview.net/pdf?id=Bki1Ct1AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arezoo.alizadehkhajehiem%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="arezoo.alizadehkhajehiem@iit.it">Arezoo Alizadeh</a>, <a href="https://openreview.net/profile?email=marion.mutter%40gmx.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="marion.mutter@gmx.de">Marion Mutter</a>, <a href="https://openreview.net/profile?email=thomas.muench%40cin.uni-tuebingen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.muench@cin.uni-tuebingen.de">Thomas Münch</a>, <a href="https://openreview.net/profile?email=aonken%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="aonken@inf.ed.ac.uk">Arno Onken</a>, <a href="https://openreview.net/profile?email=stefano.panzeri%40iit.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefano.panzeri@iit.it">Stefano Panzeri</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bki1Ct1AW-details-355" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bki1Ct1AW-details-355"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Activity of populations of sensory neurons carries stimulus information in both the temporal and the spatial dimensions. This poses the question of how to compactly represent all the information that the population codes carry across all these dimensions. Here, we developed an analytical method to factorize a large number of retinal ganglion cells' spike trains into a robust low-dimensional representation that captures efficiently both their spatial and temporal information. In particular, we extended previously used single-trial space-by-time tensor decomposition based on non-negative matrix factorization to efficiently discount pre-stimulus baseline activity. On data recorded from retinal ganglion cells with strong pre-stimulus baseline, we showed that in situations were the stimulus elicits a strong change in firing rate, our extensions yield a boost in stimulus decoding performance. Our results thus suggest that taking into account the baseline can be important for finding a compact information-rich representation of neural activity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We extended single-trial space-by-time tensor decomposition based on non-negative matrix factorization to efficiently discount pre-stimulus baseline activity that improves decoding performance on data with non-negligible baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Space-by-time non-negative matrix factorization, dimensionality reduction, baseline correction, neuronal decoding, mutual information</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1GUgxgCW">
      <h4>
        <a href="https://openreview.net/forum?id=S1GUgxgCW">
          Latent Topic Conversational Models
        </a>
        
          <a href="https://openreview.net/pdf?id=S1GUgxgCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thw28%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="thw28@cam.ac.uk">Tsung-Hsien Wen</a>, <a href="https://openreview.net/profile?email=thangluong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thangluong@google.com">Minh-Thang Luong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1GUgxgCW-details-966" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1GUgxgCW-details-966"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite much success in many large-scale language tasks, sequence-to-sequence (seq2seq) models have not been an ideal choice for conversational modeling as they tend to generate generic and repetitive responses. In this paper, we propose a Latent Topic Conversational Model (LTCM) that augments the seq2seq model with a neural topic component to better model human-human conversations. The neural topic component encodes information from the source sentence to build a global “topic” distribution over words, which is then consulted by the seq2seq model to improve generation at each time step. The experimental results show that the proposed LTCM can generate more diverse and interesting responses by sampling from its learnt latent representations. In a subjective human evaluation, the judges also confirm that LTCM is the preferred option comparing to competitive baseline models.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Latent Topic Conversational Model, a hybrid of seq2seq and neural topic model to generate more diverse and interesting responses.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">conversational modeling, dialogue, chitchat, open-domain dialogue, topic model, neural variational inference, human evaluation, latent variable model, gaussian reparameterisation trick</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkBHr1WRW">
      <h4>
        <a href="https://openreview.net/forum?id=SkBHr1WRW">
          Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures
        </a>
        
          <a href="https://openreview.net/pdf?id=SkBHr1WRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rctzeng%40datalab.cs.nthu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="rctzeng@datalab.cs.nthu.edu.tw">Ruo-Chun Tzeng</a>, <a href="https://openreview.net/profile?email=shwu%40cs.nthu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="shwu@cs.nthu.edu.tw">Shan-Hung Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkBHr1WRW-details-945" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkBHr1WRW-details-945"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph embedding, CNN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ6anzb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=BJ6anzb0Z">
          Multimodal Sentiment Analysis To Explore the Structure of Emotions
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ6anzb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anthony.hu%40stats.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="anthony.hu@stats.ox.ac.uk">Anthony Hu</a>, <a href="https://openreview.net/profile?email=s.flaxman%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.flaxman@imperial.ac.uk">Seth Flaxman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ6anzb0Z-details-414" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ6anzb0Z-details-414"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel approach to multimodal sentiment analysis using deep neural
      networks combining visual recognition and natural language processing. Our
      goal is different than the standard sentiment analysis goal of predicting whether
      a sentence expresses positive or negative sentiment; instead, we aim to infer the
      latent emotional state of the user. Thus, we focus on predicting the emotion word
      tags attached by users to their Tumblr posts, treating these as “self-reported emotions.”
      We demonstrate that our multimodal model combining both text and image
      features outperforms separate models based solely on either images or text. Our
      model’s results are interpretable, automatically yielding sensible word lists associated
      with emotions. We explore the structure of emotions implied by our model
      and compare it to what has been posited in the psychology literature, and validate
      our model on a set of images that have been used in psychology studies. Finally,
      our work also provides a useful tool for the growing academic study of images—
      both photographs and memes—on social networks.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ7yZ2P6-">
      <h4>
        <a href="https://openreview.net/forum?id=rJ7yZ2P6-">
          Enhance Word Representation for Out-of-Vocabulary on Ubuntu Dialogue Corpus
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ7yZ2P6-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jdongca2003%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jdongca2003@gmail.com">JIANXIONG DONG</a>, <a href="https://openreview.net/profile?email=ccjimhuang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ccjimhuang@gmail.com">Jim Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ7yZ2P6--details-73" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ7yZ2P6--details-73"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Ubuntu dialogue corpus is the largest public available dialogue corpus to make it feasible to build end-to-end
      deep neural network models directly from the conversation data. One challenge of Ubuntu dialogue corpus is 
      the large number of out-of-vocabulary words. In this paper we proposed an algorithm which combines the general pre-trained word embedding vectors with those  generated on the task-specific training set to address this issue.  We integrated character embedding into Chen et al's Enhanced LSTM method (ESIM) and used it to evaluate the effectiveness of our proposed method. For the task of next utterance selection, the proposed method has demonstrated a significant performance improvement against original ESIM and the new model has achieved state-of-the-art results on both Ubuntu dialogue corpus and Douban conversation corpus. In addition, we investigated the performance impact of end-of-utterance and end-of-turn token tags. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Combine information between pre-built word embedding and task-specific word representation to address out-of-vocabulary issue</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">next utterance selection, ubuntu dialogue corpus, out-of-vocabulary, word representation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By5SY2gA-">
      <h4>
        <a href="https://openreview.net/forum?id=By5SY2gA-">
          Towards Building Affect sensitive Word Distributions
        </a>
        
          <a href="https://openreview.net/pdf?id=By5SY2gA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kchawla%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kchawla@adobe.com">Kushal Chawla</a>, <a href="https://openreview.net/profile?email=skhosla%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skhosla@adobe.com">Sopan Khosla</a>, <a href="https://openreview.net/profile?email=nchhaya%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nchhaya@adobe.com">Niyati Chhaya</a>, <a href="https://openreview.net/profile?email=jaidka%40sas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaidka@sas.upenn.edu">Kokil Jaidka</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By5SY2gA--details-791" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By5SY2gA--details-791"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning word representations from large available corpora relies on the distributional hypothesis that words present in similar contexts tend to have similar meanings. Recent work has shown that word representations learnt in this manner lack sentiment information which, fortunately, can be leveraged using external knowledge. Our work addresses the question: can affect lexica improve the word representations learnt from a corpus? In this work, we propose techniques to incorporate affect lexica, which capture fine-grained information about a word's psycholinguistic and emotional orientation, into the training process of Word2Vec SkipGram, Word2Vec CBOW and GloVe methods using a joint learning approach. We use affect scores from Warriner's affect lexicon to regularize the vector representations learnt from an unlabelled corpus. Our proposed method outperforms previously proposed methods on standard tasks for word similarity detection, outlier detection and sentiment detection. We also demonstrate the usefulness of our approach for a new task related to the prediction of formality, frustration and politeness in corporate communication.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Enriching word embeddings with affect information improves their performance on sentiment prediction tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Affect lexicon, word embeddings, Word2Vec, GloVe, WordNet, joint learning, sentiment analysis, word similarity, outlier detection, affect prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r17lFgZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=r17lFgZ0Z">
          Relevance of Unsupervised Metrics in Task-Oriented Dialogue for Evaluating Natural Language Generation
        </a>
        
          <a href="https://openreview.net/pdf?id=r17lFgZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shikhar.sharma%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shikhar.sharma@microsoft.com">Shikhar Sharma</a>, <a href="https://openreview.net/profile?email=layla.elasri%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="layla.elasri@microsoft.com">Layla El Asri</a>, <a href="https://openreview.net/profile?email=hannes.schulz%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hannes.schulz@microsoft.com">Hannes Schulz</a>, <a href="https://openreview.net/profile?email=jeremie_zumer%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeremie_zumer@hotmail.com">Jeremie Zumer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r17lFgZ0Z-details-324" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r17lFgZ0Z-details-324"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Automated metrics such as BLEU are widely used in the machine translation literature. They have also been used recently in the dialogue community for evaluating dialogue response generation. However, previous work in dialogue response generation has shown that these metrics do not correlate strongly with human judgment in the non task-oriented dialogue setting. Task-oriented dialogue responses are expressed on narrower domains and exhibit lower diversity. It is thus reasonable to think that these automated metrics would correlate well with human judgment in the task-oriented setting where the generation task consists of translating dialogue acts into a sentence. We conduct an empirical study to confirm whether this is the case. Our findings indicate that these automated metrics have stronger correlation with human judgments in the task-oriented setting compared to what has been observed in the non task-oriented setting. We also observe that these metrics correlate even better for datasets which provide multiple ground truth reference sentences. In addition, we show that some of the currently available corpora for task-oriented language generation can be solved with simple models and advocate for more challenging datasets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">task-oriented dialog, goal-oriented dialog, nlg evaluation, natural language generation, automated metrics for nlg</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByhthReRb">
      <h4>
        <a href="https://openreview.net/forum?id=ByhthReRb">
          A Neural Method for Goal-Oriented Dialog Systems to interact with Named Entities
        </a>
        
          <a href="https://openreview.net/pdf?id=ByhthReRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rjana%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rjana@umich.edu">Janarthanan Rajendran</a>, <a href="https://openreview.net/profile?email=jatinganhotra%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jatinganhotra@us.ibm.com">Jatin Ganhotra</a>, <a href="https://openreview.net/profile?email=xiaoxiao.guo%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoxiao.guo@ibm.com">Xiaoxiao Guo</a>, <a href="https://openreview.net/profile?email=yum%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yum@us.ibm.com">Mo Yu</a>, <a href="https://openreview.net/profile?email=baveja%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baveja@umich.edu">Satinder Singh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByhthReRb-details-73" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByhthReRb-details-73"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many goal-oriented dialog tasks, especially ones in which the dialog system has to interact with external knowledge sources such as databases, have to handle a large number of Named Entities (NEs). There are at least two challenges in handling NEs using neural methods in such settings: individual NEs may occur only rarely making it hard to learn good representations of them, and many of the Out Of Vocabulary words that occur during test time may be NEs. Thus, the need to interact well with these NEs has emerged as a serious challenge to building neural methods for goal-oriented dialog tasks. In this paper, we propose a new neural method for this problem, and present empirical evaluations on a structured Question answering task and three related goal-oriented dialog tasks that show that our proposed method can be effective in interacting with NEs in these settings.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Named Entities, Neural methods, Goal oriented dialog</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJXyS7bRb">
      <h4>
        <a href="https://openreview.net/forum?id=HJXyS7bRb">
          A Goal-oriented Neural Conversation Model by Self-Play
        </a>
        
          <a href="https://openreview.net/pdf?id=HJXyS7bRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wewei%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wewei@google.com">Wei Wei</a>, <a href="https://openreview.net/profile?email=adai%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adai@google.com">Quoc V. Le</a>, <a href="https://openreview.net/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Andrew M. Dai</a>, <a href="https://openreview.net/profile?email=lijiali%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lijiali@google.com">Li-Jia Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJXyS7bRb-details-721" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJXyS7bRb-details-721"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Building chatbots that can accomplish goals such as booking a flight ticket is an unsolved problem in natural language understanding. Much progress has been made to build conversation models using techniques such as sequence2sequence modeling. One challenge in applying such techniques to building goal-oriented conversation models is that maximum likelihood-based models are not optimized toward accomplishing goals. Recently, many methods have been proposed to address this issue by optimizing a reward that contains task status or outcome. However, adding the reward optimization on the fly usually provides little guidance for language construction and the conversation model soon becomes decoupled from the language model. In this paper, we propose a new setting in goal-oriented dialogue system to tighten the gap between these two aspects by enforcing model level information isolation on individual models between two agents. Language construction now becomes an important part in reward optimization since it is the only way information can be exchanged. We experimented our models using self-play and results showed that our method not only beat the baseline sequence2sequence model in rewards but can also generate human-readable meaningful conversations of comparable quality. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A Goal-oriented Neural Conversation Model by Self-Play</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">conversation model, seq2seq, self-play, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syl3_2JCZ">
      <h4>
        <a href="https://openreview.net/forum?id=Syl3_2JCZ">
          A Self-Organizing Memory Network
        </a>
        
          <a href="https://openreview.net/pdf?id=Syl3_2JCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=callie.federer%40ucdenver.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="callie.federer@ucdenver.edu">Callie Federer</a>, <a href="https://openreview.net/profile?email=joel.zylberberg%40ucdenver.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="joel.zylberberg@ucdenver.edu">Joel Zylberberg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Syl3_2JCZ-details-844" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syl3_2JCZ-details-844"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Working memory requires information about external stimuli to be represented in the brain even after those stimuli go away. This information is encoded in the activities of neurons, and neural activities change over timescales of tens of milliseconds. Information in working memory, however, is retained for tens of seconds, suggesting the question of how time-varying neural activities maintain stable representations. Prior work shows that, if the neural dynamics are in the `  null space' of the representation - so that changes to neural activity do not affect the downstream read-out of stimulus information - then information can be retained for periods much longer than the time-scale of individual-neuronal activities. The prior work, however, requires precisely constructed synaptic connectivity matrices, without explaining how this would arise in a biological neural network. To identify mechanisms through which biological networks can self-organize to learn  memory function, we derived biologically plausible synaptic plasticity rules that dynamically modify the connectivity matrix to enable information storing. Networks implementing this plasticity rule can successfully learn to form memory representations even if only 10% of the synapses are plastic, they are robust to synaptic noise, and they can represent information about multiple stimuli. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We derived biologically plausible synaptic plasticity learning rules for a recurrent neural network to store stimulus representations. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Working Memory, Learning Rules, Stimulus Representations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJXOfZ-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJXOfZ-AZ">
          When and where do feed-forward neural networks learn localist representations?
        </a>
        
          <a href="https://openreview.net/pdf?id=HJXOfZ-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eg16993%40bristol.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="eg16993@bristol.ac.uk">Ella M. Gale</a>, <a href="https://openreview.net/profile?email=nm13850%40bristol.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="nm13850@bristol.ac.uk">Nicolas Martin</a>, <a href="https://openreview.net/profile?email=j.bowers%40bristol.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.bowers@bristol.ac.uk">Jeffrey Bowers</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJXOfZ-AZ-details-920" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJXOfZ-AZ-details-920"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">According to parallel distributed processing (PDP) theory in psychology, neural networks (NN) learn distributed rather than interpretable localist representations. This view has been held so strongly that few researchers have analysed single units to determine if this assumption is correct. However, recent results from psychology, neuroscience and computer science have shown the occasional existence of local codes emerging in artificial and biological neural networks. In this paper, we undertake the first systematic survey of when local codes emerge in a feed-forward neural network, using generated input and output data with known qualities. We find that the number of local codes that emerge from a NN follows a well-defined distribution across the number of hidden layer neurons, with a peak determined by the size of input data, number of examples presented and the sparsity of input data. Using a 1-hot output code drastically decreases the number of local codes on the hidden layer. The number of emergent local codes increases with the percentage of dropout applied to the hidden layer, suggesting that the localist encoding may offer a resilience to noisy networks. This data suggests that localist coding can emerge from feed-forward PDP networks and suggests some of the conditions that may lead to interpretable localist representations in the cortex. The findings highlight how local codes should not be dismissed out of hand.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Local codes have been found in feed-forward neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">localist, pdp, neural network, representation, psychology, cognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJiHOSeR-">
      <h4>
        <a href="https://openreview.net/forum?id=SJiHOSeR-">
          Contextual memory bandit for pro-active dialog engagement
        </a>
        
          <a href="https://openreview.net/pdf?id=SJiHOSeR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=julien.perez%40naverlabs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="julien.perez@naverlabs.com">julien perez</a>, Tomi Silander
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJiHOSeR--details-43" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJiHOSeR--details-43"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">An objective of pro-activity in dialog systems is to enhance the usability of conversational
      agents by enabling them to initiate conversation on their own. While
      dialog systems have become increasingly popular during the last couple of years,
      current task oriented dialog systems are still mainly reactive and users tend to
      initiate conversations. In this paper, we propose to introduce the paradigm of contextual
      bandits as framework for pro-active dialog systems. Contextual bandits
      have been the model of choice for the problem of reward maximization with partial
      feedback since they fit well to the task description. As a second contribution,
      we introduce and explore the notion of memory into this paradigm. We propose
      two differentiable memory models that act as parts of the parametric reward estimation
      function. The first one, Convolutional Selective Memory Networks, uses
      a selection of past interactions as part of the decision support. The second model,
      called Contextual Attentive Memory Network, implements a differentiable attention
      mechanism over the past interactions of the agent. The goal is to generalize
      the classic model of contextual bandits to settings where temporal information
      needs to be incorporated and leveraged in a learnable manner. Finally, we illustrate
      the usability and performance of our model for building a pro-active mobile
      assistant through an extensive set of experiments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">contextual bandit, memory network, proactive dialog engagement</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkpXqwUTZ">
      <h4>
        <a href="https://openreview.net/forum?id=BkpXqwUTZ">
          Iterative temporal differencing with fixed random feedback alignment support spike-time dependent plasticity in vanilla backpropagation for deep learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BkpXqwUTZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=arasdar%40uri.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arasdar@uri.edu">Aras Dargazany</a>, Kunal Mankodiya
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkpXqwUTZ-details-230" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkpXqwUTZ-details-230"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In vanilla backpropagation (VBP), activation function matters considerably in terms of non-linearity and differentiability.
      Vanishing gradient has been an important problem related to the bad choice of activation function in deep learning (DL).
      This work shows that a differentiable activation function is not necessary any more for error backpropagation. 
      The derivative of the activation function can be replaced by an iterative temporal differencing (ITD) using fixed random feedback weight alignment (FBA).
      Using FBA with ITD, we can transform the VBP into a more biologically plausible approach for learning deep neural network architectures.
      We don't claim that ITD works completely the same as the spike-time dependent plasticity (STDP) in our brain but this work can be a step toward the integration of STDP-based error backpropagation in deep learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Iterative temporal differencing with fixed random feedback alignment support spike-time dependent plasticity in vanilla backpropagation for deep learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Iterative temporal differencing, feedback alignment, spike-time dependent plasticity, vanilla backpropagation, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ_QxP1AZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJ_QxP1AZ">
          Unleashing the Potential of CNNs for Interpretable Few-Shot Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ_QxP1AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=billydeng%40buaa.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="billydeng@buaa.edu.cn">Boyang Deng</a>, <a href="https://openreview.net/profile?email=qingliu%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qingliu@jhu.edu">Qing Liu</a>, <a href="https://openreview.net/profile?email=siyuan.qiao%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="siyuan.qiao@jhu.edu">Siyuan Qiao</a>, <a href="https://openreview.net/profile?email=alan.yuille%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alan.yuille@jhu.edu">Alan Yuille</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ_QxP1AZ-details-216" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ_QxP1AZ-details-216"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks (CNNs) have been generally acknowledged as one of the driving forces for the advancement of computer vision. Despite their promising performances on many tasks, CNNs still face major obstacles on the road to achieving ideal machine intelligence. One is that CNNs are complex and hard to interpret. Another is that standard CNNs require large amounts of annotated data, which is sometimes very hard to obtain, and it is desirable to be able to learn them from few examples. In this work, we address these limitations of CNNs by developing novel, simple, and interpretable models for few-shot learn- ing. Our models are based on the idea of encoding objects in terms of visual concepts, which are interpretable visual cues represented by the feature vectors within CNNs. We first adapt the learning of visual concepts to the few-shot setting, and then uncover two key properties of feature encoding using visual concepts, which we call category sensitivity and spatial pattern. Motivated by these properties, we present two intuitive models for the problem of few-shot learning. Experiments show that our models achieve competitive performances, while being much more flexible and interpretable than alternative state-of-the-art few-shot learning methods. We conclude that using visual concepts helps expose the natural capability of CNNs for few-shot learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We enable ordinary CNNs for few-shot learning by exploiting visual concepts which are interpretable visual cues learnt within CNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Few-Shot Learning, Neural Network Understanding, Visual Concepts</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1i7ezW0-">
      <h4>
        <a href="https://openreview.net/forum?id=B1i7ezW0-">
          Semi-Supervised Learning via New Deep Network Inversion
        </a>
        
          <a href="https://openreview.net/pdf?id=B1i7ezW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=randallbalestriero%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="randallbalestriero@gmail.com">Balestriero R.</a>, <a href="https://openreview.net/profile?email=roger.dyni%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="roger.dyni@gmail.com">Roger V.</a>, <a href="https://openreview.net/profile?email=herve.glotin%40univ-tln.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="herve.glotin@univ-tln.fr">Glotin H.</a>, <a href="https://openreview.net/profile?email=richb%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="richb@rice.edu">Baraniuk R.</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1i7ezW0--details-551" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1i7ezW0--details-551"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We exploit a recently derived inversion scheme for arbitrary deep neural networks to develop a new semi-supervised learning framework that applies to a wide range of systems and problems.  
      The approach reaches current state-of-the-art methods on MNIST and provides reasonable performances on SVHN and CIFAR10. Through the introduced method, residual networks are for the first time applied to semi-supervised tasks. Experiments with one-dimensional signals highlight the generality of the method. Importantly, our approach is simple, efficient, and requires no change in the deep network architecture.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We exploit an inversion scheme for arbitrary deep neural networks to develop a new semi-supervised learning framework applicable to many topologies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">inversion scheme, deep neural networks, semi-supervised learning, MNIST, SVHN, CIFAR10</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByzvHagA-">
      <h4>
        <a href="https://openreview.net/forum?id=ByzvHagA-">
          Disentangled activations in deep networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ByzvHagA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kageback%40chalmers.se" class="profile-link" data-toggle="tooltip" data-placement="top" title="kageback@chalmers.se">Mikael Kågebäck</a>, <a href="https://openreview.net/profile?email=olof%40mogren.one" class="profile-link" data-toggle="tooltip" data-placement="top" title="olof@mogren.one">Olof Mogren</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByzvHagA--details-610" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByzvHagA--details-610"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks have been tremendously successful in a number of tasks.
      One of the main reasons for this is their capability to automatically
      learn representations of data in levels of abstraction,
      increasingly disentangling the data as the internal transformations are applied.
      In this paper we propose a novel regularization method that penalize covariance between dimensions of the hidden layers in a network, something that benefits the disentanglement.
      This makes the network learn nonlinear representations that are linearly uncorrelated, yet allows the model to obtain good results on a number of tasks, as demonstrated by our experimental evaluation.
      The proposed technique can be used to find the dimensionality of the underlying data, because it effectively disables dimensions that aren't needed.
      Our approach is simple and computationally cheap, as it can be applied as a regularizer to any gradient-based learning model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel regularization method that penalize covariance between dimensions of the hidden layers in a network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, disentanglement, regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SySpa-Z0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SySpa-Z0Z">
          From Information Bottleneck To Activation Norm Penalty
        </a>
        
          <a href="https://openreview.net/pdf?id=SySpa-Z0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anie%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anie@stanford.edu">Allen Nie</a>, <a href="https://openreview.net/profile?email=mihir.mongia%40mssm.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mihir.mongia@mssm.edu">Mihir Mongia</a>, <a href="https://openreview.net/profile?email=jamesz%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamesz@stanford.edu">James Zou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SySpa-Z0Z-details-441" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SySpa-Z0Z-details-441"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many regularization methods have been proposed to prevent overfitting in neural networks. Recently, a regularization method has been proposed to optimize the variational lower bound of the Information Bottleneck Lagrangian. However, this method cannot be generalized to regular neural network architectures. We present the activation norm penalty that is derived from the information bottleneck principle and is theoretically grounded in a variation dropout framework. Unlike in previous literature, it can be applied to any general neural network. We demonstrate that this penalty can give consistent improvements to different state of the art architectures both in language modeling and image classification. We present analyses on the properties of this penalty and compare it to other methods that also reduce mutual information.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We derive a norm penalty on the output of the neural network from the information bottleneck perspective</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Natural Language Processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryykVe-0W">
      <h4>
        <a href="https://openreview.net/forum?id=ryykVe-0W">
          Learning Independent Features with Adversarial Nets for Non-linear ICA
        </a>
        
          <a href="https://openreview.net/pdf?id=ryykVe-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pbpop3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pbpop3@gmail.com">Philemon Brakel</a>, <a href="https://openreview.net/profile?email=yoshua.bengio%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@umontreal.ca">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryykVe-0W-details-921" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryykVe-0W-details-921"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reliable measures of statistical dependence could potentially be useful tools for learning independent features and performing tasks like source separation using Independent Component Analysis (ICA).  Unfortunately, many of such measures, like the mutual information, are hard to estimate and optimize directly.  We propose to learn independent features with adversarial objectives (Goodfellow et al. 2014, Arjovsky et al. 2017) which optimize such measures implicitly.  These objectives compare samples from the joint distribution and the product of the marginals without the need to compute any probability densities. We also propose two methods for obtaining samples from the product of the marginals using either a simple resampling trick or a separate parametric distribution.  Our experiments show that this strategy can easily be applied to different types of model architectures and solve both linear and non-linear ICA problems.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial networks, ica, unsupervised, independence</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry0WOxbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=ry0WOxbRZ">
          IVE-GAN: Invariant Encoding Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ry0WOxbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=robin.winter%40bayer.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="robin.winter@bayer.com">Robin Winter</a>, <a href="https://openreview.net/profile?email=djork-arne.clevert%40bayer.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="djork-arne.clevert@bayer.com">Djork-Arnè Clevert</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry0WOxbRZ-details-309" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry0WOxbRZ-details-309"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial networks (GANs) are a powerful framework for generative tasks. However, they are difficult to train and tend to miss modes of the true data generation process. Although GANs can learn a rich representation of the covered modes of the data in their latent space, the framework misses an inverse mapping from data to this latent space. We propose Invariant Encoding Generative Adversarial Networks (IVE-GANs), a novel GAN framework that introduces such a mapping for individual samples from the data by utilizing features in the data which are invariant to certain transformations. Since the model maps individual samples to the latent space, it naturally encourages the generator to cover all modes. We demonstrate the effectiveness of our approach in terms of generative performance and learning rich representations on several datasets including common benchmark image generation tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A noval GAN framework that utilizes transformation-invariant features to learn rich representations and strong generators.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, Unsupervised Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S17mtzbRb">
      <h4>
        <a href="https://openreview.net/forum?id=S17mtzbRb">
          Forced Apart: Discovering Disentangled Representations Without Exhaustive Labels
        </a>
        
          <a href="https://openreview.net/pdf?id=S17mtzbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jgc128%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgc128@outlook.com">Alexey Romanov</a>, <a href="https://openreview.net/profile?email=arum%40cs.uml.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arum@cs.uml.edu">Anna Rumshisky</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S17mtzbRb-details-399" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S17mtzbRb-details-399"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning a better representation with neural networks is a challenging problem, which has been tackled from different perspectives in the past few years. In this work, we focus on learning a representation that would be useful in a clustering task. We introduce two novel loss components that substantially improve the quality of produced clusters, are simple to apply to arbitrary models and cost functions, and do not require a complicated training procedure. We perform an extensive set of experiments, supervised and unsupervised, and evaluate the proposed loss components on two most common types of models, Recurrent Neural Networks and Convolutional Neural Networks, showing that the approach we propose consistently improves the quality of KMeans clustering in terms of mutual information scores and outperforms previously proposed methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel loss component that forces the network to learn a representation that is well-suited for clustering during training for a classification task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">learning representation, clustering, loss</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyYYPdg0-">
      <h4>
        <a href="https://openreview.net/forum?id=SyYYPdg0-">
          Counterfactual Image Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SyYYPdg0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=denizokt%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="denizokt@mit.edu">Deniz Oktay</a>, <a href="https://openreview.net/profile?email=vondrick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vondrick@google.com">Carl Vondrick</a>, <a href="https://openreview.net/profile?email=torralba%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="torralba@mit.edu">Antonio Torralba</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyYYPdg0--details-146" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyYYPdg0--details-146"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We capitalize on the natural compositional structure of images in order to learn object segmentation with weakly labeled images. The intuition behind our approach is that removing objects from images will yield natural images, however removing random patches will yield unnatural images. We leverage this signal to develop a generative model that decomposes an image into layers, and when all layers are combined, it reconstructs the input image. However, when a layer is removed, the model learns to produce a different image that still looks natural to an adversary, which is possible by removing objects. Experiments and visualizations suggest that this model automatically learns object segmentation on images labeled only by scene better than baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Weakly-supervised image segmentation using compositional structure of images and generative models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">computer vision, image segmentation, generative models, adversarial networks, unsupervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJTGkKxAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJTGkKxAZ">
          Learning Generative Models with Locally Disentangled Latent Factors
        </a>
        
          <a href="https://openreview.net/pdf?id=rJTGkKxAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nealb%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nealb@seas.upenn.edu">Brady Neal</a>, <a href="https://openreview.net/profile?email=alex6200%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alex6200@gmail.com">Alex Lamb</a>, <a href="https://openreview.net/profile?email=sherjilozair%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sherjilozair@gmail.com">Sherjil Ozair</a>, <a href="https://openreview.net/profile?email=erroneus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="erroneus@gmail.com">Devon Hjelm</a>, <a href="https://openreview.net/profile?email=aaron.courville%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaron.courville@gmail.com">Aaron Courville</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>, <a href="https://openreview.net/profile?email=imitliagkas%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="imitliagkas@gmail.com">Ioannis Mitliagkas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJTGkKxAZ-details-594" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJTGkKxAZ-details-594"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the most successful techniques in generative models has been decomposing a complicated generation task into a series of simpler generation tasks.  For example, generating an image at a low resolution and then learning to refine that into a high resolution image often improves results substantially.  Here we explore a novel strategy for decomposing generation for complicated objects in which we first generate latent variables which describe a subset of the observed variables, and then map from these latent variables to the observed space.  We show that this allows us to achieve decoupled training of complicated generative models and present both theoretical and experimental results supporting the benefit of such an approach.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Decompose the task of learning a generative model into learning disentangled latent factors for subsets of the data and then learning the joint over those latent factors.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Models, Hierarchical Models, Latent Variable Models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJL6pz-CZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJL6pz-CZ">
          Transfer Learning on Manifolds via Learned Transport Operators
        </a>
        
          <a href="https://openreview.net/pdf?id=rJL6pz-CZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=marissa.connor%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="marissa.connor@gatech.edu">Marissa Connor</a>, <a href="https://openreview.net/profile?email=crozell%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="crozell@gatech.edu">Christopher Rozell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJL6pz-CZ-details-237" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJL6pz-CZ-details-237"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Within-class variation in a high-dimensional dataset can be modeled as being on a low-dimensional manifold due to the constraints of the physical processes producing that variation (e.g., translation, illumination, etc.). We desire a method for learning a representation of the manifolds induced by identity-preserving transformations that can be used to increase robustness, reduce the training burden, and encourage interpretability in machine learning tasks. In particular, what is needed is a representation of the transformation manifold that can robustly capture the shape of the manifold from the input data, generate new points on the manifold, and extend transformations outside of the training domain without significantly increasing the error. Previous work has proposed algorithms to efficiently learn analytic operators (called transport operators) that define the process of transporting one data point on a manifold to another.  The main contribution of this paper is to define two transfer learning methods that use this generative manifold representation to learn natural transformations and incorporate them into new data. The first method uses this representation in a novel randomized approach to transfer learning that employs the learned generative model to map out unseen regions of the data space. These results are shown through demonstrations of transfer learning in a data augmentation task for few-shot image classification. The second method use of transport operators for injecting specific transformations into new data examples which allows for realistic image animation and informed data augmentation.  These results are shown on stylized constructions using the classic swiss roll data structure and in demonstrations of transfer learning in a data augmentation task for few-shot image classification. We also propose the use of transport operators for injecting transformations into new data examples which allows for realistic image animation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learning transport operators on manifolds forms a valuable representation for doing tasks like transfer learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">manifold learning, transfer learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJaDJZ-0W">
      <h4>
        <a href="https://openreview.net/forum?id=HJaDJZ-0W">
          Block-Sparse Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJaDJZ-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sharan%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sharan@baidu.com">Sharan Narang</a>, <a href="https://openreview.net/profile?email=undersandereric%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="undersandereric@baidu.com">Eric Undersander</a>, <a href="https://openreview.net/profile?email=gdiamos%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdiamos@baidu.com">Gregory Diamos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJaDJZ-0W-details-599" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJaDJZ-0W-details-599"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent Neural Networks (RNNs) are used in state-of-the-art models in domains such as speech recognition, machine translation, and language modelling. Sparsity is a technique to reduce compute and memory requirements of deep learning models. Sparse RNNs are easier to deploy on devices and high-end server processors. Even though sparse operations need less compute and memory relative to their dense counterparts, the speed-up observed by using sparse operations is less than expected on different hardware platforms. In order to address this issue, we investigate two different approaches to induce block sparsity in RNNs: pruning blocks of weights in a layer and using group lasso regularization with pruning to create blocks of weights with zeros. Using these techniques, we can create block-sparse RNNs with sparsity ranging from 80% to 90% with a small loss in accuracy. This technique allows us to reduce the model size by roughly 10x. Additionally, we can prune a larger dense network to recover this loss in accuracy while maintaining high block sparsity and reducing the overall parameter count. Our technique works with a variety of block sizes up to 32x32. Block-sparse RNNs eliminate overheads related to data storage and irregular memory accesses while increasing hardware efficiency compared to unstructured sparsity.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show the RNNs can be pruned to induce block sparsity which improves speedup for sparse operations on existing hardware</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Pruning, block sparsity, structured sparsity, Recurrent Neural Networks, Speech Recognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1NGT8xCZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1NGT8xCZ">
          Principled Hybrids of Generative and Discriminative Domain Adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=B1NGT8xCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=han.zhao%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="han.zhao@cs.cmu.edu">Han Zhao</a>, <a href="https://openreview.net/profile?email=zhenyaozhu%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhenyaozhu@baidu.com">Zhenyao Zhu</a>, <a href="https://openreview.net/profile?email=junjieh%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junjieh@cmu.edu">Junjie Hu</a>, <a href="https://openreview.net/profile?email=adamcoates%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adamcoates@baidu.com">Adam Coates</a>, <a href="https://openreview.net/profile?email=ggordon%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ggordon@cs.cmu.edu">Geoff Gordon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1NGT8xCZ-details-851" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1NGT8xCZ-details-851"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a probabilistic framework for domain adaptation that blends both generative and discriminative modeling in a principled way. Under this framework, generative and discriminative models correspond to specific choices of the prior over parameters. This provides us a very general way to interpolate between generative and discriminative extremes through different choices of priors. By maximizing both the marginal and the conditional log-likelihoods, models derived from this framework can use both labeled instances from the source domain as well as unlabeled instances from \emph{both} source and target domains. Under this framework, we show that the popular reconstruction loss of autoencoder corresponds to an upper bound of the negative marginal log-likelihoods of unlabeled instances, where marginal distributions are given by proper kernel density estimations. This provides a way to interpret the empirical success of autoencoders in domain adaptation and semi-supervised learning. We instantiate our framework using neural networks, and build a concrete model,  \emph{DAuto}. Empirically, we demonstrate the effectiveness of DAuto on text, image and speech datasets, showing that it outperforms related competitors when domain adaptation is possible.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">domain adaptation, neural networks, generative models, discriminative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1tC-LT6W">
      <h4>
        <a href="https://openreview.net/forum?id=B1tC-LT6W">
          Trace norm regularization and faster inference for embedded speech recognition RNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=B1tC-LT6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mkliegl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkliegl@gmail.com">Markus Kliegl</a>, <a href="https://openreview.net/profile?email=goyalsiddharth%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goyalsiddharth@baidu.com">Siddharth Goyal</a>, <a href="https://openreview.net/profile?email=zhaokexin01%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaokexin01@baidu.com">Kexin Zhao</a>, <a href="https://openreview.net/profile?email=srinetkavya%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="srinetkavya@baidu.com">Kavya Srinet</a>, <a href="https://openreview.net/profile?email=shoeybim%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shoeybim@gmail.com">Mohammad Shoeybi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1tC-LT6W-details-764" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1tC-LT6W-details-764"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose and evaluate new techniques for compressing and speeding up dense matrix multiplications as found in the fully connected and recurrent layers of neural networks for embedded large vocabulary continuous speech recognition (LVCSR). For compression, we introduce and study a trace norm regularization technique for training low rank factored versions of matrix multiplications. Compared to standard low rank training, we show that our method leads to good accuracy versus number of parameter trade-offs and can be used to speed up training of large models. For speedup, we enable faster inference on ARM processors through new open sourced kernels optimized for small batch sizes, resulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond LVCSR, we expect our techniques and kernels to be more generally applicable to embedded neural networks with large fully connected or recurrent layers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We compress and speed up speech recognition models on embedded devices through a trace norm regularization technique and optimized kernels.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">LVCSR, speech recognition, embedded, low rank factorization, RNN, GRU, trace norm</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkJd_y-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=SkJd_y-Cb">
          Word2net: Deep Representations of Language
        </a>
        
          <a href="https://openreview.net/pdf?id=SkJd_y-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=marirudolph%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marirudolph@gmail.com">Maja Rudolph</a>, <a href="https://openreview.net/profile?email=f.ruiz%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="f.ruiz@columbia.edu">Francisco Ruiz</a>, <a href="https://openreview.net/profile?email=david.blei%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.blei@columbia.edu">David Blei</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkJd_y-Cb-details-433" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkJd_y-Cb-details-433"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Word embeddings extract semantic features of words from large datasets of text.
      Most embedding methods rely on a log-bilinear model to predict the occurrence
      of a word in a context of other words. Here we propose word2net, a method that
      replaces their linear parametrization with neural networks. For each term in the
      vocabulary, word2net posits a neural network that takes the context as input and
      outputs a probability of occurrence. Further, word2net can use the hierarchical
      organization of its word networks to incorporate additional meta-data, such as
      syntactic features, into the embedding model. For example, we show how to share
      parameters across word networks to develop an embedding model that includes
      part-of-speech information. We study word2net with two datasets, a collection
      of Wikipedia articles and a corpus of U.S. Senate speeches. Quantitatively, we
      found that word2net outperforms popular embedding methods on predicting held-
      out words and that sharing parameters based on part of speech further boosts
      performance. Qualitatively, word2net learns interpretable semantic representations
      and, compared to vector-based methods, better incorporates syntactic information.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Word2net is a novel method for learning neural network representations of words that can use syntactic information to learn better semantic features.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural language models, word embeddings, neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyig0zb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=Hyig0zb0Z">
          Gated ConvNets for Letter-Based ASR
        </a>
        
          <a href="https://openreview.net/pdf?id=Hyig0zb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vitaliy888%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitaliy888@fb.com">Vitaliy Liptchinsky</a>, <a href="https://openreview.net/profile?email=gab%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gab@fb.com">Gabriel Synnaeve</a>, <a href="https://openreview.net/profile?email=locronan%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="locronan@fb.com">Ronan Collobert</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hyig0zb0Z-details-668" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyig0zb0Z-details-668"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper we introduce a new speech recognition system, leveraging a simple letter-based ConvNet acoustic model. The acoustic model requires only audio transcription for training -- no alignment annotations, nor any forced alignment step is needed. At inference, our decoder takes only a word list and a language model, and is fed with letter scores from the acoustic model -- no phonetic word lexicon is needed. Key ingredients for the acoustic model are Gated Linear Units and high dropout. We show near state-of-the-art results in word error rate on the LibriSpeech corpus with MFSC features, both on the clean and other configurations.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A letter-based ConvNet acoustic model leads to a simple and competitive speech recognition pipeline.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">automatic speech recognition, letter-based acoustic model, gated convnets</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Ow_e-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=S1Ow_e-Rb">
          How do deep convolutional neural networks learn from raw audio waveforms?
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Ow_e-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ygong1%40nd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ygong1@nd.edu">Yuan Gong</a>, <a href="https://openreview.net/profile?email=cpoellab%40nd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cpoellab@nd.edu">Christian Poellabauer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Ow_e-Rb-details-624" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Ow_e-Rb-details-624"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Prior work on speech and audio processing has demonstrated the ability to obtain excellent performance when learning directly from raw audio waveforms using convolutional neural networks (CNNs). However, the exact inner workings of a CNN remain unclear, which hinders further developments and improvements into this direction. In this paper, we theoretically analyze and explain how deep CNNs learn from raw audio waveforms and identify potential limitations of existing network structures. Based on this analysis, we further propose a new network architecture (called SimpleNet), which offers a very simple but concise structure and high model interpretability. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Convolutional neural networks, Audio processing, Speech processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BybQ7zWCb">
      <h4>
        <a href="https://openreview.net/forum?id=BybQ7zWCb">
          “Style” Transfer for Musical Audio Using Multiple Time-Frequency Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=BybQ7zWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=smb484%40drexel.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="smb484@drexel.edu">Shaun Barry</a>, <a href="https://openreview.net/profile?email=ykim%40drexel.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ykim@drexel.edu">Youngmoo Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BybQ7zWCb-details-957" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BybQ7zWCb-details-957"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural Style Transfer has become a popular technique for
      generating images of distinct artistic styles using convolutional neural networks. This
      recent success in image style transfer has raised the question of
      whether similar methods can be leveraged to alter the “style” of musical
      audio. In this work, we attempt long time-scale high-quality audio transfer
      and texture synthesis in the time-domain that captures harmonic,
      rhythmic, and timbral elements related to musical style, using examples that
      may have different lengths and musical keys. We demonstrate the ability
      to use randomly initialized convolutional neural networks to transfer
      these aspects of musical style from one piece onto another using 3
      different representations of audio: the log-magnitude of the Short Time
      Fourier Transform (STFT), the Mel spectrogram, and the Constant-Q Transform
      spectrogram. We propose using these representations as a way of
      generating and modifying perceptually significant characteristics of
      musical audio content. We demonstrate each representation's
      shortcomings and advantages over others by carefully designing
      neural network structures that complement the nature of musical audio. Finally, we show that the most
      compelling “style” transfer examples make use of an ensemble of these
      representations to help capture the varying desired characteristics of
      audio signals.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present a long time-scale musical audio style transfer algorithm which synthesizes audio in the time-domain, but uses Time-Frequency representations of audio.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Musical audio, neural style transfer, Time-Frequency, Spectrogram</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ60SbW0b">
      <h4>
        <a href="https://openreview.net/forum?id=SJ60SbW0b">
          Modeling Latent Attention Within Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ60SbW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=crgrimm%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="crgrimm@umich.edu">Christopher Grimm</a>, <a href="https://openreview.net/profile?email=dilip_arumugam%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dilip_arumugam@brown.edu">Dilip Arumugam</a>, <a href="https://openreview.net/profile?email=siddharth_karamcheti%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="siddharth_karamcheti@brown.edu">Siddharth Karamcheti</a>, <a href="https://openreview.net/profile?email=david_abel%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="david_abel@brown.edu">David Abel</a>, <a href="https://openreview.net/profile?email=lsw%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsw@brown.edu">Lawson L.S. Wong</a>, <a href="https://openreview.net/profile?email=mlittman%40cs.brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mlittman@cs.brown.edu">Michael L. Littman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ60SbW0b-details-658" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ60SbW0b-details-658"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks are able to solve tasks across a variety of domains and modalities of data. Despite many empirical successes, we lack the ability to clearly understand and interpret the learned mechanisms that contribute to such effective behaviors and more critically, failure modes. In this work, we present a general method for visualizing an arbitrary neural network's inner mechanisms and their power and limitations. Our dataset-centric method produces visualizations of how a trained network attends to components of its inputs. The computed "attention masks" support improved interpretability by highlighting which input attributes are critical in determining output. We demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision and natural language processing. The primary contribution of our approach is an interpretable visualization of attention that provides unique insights into the network's underlying decision-making process irrespective of the data modality.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We develop a technique to visualize attention mechanisms in arbitrary neural networks. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, neural network, attention, attention mechanism, interpretability, visualization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkmoiMbCb">
      <h4>
        <a href="https://openreview.net/forum?id=rkmoiMbCb">
          Tandem Blocks in Deep Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rkmoiMbCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chrishettinger%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrishettinger@gmail.com">Chris Hettinger</a>, <a href="https://openreview.net/profile?email=tkchristensen%40byu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tkchristensen@byu.edu">Tanner Christensen</a>, <a href="https://openreview.net/profile?email=jeffh%40math.byu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeffh@math.byu.edu">Jeff Humpherys</a>, <a href="https://openreview.net/profile?email=jarvis%40math.byu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jarvis@math.byu.edu">Tyler J Jarvis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkmoiMbCb-details-311" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkmoiMbCb-details-311"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Due to the success of residual networks (resnets) and related architectures, shortcut connections have quickly become standard tools for building convolutional neural networks. The explanations in the literature for the apparent effectiveness of shortcuts are varied and often contradictory. We hypothesize that shortcuts work primarily because they act as linear counterparts to nonlinear layers. We test this hypothesis by using several variations on the standard residual block, with different types of linear connections, to build small (100k--1.2M parameter) image classification networks. Our experiments show that other kinds of linear connections can be even more effective than the identity shortcuts. Our results also suggest that the best type of linear connection for a given application may depend on both network width and depth.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We generalize residual blocks to tandem blocks, which use arbitrary linear maps instead of shortcuts, and improve performance over ResNets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">resnet, residual, shortcut, convolutional, linear, skip, highway</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1PWi_lC-">
      <h4>
        <a href="https://openreview.net/forum?id=S1PWi_lC-">
          Multi-task Learning on MNIST Image Datasets
        </a>
        
          <a href="https://openreview.net/pdf?id=S1PWi_lC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=st70712%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="st70712@gmail.com">Po-Chen Hsieh</a>, <a href="https://openreview.net/profile?email=cpchen%40cse.nsysu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="cpchen@cse.nsysu.edu.tw">Chia-Ping Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1PWi_lC--details-855" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1PWi_lC--details-855"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We apply multi-task learning to image classification tasks on MNIST-like datasets. MNIST dataset has been referred to as the {\em drosophila} of machine learning and has been the testbed of many learning theories. The NotMNIST dataset and the FashionMNIST dataset have been created with the MNIST dataset as reference. In this work, we exploit these MNIST-like datasets for multi-task learning. The datasets are pooled together for learning the parameters of joint classification networks. Then the learned parameters are used as the initial parameters to retrain disjoint classification networks. The baseline recognition model are all-convolution neural networks. Without multi-task learning, the recognition accuracies for MNIST, NotMNIST and FashionMNIST are 99.56\%, 97.22\% and 94.32\% respectively. With multi-task learning to pre-train the networks, the recognition accuracies are respectively 99.70\%, 97.46\% and 95.25\%. The results re-affirm that multi-task learning framework, even with data with different genres, does lead to significant improvement.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">multi-task learning works </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-task learning, MNIST, image recognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1p461b0W">
      <h4>
        <a href="https://openreview.net/forum?id=B1p461b0W">
          Deep Learning is Robust to Massive Label Noise
        </a>
        
          <a href="https://openreview.net/pdf?id=B1p461b0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=drolnick%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="drolnick@mit.edu">David Rolnick</a>, <a href="https://openreview.net/profile?email=av443%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="av443@cornell.edu">Andreas Veit</a>, <a href="https://openreview.net/profile?email=sjb344%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjb344@cornell.edu">Serge Belongie</a>, <a href="https://openreview.net/profile?email=shanir%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shanir@csail.mit.edu">Nir Shavit</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1p461b0W-details-961" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1p461b0W-details-961"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">label noise, weakly supervised learning, robustness of neural networks, deep learning, large datasets</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1O0KGC6b">
      <h4>
        <a href="https://openreview.net/forum?id=H1O0KGC6b">
          Post-training for Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=H1O0KGC6b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thomas.moreau%40cmla.ens-cachan.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.moreau@cmla.ens-cachan.fr">Thomas Moreau</a>, <a href="https://openreview.net/profile?email=julien.audiffren%40cmla.ens-cachan.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="julien.audiffren@cmla.ens-cachan.fr">Julien Audiffren</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1O0KGC6b-details-674" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1O0KGC6b-details-674"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the main challenges of deep learning methods is the choice of an appropriate training strategy. In particular, additional steps, such as unsupervised pre-training, have been shown to greatly improve the performances of deep structures. In this article, we propose an extra training step, called post-training, which only optimizes the last layer of the network. We show that this procedure can be analyzed in the context of kernel theory, with the first layers computing an embedding of the data and the last layer a statistical model to solve the task based on this embedding. This step makes sure that the embedding, or representation, of the data is used in the best possible way for the considered task. This idea is then tested on multiple architectures with various data sets, showing that it consistently provides a boost in performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an additional training step, called post-training, which computes optimal weights for the last layer of the network.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1-oTz-Cb">
      <h4>
        <a href="https://openreview.net/forum?id=H1-oTz-Cb">
          Parametrizing filters of a CNN with a GAN
        </a>
        
          <a href="https://openreview.net/pdf?id=H1-oTz-Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yannic.kilcher%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="yannic.kilcher@inf.ethz.ch">Yannic Kilcher</a>, <a href="https://openreview.net/profile?email=gary.becigneul%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="gary.becigneul@inf.ethz.ch">Gary Becigneul</a>, <a href="https://openreview.net/profile?email=thomas.hofmann%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.hofmann@inf.ethz.ch">Thomas Hofmann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1-oTz-Cb-details-583" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1-oTz-Cb-details-583"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">It is commonly agreed that the use of relevant invariances as a good statistical bias is important in machine-learning. However, most approaches that explicitely incorporate invariances into a model architecture only make use of very simple transformations, such as translations and rotations. Hence, there is a need for methods to model and extract richer transformations that capture much higher-level invariances. To that end, we introduce a tool allowing to parametrize the set of filters of a trained convolutional neural network with the latent space of a generative adversarial network. We then show that the method can capture highly non-linear invariances of the data by visualizing their effect in the data space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">invariance, cnn, gan, infogan, transformation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkwrqtlR-">
      <h4>
        <a href="https://openreview.net/forum?id=HkwrqtlR-">
          WHAT ARE GANS USEFUL FOR?
        </a>
        
          <a href="https://openreview.net/pdf?id=HkwrqtlR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=olmos%40tsc.uc3m.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="olmos@tsc.uc3m.es">Pablo M. Olmos</a>, <a href="https://openreview.net/profile?email=bhitaj%40stevens.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bhitaj@stevens.edu">Briland Hitaj</a>, <a href="https://openreview.net/profile?email=pgasti%40nyit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pgasti@nyit.edu">Paolo Gasti</a>, <a href="https://openreview.net/profile?email=gatenies%40stevens.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gatenies@stevens.edu">Giuseppe Ateniese</a>, <a href="https://openreview.net/profile?email=fernando.perezcruz%40sdsc.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="fernando.perezcruz@sdsc.ethz.ch">Fernando Perez-Cruz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkwrqtlR--details-645" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkwrqtlR--details-645"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">GANs have shown how deep neural networks can be used for generative modeling, aiming at achieving the same impact that they brought for discriminative modeling. The first results were impressive, GANs were shown to be able to generate samples in high dimensional structured spaces, like images and text, that were no copies of the training data. But generative and discriminative learning are quite different. Discriminative learning has a clear end, while generative modeling is an intermediate step to understand the data or generate hypothesis. The quality of implicit density estimation is hard to evaluate, because we cannot tell how well a data is represented by the model. How can we certainly say that a generative process is generating natural images with the same distribution as we do? In this paper, we noticed that even though GANs might not be able to generate samples from the underlying distribution (or we cannot tell at least), they are capturing some structure of the data in that high dimensional space. It is therefore needed to address how we can leverage those estimates produced by GANs in the same way we are able to use other generative modeling algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Modeling, Generative Adversarial Networks, Density Estimation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJQPG5lR-">
      <h4>
        <a href="https://openreview.net/forum?id=BJQPG5lR-">
          Avoiding degradation in deep feed-forward networks by phasing out skip-connections
        </a>
        
          <a href="https://openreview.net/pdf?id=BJQPG5lR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=r.monti%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="r.monti@ucl.ac.uk">Ricardo Pio Monti</a>, <a href="https://openreview.net/profile?email=sina%40gatsby.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sina@gatsby.ucl.ac.uk">Sina Tootoonian</a>, <a href="https://openreview.net/profile?email=robin.cao%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="robin.cao@ucl.ac.uk">Robin Cao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJQPG5lR--details-136" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJQPG5lR--details-136"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A widely observed phenomenon in deep learning is the degradation problem: increasing
      the depth of a network leads to a decrease in performance on both test and training data. Novel architectures such as ResNets and Highway networks have addressed this issue by introducing various flavors of skip-connections or gating mechanisms. However, the degradation problem persists in the context of plain feed-forward networks. In this work we propose a simple method to address this issue. The proposed method poses the learning of weights in deep networks as a constrained optimization problem where the presence of skip-connections is penalized by Lagrange multipliers. This allows for skip-connections to be introduced during the early stages of training and subsequently phased out in a principled manner. We demonstrate the benefits of such an approach with experiments on MNIST, fashion-MNIST, CIFAR-10 and CIFAR-100 where the proposed method is shown to greatly decrease the degradation effect (compared to plain networks) and is often competitive with ResNets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Phasing out skip-connections in a principled manner avoids degradation in deep feed-forward networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimization, vanishing gradients, shattered gradients, skip-connections</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1D6ty-A-">
      <h4>
        <a href="https://openreview.net/forum?id=B1D6ty-A-">
          Training Autoencoders by Alternating Minimization
        </a>
        
          <a href="https://openreview.net/pdf?id=B1D6ty-A-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cs14btech11020%40iith.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="cs14btech11020@iith.ac.in">Sneha Kudugunta</a>, <a href="https://openreview.net/profile?email=cs14resch11001%40iith.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="cs14resch11001@iith.ac.in">Adepu Shankar</a>, <a href="https://openreview.net/profile?email=cs13b1028%40iith.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="cs13b1028@iith.ac.in">Surya Chavali</a>, <a href="https://openreview.net/profile?email=vineethnb%40iith.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="vineethnb@iith.ac.in">Vineeth Balasubramanian</a>, <a href="https://openreview.net/profile?email=purushot%40cse.iitk.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="purushot@cse.iitk.ac.in">Purushottam Kar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1D6ty-A--details-430" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1D6ty-A--details-430"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present DANTE, a novel method for training neural networks, in particular autoencoders, using the alternating minimization principle. DANTE provides a distinct perspective in lieu of traditional gradient-based backpropagation techniques commonly used to train deep networks. It utilizes an adaptation of quasi-convex optimization techniques to cast autoencoder training as a bi-quasi-convex optimization problem. We show that for autoencoder configurations with both differentiable (e.g. sigmoid) and non-differentiable (e.g. ReLU) activation functions, we can perform the alternations very effectively. DANTE effortlessly extends to networks with multiple hidden layers and varying network configurations. In experiments on standard datasets, autoencoders trained using the proposed method were found to be very promising when compared to those trained using traditional backpropagation techniques, both in terms of training speed, as well as feature extraction and reconstruction performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We utilize the alternating minimization principle to provide an effective novel technique to train deep autoencoders.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Autoencoders, Alternating Optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyL9u-WA-">
      <h4>
        <a href="https://openreview.net/forum?id=SyL9u-WA-">
          Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization
        </a>
        
          <a href="https://openreview.net/pdf?id=SyL9u-WA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhangjiong724%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangjiong724@utexas.edu">Jiong Zhang</a>, <a href="https://openreview.net/profile?email=leiqi%40ices.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="leiqi@ices.utexas.edu">Qi Lei</a>, <a href="https://openreview.net/profile?email=inderjit%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="inderjit@cs.utexas.edu">Inderjit S. Dhillon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyL9u-WA--details-299" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyL9u-WA--details-299"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Vanishing and exploding gradients are two of the main obstacles in training deep neural networks, especially in capturing long range dependencies in recurrent neural networks (RNNs). In this paper, we present an efficient parametrization of the transition matrix of an RNN that allows us to stabilize the gradients that arise in its training. Specifically, we parameterize the transition matrix by its singular value decomposition (SVD), which allows us to explicitly track and control its singular values. We attain efficiency by using tools that are common in numerical linear algebra, namely Householder reflectors for representing the orthogonal matrices that arise in the SVD. By explicitly controlling the singular values, our proposed svdRNN method allows us to easily solve the exploding gradient problem and we observe that it empirically solves the vanishing gradient issue to a large extent. We note that the SVD parameterization can be used for any rectangular weight matrix, hence it can be easily extended to any deep neural network, such as a multi-layer perceptron. Theoretically, we demonstrate that our parameterization does not lose any expressive power, and show how it potentially makes the optimization process easier. Our extensive  experimental results also demonstrate that the proposed framework converges faster, and has good generalization, especially when the depth is large. 
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">To solve the gradient vanishing/exploding problems, we proprose an efficient parametrization of the transition matrix of RNN that loses no expressive power, converges faster and has good generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Recurrent Neural Network, Vanishing Gradient, Exploding Gradient, Linear Algebra, Householder Reflections</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1twdMCab">
      <h4>
        <a href="https://openreview.net/forum?id=B1twdMCab">
          Dynamic Integration of Background Knowledge in Neural NLU Systems
        </a>
        
          <a href="https://openreview.net/pdf?id=B1twdMCab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dirk.weissenborn%40dfki.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="dirk.weissenborn@dfki.de">Dirk Weissenborn</a>, <a href="https://openreview.net/profile?email=tkocisky%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tkocisky@google.com">Tomas Kocisky</a>, <a href="https://openreview.net/profile?email=cdyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdyer@google.com">Chris Dyer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1twdMCab-details-772" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1twdMCab-details-772"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Common-sense or background knowledge is required to understand natural language, but in most neural natural language understanding (NLU) systems, the requisite background knowledge is indirectly acquired from static corpora. We develop a new reading architecture for the dynamic integration of explicit background knowledge in NLU models. A new task-agnostic reading module provides refined word representations to a task-specific NLU architecture by processing background knowledge in the form of free-text statements, together with the task-specific inputs. Strong performance on the tasks of document question answering (DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness and flexibility of our approach. Analysis shows that our models learn to exploit knowledge selectively and in a semantically appropriate way.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In this paper we present a task-agnostic reading architecture for the dynamic integration of explicit background knowledge in neural NLU models. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural language processing, background knowledge, word embeddings, question answering, natural language inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ19eUg0-">
      <h4>
        <a href="https://openreview.net/forum?id=SJ19eUg0-">
          BLOCK-DIAGONAL HESSIAN-FREE OPTIMIZATION FOR TRAINING NEURAL NETWORKS
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ19eUg0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hzhan23%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hzhan23@syr.edu">Huishuai Zhang</a>, <a href="https://openreview.net/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>, <a href="https://openreview.net/profile?email=james.bradbury%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.bradbury@salesforce.com">James Bradbury</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ19eUg0--details-960" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ19eUg0--details-960"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Second-order methods for neural network optimization have several advantages over methods based on first-order gradient descent, including better scaling to large mini-batch sizes and fewer updates needed for convergence. But they are rarely applied to deep learning in practice because of high computational cost and the need for model-dependent algorithmic variations. We introduce a vari- ant of the Hessian-free method that leverages a block-diagonal approximation of the generalized Gauss-Newton matrix. Our method computes the curvature approximation matrix only for pairs of parameters from the same layer or block of the neural network and performs conjugate gradient updates independently for each block. Experiments on deep autoencoders, deep convolutional networks, and multilayer LSTMs demonstrate better convergence and generalization compared to the original Hessian-free approach and the Adam method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, second-order optimization, hessian free</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1bhRHeA-">
      <h4>
        <a href="https://openreview.net/forum?id=H1bhRHeA-">
          Unbiased scalable softmax optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=H1bhRHeA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ff2316%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ff2316@columbia.edu">Francois Fagan</a>, <a href="https://openreview.net/profile?email=garud%40ieor.columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="garud@ieor.columbia.edu">Garud Iyengar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1bhRHeA--details-386" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1bhRHeA--details-386"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent neural network and language models have begun to rely on softmax distributions with an extremely large number of categories. In this context calculating the softmax normalizing constant is prohibitively expensive. This has spurred a growing literature of efficiently computable but biased estimates of the softmax. In this paper we present the first two unbiased algorithms for maximizing the softmax likelihood whose work per iteration is independent of the number of classes and datapoints (and does not require extra work at the end of each epoch). We compare our unbiased methods' empirical performance to the state-of-the-art on seven real world datasets, where they comprehensively outperform all competitors.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Propose first methods for exactly optimizing the softmax distribution using stochastic gradient with runtime independent on the number of classes or datapoints.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">softmax, optimization, implicit sgd</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyKZyYlRZ">
      <h4>
        <a href="https://openreview.net/forum?id=HyKZyYlRZ">
          Large Scale Multi-Domain Multi-Task Learning with MultiModel
        </a>
        
          <a href="https://openreview.net/pdf?id=HyKZyYlRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lukaszkaiser%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukaszkaiser@google.com">Lukasz Kaiser</a>, <a href="https://openreview.net/profile?email=aidan.n.gomez%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aidan.n.gomez@gmail.com">Aidan N. Gomez</a>, <a href="https://openreview.net/profile?email=noam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="noam@google.com">Noam Shazeer</a>, <a href="https://openreview.net/profile?email=avaswani%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avaswani@google.com">Ashish Vaswani</a>, <a href="https://openreview.net/profile?email=nikip%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikip@google.com">Niki Parmar</a>, <a href="https://openreview.net/profile?email=llion%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="llion@google.com">Llion Jones</a>, <a href="https://openreview.net/profile?email=usz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="usz@google.com">Jakob Uszkoreit</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyKZyYlRZ-details-934" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyKZyYlRZ-details-934"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning yields great results across many fields,
      from speech recognition, image classification, to translation.
      But for each problem, getting a deep model to work well involves
      research into the architecture and a long period of tuning.
      
      We present a single model that yields good results on a number
      of problems spanning multiple domains. In particular, this single model
      is trained concurrently on ImageNet, multiple translation tasks,
      image captioning (COCO dataset), a speech recognition corpus,
      and an English parsing task. 
      
      Our model architecture incorporates building blocks from multiple
      domains. It contains convolutional layers, an attention mechanism,
      and sparsely-gated layers.
      
      Each of these computational blocks is crucial for a subset of
      the tasks we train on. Interestingly, even if a block is not
      crucial for a task, we observe that adding it never hurts performance
      and in most cases improves it on all tasks.
      
      We also show that tasks with less data benefit largely from joint
      training with other tasks, while performance on large tasks degrades
      only slightly if at all.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Large scale multi-task architecture solves ImageNet and translation together and shows transfer learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multi-task learning, transfer learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ4uaX2aW">
      <h4>
        <a href="https://openreview.net/forum?id=rJ4uaX2aW">
          Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ4uaX2aW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bginsburg%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bginsburg@nvidia.com">Boris Ginsburg</a>, <a href="https://openreview.net/profile?email=igitman%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="igitman@andrew.cmu.edu">Igor Gitman</a>, <a href="https://openreview.net/profile?email=youyang%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="youyang@cs.berkeley.edu">Yang You</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ4uaX2aW-details-591" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ4uaX2aW-details-591"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A common way to speed up training of large convolutional networks is to add  computational units. Training is then performed using data-parallel synchronous Stochastic Gradient Descent (SGD) with a mini-batch divided between computational units. With an increase in the number of nodes, the batch size grows. However,  training with a large batch  often results in lower model accuracy. We argue that the current recipe for large batch training (linear learning rate scaling with warm-up) is not general enough and training may diverge. To overcome these optimization difficulties, we propose a new training algorithm based on Layer-wise Adaptive Rate Scaling (LARS). Using LARS, we scaled AlexNet  and ResNet-50 to a batch size of 16K.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new large batch training algorithm  based on Layer-wise Adaptive Rate Scaling (LARS); using LARS, we scaled AlexNet  and ResNet-50 to a batch of 16K.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">large batch, LARS, adaptive rate scaling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJSA_e1AW">
      <h4>
        <a href="https://openreview.net/forum?id=HJSA_e1AW">
          Normalized Direction-preserving Adam
        </a>
        
          <a href="https://openreview.net/pdf?id=HJSA_e1AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zijun.zhang%40ucalgary.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="zijun.zhang@ucalgary.ca">Zijun Zhang</a>, <a href="https://openreview.net/profile?email=linmawhu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="linmawhu@gmail.com">Lin Ma</a>, <a href="https://openreview.net/profile?email=zongpeng%40ucalgary.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="zongpeng@ucalgary.ca">Zongpeng Li</a>, <a href="https://openreview.net/profile?email=cwu%40cs.hku.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="cwu@cs.hku.hk">Chuan Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJSA_e1AW-details-663" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJSA_e1AW-details-663"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Optimization algorithms for training deep models not only affects the convergence rate and stability of the training process, but are also highly related to the generalization performance of trained models. While adaptive algorithms, such as Adam and RMSprop, have shown better optimization performance than stochastic gradient descent (SGD) in many scenarios, they often lead to worse generalization performance than SGD, when used for training deep neural networks (DNNs). In this work, we identify two problems regarding the direction and step size for updating the weight vectors of hidden units, which may degrade the generalization performance of Adam. As a solution, we propose the normalized direction-preserving Adam (ND-Adam) algorithm, which controls the update direction and step size more precisely, and thus bridges the generalization gap between Adam and SGD. Following a similar rationale, we further improve the generalization performance in classification tasks by regularizing the softmax logits. By bridging the gap between SGD and Adam, we also shed some light on why certain optimization algorithms generalize better than others.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A tailored version of Adam for training DNNs, which bridges the generalization gap between Adam and SGD.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">optimization, generalization, Adam, SGD</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SybqeKgA-">
      <h4>
        <a href="https://openreview.net/forum?id=SybqeKgA-">
          On Batch Adaptive Training for Deep Learning: Lower Loss and Larger Step Size
        </a>
        
          <a href="https://openreview.net/pdf?id=SybqeKgA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chenrunyao14%40mails.ucas.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenrunyao14@mails.ucas.ac.cn">Runyao Chen</a>, <a href="https://openreview.net/profile?email=WuKun14%40mails.ucas.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="WuKun14@mails.ucas.ac.cn">Kun Wu</a>, <a href="https://openreview.net/profile?email=luop%40ict.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luop@ict.ac.cn">Ping Luo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SybqeKgA--details-771" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SybqeKgA--details-771"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Mini-batch gradient descent and its variants are commonly used in deep learning. The principle of mini-batch gradient descent is to use noisy gradient calculated on a batch to estimate the real gradient, thus balancing the computation cost per iteration and the uncertainty of noisy gradient. However, its batch size is a fixed hyper-parameter requiring manual setting before training the neural network. Yin et al. (2017) proposed a batch adaptive stochastic gradient descent (BA-SGD) that can dynamically choose a proper batch size as learning proceeds. We extend the BA-SGD to momentum algorithm and evaluate both the BA-SGD and the batch adaptive momentum (BA-Momentum) on two deep learning tasks from natural language processing to image classification. Experiments confirm that batch adaptive methods can achieve a lower loss compared with mini-batch methods after scanning the same epochs of data. Furthermore, our BA-Momentum is more robust against larger step sizes, in that it can dynamically enlarge the batch size to reduce the larger uncertainty brought by larger step sizes. We also identified an interesting phenomenon, batch size boom. The code implementing batch adaptive framework is now open source, applicable to any gradient-based optimization problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We developed a batch adaptive momentum that can achieve lower loss compared with mini-batch methods after scanning same epochs of data, and it is more robust against large step size.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1A5ztj3b">
      <h4>
        <a href="https://openreview.net/forum?id=H1A5ztj3b">
          Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates
        </a>
        
          <a href="https://openreview.net/pdf?id=H1A5ztj3b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=leslie.smith%40nrl.navy.mil" class="profile-link" data-toggle="tooltip" data-placement="top" title="leslie.smith@nrl.navy.mil">Leslie N. Smith</a>, <a href="https://openreview.net/profile?email=ntopin1%40umbc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ntopin1@umbc.edu">Nicholay Topin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1A5ztj3b-details-420" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1A5ztj3b-details-420"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we show a phenomenon, which we named ``super-convergence'', where residual networks can be trained using an order of magnitude fewer iterations than is used with standard training methods.   The existence of super-convergence is relevant to understanding why deep networks generalize well.  One of the key elements of super-convergence is training with cyclical learning rates and a large maximum learning rate.  Furthermore, we present evidence that training with large learning rates improves performance by regularizing the network. In addition, we show that super-convergence provides a  greater boost in performance relative to standard training when the amount of labeled training data is limited.  We also derive a simplification of the Hessian Free optimization method to compute an estimate of the optimal learning rate.  The architectures to replicate this work will be made available upon publication.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Empirical proof of a new phenomenon requires new theoretical insights and is relevent to the active discussions in the literature on SGD and understanding generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, machine learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByJ7obb0b">
      <h4>
        <a href="https://openreview.net/forum?id=ByJ7obb0b">
          Understanding and Exploiting the Low-Rank Structure of Deep Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ByJ7obb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=craig.bakker%40pnnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="craig.bakker@pnnl.gov">Craig Bakker</a>, <a href="https://openreview.net/profile?email=michael.j.henry%40pnnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.j.henry@pnnl.gov">Michael J. Henry</a>, <a href="https://openreview.net/profile?email=nathan.hodas%40pnnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="nathan.hodas@pnnl.gov">Nathan O. Hodas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByJ7obb0b-details-539" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByJ7obb0b-details-539"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Training methods for deep networks are primarily variants on stochastic gradient descent.  Techniques that use (approximate) second-order information are rarely used because of the computational cost and noise associated with those approaches in deep learning contexts.  However, in this paper, we show how feedforward deep networks exhibit a low-rank derivative structure.  This low-rank structure makes it possible to use second-order information without needing approximations and without incurring a significantly greater computational cost than gradient descent.  To demonstrate this capability, we implement Cubic Regularization (CR) on a feedforward deep network with stochastic gradient descent and two of its variants.  There, we use CR to calculate learning rates on a per-iteration basis while training on the MNIST and CIFAR-10 datasets.  CR proved particularly successful in escaping plateau regions of the objective function.  We also found that this approach requires less problem-specific information (e.g. an optimal initial learning rate) than other first-order methods in order to perform well.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that deep learning network derivatives have a low-rank structure, and this structure allows us to use second-order derivative information to calculate learning rates adaptively and in a computationally feasible manner.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Derivative Calculations, Optimization Algorithms</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJg1NTGZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJg1NTGZRZ">
          Bit-Regularized Optimization of Neural Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=HJg1NTGZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mohamed.amer%40sri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohamed.amer@sri.com">Mohamed Amer</a>, <a href="https://openreview.net/profile?email=aswin.raghavan%40sri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aswin.raghavan@sri.com">Aswin Raghavan</a>, <a href="https://openreview.net/profile?email=gwtaylor%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gwtaylor@uoguelph.ca">Graham W. Taylor</a>, <a href="https://openreview.net/profile?email=sek.chai%40sri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sek.chai@sri.com">Sek Chai</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJg1NTGZRZ-details-290" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJg1NTGZRZ-details-290"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a novel regularization strategy for training neural networks which we call ``BitNet''. The parameters of neural networks are usually unconstrained and have a dynamic range dispersed over a real valued range. Our key idea is to control the expressive power of the network by dynamically quantizing the range and set of values that the parameters can take. We formulate this idea using a novel end-to-end approach  that regularizes a typical classification loss function. Our regularizer is inspired by the Minimum Description Length (MDL) principle. For each layer of the network, our approach optimizes a translation and scaling factor along with integer-valued parameters. We empirically compare BitNet to an equivalent unregularized model on the MNIST and CIFAR-10 datasets. We show that BitNet converges faster to a superior quality solution. Additionally, the resulting model is significantly smaller in size due to the use of integer instead of floating-point parameters.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1Kr3TyAb">
      <h4>
        <a href="https://openreview.net/forum?id=r1Kr3TyAb">
          ANALYSIS ON GRADIENT PROPAGATION IN BATCH NORMALIZED RESIDUAL NETWORKS
        </a>
        
          <a href="https://openreview.net/pdf?id=r1Kr3TyAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=abhishekpanigrahi%40iitkgp.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhishekpanigrahi@iitkgp.ac.in">Abhishek Panigrahi</a>, <a href="https://openreview.net/profile?email=yueruche%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yueruche@usc.edu">Yueru Chen</a>, <a href="https://openreview.net/profile?email=cckuo%40sipi.usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cckuo@sipi.usc.edu">C.-C. Jay Kuo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1Kr3TyAb-details-365" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1Kr3TyAb-details-365"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We conduct a mathematical analysis on the Batch normalization (BN) effect on gradient backpropagation in residual network training in this work, which is believed to play a critical role in addressing the gradient vanishing/explosion problem. Specifically, by analyzing the mean and variance behavior of the input and the gradient in the forward and backward passes through the BN and residual branches, respectively, we show that they work together to confine the gradient variance to a certain range across residual blocks in backpropagation. As a result, the gradient vanishing/explosion problem is avoided. Furthermore, we use the same analysis to discuss the tradeoff between depth and width of a residual network and demonstrate that shallower yet wider resnets have stronger learning performance than deeper yet thinner resnets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Batch normalisation maintains gradient variance throughout training, thus stabilizing optimization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Batch normalization, gradient backpropagation, Residual network, wide residual network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJUBryZ0W">
      <h4>
        <a href="https://openreview.net/forum?id=rJUBryZ0W">
          Lifelong Learning by Adjusting Priors
        </a>
        
          <a href="https://openreview.net/pdf?id=rJUBryZ0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ronamit%40campus.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronamit@campus.technion.ac.il">Ron Amit</a>, <a href="https://openreview.net/profile?email=rmeir%40ee.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="rmeir@ee.technion.ac.il">Ron Meir</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJUBryZ0W-details-99" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJUBryZ0W-details-99"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In representational lifelong learning an agent aims to continually learn to solve novel tasks while updating its representation in light of previous tasks. Under the assumption that future tasks are related to previous tasks, representations should be learned in such a way that they capture the common structure across learned tasks, while allowing the learner sufficient flexibility to adapt to novel aspects of a new task. We develop a framework for lifelong learning in deep neural networks that is based on generalization bounds, developed within the PAC-Bayes framework. Learning takes place through the construction of a distribution over networks based on the tasks seen so far, and its utilization for learning a new task. Thus, prior knowledge is incorporated through setting a history-dependent prior for novel tasks. We develop a gradient-based algorithm implementing these ideas, based on minimizing an objective function motivated by generalization bounds, and demonstrate its effectiveness through numerical examples. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We develop a lifelong learning approach to transfer learning based on PAC-Bayes theory, whereby priors are adjusted as new tasks are encountered thereby facilitating the learning of novel tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Lifelong learning, Transfer learning, PAC-Bayes theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkPoRg10b">
      <h4>
        <a href="https://openreview.net/forum?id=SkPoRg10b">
          Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior
        </a>
        
          <a href="https://openreview.net/pdf?id=SkPoRg10b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=charles%40calculationconsulting.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="charles@calculationconsulting.com">Charles H. Martin</a>, <a href="https://openreview.net/profile?email=mmahoney%40stat.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mmahoney@stat.berkeley.edu">Michael W. Mahoney</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkPoRg10b-details-687" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkPoRg10b-details-687"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We describe an approach to understand the peculiar and counterintuitive generalization properties of deep neural networks.  The approach involves going beyond worst-case theoretical capacity control frameworks that have been popular in machine learning in recent years to revisit old ideas in the statistical mechanics of neural networks.  Within this approach, we present a prototypical Very Simple Deep Learning (VSDL) model, whose behavior is controlled by two control parameters, one describing an effective amount of data, or load, on the network (that decreases when noise is added to the input), and one with an effective temperature interpretation (that increases when algorithms are early stopped).  Using this model, we describe how a very simple application of ideas from the statistical mechanics theory of generalization provides a strong qualitative description of recently-observed empirical results regarding the inability of deep neural networks not to overfit training data, discontinuous learning and sharp transitions in the generalization properties of learning algorithms, etc.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByJWeR1AW">
      <h4>
        <a href="https://openreview.net/forum?id=ByJWeR1AW">
          Data augmentation instead of explicit regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=ByJWeR1AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alexhg15%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexhg15@gmail.com">Alex Hernández-García</a>, <a href="https://openreview.net/profile?email=pkoenig%40uos.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="pkoenig@uos.de">Peter König</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByJWeR1AW-details-786" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByJWeR1AW-details-786"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Modern deep artificial neural networks have achieved impressive results through models with very large capacity---compared to the number of training examples---that control overfitting with the help of different forms of regularization. Regularization can be implicit, as is the case of stochastic gradient descent or parameter sharing in convolutional layers, or explicit. Most common explicit regularization techniques, such as dropout and weight decay, reduce the effective capacity of the model and typically require the use of deeper and wider architectures to compensate for the reduced capacity. Although these techniques have been proven successful in terms of results, they seem to waste capacity. In contrast, data augmentation techniques reduce the generalization error by increasing the number of training examples and without reducing the effective capacity. In this paper we systematically analyze the effect of data augmentation on some popular architectures and conclude that data augmentation alone---without any other explicit regularization techniques---can achieve the same performance or higher as regularized models, especially when training with fewer examples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In a deep convolutional neural network trained with sufficient level of data augmentation, optimized by SGD, explicit regularizers (weight decay and dropout) might not provide any additional generalization improvement.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, data augmentation, regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByED-X-0W">
      <h4>
        <a href="https://openreview.net/forum?id=ByED-X-0W">
          Parametric Information Bottleneck to Optimize Stochastic Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ByED-X-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thanhnguyen2792%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thanhnguyen2792@gmail.com">Thanh T. Nguyen</a>, <a href="https://openreview.net/profile?email=jaesik%40unist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaesik@unist.ac.kr">Jaesik Choi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 29 Oct 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByED-X-0W-details-123" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByED-X-0W-details-123"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we present a layer-wise learning of stochastic neural networks (SNNs) in an information-theoretic perspective. In each layer of an SNN, the compression and the relevance are defined to quantify the amount of information that the layer contains about the input space and the target space, respectively. We jointly optimize the compression and the relevance of all parameters in an SNN to better exploit the neural network's representation. Previously, the Information Bottleneck (IB) framework (\cite{Tishby99}) extracts relevant information for a target variable. Here, we propose Parametric Information Bottleneck (PIB) for a neural network by utilizing (only) its model parameters explicitly to approximate the compression and the relevance. We show that, as compared to the maximum likelihood estimate (MLE) principle, PIBs : (i) improve the generalization of neural networks in classification tasks, (ii) push the representation of neural networks closer to the optimal information-theoretical representation in a faster manner.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learning a better neural networks' representation with Information Bottleneck principle</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Information Bottleneck, Deep Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJZiRkZC-">
      <h4>
        <a href="https://openreview.net/forum?id=HJZiRkZC-">
          Byte-Level Recursive Convolutional Auto-Encoder for Text
        </a>
        
          <a href="https://openreview.net/pdf?id=HJZiRkZC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiang%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiang@cs.nyu.edu">Xiang Zhang</a>, <a href="https://openreview.net/profile?email=yann%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yann@cs.nyu.edu">Yann LeCun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJZiRkZC--details-702" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJZiRkZC--details-702"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This article proposes to auto-encode text at byte-level using convolutional networks with a recursive architecture. The motivation is to explore whether it is possible to have scalable and homogeneous text generation at byte-level in a non-sequential fashion through the simple task of auto-encoding. We show that non-sequential text generation from a fixed-length representation is not only possible, but also achieved much better auto-encoding results than recurrent networks. The proposed model is a multi-stage deep convolutional encoder-decoder framework using residual connections, containing up to 160 parameterized layers. Each encoder or decoder contains a shared group of modules that consists of either pooling or upsampling layers, making the network recursive in terms of abstraction levels in representation. Results for 6 large-scale paragraph datasets are reported, in 3 languages including Arabic, Chinese and English. Analyses are conducted to study several properties of the proposed model.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1a37GWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1a37GWCZ">
          UNSUPERVISED SENTENCE EMBEDDING USING DOCUMENT STRUCTURE-BASED CONTEXT
        </a>
        
          <a href="https://openreview.net/pdf?id=H1a37GWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=taesung.lee%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taesung.lee@ibm.com">Taesung Lee</a>, <a href="https://openreview.net/profile?email=young_park%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="young_park@us.ibm.com">Youngja Park</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1a37GWCZ-details-353" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1a37GWCZ-details-353"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a new unsupervised method for learning general-purpose sentence embeddings.
      Unlike existing methods which rely on local contexts, such as words
      inside the sentence or immediately neighboring sentences, our method selects, for
      each target sentence, influential sentences in the entire document based on a document
      structure. We identify a dependency structure of sentences using metadata
      or text styles. Furthermore, we propose a novel out-of-vocabulary word handling
      technique to model many domain-specific terms, which were mostly discarded by
      existing sentence embedding methods. We validate our model on several tasks
      showing 30% precision improvement in coreference resolution in a technical domain,
      and 7.5% accuracy increase in paraphrase detection compared to baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">To train a sentence embedding using technical documents, our approach considers document structure to find broader context and handle out-of-vocabulary words.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distributed representation, sentence embedding, structure, technical documents, sentence embedding, out-of-vocabulary</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk03Yi10Z">
      <h4>
        <a href="https://openreview.net/forum?id=Sk03Yi10Z">
          An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems.
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk03Yi10Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=songyiping%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="songyiping@pku.edu.cn">Yiping Song</a>, <a href="https://openreview.net/profile?email=ruiyan%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruiyan@pku.edu.cn">Rui Yan</a>, <a href="https://openreview.net/profile?email=chengte%40mail.ncku.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="chengte@mail.ncku.edu.tw">Cheng-Te Li</a>, <a href="https://openreview.net/profile?email=nie%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="nie@iro.umontreal.ca">Jian-Yun Nie</a>, <a href="https://openreview.net/profile?email=mzhang_cs%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="mzhang_cs@pku.edu.cn">Ming Zhang</a>, <a href="https://openreview.net/profile?email=zhaody%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaody@pku.edu.cn">Dongyan Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk03Yi10Z-details-209" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk03Yi10Z-details-209"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Human-computer conversation systems have attracted much attention in Natural Language Processing. Conversation systems can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (namely a query) in a large conversational repository and return a reply that best matches the query. Generative approaches synthesize new replies. Both ways have certain advantages but suffer from their own disadvantages. We propose a novel ensemble of retrieval-based and generation-based conversation system. The retrieved candidates, in addition to the original query, are fed to a reply generator via a neural network, so that the model is aware of more information. The generated reply together with the retrieved ones then participates in a re-ranking process to find the final reply to output. Experimental results show that such an ensemble system outperforms each single module by a large margin.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel ensemble of retrieval-based and generation-based for open-domain conversation systems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">conversation systems, retrieval method, generation method</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkaqxm-0b">
      <h4>
        <a href="https://openreview.net/forum?id=rkaqxm-0b">
          Neural Compositional Denotational Semantics for Question Answering
        </a>
        
          <a href="https://openreview.net/pdf?id=rkaqxm-0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nitishg%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nitishg@cis.upenn.edu">Nitish Gupta</a>, <a href="https://openreview.net/profile?email=mikelewis%40facebook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mikelewis@facebook.com">Mike Lewis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkaqxm-0b-details-826" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkaqxm-0b-details-826"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Answering compositional questions requiring multi-step reasoning is challenging for current models. We introduce an end-to-end differentiable model for interpreting questions, which is inspired by formal approaches to semantics. Each span of text is represented by a denotation in a knowledge graph, together with a vector that captures ungrounded aspects of meaning. Learned composition modules recursively combine constituents, culminating in a grounding for the complete sentence which is an answer to the question. For example, to interpret ‘not green’, the model will represent ‘green’ as a set of entities, ‘not’ as a trainable ungrounded vector, and then use this vector to parametrize a composition function to perform a complement operation. For each sentence, we build a parse chart subsuming all possible parses, allowing the model to jointly learn both the composition operators and output structure by gradient descent. We show the model can learn to represent a variety of challenging semantic operators, such as quantifiers, negation, disjunctions and composed relations on a synthetic question answering task. The model also generalizes well to longer sentences than seen in its training data, in contrast to LSTM and RelNet baselines. We will release our code.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe an end-to-end differentiable model for QA that learns to represent spans of text in the question as denotations in knowledge graph, by learning both neural modules for composition and the syntactic structure of the sentence.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">question answering, knowledge graph, compositional model, semantics</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1kNDlbCb">
      <h4>
        <a href="https://openreview.net/forum?id=r1kNDlbCb">
          Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1kNDlbCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=king6101%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="king6101@gmail.com">Yau-Shian Wang</a>, <a href="https://openreview.net/profile?email=tlkagkb93901106%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tlkagkb93901106@gmail.com">Hung-Yi Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1kNDlbCb-details-474" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1kNDlbCb-details-474"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Auto-encoders compress input data into a latent-space representation and reconstruct the original data from the representation. This latent representation is not easily interpreted by humans. In this paper, we propose training an auto-encoder that encodes input text into human-readable sentences. The auto-encoder is composed of a generator and a reconstructor. The generator encodes the input text into a shorter word sequence, and the reconstructor recovers the generator input from the generator output.
      To make the generator output human-readable, a discriminator restricts the output of the generator to resemble human-written sentences. By taking the generator output as the summary of the input text, abstractive summarization is achieved without document-summary pairs as training data. Promising results are shown on both English and Chinese corpora.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, text summarization, adversarial training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy3MvSlRW">
      <h4>
        <a href="https://openreview.net/forum?id=Hy3MvSlRW">
          Adversarial reading networks for machine comprehension
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy3MvSlRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=julien.perez%40naverlabs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="julien.perez@naverlabs.com">Quentin Grail</a>, Julien Perez
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy3MvSlRW-details-212" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy3MvSlRW-details-212"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Machine reading has recently shown remarkable progress thanks to differentiable
      reasoning models. In this context, End-to-End trainable Memory Networks
      (MemN2N) have demonstrated promising performance on simple natural language
      based reasoning tasks such as factual reasoning and basic deduction. However,
      the task of machine comprehension is currently bounded to a supervised setting
      and available question answering dataset. In this paper we explore the paradigm
      of adversarial learning and self-play for the task of machine reading comprehension.
      Inspired by the successful propositions in the domain of game learning, we
      present a novel approach of training for this task that is based on the definition
      of a coupled attention-based memory model. On one hand, a reader network is
      in charge of finding answers regarding a passage of text and a question. On the
      other hand, a narrator network is in charge of obfuscating spans of text in order
      to minimize the probability of success of the reader. We experimented the model
      on several question-answering corpora. The proposed learning paradigm and associated
      models present encouraging results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine reading, adversarial training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1QZ3zbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1QZ3zbAZ">
          Adversarial Examples for Natural Language Classification Problems
        </a>
        
          <a href="https://openreview.net/pdf?id=r1QZ3zbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vol.kuleshov%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vol.kuleshov@gmail.com">Volodymyr Kuleshov</a>, <a href="https://openreview.net/profile?email=shanu.thakoor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shanu.thakoor@gmail.com">Shantanu Thakoor</a>, <a href="https://openreview.net/profile?email=ldf921%40126.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ldf921@126.com">Tingfung Lau</a>, <a href="https://openreview.net/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1QZ3zbAZ-details-478" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1QZ3zbAZ-details-478"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Modern machine learning algorithms are often susceptible to adversarial examples — maliciously crafted inputs that are undetectable by humans but that fool the algorithm into producing undesirable behavior. In this work, we show that adversarial examples exist in natural language classification: we formalize the notion of an adversarial example in this setting and describe algorithms that construct such examples. Adversarial perturbations can be crafted for a wide range of tasks — including spam filtering, fake news detection, and sentiment analysis — and affect different models — convolutional and recurrent neural networks as well as linear classifiers to a lesser degree. Constructing an adversarial example involves replacing 10-30% of words in a sentence with synonyms that don’t change its meaning. Up to 90% of input examples admit adversarial perturbations; furthermore, these perturbations retain a degree of transferability across models. Our findings demonstrate the existence of vulnerabilities in machine learning systems and hint at limitations in our understanding of classification algorithms.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rybDdHe0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rybDdHe0Z">
          Sequence Transfer Learning for Neural Decoding
        </a>
        
          <a href="https://openreview.net/pdf?id=rybDdHe0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=velango%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="velango@eng.ucsd.edu">Venkatesh Elango*</a>, <a href="https://openreview.net/profile?email=anp054%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anp054@eng.ucsd.edu">Aashish N Patel*</a>, <a href="https://openreview.net/profile?email=kai.miller%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kai.miller@stanford.edu">Kai J Miller</a>, <a href="https://openreview.net/profile?email=vgilja%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vgilja@eng.ucsd.edu">Vikash Gilja</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rybDdHe0Z-details-968" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rybDdHe0Z-details-968"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A fundamental challenge in designing brain-computer interfaces (BCIs) is decoding behavior from time-varying neural oscillations. In typical applications, decoders are constructed for individual subjects and with limited data leading to restrictions on the types of models that can be utilized. Currently, the best performing decoders are typically linear models capable of utilizing rigid timing constraints with limited training data. Here we demonstrate the use of Long Short-Term Memory (LSTM) networks to take advantage of the temporal information present in sequential neural data collected from subjects implanted with electrocorticographic (ECoG) electrode arrays performing a finger flexion task. Our constructed models are capable of achieving accuracies that are comparable to existing techniques while also being robust to variation in sample data size. Moreover, we utilize the LSTM networks and an affine transformation layer to construct a novel architecture for transfer learning. We demonstrate that in scenarios where only the affine transform is learned for a new subject, it is possible to achieve results comparable to existing state-of-the-art techniques. The notable advantage is the increased stability of the model during training on novel subjects. Relaxing the constraint of only training the affine transformation, we establish our model as capable of exceeding performance of current models across all training data sizes. Overall, this work demonstrates that LSTMs are a versatile model that can accurately capture temporal patterns in neural data and can provide a foundation for transfer learning in neural decoding.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Transfer Learning, Applications, Neural decoding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ_X8GupW">
      <h4>
        <a href="https://openreview.net/forum?id=HJ_X8GupW">
          Multi-label Learning for Large Text Corpora using Latent Variable Model with Provable Gurantees
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ_X8GupW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sayandg%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sayandg@umich.edu">Sayantan Dasgupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ_X8GupW-details-926" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ_X8GupW-details-926"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Here we study the problem of learning labels for large text corpora where each document can be assigned a variable number of labels. The problem is trivial when the label dimensionality is small and can be easily solved by a series of one-vs-all classifiers. However, as the label dimensionality increases, the parameter space of such one-vs-all classifiers becomes extremely large and outstrips the memory. Here we propose a latent variable model to reduce the size of the parameter space, but still efficiently learn the labels. We learn the model using spectral learning and show how to extract the parameters using only three passes through the training dataset. Further, we analyse the sample complexity of our model using PAC learning theory and then demonstrate the performance of our algorithm on several benchmark datasets in comparison with existing algorithms.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Spectral Method, Multi-label Learning, Tensor Factorisation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1AMITFaW">
      <h4>
        <a href="https://openreview.net/forum?id=r1AMITFaW">
          Dependent Bidirectional RNN with Extended-long Short-term Memory
        </a>
        
          <a href="https://openreview.net/pdf?id=r1AMITFaW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yuanhans%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanhans@usc.edu">Yuanhang Su</a>, <a href="https://openreview.net/profile?email=yuzhongh%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuzhongh@usc.edu">Yuzhong Huang</a>, <a href="https://openreview.net/profile?email=cckuo%40sipi.usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cckuo@sipi.usc.edu">C.-C. Jay Kuo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1AMITFaW-details-296" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1AMITFaW-details-296"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work, we first conduct mathematical analysis on the memory, which is
      defined as a function that maps an element in a sequence to the current output,
      of three RNN cells; namely, the simple recurrent neural network (SRN), the long
      short-term memory (LSTM) and the gated recurrent unit (GRU). Based on the
      analysis, we propose a new design, called the extended-long short-term memory
      (ELSTM), to extend the memory length of a cell. Next, we present a multi-task
      RNN model that is robust to previous erroneous predictions, called the dependent
      bidirectional recurrent neural network (DBRNN), for the sequence-in-sequenceout
      (SISO) problem. Finally, the performance of the DBRNN model with the
      ELSTM cell is demonstrated by experimental results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A recurrent neural network cell with extended-long short-term memory and a multi-task RNN model for sequence-in-sequence-out problems</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNN, memory, LSTM, GRU, BRNN, encoder-decoder, Natural language processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ39YKiTb">
      <h4>
        <a href="https://openreview.net/forum?id=HJ39YKiTb">
          Associative Conversation Model: Generating Visual Information from Textual Information
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ39YKiTb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=g1445539%40cc.kyoto-su.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="g1445539@cc.kyoto-su.ac.jp">Yoichi Ishibashi</a>, <a href="https://openreview.net/profile?email=miya%40cc.kyoto-su.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="miya@cc.kyoto-su.ac.jp">Hisashi Miyamori</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ39YKiTb-details-248" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ39YKiTb-details-248"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose the Associative Conversation Model that generates visual information from textual information and uses it for generating sentences in order to utilize visual information in a dialogue system without image input. In research on Neural Machine Translation, there are studies that generate translated sentences using both images and sentences, and these studies show that visual information improves translation performance. However, it is not possible to use sentence generation algorithms using images for the dialogue systems since many text-based dialogue systems only accept text input. Our approach generates (associates) visual information from input text and generates response text using context vector  fusing associative visual information and sentence textual information. A comparative experiment between our proposed model and a model without association showed that our proposed model is generating useful sentences by associating visual information related to sentences. Furthermore, analysis experiment of visual association showed that our proposed model generates (associates) visual information effective for sentence generation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Proposal of the sentence generation method based on fusion between textual information and visual information associated with the textual information</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">conversation model, multimodal embedding, attention mechanism, natural language processing, encoder-decoder model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HypkN9yRW">
      <h4>
        <a href="https://openreview.net/forum?id=HypkN9yRW">
          DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer
        </a>
        
          <a href="https://openreview.net/pdf?id=HypkN9yRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joseph15%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="joseph15@stanford.edu">Joseph Suarez</a>, <a href="https://openreview.net/profile?email=jcjohns%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jcjohns@cs.stanford.edu">Justin Johnson</a>, <a href="https://openreview.net/profile?email=feifeili%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="feifeili@cs.stanford.edu">Fei-Fei Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HypkN9yRW-details-788" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HypkN9yRW-details-788"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a generic dynamic architecture that employs a problem specific differentiable forking mechanism to leverage discrete logical information about the problem data structure. We adapt and apply our model to CLEVR Visual Question Answering, giving rise to the DDRprog architecture; compared to previous approaches, our model achieves higher accuracy in half as many epochs with five times fewer learnable parameters. Our model directly models underlying question logic using a recurrent controller that jointly predicts and executes functional neural modules; it explicitly forks subprocesses to handle logical branching. While FiLM and other competitive models are static architectures with less supervision, we argue that inclusion of program labels enables learning of higher level logical operations -- our architecture achieves particularly high performance on questions requiring counting and integer comparison. We further demonstrate the generality of our approach though DDRstack -- an application of our method to reverse Polish notation expression evaluation in which the inclusion of a stack assumption allows our approach to generalize to long expressions, significantly outperforming an LSTM with ten times as many learnable parameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A generic dynamic architecture that employs a problem specific differentiable forking mechanism to encode hard data structure assumptions. Applied to CLEVR VQA and expression evaluation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">CLEVR, VQA, Visual Question Answering, Neural Programmer</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1TA9ZbA-">
      <h4>
        <a href="https://openreview.net/forum?id=r1TA9ZbA-">
          Learning to search with MCTSnets
        </a>
        
          <a href="https://openreview.net/pdf?id=r1TA9ZbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aguez%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aguez@google.com">Arthur Guez</a>, <a href="https://openreview.net/profile?email=theophane%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="theophane@google.com">Theophane Weber</a>, <a href="https://openreview.net/profile?email=ioannisa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ioannisa@google.com">Ioannis Antonoglou</a>, <a href="https://openreview.net/profile?email=simonyan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="simonyan@google.com">Karen Simonyan</a>, <a href="https://openreview.net/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>, <a href="https://openreview.net/profile?email=wierstra%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wierstra@google.com">Daan Wierstra</a>, <a href="https://openreview.net/profile?email=munos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="munos@google.com">Remi Munos</a>, <a href="https://openreview.net/profile?email=davidsilver%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidsilver@google.com">David Silver</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1TA9ZbA--details-261" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1TA9ZbA--details-261"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Planning problems are among the most important and well-studied problems in artificial intelligence. They are most typically solved by tree search algorithms that simulate ahead into the future, evaluate future states, and back-up those evaluations to the root of a search tree. Among these algorithms, Monte-Carlo tree search (MCTS) is one of the most general, powerful and widely used. A typical implementation of MCTS uses cleverly designed rules, optimised to the particular characteristics of the domain. These rules control where the simulation traverses, what to evaluate in the states that are reached, and how to back-up those evaluations. In this paper we instead learn where, what and how to search. Our architecture, which we call an MCTSnet, incorporates simulation-based search inside a neural network, by expanding, evaluating and backing-up a vector embedding. The parameters of the network are trained end-to-end using gradient-based optimisation. When applied to small searches in the well-known planning problem Sokoban, the learned search algorithm significantly outperformed MCTS baselines. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Monte-Carlo Tree Search, search, planning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkPrDFgR-">
      <h4>
        <a href="https://openreview.net/forum?id=BkPrDFgR-">
          Piecewise Linear Neural Networks verification: A comparative study
        </a>
        
          <a href="https://openreview.net/pdf?id=BkPrDFgR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rudy%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="rudy@robots.ox.ac.uk">Rudy Bunel</a>, <a href="https://openreview.net/profile?email=ilker.turkaslan%40lmh.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilker.turkaslan@lmh.ox.ac.uk">Ilker Turkaslan</a>, <a href="https://openreview.net/profile?email=philip.torr%40eng.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="philip.torr@eng.ox.ac.uk">Philip H.S. Torr</a>, <a href="https://openreview.net/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>, <a href="https://openreview.net/profile?email=pawan%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="pawan@robots.ox.ac.uk">M. Pawan Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkPrDFgR--details-512" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkPrDFgR--details-512"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The success of Deep Learning and its potential use in many important safety-
      critical applications has motivated research on formal verification of Neural Net-
      work (NN) models. Despite the reputation of learned NN models to behave as
      black boxes and theoretical hardness results of the problem of proving their prop-
      erties, researchers have been successful in verifying some classes of models by
      exploiting their piecewise linear structure. Unfortunately, most of these works
      test their algorithms on their own models and do not offer any comparison with
      other approaches. As a result, the advantages and downsides of the different al-
      gorithms are not well understood. Motivated by the need of accelerating progress
      in this very important area, we investigate the trade-offs of a number of different
      approaches based on Mixed Integer Programming, Satisfiability Modulo Theory,
      as well as a novel method based on the Branch-and-Bound framework. We also
      propose a new data set of benchmarks, in addition to a collection of previously
      released testcases that can be used to compare existing methods. Our analysis not
      only allowed a comparison to be made between different strategies, the compar-
      ision of results from different solvers also revealed implementation bugs in pub-
      lished methods. We expect that the availability of our benchmark and the analysis
      of the different approaches will allow researchers to invent and evaluate promising
      approaches for making progress on this important topic.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Verification, SMT solver, Mixed Integer Programming, Neural Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1nxTzbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1nxTzbRZ">
          Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
        </a>
        
          <a href="https://openreview.net/pdf?id=B1nxTzbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gab%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gab@fb.com">Gabriel Synnaeve</a>, <a href="https://openreview.net/profile?email=zlin%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlin@fb.com">Zeming Lin</a>, <a href="https://openreview.net/profile?email=jgehring%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgehring@fb.com">Jonas Gehring</a>, <a href="https://openreview.net/profile?email=vkhalidov%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkhalidov@fb.com">Vasil Khalidov</a>, <a href="https://openreview.net/profile?email=alcinos%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alcinos@fb.com">Nicolas Carion</a>, <a href="https://openreview.net/profile?email=usunier%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="usunier@fb.com">Nicolas Usunier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1nxTzbRZ-details-931" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1nxTzbRZ-details-931"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper we present a defogger, a model that learns to predict future hidden information from partial observations. We formulate this model in the context of forward modeling and leverage spatial and sequential constraints and correlations via convolutional neural networks and long short-term memory networks, respectively. We evaluate our approach on a large dataset of human games of StarCraft: Brood War, a real-time strategy video game. Our models consistently beat strong rule-based baselines and qualitatively produce sensible future game states.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper presents a defogger, a model that learns to predict future hidden information from partial observations, applied to a StarCraft dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">forward modeling, partially observable, deep learning, strategy game, real-time strategy</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1LAqMbRW">
      <h4>
        <a href="https://openreview.net/forum?id=H1LAqMbRW">
          Latent forward model for Real-time Strategy game planning with incomplete information
        </a>
        
          <a href="https://openreview.net/pdf?id=H1LAqMbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yuandong%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuandong@fb.com">Yuandong Tian</a>, <a href="https://openreview.net/profile?email=qucheng%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qucheng@fb.com">Qucheng Gong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1LAqMbRW-details-589" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1LAqMbRW-details-589"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model-free deep reinforcement learning approaches have shown superhuman performance in simulated environments (e.g., Atari games, Go, etc). During training, these approaches often implicitly construct a latent space that contains key information for decision making. In this paper, we learn a forward model on this latent space and apply it to model-based planning in miniature Real-time Strategy game with incomplete information (MiniRTS). We first show that the latent space constructed from existing actor-critic models contains relevant information of the game, and design training procedure to learn forward models. We also show that our learned forward model can predict meaningful future state and is usable for latent space Monte-Carlo Tree Search (MCTS), in terms of win rates against rule-based agents.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper analyzes the latent space learned by model-free approaches in a miniature incomplete information game, trains a forward model in the latent space and apply it to Monte-Carlo Tree Search, yielding positive performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Real time strategy, latent space, forward model, monte carlo tree search, reinforcement learning, planning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r15kjpHa-">
      <h4>
        <a href="https://openreview.net/forum?id=r15kjpHa-">
          Reward Design in Cooperative Multi-agent Reinforcement Learning for Packet Routing
        </a>
        
          <a href="https://openreview.net/pdf?id=r15kjpHa-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pku.hy.mao%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pku.hy.mao@gmail.com">Hangyu Mao</a>, <a href="https://openreview.net/profile?email=gongzhibo%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gongzhibo@huawei.com">Zhibo Gong</a>, <a href="https://openreview.net/profile?email=gtxaio%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gtxaio@gmail.com">Zhen Xiao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r15kjpHa--details-634" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r15kjpHa--details-634"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In cooperative multi-agent reinforcement learning (MARL), how to design a suitable reward signal to accelerate learning and stabilize convergence is a critical problem. The global reward signal assigns the same global reward to all agents without distinguishing their contributions, while the local reward signal provides different local rewards to each agent based solely on individual behavior. Both of the two reward assignment approaches have some shortcomings: the former might encourage lazy agents, while the latter might produce selfish agents.
      
      In this paper, we study reward design problem in cooperative MARL based on packet routing environments. Firstly, we show that the above two reward signals are prone to produce suboptimal policies. Then, inspired by some observations and considerations, we design some mixed reward signals, which are off-the-shelf to learn better policies. Finally, we turn the mixed reward signals into the adaptive counterparts, which achieve best results in our experiments. Other reward signals are also discussed in this paper. As reward design is a very fundamental problem in RL and especially in MARL, we hope that MARL researchers can rethink the rewards used in their systems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We study reward design problem in cooperative MARL based on packet routing environments. The experimental results remind us to be careful to design the rewards, as they are really important to guide the agent behavior.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reward Design, Cooperative Multi-agent Reinforcement Learning, Packet Routing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJvrXqvaZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJvrXqvaZ">
          Adversary A3C for Robust Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SJvrXqvaZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=guzhaoyuan14%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="guzhaoyuan14@gmail.com">Zhaoyuan Gu</a>, <a href="https://openreview.net/profile?email=zhenzhong.jia%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhenzhong.jia@gmail.com">Zhenzhong Jia</a>, <a href="https://openreview.net/profile?email=choset%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="choset@cs.cmu.edu">Howie Choset</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJvrXqvaZ-details-10" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJvrXqvaZ-details-10"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Asynchronous Advantage Actor Critic (A3C) is an effective Reinforcement Learning (RL) algorithm for a wide range of tasks, such as Atari games and robot control. The agent learns policies and value function through trial-and-error interactions with the environment until converging to an optimal policy. Robustness and stability are critical in RL; however, neural network can be vulnerable to noise from unexpected sources and is not likely to withstand very slight disturbances. We note that agents generated from mild environment using A3C are not able to handle challenging environments. Learning from adversarial examples, we proposed an algorithm called Adversary Robust A3C (AR-A3C) to improve the agent’s performance under noisy environments. In this algorithm, an adversarial agent is introduced to the learning process to make it more robust against adversarial disturbances, thereby making it more adaptive to noisy environments. Both simulations and real-world experiments are carried out to illustrate the stability of the proposed algorithm. The AR-A3C algorithm outperforms A3C in both clean and noisy environments. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversary, Robust, Reinforcement Learning, A3C</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJIN_4lA-">
      <h4>
        <a href="https://openreview.net/forum?id=rJIN_4lA-">
          Maintaining cooperation in complex social dilemmas using deep reinforcement learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rJIN_4lA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alex.peys%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alex.peys@gmail.com">Alexander Peysakhovich</a>, <a href="https://openreview.net/profile?email=alerer%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alerer@fb.com">Adam Lerer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJIN_4lA--details-166" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJIN_4lA--details-166"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Social dilemmas are situations where individuals face a temptation to increase their payoffs at a cost to total welfare. Building artificially intelligent agents that achieve good outcomes in these situations is important because many real world interactions include a tension between selfish interests and the welfare of others. We show how to modify modern reinforcement learning methods to construct agents that act in ways that are simple to understand, nice (begin by cooperating), provokable (try to avoid being exploited), and forgiving (try to return to mutual cooperation). We show both theoretically and experimentally that such agents can maintain cooperation in Markov social dilemmas. Our construction does not require training methods beyond a modification of self-play, thus if an environment is such that good strategies can be constructed in the zero-sum case (eg. Atari) then we can construct agents that solve social dilemmas in this environment. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">How can we build artificial agents that solve social dilemmas (situations where individuals face a temptation to increase their payoffs at a cost to total welfare)?</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, cooperation, social dilemmas, game theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1EGg7ZCb">
      <h4>
        <a href="https://openreview.net/forum?id=B1EGg7ZCb">
          Autonomous Vehicle Fleet Coordination With Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B1EGg7ZCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cane.cane%40live.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cane.cane@live.com">Cane Punma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1EGg7ZCb-details-296" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1EGg7ZCb-details-296"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Autonomous vehicles are becoming more common in city transportation.  Companies will begin to find a need to teach these vehicles smart city fleet coordination.  Currently, simulation based modeling along with hand coded rules dictate the decision making of these autonomous vehicles. We believe that complex intelligent behavior can be learned by these agents through Reinforcement Learning.In this paper, we discuss our work for solving this system by adapting the Deep Q-Learning (DQN) model to the multi-agent setting.  Our approach applies deep reinforcement learning by combining convolutional neural networks with DQN to teach agents to fulfill customer demand in an environment that is partially observ-able to them. We also demonstrate how to utilize transfer learning to teach agents to balance multiple objectives such as navigating to a charging station when its en-ergy level is low. The two evaluations presented show that our solution has shown  hat we are successfully able to teach agents cooperation policies while balancing multiple objectives.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Utilized Deep Reinforcement Learning to teach agents ride-sharing fleet style coordination.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning, mult-agent systems</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rye7IMbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rye7IMbAZ">
           Explicit Induction Bias for Transfer Learning with Convolutional Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rye7IMbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xuhong.li%40utc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuhong.li@utc.fr">Xuhong LI</a>, <a href="https://openreview.net/profile?email=yves.grandvalet%40utc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="yves.grandvalet@utc.fr">Yves GRANDVALET</a>, <a href="https://openreview.net/profile?email=franck.davoine%40utc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="franck.davoine@utc.fr">Franck DAVOINE</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rye7IMbAZ-details-317" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rye7IMbAZ-details-317"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch.
      When using fine-tuning, the underlying assumption is that the pre-trained model extracts generic features, which are at least partially relevant for solving the target task, but would be difficult to extract from the limited amount of data available on the target task.
      However, besides the initialization with the pre-trained model and the early stopping, there is no mechanism in fine-tuning for retaining the features learned on the source task.
      In this paper, we investigate several regularization schemes that explicitly promote the similarity of the final solution with the initial model.
      We eventually recommend a simple $L^2$ penalty using the pre-trained model as a reference, and we show that this approach behaves much better than the standard scheme using weight decay on a partially frozen network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">transfer Learning, convolutional networks, fine-tuning, regularization, induction bias</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkZzY-lCb">
      <h4>
        <a href="https://openreview.net/forum?id=rkZzY-lCb">
          Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features
        </a>
        
          <a href="https://openreview.net/pdf?id=rkZzY-lCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=luisarmona%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="luisarmona@gmail.com">Luis Armona</a>, <a href="https://openreview.net/profile?email=jgonzalez%40chegg.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgonzalez@chegg.com">José P. González-Brenes</a>, <a href="https://openreview.net/profile?email=ralph.angelus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ralph.angelus@gmail.com">Ralph Edezhath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkZzY-lCb-details-100" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkZzY-lCb-details-100"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Methods that calculate dense vector representations for features in unstructured data—such as words in a document—have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start
      problem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, supervised learning, knowledge representation, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H18uzzWAZ">
      <h4>
        <a href="https://openreview.net/forum?id=H18uzzWAZ">
          Correcting Nuisance Variation using Wasserstein Distance
        </a>
        
          <a href="https://openreview.net/pdf?id=H18uzzWAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tabak.gil%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tabak.gil@gmail.com">Gil Tabak</a>, <a href="https://openreview.net/profile?email=mjfan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjfan@google.com">Minjie Fan</a>, <a href="https://openreview.net/profile?email=samuely%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="samuely@google.com">Samuel J. Yang</a>, <a href="https://openreview.net/profile?email=shoyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shoyer@google.com">Stephan Hoyer</a>, <a href="https://openreview.net/profile?email=geoffd%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="geoffd@google.com">Geoff Davis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H18uzzWAZ-details-23" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H18uzzWAZ-details-23"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Profiling cellular phenotypes from microscopic imaging can provide meaningful biological information resulting from various factors affecting the cells. One motivating application is drug development: morphological cell features can be captured from images, from which similarities between different drugs applied at different dosages can be quantified. The general approach is to find a function mapping the images to an embedding space of manageable dimensionality whose geometry captures relevant features of the input images. An important known issue for such methods is separating relevant biological signal from nuisance variation. For example, the embedding vectors tend to be more correlated for cells that were cultured and imaged during the same week than for cells from a different week, despite having identical drug compounds applied in both cases. In this case, the particular batch a set of experiments were conducted in constitutes the domain of the data; an ideal set of image embeddings should contain only the relevant biological information (e.g. drug effects). We develop a general framework for adjusting the image embeddings in order to `forget' domain-specific information while preserving relevant biological information. To do this, we minimize a loss function based on distances between marginal distributions (such as the Wasserstein distance) of embeddings across domains for each replicated treatment. For the dataset presented, the replicated treatment is the negative control. We find that for our transformed embeddings (1) the underlying geometric structure is not only preserved but the embeddings also carry improved biological signal (2) less domain-specific information is present.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We correct nuisance variation for image embeddings across different domains, preserving only relevant information.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Nuisance variation, transform learning, image embeddings</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJvVbCJCb">
      <h4>
        <a href="https://openreview.net/forum?id=BJvVbCJCb">
          Neural Clustering By Predicting And Copying Noise
        </a>
        
          <a href="https://openreview.net/pdf?id=BJvVbCJCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sam%40digitalgenius.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sam@digitalgenius.com">Sam Coope</a>, <a href="https://openreview.net/profile?email=andrej%40digitalgenius.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrej@digitalgenius.com">Andrej Zukov-Gregoric</a>, <a href="https://openreview.net/profile?email=yoram%40digitalgenius.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoram@digitalgenius.com">Yoram Bachrach</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJvVbCJCb-details-338" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJvVbCJCb-details-338"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a neural clustering model that jointly learns both latent features and how they cluster. Unlike similar methods our model does not require a predefined number of clusters. Using a supervised approach, we agglomerate latent features towards randomly sampled targets within the same space whilst progressively removing the targets until we are left with only targets which represent cluster centroids. To show the behavior of our model across different modalities we apply our model on both text and image data and very competitive results on MNIST. Finally, we also provide results against baseline models for fashion-MNIST, the 20 newsgroups dataset, and a Twitter dataset we ourselves create.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Neural clustering without needing a number of clusters</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, clustering, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S191YzbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=S191YzbRZ">
          Prototype Matching Networks for Large-Scale Multi-label  Genomic Sequence Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=S191YzbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jjl5sw%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjl5sw@virginia.edu">Jack Lanchantin</a>, <a href="https://openreview.net/profile?email=as5cu%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="as5cu@virginia.edu">Arshdeep Sekhon</a>, <a href="https://openreview.net/profile?email=rs3zz%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rs3zz@virginia.edu">Ritambhara Singh</a>, <a href="https://openreview.net/profile?email=yq2h%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yq2h@virginia.edu">Yanjun Qi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S191YzbRZ-details-759" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S191YzbRZ-details-759"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One of the fundamental tasks in understanding genomics is the problem of predicting Transcription Factor Binding Sites (TFBSs). With more than hundreds of Transcription Factors (TFs) as labels, genomic-sequence based TFBS prediction is a challenging multi-label classification task. There are two major biological mechanisms for TF binding: (1) sequence-specific binding patterns on genomes known as “motifs” and (2) interactions among TFs known as co-binding effects. In this paper, we propose a novel deep architecture, the Prototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN model automatically extracts prototypes (“motif”-like features) for each TF through a novel prototype-matching loss. Borrowing ideas from few-shot matching models, we use the notion of support set of prototypes and an LSTM to learn how TFs interact and bind to genomic sequences. On a reference TFBS dataset with 2.1 million genomic sequences, PMN significantly outperforms baselines and validates our design choices empirically. To our knowledge, this is the first deep learning architecture that introduces prototype learning and considers TF-TF interactions for large scale TFBS prediction. Not only is the proposed architecture accurate, but it also models the underlying biology.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We combine the matching network framework for few shot learning into a large scale multi-label model for genomic sequence classification.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">bioinformatics, multi-label classification, matching networks, prototypes, memory networks, attention</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJzmJEq6W">
      <h4>
        <a href="https://openreview.net/forum?id=SJzmJEq6W">
          Learning non-linear transform with discriminative and minimum information loss priors
        </a>
        
          <a href="https://openreview.net/pdf?id=SJzmJEq6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dimche.kostadinov%40unige.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimche.kostadinov@unige.ch">Dimche Kostadinov</a>, <a href="https://openreview.net/profile?email=svolos%40unige.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="svolos@unige.ch">Slava Voloshynovskiy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJzmJEq6W-details-707" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJzmJEq6W-details-707"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper proposes a novel approach for learning discriminative and sparse representations. It consists of utilizing two different models. A predefined number of non-linear transform models are used in the learning stage, and one sparsifying transform model is used at test time. The non-linear transform models have discriminative and minimum information loss priors. A novel measure related to the discriminative prior is proposed and defined on the support intersection for the transform representations. The minimum information loss prior is expressed as a constraint on the conditioning and the expected coherence of the transform matrix. An equivalence between the non-linear models and the sparsifying model is shown only when the measure that is used to define the discriminative prior goes to zero. An approximation of the measure used in the discriminative prior is addressed, connecting it to a similarity concentration. To quantify the discriminative properties of the transform representation, we introduce another measure and present its bounds. Reflecting the discriminative quality of the transform representation we name it as discrimination power. 
      
      To support and validate the theoretical analysis a practical learning algorithm is presented. We evaluate the advantages and the potential of the proposed algorithm by a computer simulation. A favorable performance is shown considering the execution time, the quality of the representation, measured by the discrimination power and the recognition accuracy in comparison with the state-of-the-art methods of the same category.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">transform learning, sparse representation, discrimininative prior, information preservation, discrimination power</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1tJKuyRZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1tJKuyRZ">
          The Set Autoencoder: Unsupervised Representation Learning for Sets
        </a>
        
          <a href="https://openreview.net/pdf?id=r1tJKuyRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=malte.probst%40honda-ri.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="malte.probst@honda-ri.de">Malte Probst</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1tJKuyRZ-details-988" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1tJKuyRZ-details-988"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose the set autoencoder, a model for unsupervised representation learning for sets of elements. It is closely related to sequence-to-sequence models, which learn fixed-sized latent representations for sequences, and have been applied to a number of challenging supervised sequence tasks such as machine translation, as well as unsupervised representation learning for sequences.
      In contrast to sequences, sets are permutation invariant. The proposed set autoencoder considers this fact, both with respect to the input as well as the output of the model. On the input side, we adapt a recently-introduced recurrent neural architecture using a content-based attention mechanism. On the output side, we use a stable marriage algorithm to align predictions to labels in the learning phase.
      We train the model on synthetic data sets of point clouds and show that the learned representations change smoothly with translations in the inputs, preserve distances in the inputs, and that the set size is represented directly. We apply the model to supervised tasks on the point clouds using the fixed-size latent representation. For a number of difficult classification problems, the results are better than those of a model that does not consider the permutation invariance. Especially for small training sets, the set-aware model benefits from unsupervised pretraining.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose the set autoencoder, a model for unsupervised representation learning for sets of elements.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">set, unsupervised learning, representation learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1EVwkqTW">
      <h4>
        <a href="https://openreview.net/forum?id=B1EVwkqTW">
          Make SVM great again with Siamese kernel for  few-shot learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B1EVwkqTW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bence.tilk%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bence.tilk@gmail.com">Bence Tilk</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1EVwkqTW-details-102" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1EVwkqTW-details-102"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While deep neural networks have shown outstanding results in a wide range of applications,
      learning from a very limited number of examples is still a challenging
      task. Despite the difficulties of the few-shot learning, metric-learning techniques
      showed the potential of the neural networks for this task. While these methods
      perform well, they don’t provide satisfactory results. In this work, the idea of
      metric-learning is extended with Support Vector Machines (SVM) working mechanism,
      which is well known for generalization capabilities on a small dataset.
      Furthermore, this paper presents an end-to-end learning framework for training
      adaptive kernel SVMs, which eliminates the problem of choosing a correct kernel
      and good features for SVMs. Next, the one-shot learning problem is redefined
      for audio signals. Then the model was tested on vision task (using Omniglot
      dataset) and speech task (using TIMIT dataset) as well. Actually, the algorithm
      using Omniglot dataset improved accuracy from 98.1% to 98.5% on the one-shot
      classification task and from 98.9% to 99.3% on the few-shot classification task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The proposed method is an end-to-end neural SVM, which is optimized for few-shot learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">SVM, siamese network, one-shot learning, few-shot learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkVf1AeAZ">
      <h4>
        <a href="https://openreview.net/forum?id=BkVf1AeAZ">
          Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BkVf1AeAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xusun%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xusun@pku.edu.cn">Xu Sun</a>, <a href="https://openreview.net/profile?email=weibz%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="weibz@pku.edu.cn">Bingzhen Wei</a>, <a href="https://openreview.net/profile?email=renxc%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="renxc@pku.edu.cn">Xuancheng Ren</a>, <a href="https://openreview.net/profile?email=shumingma%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="shumingma@pku.edu.cn">Shuming Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkVf1AeAZ-details-947" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkVf1AeAZ-details-947"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learning Label Representation for Deep Networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">label embedding, deep learning, label representation, computer vision, natural language processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJsk5-Z0W">
      <h4>
        <a href="https://openreview.net/forum?id=HJsk5-Z0W">
          Structured Deep Factorization Machine: Towards General-Purpose Architectures
        </a>
        
          <a href="https://openreview.net/pdf?id=HJsk5-Z0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jgonzalez%40chegg.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgonzalez@chegg.com">José P. González-Brenes</a>, <a href="https://openreview.net/profile?email=redezhath%40chegg.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="redezhath@chegg.com">Ralph Edezhath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJsk5-Z0W-details-564" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJsk5-Z0W-details-564"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In spite of their great success, traditional factorization algorithms typically do not support features (e.g., Matrix Factorization), or their complexity scales quadratically with the number of features (e.g, Factorization Machine). On the other hand, neural methods allow large feature sets, but are often designed for a specific application. We propose novel deep factorization methods that allow efficient and flexible feature representation. For example, we enable describing items with natural language with complexity linear to the vocabulary size—this enables prediction for unseen items and avoids the cold start problem. We show that our architecture can generalize some previously published single-purpose neural architectures. Our experiments suggest improved training times and accuracy compared to shallow methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Scalable general-purpose factorization algorithm-- also helps to circumvent cold start problem.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">factorization, general-purpose methods</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyGT_6yCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyGT_6yCZ">
          Simple Fast Convolutional Feature Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SyGT_6yCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dlm%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlm@cin.ufpe.br">David Macêdo</a>, <a href="https://openreview.net/profile?email=cz%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="cz@cin.ufpe.br">Cleber Zanchettin</a>, <a href="https://openreview.net/profile?email=tbl%40cin.ufpe.br" class="profile-link" data-toggle="tooltip" data-placement="top" title="tbl@cin.ufpe.br">Teresa Ludermir</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyGT_6yCZ-details-929" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyGT_6yCZ-details-929"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simple fast method for extracting visual features from convolutional neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Feature Learning, Convolutional Neural Networks, Visual Recognition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1cLblgCZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1cLblgCZ">
          Recurrent Auto-Encoder Model for Multidimensional Time Series Representation
        </a>
        
          <a href="https://openreview.net/pdf?id=r1cLblgCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=timothy.wong%40centrica.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="timothy.wong@centrica.com">Timothy Wong</a>, <a href="https://openreview.net/profile?email=zhiyuan.luo%40cs.rhul.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhiyuan.luo@cs.rhul.ac.uk">Zhiyuan Luo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1cLblgCZ-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1cLblgCZ-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent auto-encoder model can summarise sequential data through an encoder structure into a fixed-length vector and then reconstruct into its original sequential form through the decoder structure. The summarised information can be used to represent time series features. In this paper, we propose relaxing the dimensionality of the decoder output so that it performs partial reconstruction. The fixed-length vector can therefore represent features only in the selected dimensions. In addition, we propose using rolling fixed window approach to generate samples. The change of time series features over time can be summarised as a smooth trajectory path. The fixed-length vectors are further analysed through additional visualisation and unsupervised clustering techniques. 
      
      This proposed method can be applied in large-scale industrial processes for sensors signal analysis purpose where clusters of the vector representations can be used to reflect the operating states of selected aspects of the industrial system.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using recurrent auto-encoder model to extract multidimensional time series features</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent autoencoder, seq2seq, rnn, multidimensional time series, clustering, sensor, signal analysis, industrial application</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1uP7ebAW">
      <h4>
        <a href="https://openreview.net/forum?id=H1uP7ebAW">
          Learning to diagnose from scratch by exploiting dependencies among labels
        </a>
        
          <a href="https://openreview.net/pdf?id=H1uP7ebAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=li%40enlitic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="li@enlitic.com">Li Yao</a>, <a href="https://openreview.net/profile?email=eric%40enlitic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eric@enlitic.com">Eric Poblenz</a>, <a href="https://openreview.net/profile?email=dmitry%40enlitic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmitry@enlitic.com">Dmitry Dagunts</a>, <a href="https://openreview.net/profile?email=ben%40enlitic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ben@enlitic.com">Ben Covington</a>, <a href="https://openreview.net/profile?email=devon%40entlic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="devon@entlic.com">Devon Bernard</a>, <a href="https://openreview.net/profile?email=kevin%40enlitic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevin@enlitic.com">Kevin Lyman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1uP7ebAW-details-862" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1uP7ebAW-details-862"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">we present the state-of-the-art results of using neural networks to diagnose chest x-rays</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">medical diagnosis, medical imaging, multi-label classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryserbZR-">
      <h4>
        <a href="https://openreview.net/forum?id=ryserbZR-">
          Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach
        </a>
        
          <a href="https://openreview.net/pdf?id=ryserbZR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pierre.courtiol%40owkin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pierre.courtiol@owkin.com">Pierre Courtiol</a>, <a href="https://openreview.net/profile?email=eric.tramel%40owkin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eric.tramel@owkin.com">Eric W. Tramel</a>, <a href="https://openreview.net/profile?email=marc.sanselme%40owkin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marc.sanselme@owkin.com">Marc Sanselme</a>, <a href="https://openreview.net/profile?email=gilles.wainrib%40owkin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gilles.wainrib@owkin.com">Gilles Wainrib</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryserbZR--details-783" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryserbZR--details-783"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Weakly Supervised Learning, Medical Imaging, Histopathology, Deep Feature Extraction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk1FQA0pW">
      <h4>
        <a href="https://openreview.net/forum?id=rk1FQA0pW">
          End-to-End Abnormality Detection in Medical Imaging
        </a>
        
          <a href="https://openreview.net/pdf?id=rk1FQA0pW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dwu6%40mgh.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dwu6@mgh.harvard.edu">Dufan Wu</a>, <a href="https://openreview.net/profile?email=kkim24%40mgh.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kkim24@mgh.harvard.edu">Kyungsang Kim</a>, <a href="https://openreview.net/profile?email=dongbin%40math.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dongbin@math.pku.edu.cn">Bin Dong</a>, <a href="https://openreview.net/profile?email=li.quanzheng%40mgh.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="li.quanzheng@mgh.harvard.edu">Quanzheng Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk1FQA0pW-details-237" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk1FQA0pW-details-237"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks (DNN) have shown promising performance in computer vision. In medical imaging, encouraging results have been achieved with deep learning for applications such as segmentation, lesion detection and classification. Nearly all of the deep learning based image analysis methods work on reconstructed images, which are obtained from original acquisitions via solving inverse problems (reconstruction). The reconstruction algorithms are designed for human observers, but not necessarily optimized for DNNs which can often observe features that are incomprehensible for human eyes. Hence, it is desirable to train the DNNs directly from the original data which lie in a different domain with the images. In this paper, we proposed an end-to-end DNN for abnormality detection in medical imaging. To align the acquisition with the annotations made by radiologists in the image domain, a DNN was built as the unrolled version of iterative reconstruction algorithms to map the acquisitions to images, and followed by a 3D convolutional neural network (CNN) to detect the abnormality in the reconstructed images. The two networks were trained jointly in order to optimize the entire DNN for the detection task from the original acquisitions. The DNN was implemented for lung nodule detection in low-dose chest computed tomography (CT), where a numerical simulation was done to generate acquisitions from 1,018 chest CT images with radiologists' annotations. The proposed end-to-end DNN demonstrated better sensitivity and accuracy for the task compared to a two-step approach, in which the reconstruction and detection DNNs were trained separately. A significant reduction of false positive rate on suspicious lesions were observed, which is crucial for the known over-diagnosis in low-dose lung CT imaging. The images reconstructed by the proposed end-to-end network also presented enhanced details in the region of interest. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Detection of lung nodule starting from projection data rather than images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">End-to-End training, deep neural networks, medical imaging, image reconstruction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkJ1rgbCb">
      <h4>
        <a href="https://openreview.net/forum?id=HkJ1rgbCb">
          Using Deep Reinforcement Learning to Generate Rationales for Molecules
        </a>
        
          <a href="https://openreview.net/pdf?id=HkJ1rgbCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bensonc%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bensonc@mit.edu">Benson Chen</a>, <a href="https://openreview.net/profile?email=ccoley%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ccoley@mit.edu">Connor Coley</a>, <a href="https://openreview.net/profile?email=regina%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="regina@csail.mit.edu">Regina Barzilay</a>, <a href="https://openreview.net/profile?email=tommi%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tommi@csail.mit.edu">Tommi Jaakkola</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkJ1rgbCb-details-263" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkJ1rgbCb-details-263"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning algorithms are increasingly used in modeling chemical processes. However, black box predictions without rationales have limited used in practical applications, such as drug design. To this end, we learn to identify molecular substructures -- rationales -- that are associated with the target chemical property (e.g., toxicity). The rationales are learned in an unsupervised fashion, requiring no additional information beyond the end-to-end task. We formulate this problem as a reinforcement learning problem over the molecular graph, parametrized by two convolution networks corresponding to the rationale selection and prediction based on it, where the latter induces the reward function. We evaluate the approach on two benchmark toxicity datasets. We demonstrate that our model sustains high performance under the additional constraint that predictions strictly follow the rationales. Additionally, we validate the extracted rationales through comparison against those described in chemical literature and through synthetic experiments. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use a reinforcement learning over molecular graphs to generate rationales for interpretable molecular property prediction.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Chemistry, Interpretable Models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HytSvlWRZ">
      <h4>
        <a href="https://openreview.net/forum?id=HytSvlWRZ">
          Subspace Network: Deep Multi-Task Censored Regression for Modeling Neurodegenerative Diseases
        </a>
        
          <a href="https://openreview.net/pdf?id=HytSvlWRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sunmeng2%40msu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sunmeng2@msu.edu">Mengying Sun</a>, <a href="https://openreview.net/profile?email=baytasin%40msu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baytasin@msu.edu">Inci M. Baytas</a>, <a href="https://openreview.net/profile?email=atlaswang%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="atlaswang@tamu.edu">Zhangyang Wang</a>, <a href="https://openreview.net/profile?email=jiayuz%40msu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiayuz@msu.edu">Jiayu Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HytSvlWRZ-details-813" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HytSvlWRZ-details-813"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Over the past decade a wide spectrum of machine learning models have been developed to model the neurodegenerative diseases, associating biomarkers, especially non-intrusive neuroimaging markers, with key clinical scores measuring the cognitive status of patients. Multi-task learning (MTL) has been extensively explored in these studies to address challenges associated to high dimensionality and small cohort size. However, most existing MTL approaches are based on linear models and suffer from two major limitations: 1) they cannot explicitly consider upper/lower bounds in these clinical scores; 2) they lack the capability to capture complicated non-linear effects among the variables. In this paper, we propose the Subspace Network, an efficient deep modeling approach for non-linear multi-task censored regression. Each layer of the subspace network performs a multi-task censored regression to improve upon the predictions from the last layer via sketching a low-dimensional subspace to perform knowledge transfer among learning tasks. We show that under mild assumptions, for each layer the parametric subspace can be recovered using only one pass of training data. In addition, empirical results demonstrate that the proposed subspace network quickly picks up correct parameter subspaces, and outperforms state-of-the-arts in predicting neurodegenerative clinical scores using information in brain imaging. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">subspace, censor, multi-task, deep network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkanP0lRW">
      <h4>
        <a href="https://openreview.net/forum?id=HkanP0lRW">
          Data-driven Feature Sampling for Deep Hyperspectral Classification and Segmentation
        </a>
        
          <a href="https://openreview.net/pdf?id=HkanP0lRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wmsever%40sandia.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="wmsever@sandia.gov">William M. Severa</a>, <a href="https://openreview.net/profile?email=jatimli%40sandia.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="jatimli@sandia.gov">Jerilyn A. Timlin</a>, <a href="https://openreview.net/profile?email=skholwadwala%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skholwadwala@gmail.com">Suraj Kholwadwala</a>, <a href="https://openreview.net/profile?email=cdjame%40sandia.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdjame@sandia.gov">Conrad D. James</a>, <a href="https://openreview.net/profile?email=jbaimon%40sandia.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbaimon@sandia.gov">James B. Aimone</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkanP0lRW-details-260" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkanP0lRW-details-260"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The high dimensionality of hyperspectral imaging forces unique challenges in scope, size and processing requirements.  Motivated by the potential for an in-the-field cell sorting detector, we examine a Synechocystis sp. PCC 6803 dataset wherein cells are grown alternatively in nitrogen rich or deplete cultures.  We use deep learning techniques to both successfully classify cells and generate a mask segmenting the cells/condition from the background. Further, we use the classification accuracy to guide a data-driven, iterative feature selection method, allowing the design neural networks requiring 90% fewer input features with little accuracy degradation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We applied deep learning techniques to hyperspectral image segmentation and iterative feature sampling.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Applied deep learning, Image segmentation, Hyperspectral Imaging, Feature sampling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1K6Tb-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1K6Tb-AZ">
          TESLA: Task-wise Early Stopping and Loss Aggregation for Dynamic Neural Network Inference
        </a>
        
          <a href="https://openreview.net/pdf?id=H1K6Tb-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cmchang%40iis.sinica.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="cmchang@iis.sinica.edu.tw">Chun-Min Chang</a>, <a href="https://openreview.net/profile?email=d05921018%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="d05921018@ntu.edu.tw">Chia-Ching Lin</a>, <a href="https://openreview.net/profile?email=frank840925%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="frank840925@gmail.com">Hung-Yi Ou Yang</a>, <a href="https://openreview.net/profile?email=cllei%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="cllei@ntu.edu.tw">Chin-Laung Lei</a>, <a href="https://openreview.net/profile?email=swc%40iis.sinica.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="swc@iis.sinica.edu.tw">Kuan-Ta Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1K6Tb-AZ-details-855" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1K6Tb-AZ-details-855"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">For inference operations in deep neural networks on end devices, it is desirable to deploy a single pre-trained neural network model, which can dynamically scale across a computation range without comprising accuracy. To achieve this goal, Incomplete Dot Product (IDP) has been proposed to use only a subset of terms in dot products during forward propagation. However, there are some limitations, including noticeable performance degradation in operating regions with low computational costs, and essential performance limitations since IDP uses hand-crafted profile coefficients. In this paper, we extend IDP by proposing new training algorithms involving a single profile, which may be trainable or pre-determined, to significantly improve the overall performance, especially in operating regions with low computational costs. Specifically, we propose the Task-wise Early Stopping and Loss Aggregation (TESLA) algorithm, which is showed in our 3-layer multilayer perceptron on MNIST that outperforms the original IDP by 32\% when only 10\% of dot products terms are used and achieves 94.7\% accuracy on average. By introducing trainable profile coefficients, TESLA further improves the accuracy to 95.5\% without specifying coefficients in advance. Besides, TESLA is applied to the VGG-16 model, which achieves 80\% accuracy using only 20\% of dot product terms on CIFAR-10 and also keeps 60\% accuracy using only 30\% of dot product terms on CIFAR-100, but the original IDP performs like a random guess in these two datasets at such low computation costs. Finally, we visualize the learned representations at different dot product percentages by class activation map and show that, by applying TESLA, the learned representations can adapt over a wide range of operation regions.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkjL6MiTb">
      <h4>
        <a href="https://openreview.net/forum?id=HkjL6MiTb">
          Siamese Survival Analysis with Competing Risks
        </a>
        
          <a href="https://openreview.net/pdf?id=HkjL6MiTb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=santon834%40g.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="santon834@g.ucla.edu">Anton Nemchenko</a>, <a href="https://openreview.net/profile?email=ahujak%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahujak@ucla.edu">Kartik Ahuja</a>, <a href="https://openreview.net/profile?email=mihaela%40ee.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mihaela@ee.ucla.edu">Mihaela Van Der Schaar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkjL6MiTb-details-401" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkjL6MiTb-details-401"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Survival Analysis (time-to-event analysis) in the presence of multiple possible adverse events, i.e., competing risks, is a challenging, yet very important problem in medicine, finance, manufacturing, etc. Extending classical survival analysis to competing risks is not trivial since only one event (e.g. one cause of death) is observed and hence, the incidence of an event of interest is often obscured by other related competing events. This leads to the nonidentifiability of the event times’ distribution parameters, which makes the problem significantly more challenging. In this work we introduce Siamese Survival Prognosis Network, a novel Siamese Deep Neural Network architecture that is able to effectively learn from data in the presence of multiple adverse events. The Siamese Survival Network is especially crafted to issue pairwise concordant time-dependent risks, in which longer event times are assigned lower risks. Furthermore, our architecture is able to directly optimize an approximation to the C-discrimination index, rather than relying on well-known metrics of cross-entropy etc., and which are not able to capture the unique requirements of survival analysis with competing risks. Our results show consistent performance improvements on a number of publicly available medical datasets over both statistical and deep learning state-of-the-art methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In this work we introduce a novel Siamese Deep Neural Network architecture that is able to effectively learn from data in the presence of multiple adverse events.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">survival analysis, competing risks, siamese neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByJbJwxCW">
      <h4>
        <a href="https://openreview.net/forum?id=ByJbJwxCW">
          Relational Multi-Instance Learning for Concept Annotation from Medical Time Series
        </a>
        
          <a href="https://openreview.net/pdf?id=ByJbJwxCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=spurusho%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="spurusho@usc.edu">Sanjay Purushotham</a>, <a href="https://openreview.net/profile?email=zche%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zche@usc.edu">Zhengping Che</a>, <a href="https://openreview.net/profile?email=boj%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="boj@usc.edu">Bo Jiang</a>, <a href="https://openreview.net/profile?email=nilanon%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nilanon@usc.edu">Tanachat Nilanon</a>, <a href="https://openreview.net/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByJbJwxCW-details-829" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByJbJwxCW-details-829"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent advances in computing technology and sensor design have made it easier to collect longitudinal or time series data from patients, resulting in a gigantic amount of available medical data. Most of the medical time series lack annotations or even when the annotations are available they could be subjective and prone to human errors. Earlier works have developed natural language processing techniques to extract concept annotations and/or clinical narratives from doctor notes. However, these approaches are slow and do not use the accompanying medical time series data. To address this issue, we introduce the problem of concept annotation for the medical time series data, i.e., the task of predicting and localizing medical concepts by using the time series data as input. We propose Relational Multi-Instance Learning (RMIL) - a deep Multi Instance Learning framework based on recurrent neural networks, which uses pooling functions and attention mechanisms for the concept annotation tasks. Empirical results on medical datasets show that our proposed models outperform various multi-instance learning models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a deep Multi Instance Learning framework based on recurrent neural networks which uses pooling functions and attention mechanisms for the concept annotation tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Multi-instance learning, Medical Time Series, Concept Annotation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJFM0ZWCb">
      <h4>
        <a href="https://openreview.net/forum?id=SJFM0ZWCb">
          Deep Temporal Clustering: Fully unsupervised learning of time-domain features
        </a>
        
          <a href="https://openreview.net/pdf?id=SJFM0ZWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=naveen%40avlab.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="naveen@avlab.ai">Naveen Sai Madiraju</a>, <a href="https://openreview.net/profile?email=behnam%40avlab.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="behnam@avlab.ai">Seid M. Sadat</a>, <a href="https://openreview.net/profile?email=dimitry%40avlab.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimitry@avlab.ai">Dimitry Fisher</a>, <a href="https://openreview.net/profile?email=homa%40avlab.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="homa@avlab.ai">Homa Karimabadi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJFM0ZWCb-details-219" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJFM0ZWCb-details-219"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Unsupervised learning of timeseries data is a challenging problem in machine learning. Here, 
      we propose a novel algorithm, Deep Temporal Clustering (DTC), a fully unsupervised method, to naturally integrate dimensionality reduction and temporal clustering into a single end to end learning framework. The algorithm starts with an initial cluster estimates using an autoencoder for dimensionality reduction and a novel temporal clustering layer for cluster assignment. Then it jointly optimizes the clustering objective and the dimensionality reduction objective. Based on requirement and application, the temporal clustering layer can be customized with any temporal similarity metric. Several similarity metrics are considered and compared.  To gain insight into features that the network has learned for its clustering, we apply a visualization method that generates a heat map of regions of interest in the timeseries. The viability of the algorithm is demonstrated using timeseries data from diverse domains, ranging from earthquakes to sensor data from spacecraft. In each case, we show that our algorithm outperforms traditional methods. This performance is attributed to fully integrated temporal dimensionality reduction and clustering criterion.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A fully unsupervised method, to naturally integrate dimensionality reduction and temporal clustering into a single end to end learning framework.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Unsupervised deep learning, Temporal clustering, Event Visualization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJr4kfWCb">
      <h4>
        <a href="https://openreview.net/forum?id=rJr4kfWCb">
          Lung Tumor Location and Identification with AlexNet and a Custom CNN
        </a>
        
          <a href="https://openreview.net/pdf?id=rJr4kfWCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=allison_rossetto%40student.uml.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="allison_rossetto@student.uml.edu">Allison M Rossetto</a>, <a href="https://openreview.net/profile?email=wenjin_zhou%40uml.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenjin_zhou@uml.edu">Wenjin Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJr4kfWCb-details-450" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJr4kfWCb-details-450"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Lung cancer is the leading cause of cancer deaths in the world and early detection is a crucial part of increasing patient survival. Deep learning techniques provide us with a method of automated analysis of patient scans. In this work, we compare AlexNet, a multi-layered and highly ﬂexible architecture, with a custom CNN to determine if lung nodules with patient scans are benign or cancerous. We have found our CNN architecture to be highly accurate (99.79%) and fast while maintaining low False Positive and False Negative rates (&lt; 0.01% and 0.15% respectively). This is important as high false positive rates are a serious issue with lung cancer diagnosis. We have found that AlexNet is not well suited to the problem of nodule identiﬁcation, though it is a good baseline comparison because of its ﬂexibility.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJqUtdOaZ">
      <h4>
        <a href="https://openreview.net/forum?id=HJqUtdOaZ">
          ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES
        </a>
        
          <a href="https://openreview.net/pdf?id=HJqUtdOaZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mehran.tg.88%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mehran.tg.88@gmail.com">Mehran Taghipour-Gorjikolaie</a>, <a href="https://openreview.net/profile?email=razavism%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="razavism@gmail.com">Seyyed Mohammad Razavi</a>, <a href="https://openreview.net/profile?email=j_sadri%40encs.concordia.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="j_sadri@encs.concordia.ca">Javad Sadri</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJqUtdOaZ-details-663" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJqUtdOaZ-details-663"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Automatic classification of objects is one of the most important tasks in engineering
      and data mining applications. Although using more complex and advanced
      classifiers can help to improve the accuracy of classification systems, it can be
      done by analyzing data sets and their features for a particular problem. Feature
      combination is the one which can improve the quality of the features. In this paper,
      a structure similar to Feed-Forward Neural Network (FFNN) is used to generate an
      optimized linear or non-linear combination of features for classification. Genetic
      Algorithm (GA) is applied to update weights and biases. Since nature of data sets
      and their features impact on the effectiveness of combination and classification
      system, linear and non-linear activation functions (or transfer function) are used
      to achieve more reliable system. Experiments of several UCI data sets and using
      minimum distance classifier as a simple classifier indicate that proposed linear and
      non-linear intelligent FFNN-based feature combination can present more reliable
      and promising results. By using such a feature combination method, there is no
      need to use more powerful and complex classifier anymore.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A method for enriching and combining features to improve classification accuracy</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Classification, Feature Combination, Feature Mapping, Feed-Forward Neural Network, Genetic Algorithm, Linear Transfer Function, Non-Linear Transfer Function</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1m6h21Cb">
      <h4>
        <a href="https://openreview.net/forum?id=S1m6h21Cb">
          The Cramer Distance as a Solution to Biased Wasserstein Gradients
        </a>
        
          <a href="https://openreview.net/pdf?id=S1m6h21Cb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bellemare%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bellemare@google.com">Marc G. Bellemare</a>, <a href="https://openreview.net/profile?email=danihelka%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danihelka@google.com">Ivo Danihelka</a>, <a href="https://openreview.net/profile?email=shakir%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shakir@google.com">Will Dabney</a>, <a href="https://openreview.net/profile?email=balajiln%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="balajiln@google.com">Shakir Mohamed</a>, <a href="https://openreview.net/profile?email=shoyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shoyer@google.com">Balaji Lakshminarayanan</a>, <a href="https://openreview.net/profile?email=munos%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="munos@google.com">Stephan Hoyer</a>, Remi Munos
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1m6h21Cb-details-718" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1m6h21Cb-details-718"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The Wasserstein probability metric has received much attention from the machine learning community. Unlike the Kullback-Leibler divergence, which strictly measures change in probability, the Wasserstein metric reflects the underlying geometry between outcomes. The value of being sensitive to this geometry has been demonstrated, among others, in ordinal regression and generative modelling, and most recently in reinforcement learning. In this paper we describe three natural properties of probability divergences that we believe reflect requirements from machine learning: sum invariance, scale sensitivity, and unbiased sample gradients. The Wasserstein metric possesses the first two properties but, unlike the Kullback-Leibler divergence, does not possess the third. We provide empirical evidence suggesting this is a serious issue in practice. Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric, the Cramér distance. We show that the Cramér distance possesses all three desired properties, combining the best of the Wasserstein and Kullback-Leibler divergences. We give empirical results on a number of domains comparing these three divergences. To illustrate the practical relevance of the Cramér distance we design a new algorithm, the Cramér Generative Adversarial Network (GAN), and show that it has a number of desirable properties over the related Wasserstein GAN.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The Wasserstein distance is hard to minimize with stochastic gradient descent, while the Cramer distance can be optimized easily and works just as well.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Probability metrics, Wasserstein metric, stochastic gradient descent, GANs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJahqJZAW">
      <h4>
        <a href="https://openreview.net/forum?id=SJahqJZAW">
          Stabilizing GAN Training with Multiple Random Projections
        </a>
        
          <a href="https://openreview.net/pdf?id=SJahqJZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bneyshabur%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bneyshabur@ttic.edu">Behnam Neyshabur</a>, <a href="https://openreview.net/profile?email=srinadh%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srinadh@ttic.edu">Srinadh Bhojanapalli</a>, <a href="https://openreview.net/profile?email=ayan%40wustl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ayan@wustl.edu">Ayan Chakrabarti</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJahqJZAW-details-311" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJahqJZAW-details-311"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Training generative adversarial networks is unstable in high-dimensions as the true data distribution tends to be concentrated in a small fraction of the ambient space. The discriminator is then quickly able to classify nearly all generated samples as fake, leaving the generator without meaningful gradients and causing it to deteriorate after a point in training. In this work, we propose training a single generator simultaneously against an array of discriminators, each of which looks at a different random low-dimensional projection of the data. Individual discriminators, now provided with restricted views of the input, are unable to reject generated samples perfectly and continue to provide meaningful gradients to the generator throughout training.  Meanwhile, the generator learns to produce samples consistent with the full data distribution to satisfy all discriminators simultaneously. We  demonstrate the practical utility of this approach experimentally, and show that it is able to produce image samples with higher quality than traditional training with a single discriminator.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Stable GAN training in high dimensions by using an array of discriminators, each with a low dimensional view of generated samples</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial networks, stable training, low-dimensional projections, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy7EPh10W">
      <h4>
        <a href="https://openreview.net/forum?id=Hy7EPh10W">
          Novelty Detection with GAN
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy7EPh10W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mark.kliger%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mark.kliger@gmail.com">Mark Kliger</a>, <a href="https://openreview.net/profile?email=shacharfl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shacharfl@gmail.com">Shachar Fleishman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy7EPh10W-details-458" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy7EPh10W-details-458"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The ability of a classifier to recognize unknown inputs is important for many classification-based systems. We discuss the problem of simultaneous classification and novelty detection, i.e. determining whether an input is from the known set of classes and from which specific class, or from an unknown domain and does not belong to any of the known classes. We propose a method based on the Generative Adversarial Networks (GAN) framework. We show that a multi-class discriminator trained with a generator that generates samples from a mixture of nominal and novel data distributions is the optimal novelty detector. We approximate that generator with a mixture generator trained with the Feature Matching loss and empirically show that the proposed method outperforms conventional methods for novelty detection. Our findings demonstrate a simple, yet powerful new application of the GAN framework for the task of novelty detection.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose to solve a problem of simultaneous classification and novelty detection within the GAN framework.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">novelty detection, GAN, feature matching, semi-supervised</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1EfylZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=S1EfylZ0Z">
          Anomaly Detection with Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S1EfylZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ldeecke%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ldeecke@gmail.com">Lucas Deecke</a>, <a href="https://openreview.net/profile?email=vandermeulen%40cs.uni-kl.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="vandermeulen@cs.uni-kl.de">Robert Vandermeulen</a>, <a href="https://openreview.net/profile?email=contact%40lukasruff.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="contact@lukasruff.com">Lukas Ruff</a>, <a href="https://openreview.net/profile?email=stephan.mandt%40disneyresearch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephan.mandt@disneyresearch.com">Stephan Mandt</a>, <a href="https://openreview.net/profile?email=kloft%40cs.uni-kl.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kloft@cs.uni-kl.de">Marius Kloft</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1EfylZ0Z-details-422" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1EfylZ0Z-details-422"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many anomaly detection methods exist that perform well on low-dimensional problems however there is a notable lack of effective methods for high-dimensional spaces, such as images. Inspired by recent successes in deep learning we propose a novel approach to anomaly detection using generative adversarial networks. Given a sample under consideration, our method is based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous.  We achieve state-of-the-art performance on standard image benchmark datasets and visual inspection of the most anomalous samples reveals that our method does indeed return anomalies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a method for anomaly detection with GANs by searching the generator's latent space for good sample representations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Anomaly Detection, Generative Adversarial Networks, Deep Learning, Inverse Problems</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJHcpW-CW">
      <h4>
        <a href="https://openreview.net/forum?id=rJHcpW-CW">
          NOVEL AND EFFECTIVE PARALLEL MIX-GENERATOR GENERATIVE ADVERSARIAL NETWORKS
        </a>
        
          <a href="https://openreview.net/pdf?id=rJHcpW-CW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xia.xiao%40uconn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xia.xiao@uconn.edu">Xia Xiao</a>, <a href="https://openreview.net/profile?email=sanguthevar.rajasekaran%40uconn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanguthevar.rajasekaran@uconn.edu">Sanguthevar Rajasekaran</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJHcpW-CW-details-757" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJHcpW-CW-details-757"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a mix-generator generative adversarial networks (PGAN) model that works in parallel by mixing multiple disjoint generators to approximate a complex real distribution. In our model, we propose an adjustment component that collects all the generated data points from the generators, learns the boundary between each pair of generators, and provides error to separate the support of each of the generated distributions. To overcome the instability in a multiplayer game, a shrinkage adjustment component method is introduced to gradually reduce the boundary between generators during the training procedure. To address the linearly growing training time problem in a multiple generators model, we propose a method to train the generators in parallel. This means that our work can be scaled up to large parallel computation frameworks. We present an efficient loss function for the discriminator, an effective adjustment component, and a suitable generator. We also show how to introduce the decay factor to stabilize the training procedure. We have performed extensive experiments on synthetic datasets, MNIST, and CIFAR-10. These experiments reveal that the error provided by the adjustment component could successfully separate the generated distributions and each of the generators can stably learn a part of the real distribution even if only a few modes are contained in the real distribution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">multi generator to capture Pdata, solve the competition and one-beat-all problem</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural networks, generative adversarial networks, parallel</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1FQEfZA-">
      <h4>
        <a href="https://openreview.net/forum?id=S1FQEfZA-">
          A Classification-Based Perspective on GAN Distributions
        </a>
        
          <a href="https://openreview.net/pdf?id=S1FQEfZA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=shibani%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shibani@mit.edu">Shibani Santurkar</a>, <a href="https://openreview.net/profile?email=ludwigs%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ludwigs@mit.edu">Ludwig Schmidt</a>, <a href="https://openreview.net/profile?email=madry%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="madry@mit.edu">Aleksander Madry</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1FQEfZA--details-578" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1FQEfZA--details-578"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A fundamental, and still largely unanswered, question in the context of Generative Adversarial Networks (GANs) is whether GANs are actually able to capture the key characteristics of the datasets they are trained on. The current approaches to examining this issue require significant human supervision, such as visual inspection of sampled images, and often offer only fairly limited scalability. In this paper, we propose new techniques that employ classification-based perspective to evaluate synthetic GAN distributions and their capability to accurately reflect the essential properties of the training data. These techniques require only minimal human supervision and can easily be scaled and adapted to evaluate a variety of state-of-the-art GANs on large, popular datasets. They also indicate that GANs have significant problems in reproducing the more distributional properties of the training dataset. In particular, the diversity of such synthetic data is orders of magnitude smaller than that of the original data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose new methods for evaluating and quantifying the quality of synthetic GAN distributions from the perspective of classification tasks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative adversarial networks, classification, benchmark, mode collapse, diversity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1tExikAW">
      <h4>
        <a href="https://openreview.net/forum?id=B1tExikAW">
          LatentPoison -- Adversarial Attacks On The Latent Space
        </a>
        
          <a href="https://openreview.net/pdf?id=B1tExikAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ac2211%40ic.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ac2211@ic.ac.uk">Antonia Creswell</a>, <a href="https://openreview.net/profile?email=b.sengupta%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="b.sengupta@imperial.ac.uk">Biswa Sengupta</a>, <a href="https://openreview.net/profile?email=a.bharath%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.bharath@imperial.ac.uk">Anil A. Bharath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1tExikAW-details-322" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1tExikAW-details-322"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Robustness and security of machine learning (ML) systems are intertwined, wherein a non-robust ML system (classifiers, regressors, etc.) can be subject to attacks using a wide variety of exploits. With the advent of scalable deep learning methodologies, a lot of emphasis has been put on the robustness of supervised, unsupervised and reinforcement learning algorithms. Here, we study the robustness of the latent space of a deep variational autoencoder (dVAE), an unsupervised generative framework, to show that it is indeed possible to perturb the latent space, flip the class predictions and keep the classification probability approximately equal before and after an attack. This means that an agent that looks at the outputs of a decoder would remain oblivious to an attack.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adversarial attacks on the latent space of variational autoencoders to change the semantic meaning of inputs</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial attacks, security, auto-encoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryepFJbA-">
      <h4>
        <a href="https://openreview.net/forum?id=ryepFJbA-">
          On Convergence and Stability of GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=ryepFJbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nkodali3%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nkodali3@gatech.edu">Naveen Kodali</a>, <a href="https://openreview.net/profile?email=hays%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hays@gatech.edu">James Hays</a>, <a href="https://openreview.net/profile?email=prof%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="prof@gatech.edu">Jacob Abernethy</a>, <a href="https://openreview.net/profile?email=zkira%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkira@gatech.edu">Zsolt Kira</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>27 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryepFJbA--details-969" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryepFJbA--details-969"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Analysis of convergence and mode collapse by studying GAN training process as regret minimization</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, Generative Adversarial Networks, Mode Collapse, Stability, Game Theory, Regret Minimization, Convergence, Gradient Penalty</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry4SNTe0-">
      <h4>
        <a href="https://openreview.net/forum?id=ry4SNTe0-">
          Improve Training Stability of Semi-supervised Generative Adversarial Networks with Collaborative Training
        </a>
        
          <a href="https://openreview.net/pdf?id=ry4SNTe0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daleiwu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daleiwu@gmail.com">Dalei Wu</a>, <a href="https://openreview.net/profile?email=dalei.wu%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dalei.wu@huawei.com">Xiaohua Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry4SNTe0--details-152" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry4SNTe0--details-152"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Improved generative adversarial network (Improved GAN) is a successful method of using generative adversarial models to solve the problem of semi-supervised learning. However, it suffers from the problem of unstable training. In this paper, we found that the instability is mostly due to the vanishing gradients on the generator. To remedy this issue, we propose a new method to use collaborative training to improve the stability of semi-supervised GAN with the combination of Wasserstein GAN. The experiments have shown that our proposed method is more stable than the original Improved GAN and achieves comparable classification accuracy on different data sets. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Improve Training Stability of Semi-supervised Generative Adversarial Networks with Collaborative Training</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative adversarial training, semi-supervised training, collaborative training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By9iRkWA-">
      <h4>
        <a href="https://openreview.net/forum?id=By9iRkWA-">
          Phase Conductor on Multi-layered Attentions for Machine Comprehension
        </a>
        
          <a href="https://openreview.net/pdf?id=By9iRkWA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ult.rui.liu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ult.rui.liu@gmail.com">Rui Liu</a>, <a href="https://openreview.net/profile?email=weiwei%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="weiwei@cs.cmu.edu">Wei Wei</a>, <a href="https://openreview.net/profile?email=mwg10.thu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mwg10.thu@gmail.com">Weiguang Mao</a>, <a href="https://openreview.net/profile?email=mchikina%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mchikina@gmail.com">Maria Chikina</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By9iRkWA--details-893" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By9iRkWA--details-893"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Attention models have been intensively studied to improve NLP tasks such as machine comprehension via both question-aware passage attention model and self-matching attention model. Our research proposes phase conductor (PhaseCond) for attention models in two meaningful ways. First, PhaseCond, an architecture of multi-layered attention models, consists of multiple phases each implementing a stack of attention layers producing passage representations and a stack of inner or outer fusion layers regulating the information flow.  Second, we extend and improve the dot-product attention function for PhaseCond by simultaneously encoding multiple question and passage embedding layers from different perspectives. We demonstrate the effectiveness of our proposed model PhaseCond on the SQuAD dataset, showing that our model significantly outperforms both state-of-the-art single-layered and multiple-layered attention models. We deepen our results with new findings via both detailed qualitative analysis and visualized examples showing the dynamic changes through multi-layered attention models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Attention Model, Machine Comprehension, Question Answering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Q79heRW">
      <h4>
        <a href="https://openreview.net/forum?id=S1Q79heRW">
          Unsupervised Learning of Entailment-Vector Word Embeddings
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Q79heRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=james.henderson%40idiap.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.henderson@idiap.ch">James Henderson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Q79heRW-details-644" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Q79heRW-details-644"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Entailment vectors are a principled way to encode in a vector what information is known and what is unknown.  They are designed to model relations where one vector should include all the information in another vector, called entailment.  This paper investigates the unsupervised learning of entailment vectors for the semantics of words.  Using simple entailment-based models of the semantics of words in text (distributional semantics), we induce entailment-vector word embeddings which outperform the best previous results for predicting entailment between words, in unsupervised and semi-supervised experiments on hyponymy.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train word embeddings based on entailment instead of similarity, successfully predicting lexical entailment.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">word embeddings, natural language semantics, entailment, unsupervised learning, distributional semantics</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryOG3fWCW">
      <h4>
        <a href="https://openreview.net/forum?id=ryOG3fWCW">
          Model Specialization for Inference Via End-to-End Distillation, Pruning, and Cascades
        </a>
        
          <a href="https://openreview.net/pdf?id=ryOG3fWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ddkang%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddkang@stanford.edu">Daniel Kang</a>, <a href="https://openreview.net/profile?email=kareyshi%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kareyshi@stanford.edu">Karey Shi</a>, <a href="https://openreview.net/profile?email=thao2605%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="thao2605@stanford.edu">Thao Ngyuen</a>, <a href="https://openreview.net/profile?email=pbailis%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pbailis@cs.stanford.edu">Stephanie Mallard</a>, <a href="https://openreview.net/profile?email=matei%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="matei@cs.stanford.edu">Peter Bailis</a>, Matei Zaharia
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryOG3fWCW-details-157" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryOG3fWCW-details-157"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The availability of general-purpose reference and benchmark datasets such as
      ImageNet have spurred the development of general-purpose popular reference
      model architectures and pre-trained weights. However, in practice, neural net-
      works are often employed to perform specific, more restrictive tasks, that are
      narrower in scope and complexity. Thus, simply fine-tuning or transfer learn-
      ing from a general-purpose network inherits a large computational cost that may
      not be necessary for a given task. In this work, we investigate the potential for
      model specialization, or reducing a model’s computational footprint by leverag-
      ing task-specific knowledge, such as a restricted inference distribution. We study
      three methods for model specialization—1) task-aware distillation, 2) task-aware
      pruning, and 3) specialized model cascades—and evaluate their performance on
      a range of classification tasks. Moreover, for the first time, we investigate how
      these techniques complement one another, enabling up to 5× speedups with no
      loss in accuracy and 9.8× speedups while remaining within 2.5% of a highly ac-
      curate ResNet on specialized image classification tasks. These results suggest that
      simple and easy-to-implement specialization procedures may benefit a large num-
      ber practical applications in which the representational power of general-purpose
      networks need not be inherited.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ8rHkWRb">
      <h4>
        <a href="https://openreview.net/forum?id=rJ8rHkWRb">
          A Simple Fully Connected Network for Composing Word Embeddings from Characters
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ8rHkWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mike.sk.traynor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mike.sk.traynor@gmail.com">Michael Traynor</a>, <a href="https://openreview.net/profile?email=trappenberg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="trappenberg@gmail.com">Thomas Trappenberg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ8rHkWRb-details-61" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ8rHkWRb-details-61"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This work introduces a simple network for producing character aware word embeddings. Position agnostic and position aware character embeddings are combined to produce an embedding vector for each word. The learned word representations are shown to be very sparse and facilitate improved results on language modeling tasks, despite using markedly fewer parameters, and without the need to apply dropout. A final experiment suggests that weight sharing contributes to sparsity, increases performance, and prevents overfitting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A fully connected architecture is used to produce word embeddings from character representations, outperforms traditional embeddings and provides insight into sparsity and dropout.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural language processing, word embeddings, language models, neural network, deep learning, sparsity, dropout</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkYgAJWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkYgAJWCZ">
          One-shot and few-shot learning of word embeddings
        </a>
        
          <a href="https://openreview.net/pdf?id=rkYgAJWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lampinen%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lampinen@stanford.edu">Andrew Kyle Lampinen</a>, <a href="https://openreview.net/profile?email=mcclelland%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcclelland@stanford.edu">James Lloyd McClelland</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkYgAJWCZ-details-129" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkYgAJWCZ-details-129"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily. By contrast, humans have an incredible ability to do one-shot or few-shot learning. For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us. Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data. This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We highlight a technique by which natural language processing systems can learn a new word from context, allowing them to be much more flexible.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">One-shot learning, embeddings, word embeddings, natural language processing, NLP</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJw8fAgA-">
      <h4>
        <a href="https://openreview.net/forum?id=HJw8fAgA-">
          Learning Dynamic State Abstractions for Model-Based Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HJw8fAgA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lbuesing%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbuesing@google.com">Lars Buesing</a>, <a href="https://openreview.net/profile?email=theophane%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="theophane@google.com">Theophane Weber</a>, <a href="https://openreview.net/profile?email=sracaniere%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sracaniere@google.com">Sebastien Racaniere</a>, <a href="https://openreview.net/profile?email=aeslami%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aeslami@google.com">S. M. Ali Eslami</a>, <a href="https://openreview.net/profile?email=danilor%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danilor@google.com">Danilo Rezende</a>, <a href="https://openreview.net/profile?email=reichert%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="reichert@google.com">David Reichert</a>, <a href="https://openreview.net/profile?email=fviola%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fviola@google.com">Fabio Viola</a>, <a href="https://openreview.net/profile?email=fbesse%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fbesse@google.com">Frederic Besse</a>, <a href="https://openreview.net/profile?email=demishassabis%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="demishassabis@google.com">Karol Gregor</a>, <a href="https://openreview.net/profile?email=wierstra%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wierstra@google.com">Demis Hassabis</a>, Daan Wierstra
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJw8fAgA--details-864" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJw8fAgA--details-864"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A key challenge in model-based reinforcement learning (RL) is to synthesize computationally efficient and accurate environment models. We show that carefully designed models that learn predictive and compact state representations, also called state-space models, substantially reduce the computational costs for predicting outcomes of sequences of actions. Extensive experiments establish that state-space models accurately capture the dynamics of Atari games from the Arcade Learning Environment (ALE) from raw pixels. Furthermore, RL agents that use Monte-Carlo rollouts of these models as features for decision making outperform strong model-free baselines on the game MS_PACMAN, demonstrating the benefits of planning using learned dynamic state abstractions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generative models, probabilistic modelling, reinforcement learning, state-space models, planning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJky6Ry0W">
      <h4>
        <a href="https://openreview.net/forum?id=SJky6Ry0W">
          Learning Independent Causal Mechanisms
        </a>
        
          <a href="https://openreview.net/pdf?id=SJky6Ry0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gparascandolo%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="gparascandolo@tue.mpg.de">Giambattista Parascandolo</a>, <a href="https://openreview.net/profile?email=mrojascarulla%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mrojascarulla@gmail.com">Mateo Rojas Carulla</a>, <a href="https://openreview.net/profile?email=nkilbertus%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nkilbertus@tue.mpg.de">Niki Kilbertus</a>, <a href="https://openreview.net/profile?email=bs%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tue.mpg.de">Bernhard Schoelkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJky6Ry0W-details-31" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJky6Ry0W-details-31"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Independent causal mechanisms are a central concept in the study of causality
      with implications for machine learning tasks. In this work we develop
      an algorithm to recover a set of (inverse) independent mechanisms relating
      a distribution transformed by the mechanisms to a reference distribution.
      The approach is fully unsupervised and based on a set of experts that compete
      for data to specialize and extract the mechanisms. We test and analyze
      the proposed method on a series of experiments based on image transformations.
      Each expert successfully maps a subset of the transformed data
      to the original domain, and the learned mechanisms generalize to other
      domains. We discuss implications for domain transfer and links to recent
      trends in generative modeling.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkepKG-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=HkepKG-Rb">
          A Semantic Loss Function for Deep Learning with Symbolic Knowledge
        </a>
        
          <a href="https://openreview.net/pdf?id=HkepKG-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jixu%40g.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jixu@g.ucla.edu">Jingyi Xu</a>, <a href="https://openreview.net/profile?email=zhangzilu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangzilu@pku.edu.cn">Zilu Zhang</a>, <a href="https://openreview.net/profile?email=tal%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tal@cs.ucla.edu">Tal Friedman</a>, <a href="https://openreview.net/profile?email=yliang%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yliang@cs.ucla.edu">Yitao Liang</a>, <a href="https://openreview.net/profile?email=guyvdb%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guyvdb@cs.ucla.edu">Guy Van den Broeck</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkepKG-Rb-details-347" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkepKG-Rb-details-347"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that our semantic loss function effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and shortest paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, symbolic knowledge, semi-supervised learning, constraints</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJnQJXbC-">
      <h4>
        <a href="https://openreview.net/forum?id=HJnQJXbC-">
          AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJnQJXbC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=algaunt%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="algaunt@microsoft.com">Alexander L. Gaunt</a>, <a href="https://openreview.net/profile?email=matjoh%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matjoh@microsoft.com">Matthew A. Johnson</a>, <a href="https://openreview.net/profile?email=allawr%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="allawr@microsoft.com">Alan Lawrence</a>, <a href="https://openreview.net/profile?email=a-mariec%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="a-mariec@microsoft.com">Maik Riechert</a>, <a href="https://openreview.net/profile?email=dannytarlow%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dannytarlow@gmail.com">Daniel Tarlow</a>, <a href="https://openreview.net/profile?email=ryoto%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryoto@microsoft.com">Ryota Tomioka</a>, <a href="https://openreview.net/profile?email=dimitris%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimitris@microsoft.com">Dimitrios Vytiniotis</a>, <a href="https://openreview.net/profile?email=sweb%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sweb@microsoft.com">Sam Webster</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJnQJXbC--details-591" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJnQJXbC--details-591"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">
      New types of compute hardware in development and entering the market hold the promise of revolutionizing deep learning in a manner as profound as GPUs. However, existing software frameworks and training algorithms for deep learning have yet to evolve to fully leverage the capability of the new wave of silicon. In particular, models that exploit structured input via complex and instance-dependent control flow are difficult to accelerate using existing algorithms and hardware that typically rely on minibatching. We present an asynchronous model-parallel (AMP) training algorithm that is specifically motivated by training on networks of interconnected devices. Through an implementation on multi-core CPUs, we show that AMP training converges to the same accuracy as conventional synchronous training algorithms in a similar number of epochs, but utilizes the available hardware more efficiently, even for small minibatch sizes, resulting in shorter overall training times. Our framework opens the door for scaling up a new class of deep learning models that cannot be efficiently trained today.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using asynchronous gradient updates to accelerate dynamic neural network training</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">asynchronous, neural network, deep learning, graph, tree, rnn</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1CQGfZ0b">
      <h4>
        <a href="https://openreview.net/forum?id=B1CQGfZ0b">
          Learning to select examples for program synthesis
        </a>
        
          <a href="https://openreview.net/pdf?id=B1CQGfZ0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yewenpu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yewenpu@mit.edu">Yewen Pu</a>, <a href="https://openreview.net/profile?email=zmiranda%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zmiranda@mit.edu">Zachery Miranda</a>, <a href="https://openreview.net/profile?email=asolar%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asolar@csail.mit.edu">Armando Solar-Lezama</a>, <a href="https://openreview.net/profile?email=lpk%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lpk@csail.mit.edu">Leslie Pack Kaelbling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1CQGfZ0b-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1CQGfZ0b-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Program synthesis is a class of regression problems where one seeks a solution, in the form of a source-code program, that maps the inputs to their corresponding outputs exactly. Due to its precise and combinatorial nature, it is commonly formulated as a constraint satisfaction problem, where input-output examples are expressed constraints, and solved with a constraint solver. A key challenge of this formulation is that of scalability: While constraint solvers work well with few well-chosen examples, constraining the entire set of example constitutes a significant overhead in both time and memory. In this paper we address this challenge by constructing a representative subset of examples that is both small and is able to constrain the solver sufficiently. We build the subset one example at a time, using a trained discriminator to predict the probability of unchosen input-output examples conditioned on the chosen input-output examples, adding the least probable example to the subset. Experiment on a diagram drawing domain shows our approach produces subset of examples that are small and representative for the constraint solver.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In a program synthesis context where the input is a set of examples, we reduce the cost by computing a subset of representative examples</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">program synthesis, program induction, example selection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1kjEuHpZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1kjEuHpZ">
          Learning Less-Overlapping Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=r1kjEuHpZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hongbao.zhang%40petuum.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongbao.zhang@petuum.com">Hongbao Zhang</a>, <a href="https://openreview.net/profile?email=pengtaox%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pengtaox@cs.cmu.edu">Pengtao Xie</a>, <a href="https://openreview.net/profile?email=eric.xing%40petuum.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eric.xing@petuum.com">Eric Xing</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1kjEuHpZ-details-605" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1kjEuHpZ-details-605"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In representation learning (RL), how to make the learned representations easy to interpret and less overfitted to training data are two important but challenging issues. To address these problems, we study a new type of regularization approach that encourages the supports of weight vectors in RL models to have small overlap, by simultaneously promoting near-orthogonality among vectors and sparsity of each vector. We apply the proposed regularizer to two models: neural networks (NNs) and sparse coding (SC), and develop an efficient ADMM-based algorithm for regularized SC. Experiments on various datasets demonstrate that weight vectors learned under our regularizer are more interpretable and have better generalization performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a new type of regularization approach that encourages non-overlapness in representation learning, for the sake of improving interpretability and reducing overfitting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Less-overlapness, regularization, near-orthogonality, sparsity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJdCUMZAW">
      <h4>
        <a href="https://openreview.net/forum?id=SJdCUMZAW">
          Data-efficient Deep Reinforcement Learning for Dexterous Manipulation
        </a>
        
          <a href="https://openreview.net/pdf?id=SJdCUMZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ivaylo.popov%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ivaylo.popov@hotmail.com">Ivo Popov</a>, <a href="https://openreview.net/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Nicolas Heess</a>, <a href="https://openreview.net/profile?email=countzero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="countzero@google.com">Timothy P. Lillicrap</a>, <a href="https://openreview.net/profile?email=rhafner%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rhafner@google.com">Roland Hafner</a>, <a href="https://openreview.net/profile?email=gabrielbm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gabrielbm@google.com">Gabriel Barth-Maron</a>, <a href="https://openreview.net/profile?email=matejvecerik%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matejvecerik@google.com">Matej Vecerik</a>, <a href="https://openreview.net/profile?email=thomaslampe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomaslampe@google.com">Thomas Lampe</a>, <a href="https://openreview.net/profile?email=etom%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="etom@google.com">Tom Erez</a>, <a href="https://openreview.net/profile?email=tassa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tassa@google.com">Yuval Tassa</a>, <a href="https://openreview.net/profile?email=riedmiller%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="riedmiller@google.com">Martin Riedmiller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJdCUMZAW-details-689" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJdCUMZAW-details-689"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Grasping an object and precisely stacking it on another is a difficult task for traditional robotic control or hand-engineered approaches. Here we examine the problem in simulation and provide techniques aimed at solving it via deep reinforcement learning. We introduce two straightforward extensions to the Deep Deterministic Policy Gradient algorithm (DDPG), which make it significantly more data-efficient and scalable. Our results show that by making extensive use of off-policy data and replay, it is possible to find high-performance control policies. Further, our results hint that it may soon be feasible to train successful stacking policies by collecting interactions on real robots.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Data-efficient deep reinforcement learning can be used to learning precise stacking policies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning, robotics, dexterous manipulation, off-policy learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1kMMmb0-">
      <h4>
        <a href="https://openreview.net/forum?id=H1kMMmb0-">
          Sequential Coordination of Deep Models for Learning Visual Arithmetic
        </a>
        
          <a href="https://openreview.net/pdf?id=H1kMMmb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=eric.crawford%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="eric.crawford@mail.mcgill.ca">Eric Crawford</a>, <a href="https://openreview.net/profile?email=guillaume.rabusseau%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="guillaume.rabusseau@mail.mcgill.ca">Guillaume Rabusseau</a>, <a href="https://openreview.net/profile?email=jpineau%40cs.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpineau@cs.mcgill.ca">Joelle Pineau</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1kMMmb0--details-259" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1kMMmb0--details-259"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Achieving machine intelligence requires a smooth integration of perception and reasoning, yet models developed to date tend to specialize in one or the other; sophisticated manipulation of symbols acquired from rich perceptual spaces has so far proved elusive. Consider a visual arithmetic task, where the goal is to carry out simple arithmetical algorithms on digits presented under natural conditions (e.g. hand-written, placed randomly). We propose a two-tiered architecture for tackling this kind of problem. The lower tier consists of a heterogeneous collection of information processing modules, which can include pre-trained deep neural networks for locating and extracting characters from the image, as well as modules performing symbolic transformations on the representations extracted by perception. The higher tier consists of a controller, trained using reinforcement learning, which coordinates the modules in order to solve the high-level task. For instance, the controller may learn in what contexts to execute the perceptual networks and what symbolic transformations to apply to their outputs. The resulting model is able to solve a variety of tasks in the visual arithmetic domain,and has several advantages over standard, architecturally homogeneous feedforward networks including improved sample efficiency.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We use reinforcement learning to train an agent to solve a set of visual arithmetic tasks using provided pre-trained perceptual modules and transformations of internal representations created by those modules.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, pretrained, deep learning, perception, algorithmic</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkIkkseAZ">
      <h4>
        <a href="https://openreview.net/forum?id=BkIkkseAZ">
          Theoretical properties of the global optimizer of two-layer Neural Network
        </a>
        
          <a href="https://openreview.net/pdf?id=BkIkkseAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=digvijaybb40%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="digvijaybb40@gatech.edu">Digvijay Boob</a>, <a href="https://openreview.net/profile?email=george.lan%40isye.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="george.lan@isye.gatech.edu">Guanghui Lan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkIkkseAZ-details-759" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkIkkseAZ-details-759"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we study the problem of optimizing a two-layer artificial neural network that best fits a training dataset. We look at this problem in the setting where the number of parameters is greater than the number of sampled points. We show that for a wide class of differentiable activation functions (this class involves most nonlinear functions and excludes piecewise linear functions), we have that arbitrary first-order optimal solutions satisfy global optimality provided the hidden layer is non-singular. We essentially show that these non-singular hidden layer matrix satisfy a ``"good" property for these big class of activation functions. Techniques involved in proving this result inspire us to look at a new algorithmic, where in between two gradient step of hidden layer, we add a stochastic gradient descent (SGD) step of the output layer. In this new algorithmic framework, we extend our earlier result and show that for all finite iterations the hidden layer satisfies the``good" property mentioned earlier therefore partially explaining success of noisy gradient methods and addressing the issue of data independency of our earlier result. Both of these results are easily extended to hidden layers given by a flat matrix from that of a square matrix. Results are applicable even if network has more than one hidden layer provided all inner hidden layers are arbitrary, satisfy non-singularity, all activations are from the given class of differentiable functions and optimization is only with respect to the outermost hidden layer. Separately, we also study the smoothness properties of the objective function and show that it is actually Lipschitz smooth, i.e., its gradients do not change sharply. We use smoothness properties to guarantee asymptotic convergence of $O(1/\text{number of iterations})$ to a first-order optimal solution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper talks about theoretical properties of first-order optimal point of two layer neural network in over-parametrized case</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Non-convex optimization, Two-layer Neural Network, global optimality, first-order optimality</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryCM8zWRb">
      <h4>
        <a href="https://openreview.net/forum?id=ryCM8zWRb">
          Recurrent Neural Networks with Top-k Gains for Session-based Recommendations
        </a>
        
          <a href="https://openreview.net/pdf?id=ryCM8zWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hidasib%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hidasib@gmail.com">Balázs Hidasi</a>, <a href="https://openreview.net/profile?email=alexk%40tid.es" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexk@tid.es">Alexandros Karatzoglou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryCM8zWRb-details-902" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryCM8zWRb-details-902"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">RNNs have been shown to be excellent models for sequential data and in particular for session-based user behavior. The use of RNNs provides impressive performance benefits over classical methods in session-based recommendations. In this work we introduce a novel ranking loss function tailored for RNNs in recommendation settings. The better performance of such loss over alternatives, along with further tricks and improvements described in this work, allow to achieve an overall improvement of up to 35% in terms of MRR and Recall@20 over previous session-based RNN solutions and up to 51% over classical collaborative filtering approaches. Unlike data augmentation-based improvements, our method does not increase training times significantly.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Improving session-based recommendations with RNNs (GRU4Rec) by 35% using newly designed loss functions and sampling.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">gru4rec, session-based recommendations, recommender systems, recurrent neural network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1saNM-RW">
      <h4>
        <a href="https://openreview.net/forum?id=r1saNM-RW">
          Small Coresets to Represent Large Training Data for Support Vector Machines
        </a>
        
          <a href="https://openreview.net/pdf?id=r1saNM-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=baykal%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baykal@mit.edu">Cenk Baykal</a>, <a href="https://openreview.net/profile?email=muradtuk%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="muradtuk@gmail.com">Murad Tukan</a>, <a href="https://openreview.net/profile?email=dannyf.post%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dannyf.post@gmail.com">Dan Feldman</a>, <a href="https://openreview.net/profile?email=rus%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rus@csail.mit.edu">Daniela Rus</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1saNM-RW-details-632" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1saNM-RW-details-632"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Support Vector Machines (SVMs) are one of the most popular algorithms for classification and regression analysis. Despite their popularity, even efficient implementations have proven to be computationally expensive to train at a large-scale, especially in streaming settings. In this paper, we propose a novel coreset construction algorithm for efficiently generating compact representations of massive data sets to speed up SVM training. A coreset is a weighted subset of the original data points such that SVMs trained on the coreset are provably competitive with those trained on the original (massive) data set. We provide both lower and upper bounds on the number of samples required to obtain accurate approximations to the SVM problem as a function of the complexity of the input data. Our analysis also establishes sufficient conditions on the existence of sufficiently compact and representative coresets for the SVM problem. We empirically evaluate the practical effectiveness of our algorithm against synthetic and real-world data sets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present an algorithm for speeding up SVM training on massive data sets by constructing compact representations that provide efficient and provably approximate inference.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">coresets, data compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1U_af-0-">
      <h4>
        <a href="https://openreview.net/forum?id=H1U_af-0-">
          Quadrature-based features for kernel approximation
        </a>
        
          <a href="https://openreview.net/pdf?id=H1U_af-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=marina.munkhoeva%40skolkovotech.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="marina.munkhoeva@skolkovotech.ru">Marina Munkhoeva</a>, <a href="https://openreview.net/profile?email=kapushev%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kapushev@gmail.com">Yermek Kapushev</a>, <a href="https://openreview.net/profile?email=e.burnaev%40skoltech.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.burnaev@skoltech.ru">Evgeny Burnaev</a>, <a href="https://openreview.net/profile?email=i.oseledets%40skoltech.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="i.oseledets@skoltech.ru">Ivan Oseledets</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1U_af-0--details-819" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1U_af-0--details-819"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider the problem of improving kernel approximation via feature maps. These maps arise as Monte Carlo approximation to integral representations of kernel functions and scale up kernel methods for larger datasets. We propose to use more efficient numerical integration technique to obtain better estimates of the integrals compared to the state-of-the-art methods. Our approach allows to use information about the integrand to enhance approximation and facilitates fast computations. We derive the convergence behavior and conduct an extensive empirical study that supports our hypothesis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Quadrature rules for kernel approximation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">kernel methods, low-rank approximation, quadrature rules, random features</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJBhEMbRb">
      <h4>
        <a href="https://openreview.net/forum?id=HJBhEMbRb">
          A Spectral Approach to Generalization and Optimization in Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJBhEMbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=farnia%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="farnia@stanford.edu">Farzan Farnia</a>, <a href="https://openreview.net/profile?email=jessez%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jessez@stanford.edu">Jesse Zhang</a>, <a href="https://openreview.net/profile?email=dntse%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dntse@stanford.edu">David Tse</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJBhEMbRb-details-150" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJBhEMbRb-details-150"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The recent success of deep neural networks stems from their ability to generalize well on real data; however, Zhang et al. have observed that neural networks can easily overfit random labels. This observation demonstrates that with the existing theory, we cannot adequately explain why gradient methods can find generalizable solutions for neural networks. In this work, we use a Fourier-based approach to study the generalization properties of gradient-based methods over 2-layer neural networks with sinusoidal activation functions. We prove that if the underlying distribution of data has nice spectral properties such as bandlimitedness, then the gradient descent method will converge to generalizable local minima. We also establish a Fourier-based generalization bound for bandlimited spaces, which generalizes to other activation functions. Our generalization bound motivates a grouped version of path norms for measuring the complexity of 2-layer neural networks with ReLU activation functions. We demonstrate numerically that regularization of this group path norm results in neural network solutions that can fit true labels without losing test accuracy while not overfitting random labels.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generalization, Neural Networks, Fourier Analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ8M9yup-">
      <h4>
        <a href="https://openreview.net/forum?id=SJ8M9yup-">
          On Optimality Conditions for Auto-Encoder Signal Recovery
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ8M9yup-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=devansharpit%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="devansharpit@gmail.com">Devansh Arpit</a>, <a href="https://openreview.net/profile?email=zybzmhhj%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zybzmhhj@gmail.com">Yingbo Zhou</a>, <a href="https://openreview.net/profile?email=hungngo%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hungngo@buffalo.edu">Hung Q. Ngo</a>, <a href="https://openreview.net/profile?email=nnapp%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nnapp@buffalo.edu">Nils Napp</a>, <a href="https://openreview.net/profile?email=venu%40cubs.buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="venu@cubs.buffalo.edu">Venu Govindaraju</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ8M9yup--details-812" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ8M9yup--details-812"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Auto-Encoders are unsupervised models that aim to learn  patterns from observed data by minimizing a reconstruction cost. The useful representations learned are often found to be sparse and distributed. On the other hand, compressed sensing and sparse coding assume a data generating process, where the observed data is generated from some true latent signal source, and try to recover the corresponding signal from measurements. Looking at auto-encoders from this signal recovery perspective enables us to have a more coherent view of these techniques. In this paper, in particular, we show that the true hidden representation can be approximately recovered if the weight matrices are highly incoherent with unit $ \ell^{2} $ row length and the bias vectors takes the value (approximately) equal to the negative of the data mean. The recovery also becomes more and more accurate as the sparsity in hidden signals increases. Additionally, we empirically also demonstrate that auto-encoders are capable of recovering the data generating dictionary when only data samples are given.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Auto Encoder, Signal Recovery, Sparse Coding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJu63o10b">
      <h4>
        <a href="https://openreview.net/forum?id=SJu63o10b">
          UNSUPERVISED METRIC LEARNING VIA NONLINEAR FEATURE SPACE TRANSFORMATIONS
        </a>
        
          <a href="https://openreview.net/pdf?id=SJu63o10b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pz335412%40ohio.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pz335412@ohio.edu">Pin Zhang</a>, <a href="https://openreview.net/profile?email=bibo.shi%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bibo.shi@duke.edu">Bibo Shi</a>, <a href="https://openreview.net/profile?email=liuj1%40ohio.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuj1@ohio.edu">JundongLiu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJu63o10b-details-321" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJu63o10b-details-321"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a nonlinear unsupervised metric learning framework to boost of the performance of clustering algorithms. Under our framework, nonlinear distance metric learning and manifold embedding are integrated and conducted simultaneously to increase the natural separations among data samples. The metric learning component is implemented through feature space transformations, regulated by a nonlinear deformable model called Coherent Point Drifting (CPD). Driven by CPD, data points can get to a higher level of linear separability, which is subsequently picked up by the manifold embedding component to generate well-separable sample projections for clustering. Experimental results on synthetic and benchmark datasets show the effectiveness of our proposed approach over the state-of-the-art solutions in unsupervised metric learning.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> a nonlinear unsupervised metric learning framework to boost the performance of clustering algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Metric Learning, K-means, CPD, Clustering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJDYgPgCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJDYgPgCZ">
          Understanding Local Minima in Neural Networks by Loss Surface Decomposition
        </a>
        
          <a href="https://openreview.net/pdf?id=SJDYgPgCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hnkwak%40bi.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="hnkwak@bi.snu.ac.kr">Hanock Kwak</a>, <a href="https://openreview.net/profile?email=btzhang%40bi.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="btzhang@bi.snu.ac.kr">Byoung-Tak Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJDYgPgCZ-details-350" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJDYgPgCZ-details-350"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">To provide principled ways of designing proper Deep Neural Network (DNN) models, it is essential to understand the loss surface of DNNs under realistic assumptions. We introduce interesting aspects for understanding the local minima and overall structure of the loss surface. The parameter domain of the loss surface can be decomposed into regions in which activation values (zero or one for rectified linear units) are consistent. We found that, in each region, the loss surface have properties similar to that of linear neural networks where every local minimum is a global minimum. This means that every differentiable local minimum is the global minimum of the corresponding region. We prove that for a neural network with one hidden layer using rectified linear units under realistic assumptions. There are poor regions that lead to poor local minima, and we explain why such regions exist even in the overparameterized DNNs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The loss surface of neural networks is a disjoint union of regions where every local minimum is a global minimum of the corresponding region.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural network, local minima, global minima, saddle point, optimization, loss surface, rectified linear unit, loss surface decomposition, gradient descent</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgd7m0xRZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJgd7m0xRZ">
          Unsupervised Adversarial Anomaly  Detection using One-Class Support Vector Machines
        </a>
        
          <a href="https://openreview.net/pdf?id=BJgd7m0xRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pweerasinghe%40student.unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="pweerasinghe@student.unimelb.edu.au">Prameesha Sandamal Weerasinghe</a>, <a href="https://openreview.net/profile?email=tansu.alpcan%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="tansu.alpcan@unimelb.edu.au">Tansu Alpcan</a>, <a href="https://openreview.net/profile?email=sarah.erfani%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="sarah.erfani@unimelb.edu.au">Sarah Monazam Erfani</a>, <a href="https://openreview.net/profile?email=caleckie%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="caleckie@unimelb.edu.au">Christopher Leckie</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJgd7m0xRZ-details-989" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgd7m0xRZ-details-989"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Anomaly detection discovers regular patterns in unlabeled data and identifies the non-conforming data points, which in some cases are the result of malicious attacks by adversaries. Learners such as One-Class Support Vector Machines (OCSVMs) have been successfully in anomaly detection, yet their performance may degrade significantly in the presence of sophisticated adversaries, who target the algorithm itself by compromising the integrity of the training data. With the rise in the use of machine learning in mission critical day-to-day activities where errors may have significant consequences, it is imperative that machine learning systems are made secure. To address this, we propose a defense mechanism that is based on a contraction of the data, and we test its effectiveness using OCSVMs. The proposed approach introduces a layer of uncertainty on top of the OCSVM learner, making it infeasible for the adversary to guess the specific configuration of the learner. We theoretically analyze the effects of adversarial perturbations on the separating margin of OCSVMs and provide empirical evidence on several benchmark datasets, which show that by carefully contracting the data in low dimensional spaces, we can successfully identify adversarial samples that would not have been identifiable in the original dimensional space. The numerical results show that the proposed method improves OCSVMs performance significantly (2-7%)</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel method to increase the resistance of OCSVMs against targeted, integrity attacks by selective nonlinear transformations of data to lower dimensions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">anomaly detection, one class support vector machine, adversarial learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyiRazbRb">
      <h4>
        <a href="https://openreview.net/forum?id=HyiRazbRb">
          Demystifying overcomplete nonlinear auto-encoders: fast SGD convergence towards sparse representation from random initialization
        </a>
        
          <a href="https://openreview.net/pdf?id=HyiRazbRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tangch%40gwu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tangch@gwu.edu">Cheng Tang</a>, <a href="https://openreview.net/profile?email=cmontel%40gwu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cmontel@gwu.edu">Claire Monteleoni</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyiRazbRb-details-101" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyiRazbRb-details-101"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Auto-encoders are commonly used for unsupervised representation learning and for pre-training deeper neural networks.
      When its activation function is linear and the encoding dimension (width of hidden layer) is smaller than the input dimension, it is well known that auto-encoder is optimized to learn the principal components of the data distribution (Oja1982).
      However, when the activation is nonlinear and when the width is larger than the input dimension (overcomplete), auto-encoder behaves differently from PCA, and in fact is known to perform well empirically for sparse coding problems. 
      
      We provide a theoretical explanation for this empirically observed phenomenon, when rectified-linear unit (ReLu) is adopted as the activation function and the hidden-layer width is set to be large.
      In this case, we show that, with significant probability, initializing the weight matrix of an auto-encoder by sampling from a spherical Gaussian distribution followed by stochastic gradient descent (SGD) training converges towards the ground-truth representation for a class of sparse dictionary learning models.
      In addition, we can show that, conditioning on convergence, the expected convergence rate is O(1/t), where t is the number of updates.
      Our analysis quantifies how increasing hidden layer width helps the training performance when random initialization is used, and how the norm of network weights influence the speed of SGD convergence. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">theoretical analysis of nonlinear wide autoencoder</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">stochastic gradient descent, autoencoders, nonconvex optimization, representation learning, theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJSr0GZR-">
      <h4>
        <a href="https://openreview.net/forum?id=rJSr0GZR-">
          Learning Priors for Adversarial Autoencoders
        </a>
        
          <a href="https://openreview.net/pdf?id=rJSr0GZR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=a88575847%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="a88575847@gmail.com">Hui-Po Wang</a>, <a href="https://openreview.net/profile?email=ts771164%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ts771164@gmail.com">Wei-Jan Ko</a>, <a href="https://openreview.net/profile?email=wpeng%40cs.nctu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="wpeng@cs.nctu.edu.tw">Wen-Hsiao Peng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJSr0GZR--details-734" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJSr0GZR--details-734"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Most deep latent factor models choose simple priors for simplicity, tractability
      or not knowing what prior to use. Recent studies show that the choice of
      the prior may have a profound effect on the expressiveness of the model,
      especially when its generative network has limited capacity. In this paper, we propose to learn a proper prior from data for adversarial autoencoders
      (AAEs). We introduce the notion of code generators to transform manually selected
      simple priors into ones that can better characterize the data distribution. Experimental results show that the proposed model can generate better image quality and learn better disentangled representations than
      AAEs in both supervised and unsupervised settings. Lastly, we present its
      ability to do cross-domain translation in a  text-to-image synthesis task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learning Priors for Adversarial Autoencoders</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, computer vision, generative adversarial networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyI6s40a-">
      <h4>
        <a href="https://openreview.net/forum?id=HyI6s40a-">
          Towards Safe Deep Learning: Unsupervised Defense Against Generic Adversarial Attacks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyI6s40a-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bita%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bita@ucsd.edu">Bita Darvish Rouhani</a>, <a href="https://openreview.net/profile?email=msamragh%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="msamragh@ucsd.edu">Mohammad Samragh</a>, <a href="https://openreview.net/profile?email=tjavidi%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tjavidi@ucsd.edu">Tara Javidi</a>, <a href="https://openreview.net/profile?email=farinaz%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="farinaz@ucsd.edu">Farinaz Koushanfar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyI6s40a--details-664" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyI6s40a--details-664"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent advances in adversarial Deep Learning (DL) have opened up a new and largely unexplored surface for malicious attacks jeopardizing the integrity of autonomous DL systems. We introduce a novel automated countermeasure called Parallel Checkpointing Learners (PCL) to thwart the potential adversarial attacks and significantly improve the reliability (safety) of a victim DL model. The proposed PCL methodology is unsupervised, meaning that no adversarial sample is leveraged to build/train parallel checkpointing learners. We formalize the goal of preventing adversarial attacks as an optimization problem to minimize the rarely observed regions in the latent feature space spanned by a DL network. To solve the aforementioned minimization problem, a set of complementary but disjoint checkpointing modules are trained and leveraged to validate the victim model execution in parallel. Each checkpointing learner explicitly characterizes the geometry of the input data and the corresponding high-level data abstractions within a particular DL layer. As such, the adversary is required to simultaneously deceive all the defender modules in order to succeed. We extensively evaluate the performance of the PCL methodology against the state-of-the-art attack scenarios, including Fast-Gradient-Sign (FGS), Jacobian Saliency Map Attack (JSMA), Deepfool, and Carlini&amp;WagnerL2 algorithm. Extensive proof-of-concept evaluations for analyzing various data collections including MNIST, CIFAR10, and ImageNet corroborate the effectiveness of our proposed defense mechanism against adversarial samples. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Devising unsupervised defense mechanisms against adversarial attacks is crucial to ensure the generalizability of the defense. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Attacks, Unsupervised Defense, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryZERzWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryZERzWCZ">
          The Information-Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Modeling
        </a>
        
          <a href="https://openreview.net/pdf?id=ryZERzWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sjzhao%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjzhao@stanford.edu">Shengjia Zhao</a>, <a href="https://openreview.net/profile?email=tsong%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsong@cs.stanford.edu">Jiaming Song</a>, <a href="https://openreview.net/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryZERzWCZ-details-614" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryZERzWCZ-details-614"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">A variety of learning objectives have been recently proposed for training generative models. We show that many of them, including InfoGAN, ALI/BiGAN, ALICE, CycleGAN, VAE, $\beta$-VAE, adversarial autoencoders, AVB, and InfoVAE, are Lagrangian duals of the same primal optimization problem. This generalization reveals the implicit modeling trade-offs  between flexibility and  computational requirements being made by these models. Furthermore, we characterize the class of all objectives that can be optimized under certain computational constraints.
      Finally, we show how this new Lagrangian perspective can explain undesirable behavior of existing methods and provide new principled solutions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Models, Variational Autoencoder, Generative Adversarial Network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1wt9x-RW">
      <h4>
        <a href="https://openreview.net/forum?id=H1wt9x-RW">
          Interpretable and Pedagogical Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=H1wt9x-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=smilli%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="smilli@berkeley.edu">Smitha Milli</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>, <a href="https://openreview.net/profile?email=igor.mordatch%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="igor.mordatch@gmail.com">Igor Mordatch</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1wt9x-RW-details-405" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1wt9x-RW-details-405"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Teachers intentionally pick the most informative examples to show their students. However, if the teacher and student are neural networks, the examples that the teacher network learns to give, although effective at teaching the student, are typically uninterpretable. We show that training the student and teacher iteratively, rather than jointly, can produce interpretable teaching strategies. We evaluate interpretability by (1) measuring the similarity of the teacher's emergent strategies to intuitive strategies in each domain and (2) conducting human experiments to evaluate how effective the teacher's strategies are at teaching humans. We show that the teacher network learns to select or generate interpretable, pedagogical examples to teach rule-based, probabilistic, boolean, and hierarchical concepts.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that training a student and teacher network iteratively, rather than jointly, can produce emergent, interpretable teaching strategies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">machine teaching, interpretability, communication, cognitive science</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B13EC5u6W">
      <h4>
        <a href="https://openreview.net/forum?id=B13EC5u6W">
          Thinking like a machine — generating visual rationales through latent space optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=B13EC5u6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jarrelscy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jarrelscy@gmail.com">Jarrel Seah</a>, Jennifer Tang, Andy Kitchen, Jonathan Seah
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B13EC5u6W-details-534" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B13EC5u6W-details-534"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Interpretability and small labelled datasets are key issues in the practical application of deep learning, particularly in areas such as medicine. In this paper, we present a semi-supervised technique that addresses both these issues simultaneously. We learn dense representations from large unlabelled image datasets, then use those representations to both learn classifiers from small labeled sets and generate visual rationales explaining the predictions. Using chest radiography diagnosis as a motivating application, we show our method has good generalization ability by learning to represent our chest radiography dataset while training a classifier on an separate set from a different institution. Our method identifies heart failure and other thoracic diseases. For each prediction, we generate visual rationales for positive classifications by optimizing a latent representation to minimize the probability of disease while constrained by a similarity measure in image space. Decoding the resultant latent representation produces an image without apparent disease. The difference between the original and the altered image forms an interpretable visual rationale for the algorithm's prediction. Our method simultaneously produces visual rationales that compare favourably to previous techniques and a classifier that outperforms the current state-of-the-art.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a method of using GANs to generate high quality visual rationales to help explain model predictions. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">interpretability, generative adversarial networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByYPLJA6W">
      <h4>
        <a href="https://openreview.net/forum?id=ByYPLJA6W">
          Distribution Regression Network
        </a>
        
          <a href="https://openreview.net/pdf?id=ByYPLJA6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=koukl%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="koukl@comp.nus.edu.sg">Connie Kou</a>, <a href="https://openreview.net/profile?email=leehk%40bii.a-star.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="leehk@bii.a-star.edu.sg">Hwee Kuan Lee</a>, <a href="https://openreview.net/profile?email=ngtk%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ngtk@comp.nus.edu.sg">Teck Khim Ng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByYPLJA6W-details-688" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByYPLJA6W-details-688"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce our Distribution Regression Network (DRN) which performs regression from input probability distributions to output probability distributions. Compared to existing methods, DRN learns with fewer model parameters and easily extends to multiple input and multiple output distributions. On synthetic and real-world datasets, DRN performs similarly or better than the state-of-the-art. Furthermore, DRN generalizes the conventional multilayer perceptron (MLP). In the framework of MLP, each node encodes a real number, whereas in DRN, each node encodes a probability distribution. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A learning network which generalizes the MLP framework to perform distribution-to-distribution regression</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distribution regression, supervised learning, regression analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry9tUX_6-">
      <h4>
        <a href="https://openreview.net/forum?id=ry9tUX_6-">
          Entropy-SGD optimizes the prior of a PAC-Bayes bound: Data-dependent PAC-Bayes priors via differential privacy
        </a>
        
          <a href="https://openreview.net/pdf?id=ry9tUX_6-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gkd22%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="gkd22@cam.ac.uk">Gintare Karolina Dziugaite</a>, <a href="https://openreview.net/profile?email=droy%40utstat.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="droy@utstat.toronto.edu">Daniel M. Roy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry9tUX_6--details-267" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry9tUX_6--details-267"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We show that Entropy-SGD (Chaudhari et al., 2017), when viewed as a learning algorithm, optimizes a PAC-Bayes bound on the risk of a Gibbs (posterior) classifier, i.e., a randomized classifier obtained by a risk-sensitive perturbation of the weights of a learned classifier. Entropy-SGD works by optimizing the bound’s prior, violating the hypothesis of the PAC-Bayes theorem that the prior is chosen independently of the data. Indeed, available implementations of Entropy-SGD rapidly obtain zero training error on random labels and the same holds of the Gibbs posterior. In order to obtain a valid generalization bound, we show that an ε-differentially private prior yields a valid PAC-Bayes bound, a straightforward consequence of results connecting generalization with differential privacy. Using stochastic gradient Langevin dynamics (SGLD) to approximate the well-known exponential release mechanism, we observe that generalization error on MNIST (measured on held out data) falls within the (empirically nonvacuous) bounds computed under the assumption that SGLD produces perfect samples. In particular, Entropy-SGLD can be configured to yield relatively tight generalization bounds and still fit real labels, although these same settings do not obtain state-of-the-art performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that Entropy-SGD optimizes the prior of a PAC-Bayes bound, violating the requirement that the prior be independent of data; we use differential privacy to resolve this and improve generalization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generalization error, neural networks, statistical learning theory, PAC-Bayes theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJUOHGWRb">
      <h4>
        <a href="https://openreview.net/forum?id=HJUOHGWRb">
          Contextual Explanation Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJUOHGWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=alshedivat%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alshedivat@cs.cmu.edu">Maruan Al-Shedivat</a>, <a href="https://openreview.net/profile?email=akdubey%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="akdubey@cs.cmu.edu">Avinava Dubey</a>, <a href="https://openreview.net/profile?email=epxing%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="epxing@cs.cmu.edu">Eric P. Xing</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJUOHGWRb-details-470" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJUOHGWRb-details-470"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce contextual explanation networks (CENs)---a class of models that learn to predict by generating and leveraging intermediate explanations. CENs are deep networks that generate parameters for context-specific probabilistic graphical models which are further used for prediction and play the role of explanations. Contrary to the existing post-hoc model-explanation tools, CENs learn to predict and to explain jointly. Our approach offers two major advantages: (i) for each prediction, valid instance-specific explanations are generated with no computational overhead and (ii) prediction via explanation acts as a regularization and boosts performance in low-resource settings. We prove that local approximations to the decision boundary of our networks are consistent with the generated explanations. Our results on image and text classification and survival analysis tasks demonstrate that CENs are competitive with the state-of-the-art while offering additional insights behind each prediction, valuable for decision support.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A class of networks that generate simple models on the fly (called explanations) that act as a regularizer and enable consistent model diagnostics and interpretability.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">interpretability, regularization, deep learning, graphical models, model diagnostics, survival analysis</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyPpD0g0Z">
      <h4>
        <a href="https://openreview.net/forum?id=HyPpD0g0Z">
          Grouping-By-ID: Guarding Against Adversarial Domain Shifts
        </a>
        
          <a href="https://openreview.net/pdf?id=HyPpD0g0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=heinzedeml%40stat.math.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="heinzedeml@stat.math.ethz.ch">Christina Heinze-Deml</a>, <a href="https://openreview.net/profile?email=meinshausen%40stat.math.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="meinshausen@stat.math.ethz.ch">Nicolai Meinshausen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyPpD0g0Z-details-290" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyPpD0g0Z-details-290"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">When training a deep neural network for supervised image classification, one can broadly distinguish between two types of latent features of images that will drive the classification of class Y. Following the notation of Gong et al. (2016), we can divide features broadly into the classes of (i) “core” or “conditionally invariant” features X^ci whose distribution P(X^ci | Y) does not change substantially across domains and (ii) “style” or “orthogonal” features X^orth whose distribution P(X^orth | Y) can change substantially across domains. These latter orthogonal features would generally include features such as position, rotation, image quality or brightness but also more complex ones like hair color or posture for images of persons. We try to guard against future adversarial domain shifts by ideally just using the “conditionally invariant” features for classification. In contrast to previous work, we assume that the domain itself is not observed and hence a latent variable. We can hence not directly see the distributional change of features across different domains. 
      
      We do assume, however, that we can sometimes observe a so-called identifier or ID variable. We might know, for example, that two images show the same person, with ID referring to the identity of the person. In data augmentation, we generate several images from the same original image, with ID referring to the relevant original image. The method requires only a small fraction of images to have an ID variable.
      
      We provide a causal framework for the problem by adding the ID variable to the model of Gong et al. (2016). However, we are interested in settings where we cannot observe the domain directly and we treat domain as a latent variable. If two or more samples share the same class and identifier, (Y, ID)=(y,i), then we treat those samples as counterfactuals under different style interventions on the orthogonal or style features. Using this grouping-by-ID approach, we regularize the network to provide near constant output across samples that share the same ID by penalizing with an appropriate graph Laplacian. This is shown to substantially improve performance in settings where domains change in terms of image quality, brightness, color changes, and more complex changes such as changes in movement and posture. We show links to questions of interpretability, fairness and transfer learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose counterfactual regularization to guard against adversarial domain shifts arising through shifts in the distribution of latent "style features" of images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">supervised representation learning, causality, interpretability, transfer learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1xJjlbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1xJjlbAZ">
          INTERPRETATION OF NEURAL NETWORK IS FRAGILE
        </a>
        
          <a href="https://openreview.net/pdf?id=H1xJjlbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amiratag%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amiratag@stanford.edu">Amirata Ghorbani</a>, <a href="https://openreview.net/profile?email=a12d%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="a12d@stanford.edu">Abubakar Abid</a>, <a href="https://openreview.net/profile?email=jamesz%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamesz@stanford.edu">James Zou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1xJjlbAZ-details-868" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1xJjlbAZ-details-868"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In order for machine learning to be deployed and trusted in many applications, it is crucial to be able to reliably explain why the machine learning algorithm makes certain predictions. For example, if an algorithm classifies a given pathology image to be a malignant tumor, then the doctor may need to know which parts of the image led the algorithm to this classification. How to interpret black-box predictors is thus an important and active area of research.  A fundamental question is: how much can we trust the interpretation itself? In this paper, we show that interpretation of deep learning predictions is extremely fragile in the following sense:  two perceptively indistinguishable inputs with the same predicted label can be assigned very different}interpretations. We systematically characterize the fragility of the interpretations generated by several widely-used feature-importance interpretation methods (saliency maps, integrated gradient, and DeepLIFT) on ImageNet and CIFAR-10. Our experiments show that even small random perturbation can change the feature importance and new systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly fragile. Our analysis of the geometry of the Hessian matrix gives insight on why fragility could be a fundamental challenge to the current interpretation approaches.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Can we trust a neural network's explanation for its prediction? We examine the robustness of several popular notions of interpretability of neural networks including saliency maps and influence functions and design adversarial examples against them.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Attack, Interpretability, Saliency Map, Influence Function, Robustness, Machine Learning, Deep Learning, Neural Network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1EzRgb0W">
      <h4>
        <a href="https://openreview.net/forum?id=S1EzRgb0W">
          Explaining the Mistakes of Neural Networks with Latent Sympathetic Examples
        </a>
        
          <a href="https://openreview.net/pdf?id=S1EzRgb0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=riaan.zoetmulder%40student.uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="riaan.zoetmulder@student.uva.nl">Riaan Zoetmulder</a>, <a href="https://openreview.net/profile?email=egavves%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="egavves@uva.nl">Efstratios Gavves</a>, <a href="https://openreview.net/profile?email=peter.ed.oconnor%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peter.ed.oconnor@gmail.com">Peter O'Connor</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1EzRgb0W-details-125" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1EzRgb0W-details-125"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks make mistakes. The reason why a mistake is made often remains a mystery. As such neural networks often are considered a black box. It would be useful to have a method that can give an explanation that is intuitive to a user as to why an image is misclassified. In this paper we develop a method for explaining the mistakes of a classifier model by visually showing what must be added to an image such that it is correctly classified. Our work combines the fields of adversarial examples, generative modeling and a correction technique based on difference target propagation to create an technique that creates explanations of why an image is misclassified. In this paper we explain our method and demonstrate it on MNIST and CelebA. This approach could aid in demystifying neural networks for a user.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">New way of explaining why a neural network has misclassified an image</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, Adversarial Examples, Difference Target Propagation, Generative Modelling, Classifiers, Explaining, Sympathetic Examples</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1Oen--RW">
      <h4>
        <a href="https://openreview.net/forum?id=r1Oen--RW">
          The (Un)reliability of saliency methods
        </a>
        
          <a href="https://openreview.net/pdf?id=r1Oen--RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pikinder%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pikinder@google.com">Pieter-Jan Kindermans</a>, <a href="https://openreview.net/profile?email=shooker%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shooker@google.com">Sara Hooker</a>, <a href="https://openreview.net/profile?email=juliusad%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="juliusad@google.com">Julius Adebayo</a>, <a href="https://openreview.net/profile?email=kristof.schuett%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kristof.schuett@tu-berlin.de">Kristof T. Schütt</a>, <a href="https://openreview.net/profile?email=maximilian.aber%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="maximilian.aber@tu-berlin.de">Maximilian Alber</a>, <a href="https://openreview.net/profile?email=sven.daehne%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="sven.daehne@tu-berlin.de">Sven Dähne</a>, <a href="https://openreview.net/profile?email=dumitru%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dumitru@google.com">Dumitru Erhan</a>, <a href="https://openreview.net/profile?email=beenkim%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="beenkim@google.com">Been Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1Oen--RW-details-304" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1Oen--RW-details-304"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Saliency methods aim to explain the predictions of deep neural networks. These methods lack reliability when the explanation is sensitive to factors that do not contribute to the model prediction. We use a simple and common pre-processing step ---adding a mean shift to the input data--- to show that a transformation with no effect on the model can cause numerous methods to incorrectly attribute. We define input invariance as the requirement that a saliency method mirror the sensitivity of the model with respect to transformations of the input. We show, through several examples, that saliency methods that do not satisfy a input invariance property are unreliable and can lead to misleading and inaccurate attribution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Attribution can sometimes be misleading</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning interpretability, understanding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJPpHzW0-">
      <h4>
        <a href="https://openreview.net/forum?id=SJPpHzW0-">
          Influence-Directed Explanations for Deep Convolutional Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJPpHzW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=danupam%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danupam@cmu.edu">Anupam Datta</a>, <a href="https://openreview.net/profile?email=mfredrik%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mfredrik@cs.cmu.edu">Matt Fredrikson</a>, <a href="https://openreview.net/profile?email=kleino%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kleino@cs.cmu.edu">Klas Leino</a>, <a href="https://openreview.net/profile?email=ly-li14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ly-li14@mails.tsinghua.edu.cn">Linyi Li</a>, <a href="https://openreview.net/profile?email=shayaks%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shayaks@cs.cmu.edu">Shayak Sen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJPpHzW0--details-474" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJPpHzW0--details-474"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the problem of explaining a rich class of behavioral properties of deep neural networks. Our influence-directed explanations approach this problem by peering inside the network to identify neurons with high influence on the property of interest using an axiomatically justified influence measure, and then providing an interpretation for the concepts these neurons represent. We evaluate our approach by training convolutional neural networks on Pubfig, ImageNet, and Diabetic Retinopathy datasets.  Our evaluation demonstrates that influence-directed explanations (1) localize features used by the network, (2) isolate features distinguishing related instances, (3) help extract the essence of what the network learned about the class, and (4) assist in debugging misclassifications.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present an influence-directed approach to constructing explanations for the behavior of deep convolutional networks, and show how it can be used to answer a broad set of questions that could not be addressed by prior work.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep neural networks, convolutional networks, influence measures, explanations</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJhR_pxCZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJhR_pxCZ">
          Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees
        </a>
        
          <a href="https://openreview.net/pdf?id=rJhR_pxCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pquint%40cse.unl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pquint@cse.unl.edu">Eleanor Quint</a>, <a href="https://openreview.net/profile?email=gwirka%40cse.unl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gwirka@cse.unl.edu">Garrett Wirka</a>, <a href="https://openreview.net/profile?email=jwilliam%40cse.unl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwilliam@cse.unl.edu">Jacob Williams</a>, <a href="https://openreview.net/profile?email=sscott%40cse.unl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sscott@cse.unl.edu">Stephen Scott</a>, <a href="https://openreview.net/profile?email=vinod%40cse.unl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinod@cse.unl.edu">N.V. Vinodchandran</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJhR_pxCZ-details-492" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJhR_pxCZ-details-492"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">interpretable classification, decision trees, deep learning, variational autoencoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1ydPgTpW">
      <h4>
        <a href="https://openreview.net/forum?id=B1ydPgTpW">
          Predicting Auction Price of Vehicle License Plate with Deep Recurrent Neural Network
        </a>
        
          <a href="https://openreview.net/pdf?id=B1ydPgTpW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=vincichow%40cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="vincichow@cuhk.edu.hk">Vinci Chow</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1ydPgTpW-details-60" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1ydPgTpW-details-60"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In Chinese societies, superstition is of paramount importance, and vehicle license plates with desirable numbers can fetch very high prices in auctions. Unlike other valuable items, license plates are not allocated an estimated price before auction. 
      
      I propose that the task of predicting plate prices can be viewed as a natural language processing (NLP) task, as the value depends on the meaning of each individual character on the plate and its semantics. I construct a deep recurrent neural network (RNN) to predict the prices of vehicle license plates in Hong Kong, based on the characters on a plate. I demonstrate the importance of having a deep network and of retraining. Evaluated on 13 years of historical auction prices, the deep RNN's predictions can explain over 80 percent of price variations, outperforming previous models by a significant margin.  I also demonstrate how the model can be extended to become a search engine for plates and to provide estimates of the expected price distribution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Predicting auction price of vehicle license plates in Hong Kong with deep recurrent neural network, based on the characters on the plates.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">price predictions, expert system, recurrent neural networks, deep learning, natural language processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJcjQTJ0W">
      <h4>
        <a href="https://openreview.net/forum?id=HJcjQTJ0W">
          PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training
        </a>
        
          <a href="https://openreview.net/pdf?id=HJcjQTJ0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=meng_li%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="meng_li@utexas.edu">Meng Li</a>, <a href="https://openreview.net/profile?email=liangzhen.lai%40arm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liangzhen.lai@arm.com">Liangzhen Lai</a>, <a href="https://openreview.net/profile?email=naveen.suda%40arm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="naveen.suda@arm.com">Naveen Suda</a>, <a href="https://openreview.net/profile?email=vikas.chandra%40arm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vikas.chandra@arm.com">Vikas Chandra</a>, <a href="https://openreview.net/profile?email=dpan%40ece.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dpan@ece.utexas.edu">David Z. Pan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJcjQTJ0W-details-219" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJcjQTJ0W-details-219"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Massive data exist among user local platforms that usually cannot support deep neural network (DNN) training due to computation and storage resource constraints. Cloud-based training schemes provide beneficial services but suffer from potential privacy risks due to excessive user data collection. To enable cloud-based DNN training while protecting the data privacy simultaneously, we propose to leverage the intermediate representations of the data, which is achieved by splitting the DNNs and deploying them separately onto local platforms and the cloud. The local neural network (NN) is used to generate the feature representations. To avoid local training and protect data privacy, the local NN is derived from pre-trained NNs. The cloud NN is then trained based on the extracted intermediate representations for the target learning task. We validate the idea of DNN splitting by characterizing the dependency of privacy loss and classification accuracy on the local NN topology for a convolutional NN (CNN) based image classification task. Based on the characterization, we further propose PrivyNet to determine the local NN topology, which optimizes the accuracy of the target learning task under the constraints on privacy loss, local computation, and storage. The efficiency and effectiveness of PrivyNet are demonstrated with CIFAR-10 dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">To enable cloud-based DNN training while protecting the data privacy simultaneously, we propose to leverage the intermediate data representations, which is achieved by splitting the DNNs and deploying them separately onto local platforms and the cloud.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Privacy-preserving deep learning, Neural network training</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1DJFybC-">
      <h4>
        <a href="https://openreview.net/forum?id=H1DJFybC-">
          Learning to Infer Graphics Programs from Hand-Drawn Images
        </a>
        
          <a href="https://openreview.net/pdf?id=H1DJFybC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ellisk%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ellisk@mit.edu">Kevin Ellis</a>, <a href="https://openreview.net/profile?email=daniel_richie%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel_richie@brown.edu">Daniel Ritchie</a>, <a href="https://openreview.net/profile?email=asolar%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asolar@csail.mit.edu">Armando Solar-Lezama</a>, <a href="https://openreview.net/profile?email=jbt%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbt@mit.edu">Joshua B. Tenenbaum</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1DJFybC--details-136" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1DJFybC--details-136"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">  We introduce a model that learns to convert simple hand drawings
        into graphics programs written in a subset of \LaTeX.~The model
        combines techniques from deep learning and program synthesis.  We
        learn a convolutional neural network that proposes plausible drawing
        primitives that explain an image. These drawing primitives are like
        a trace of the set of primitive commands issued by a graphics
        program. We learn a model that uses program synthesis techniques to
        recover a graphics program from that trace. These programs have
        constructs like variable bindings, iterative loops, or simple kinds
        of conditionals. With a graphics program in hand, we can correct
        errors made by the deep network and extrapolate drawings.  Taken
        together these results are a step towards agents that induce useful,
        human-readable programs from perceptual input.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learn to convert a hand drawn sketch into a high-level program</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">program induction, HCI, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJWGdbbCW">
      <h4>
        <a href="https://openreview.net/forum?id=HJWGdbbCW">
          Reinforcement and Imitation Learning for Diverse Visuomotor Skills
        </a>
        
          <a href="https://openreview.net/pdf?id=HJWGdbbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yukez%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yukez@cs.stanford.edu">Yuke Zhu</a>, <a href="https://openreview.net/profile?email=ziyu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziyu@google.com">Ziyu Wang</a>, <a href="https://openreview.net/profile?email=jsmerel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsmerel@google.com">Josh Merel</a>, <a href="https://openreview.net/profile?email=andreirusu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="andreirusu@google.com">Andrei Rusu</a>, <a href="https://openreview.net/profile?email=etom%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="etom@google.com">Tom Erez</a>, <a href="https://openreview.net/profile?email=cabi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cabi@google.com">Serkan Cabi</a>, <a href="https://openreview.net/profile?email=stunya%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stunya@google.com">Saran Tunyasuvunakool</a>, <a href="https://openreview.net/profile?email=janosk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="janosk@google.com">János Kramár</a>, <a href="https://openreview.net/profile?email=raia%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raia@google.com">Raia Hadsell</a>, <a href="https://openreview.net/profile?email=nandodefreitas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nandodefreitas@google.com">Nando de Freitas</a>, <a href="https://openreview.net/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Nicolas Heess</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJWGdbbCW-details-142" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJWGdbbCW-details-142"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a general deep reinforcement learning method and apply it to robot manipulation tasks. Our approach leverages demonstration data to assist a reinforcement learning agent in learning to solve a wide range of tasks, mainly previously unsolved. We train visuomotor policies end-to-end to learn a direct mapping from RGB camera inputs to joint velocities. Our experiments indicate that our reinforcement and imitation approach can solve contact-rich robot manipulation tasks that neither the state-of-the-art reinforcement nor imitation learning method can solve alone. We also illustrate that these policies achieved zero-shot sim2real transfer by training with large visual and dynamics variations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">combine reinforcement learning and imitation learning to solve complex robot manipulation tasks from pixels</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, imitation learning, robotics, visuomotor skills</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1FFLWWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=S1FFLWWCZ">
          LSD-Net: Look, Step and Detect for Joint Navigation and Multi-View Recognition with Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=S1FFLWWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dnarapur%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dnarapur@andrew.cmu.edu">N dinesh reddy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1FFLWWCZ-details-477" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1FFLWWCZ-details-477"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Multi-view recognition is the task of classifying an object from multi-view image sequences. Instead of using a single-view for classification, humans generally navigate around a target object to learn its multi-view representation. Motivated by this human behavior, the next best view can be learned by combining object recognition with navigation in complex environments. Since deep reinforcement learning has proven successful in navigation tasks, we propose a novel multi-task reinforcement learning framework for joint multi-view recognition and navigation. Our method uses a hierarchical action space for multi-task reinforcement learning. The framework was evaluated with an environment created from the ModelNet40 dataset. Our results show improvements on object recognition and demonstrate human-like behavior on navigation.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkmM6M_pW">
      <h4>
        <a href="https://openreview.net/forum?id=SkmM6M_pW">
          Egocentric Spatial Memory Network
        </a>
        
          <a href="https://openreview.net/pdf?id=SkmM6M_pW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=a0091624%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="a0091624@u.nus.edu">Mengmi Zhang</a>, <a href="https://openreview.net/profile?email=makt%40i2r.a-star.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="makt@i2r.a-star.edu.sg">Keng Teck Ma</a>, <a href="https://openreview.net/profile?email=joohwee%40i2r.a-star.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="joohwee@i2r.a-star.edu.sg">Joo Hwee Lim</a>, <a href="https://openreview.net/profile?email=shihcheng%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="shihcheng@nus.edu.sg">Shih-Cheng Yen</a>, <a href="https://openreview.net/profile?email=qzhao%40cs.umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qzhao@cs.umn.edu">Qi Zhao</a>, <a href="https://openreview.net/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkmM6M_pW-details-444" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkmM6M_pW-details-444"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Inspired by neurophysiological discoveries of navigation cells in the mammalian
      brain, we introduce the first deep neural network architecture for modeling Egocentric
      Spatial Memory (ESM). It learns to estimate the pose of the agent and
      progressively construct top-down 2D global maps from egocentric views in a spatially
      extended environment. During the exploration, our proposed ESM network
      model updates belief of the global map based on local observations using a recurrent
      neural network. It also augments the local mapping with a novel external
      memory to encode and store latent representations of the visited places based on
      their corresponding locations in the egocentric coordinate. This enables the agents
      to perform loop closure and mapping correction. This work contributes in the
      following aspects: first, our proposed ESM network provides an accurate mapping
      ability which is vitally important for embodied agents to navigate to goal locations.
      In the experiments, we demonstrate the functionalities of the ESM network in
      random walks in complicated 3D mazes by comparing with several competitive
      baselines and state-of-the-art Simultaneous Localization and Mapping (SLAM)
      algorithms. Secondly, we faithfully hypothesize the functionality and the working
      mechanism of navigation cells in the brain. Comprehensive analysis of our model
      suggests the essential role of individual modules in our proposed architecture and
      demonstrates efficiency of communications among these modules. We hope this
      work would advance research in the collaboration and communications over both
      fields of computer science and computational neuroscience.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">first deep neural network for modeling Egocentric Spatial Memory inspired by neurophysiological discoveries of navigation cells in mammalian brain</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">spatial memory, egocentric vision, deep neural network, navigation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJqfKPJ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rJqfKPJ0Z">
          Clipping Free Attacks Against Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJqfKPJ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=boussad.addad%40thalesgroup.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boussad.addad@thalesgroup.com">Boussad ADDAD</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJqfKPJ0Z-details-220" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJqfKPJ0Z-details-220"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">During the last years, a remarkable breakthrough has been made in AI domain
      thanks to artificial deep neural networks that achieved a great success in many
      machine learning tasks in computer vision, natural language processing, speech
      recognition, malware detection and so on. However, they are highly vulnerable
      to easily crafted adversarial examples. Many investigations have pointed out this
      fact and different approaches have been proposed to generate attacks while adding
      a limited perturbation to the original data. The most robust known method so far
      is the so called C&amp;W attack [1]. Nonetheless, a countermeasure known as fea-
      ture squeezing coupled with ensemble defense showed that most of these attacks
      can be destroyed [6]. In this paper, we present a new method we call Centered
      Initial Attack (CIA) whose advantage is twofold : first, it insures by construc-
      tion the maximum perturbation to be smaller than a threshold fixed beforehand,
      without the clipping process that degrades the quality of attacks. Second, it is
      robust against recently introduced defenses such as feature squeezing, JPEG en-
      coding and even against a voting ensemble of defenses. While its application is
      not limited to images, we illustrate this using five of the current best classifiers
      on ImageNet dataset among which two are adversarialy retrained on purpose to
      be robust against attacks. With a fixed maximum perturbation of only 1.5% on
      any pixel, around 80% of attacks (targeted) fool the voting ensemble defense and
      nearly 100% when the perturbation is only 6%. While this shows how it is difficult
      to defend against CIA attacks, the last section of the paper gives some guidelines
      to limit their impact.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> In this paper, a new method we call Centered Initial Attack (CIA) is provided. It insures by construction the maximum perturbation to be smaller than a threshold fixed beforehand, without the clipping process.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial examples, Neural Networks, Clipping</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByCPHrgCW">
      <h4>
        <a href="https://openreview.net/forum?id=ByCPHrgCW">
          Deep Learning Inferences with Hybrid Homomorphic Encryption
        </a>
        
          <a href="https://openreview.net/pdf?id=ByCPHrgCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anthonymeehan%40anthonymeehan.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anthonymeehan@anthonymeehan.com">Anthony Meehan</a>, <a href="https://openreview.net/profile?email=ryan.ko%40waikato.ac.nz" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryan.ko@waikato.ac.nz">Ryan K L Ko</a>, <a href="https://openreview.net/profile?email=geoff%40waikato.ac.nz" class="profile-link" data-toggle="tooltip" data-placement="top" title="geoff@waikato.ac.nz">Geoff Holmes</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByCPHrgCW-details-706" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByCPHrgCW-details-706"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.
      
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, homomorphic encryption, hybrid homomorphic encryption, privacy preserving, representation learning, neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1u8fMW0b">
      <h4>
        <a href="https://openreview.net/forum?id=H1u8fMW0b">
          Toward predictive machine learning for active vision
        </a>
        
          <a href="https://openreview.net/pdf?id=H1u8fMW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=emmanuel.dauce%40centrale-marseille.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="emmanuel.dauce@centrale-marseille.fr">Emmanuel Daucé</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1u8fMW0b-details-515" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1u8fMW0b-details-515"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We develop a comprehensive description of the active inference framework, as proposed by Friston (2010), under a machine-learning compliant perspective. Stemming from a biological inspiration and the auto-encoding principles, a sketch of a cognitive architecture is proposed that should provide ways to implement estimation-oriented control policies.  Computer simulations illustrate the effectiveness of the approach through a foveated inspection of the input data. The pros and cons of the control policy are analyzed in detail, showing interesting promises in terms of processing compression. Though optimizing future posterior entropy over the actions set is shown enough to attain locally optimal action selection, offline calculation using class-specific saliency maps is shown better for it saves processing costs through saccades pathways pre-processing, with a negligible effect on the recognition/compression rates. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Pros and cons of saccade-based computer vision under a predictive coding perspective</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">active inference, predictive coding, motor control</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1ayG7WRZ">
      <h4>
        <a href="https://openreview.net/forum?id=r1ayG7WRZ">
          Don't encrypt the data; just approximate the model \ Towards Secure Transaction and Fair Pricing of Training Data
        </a>
        
          <a href="https://openreview.net/pdf?id=r1ayG7WRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xxu%40hmc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xxu@hmc.edu">Xinlei Xu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1ayG7WRZ-details-403" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1ayG7WRZ-details-403"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">As machine learning becomes ubiquitous, deployed systems need to be as accu- rate as they can. As a result, machine learning service providers have a surging need for useful, additional training data that benefits training, without giving up all the details about the trained program. At the same time, data owners would like to trade their data for its value, without having to first give away the data itself be- fore receiving compensation. It is difficult for data providers and model providers to agree on a fair price without first revealing the data or the trained model to the other side. Escrow systems only complicate this further, adding an additional layer of trust required of both parties. Currently, data owners and model owners don’t have a fair pricing system that eliminates the need to trust a third party and training the model on the data, which 1) takes a long time to complete, 2) does not guarantee that useful data is paid valuably and that useless data isn’t, without trusting in the third party with both the model and the data. Existing improve- ments to secure the transaction focus heavily on encrypting or approximating the data, such as training on encrypted data, and variants of federated learning. As powerful as the methods appear to be, we show them to be impractical in our use case with real world assumptions for preserving privacy for the data owners when facing black-box models. Thus, a fair pricing scheme that does not rely on secure data encryption and obfuscation is needed before the exchange of data. This pa- per proposes a novel method for fair pricing using data-model efficacy techniques such as influence functions, model extraction, and model compression methods, thus enabling secure data transactions. We successfully show that without running the data through the model, one can approximate the value of the data; that is, if the data turns out redundant, the pricing is minimal, and if the data leads to proper improvement, its value is properly assessed, without placing strong assumptions on the nature of the model. Future work will be focused on establishing a system with stronger transactional security against adversarial attacks that will reveal details about the model or the data to the other party.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Facing complex, black-box models, encrypting the data is not as usable as approximating the model and using it to price a potential transaction.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Applications, Security in Machine Learning, Fairness and Security, Model Compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1BHbmWCZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1BHbmWCZ">
          TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING
        </a>
        
          <a href="https://openreview.net/pdf?id=H1BHbmWCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aaa2cn%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaa2cn@virginia.edu">Ahmed A Aly</a>, <a href="https://openreview.net/profile?email=jbd%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbd@virginia.edu">Joanne Bechta Dugan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1BHbmWCZ-details-489" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1BHbmWCZ-details-489"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">3 thrusts serving as stepping stones for robot experiential learning of vision module</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Robotics, Artificial Intelligence, Computer Vision</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyhcXjy0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SyhcXjy0Z">
          APPLICATION OF DEEP CONVOLUTIONAL NEURAL NETWORK TO PREVENT ATM FRAUD BY FACIAL DISGUISE IDENTIFICATION
        </a>
        
          <a href="https://openreview.net/pdf?id=SyhcXjy0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kothawadesuraj%40sggs.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="kothawadesuraj@sggs.ac.in">Suraj Nandkishor Kothawade</a>, <a href="https://openreview.net/profile?email=tamgalesumit%40sggs.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="tamgalesumit@sggs.ac.in">Sumit Baburao Tamgale</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyhcXjy0Z-details-450" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyhcXjy0Z-details-450"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The paper proposes and demonstrates a Deep Convolutional Neural Network (DCNN) architecture to identify users with disguised face attempting a fraudulent ATM transaction. The recent introduction of Disguised Face Identification (DFI) framework proves the applicability of deep neural networks for this very problem. All the ATMs nowadays incorporate a hidden camera in them and capture the footage of their users. However, it is impossible for the police to track down the impersonators with disguised faces from the ATM footage. The proposed deep convolutional neural network is trained to identify, in real time, whether the user in the captured image is trying to cloak his identity or not. The output of the DCNN is then reported to the ATM to take appropriate steps and prevent the swindler from completing the transaction. The network is trained using a dataset of images captured in similar situations as of an ATM. The comparatively low background clutter in the images enables the network to demonstrate high accuracy in feature extraction and classification for all the different disguises.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Proposed System can prevent impersonators with facial disguises from completing a fraudulent transaction using a pre-trained DCNN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Convolutional Neural Network, Disguised Face Identification, Fraudulent Transaction, ATM, Impersonation;</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkGcX--0-">
      <h4>
        <a href="https://openreview.net/forum?id=HkGcX--0-">
          Auxiliary Guided Autoregressive Variational Autoencoders
        </a>
        
          <a href="https://openreview.net/pdf?id=HkGcX--0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=thomas.lucas%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.lucas@inria.fr">Thomas Lucas</a>, <a href="https://openreview.net/profile?email=jakob.verbeek%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jakob.verbeek@inria.fr">Jakob Verbeek</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkGcX--0--details-317" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkGcX--0--details-317"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative modeling of high-dimensional data is a key problem in machine learning. Successful approaches include latent variable models and autoregressive models. The complementary strengths of these approaches,  to model global and local image statistics respectively, suggest hybrid models combining the strengths of both models. Our contribution is to train such hybrid models using an auxiliary loss function that controls which information is captured by the latent variables and what is left to the autoregressive decoder. In contrast, prior work on such hybrid models needed to limit the capacity of the autoregressive decoder to prevent degenerate models that ignore the latent variables and only rely on autoregressive modeling. Our approach results in models with meaningful latent variable representations, and which rely on powerful autoregressive decoders to model image details. Our model generates qualitatively convincing samples, and yields state-of-the-art quantitative results.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxqZngC-">
      <h4>
        <a href="https://openreview.net/forum?id=SkxqZngC-">
          A Bayesian Nonparametric Topic Model with Variational Auto-Encoders
        </a>
        
          <a href="https://openreview.net/pdf?id=SkxqZngC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=foxdoraame%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="foxdoraame@gmail.com">Xuefei Ning</a>, <a href="https://openreview.net/profile?email=yzheng3xg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzheng3xg@gmail.com">Yin Zheng</a>, <a href="https://openreview.net/profile?email=zjiang9310%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zjiang9310@gmail.com">Zhuxi Jiang</a>, <a href="https://openreview.net/profile?email=yu-wang%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yu-wang@mail.tsinghua.edu.cn">Yu Wang</a>, <a href="https://openreview.net/profile?email=yanghz%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanghz@tsinghua.edu.cn">Huazhong Yang</a>, <a href="https://openreview.net/profile?email=joehhuang%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joehhuang@tencent.com">Junzhou Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkxqZngC--details-755" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxqZngC--details-755"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Topic modeling of text documents is one of the most important tasks in representation learning. In this work, we propose iTM-VAE, which is a Bayesian nonparametric (BNP) topic model with variational auto-encoders. On one hand, as a BNP topic model, iTM-VAE potentially has infinite topics and can adapt the topic number to data automatically. On the other hand, different with the other BNP topic models, the inference of iTM-VAE is modeled by neural networks, which has rich representation capacity and can be computed in a simple feed-forward manner. Two variants of iTM-VAE are also proposed in this paper, where iTM-VAE-Prod models the generative process in products-of-experts fashion for better performance and iTM-VAE-G places a prior over the concentration parameter such that the model can adapt a suitable concentration parameter to data automatically. Experimental results on 20News and Reuters RCV1-V2 datasets show that the proposed models outperform the state-of-the-arts in terms of perplexity, topic coherence and document retrieval tasks. Moreover, the ability of adjusting the concentration parameter to data is also confirmed by experiments.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A Bayesian Nonparametric Topic Model with Variational Auto-Encoders which achieves the state-of-the-arts on public benchmarks in terms of perplexity, topic coherence and retrieval tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">topic model, Bayesian nonparametric, variational auto-encoder, document modeling</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJSVuReCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJSVuReCZ">
          SHADE: SHAnnon DEcay Information-Based Regularization for Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=SJSVuReCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=michael.blot%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.blot@lip6.fr">Michael Blot</a>, <a href="https://openreview.net/profile?email=thomas.robert%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.robert@lip6.fr">Thomas Robert</a>, <a href="https://openreview.net/profile?email=nicolas.thome%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicolas.thome@lip6.fr">Nicolas Thome</a>, <a href="https://openreview.net/profile?email=matthieu.cord%40lip6.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthieu.cord@lip6.fr">Matthieu Cord</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJSVuReCZ-details-983" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJSVuReCZ-details-983"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Regularization is a big issue for training deep neural networks. In this paper, we propose a new information-theory-based regularization scheme named SHADE for SHAnnon DEcay. The originality of the approach is to define a prior based on conditional entropy, which explicitly decouples the learning of invariant representations in the regularizer and the learning of correlations between inputs and labels in the data fitting term. We explain why this quantity makes our model able to achieve invariance with respect to input variations. We empirically validate the efficiency of our approach to improve classification performances compared to standard regularization schemes on several standard architectures.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJ3dBGZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=SJ3dBGZ0Z">
          LSH Softmax: Sub-Linear Learning and Inference of the Softmax Layer in Deep Architectures
        </a>
        
          <a href="https://openreview.net/pdf?id=SJ3dBGZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=danilevy%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danilevy@cs.stanford.edu">Daniel Levy</a>, <a href="https://openreview.net/profile?email=taineleau%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taineleau@gmail.com">Danlu Chan</a>, <a href="https://openreview.net/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJ3dBGZ0Z-details-81" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJ3dBGZ0Z-details-81"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Log-linear models models are widely used in machine learning, and in particular are ubiquitous in deep learning architectures in the form of the softmax. While exact inference and learning of these requires linear time, it can be done approximately in sub-linear time with strong concentrations guarantees. In this work, we present LSH Softmax, a method to perform sub-linear learning and inference of the softmax layer in the deep learning setting. Our method relies on the popular Locality-Sensitive Hashing to build a well-concentrated gradient estimator, using nearest neighbors and uniform samples. We also present an inference scheme in sub-linear time for LSH Softmax using the Gumbel distribution. On language modeling, we show that Recurrent Neural Networks trained with LSH Softmax perform on-par with computing the exact softmax while requiring sub-linear computations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">we present LSH Softmax, a softmax approximation layer for sub-linear learning and inference with strong theoretical guarantees; we showcase both its applicability and efficiency by evaluating on a real-world task: language modeling.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">LSH, softmax, deep, learning, sub, linear, efficient, GPU</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJRxfZbAW">
      <h4>
        <a href="https://openreview.net/forum?id=BJRxfZbAW">
          The Context-Aware Learner
        </a>
        
          <a href="https://openreview.net/pdf?id=BJRxfZbAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=conor.durkan%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="conor.durkan@ed.ac.uk">Conor Durkan</a>, <a href="https://openreview.net/profile?email=a.storkey%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.storkey@ed.ac.uk">Amos Storkey</a>, <a href="https://openreview.net/profile?email=h.l.edwards%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="h.l.edwards@sms.ed.ac.uk">Harrison Edwards</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJRxfZbAW-details-723" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJRxfZbAW-details-723"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">One important aspect of generalization in machine learning involves reasoning about previously seen data in new settings. Such reasoning requires learning disentangled representations of data which are interpretable in isolation, but can also be combined in a new, unseen scenario. To this end, we introduce the context-aware learner, a model based on the variational autoencoding framework, which can learn such representations across data sets exhibiting a number of distinct contexts. Moreover, it is successfully able to combine these representations to generate data not seen at training time. The model enjoys an exponential increase in representational ability for a linear increase in context count. We demonstrate that the theory readily extends to a meta-learning setting such as this, and describe a fully unsupervised model in complete generality. Finally, we validate our approach using an adaptation with weak supervision.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkPCrEZ0Z">
      <h4>
        <a href="https://openreview.net/forum?id=HkPCrEZ0Z">
          Combining Model-based and Model-free RL via Multi-step Control Variates
        </a>
        
          <a href="https://openreview.net/pdf?id=HkPCrEZ0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=gerryche%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gerryche@berkeley.edu">Tong Che</a>, <a href="https://openreview.net/profile?email=luyuchen.paul%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="luyuchen.paul@gmail.com">Yuchen Lu</a>, <a href="https://openreview.net/profile?email=gjt%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gjt@google.com">George Tucker</a>, <a href="https://openreview.net/profile?email=sbhupatiraju%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sbhupatiraju@google.com">Surya Bhupatiraju</a>, <a href="https://openreview.net/profile?email=shanegu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shanegu@google.com">Shane Gu</a>, <a href="https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>, <a href="https://openreview.net/profile?email=bengioy%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengioy@iro.umontreal.ca">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkPCrEZ0Z-details-992" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkPCrEZ0Z-details-992"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Model-free deep reinforcement learning algorithms are able to successfully solve a wide range of continuous control tasks, but typically require many on-policy samples to achieve good performance. Model-based RL algorithms are sample-efficient on the other hand, while learning accurate global models of complex dynamic environments has turned out to be tricky in practice, which leads to the unsatisfactory performance of the learned policies. In this work, we combine the sample-efficiency of model-based algorithms and the accuracy of model-free algorithms. We leverage multi-step neural network based predictive models by embedding real trajectories into imaginary rollouts of the model, and use the imaginary cumulative rewards as control variates for model-free algorithms. In this way, we achieved the strengths of both sides and derived an estimator which is not only sample-efficient, but also unbiased and of very low variance. We present our evaluation on the MuJoCo and OpenAI Gym benchmarks. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkZ-BnyCW">
      <h4>
        <a href="https://openreview.net/forum?id=SkZ-BnyCW">
          Learning Deep Generative Models With Discrete Latent Variables
        </a>
        
          <a href="https://openreview.net/pdf?id=SkZ-BnyCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hengyuah%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hengyuah@andrew.cmu.edu">Hengyuan Hu</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkZ-BnyCW-details-817" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkZ-BnyCW-details-817"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">There have been numerous recent advancements on learning deep generative models with latent variables thanks to the reparameterization trick that allows to train deep directed models effectively.  However, since reparameterization trick only works on continuous variables, deep generative models with discrete latent variables still remain hard to train and perform considerably worse than their continuous counterparts. In this paper, we attempt to shrink this gap by introducing a new architecture and its learning procedure.  We develop a hybrid generative model with binary latent variables that consists of an undirected graphical model and a deep neural network. We propose an efficient two-stage pretraining and training procedure that is crucial for learning these models. Experiments on binarized digits and images of natural scenes demonstrate that our model achieves close to the state-of-the-art performance in terms of density estimation and is capable of generating coherent images of natural scenes.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep generative models, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkbmWqxCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HkbmWqxCZ">
          The Mutual Autoencoder: Controlling Information in Latent Code Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=HkbmWqxCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bphuong%40ist.ac.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="bphuong@ist.ac.at">Mary Phuong</a>, <a href="https://openreview.net/profile?email=m.welling%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.welling@uva.nl">Max Welling</a>, <a href="https://openreview.net/profile?email=nkushman%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nkushman@microsoft.com">Nate Kushman</a>, <a href="https://openreview.net/profile?email=ryoto%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryoto@microsoft.com">Ryota Tomioka</a>, <a href="https://openreview.net/profile?email=sebastian.nowozin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.nowozin@microsoft.com">Sebastian Nowozin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkbmWqxCZ-details-257" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkbmWqxCZ-details-257"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Variational autoencoders (VAE) learn probabilistic latent variable models by optimizing a bound on the marginal likelihood of the observed data. Beyond providing a good density model a VAE model assigns to each data instance a latent code. In many applications, this latent code provides a useful high-level summary of the observation. However, the VAE may fail to learn a useful representation when the decoder family is very expressive. This is because maximum likelihood does not explicitly encourage useful representations and the latent variable is used only if it helps model the marginal distribution. This makes representation learning with VAEs unreliable. To address this issue, we propose a method for explicitly controlling the amount of information stored in the latent code. Our method can learn codes ranging from independent to nearly deterministic while benefiting from decoder capacity. Thus, we decouple the choice of decoder capacity and the latent code dimensionality from the amount of information stored in the code.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryb83alCZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryb83alCZ">
          Towards Unsupervised Classification with Deep Generative Models
        </a>
        
          <a href="https://openreview.net/pdf?id=ryb83alCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dkal%40iti.gr" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkal@iti.gr">Dimitris Kalatzis</a>, <a href="https://openreview.net/profile?email=ntina_kotta%40yahoo.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ntina_kotta@yahoo.com">Konstantia Kotta</a>, <a href="https://openreview.net/profile?email=kalamar%40iti.gr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kalamar@iti.gr">Ilias Kalamaras</a>, <a href="https://openreview.net/profile?email=anasvaf%40iti.gr" class="profile-link" data-toggle="tooltip" data-placement="top" title="anasvaf@iti.gr">Anastasios Vafeiadis</a>, <a href="https://openreview.net/profile?email=a.c.rawstron%40leeds.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.c.rawstron@leeds.ac.uk">Andrew Rawstron</a>, <a href="https://openreview.net/profile?email=dimitrios.tzovaras%40iti.gr" class="profile-link" data-toggle="tooltip" data-placement="top" title="dimitrios.tzovaras@iti.gr">Dimitris Tzovaras</a>, <a href="https://openreview.net/profile?email=kostas.stamatopoulos%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kostas.stamatopoulos@gmail.com">Kostas Stamatopoulos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryb83alCZ-details-571" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryb83alCZ-details-571"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep generative models have advanced the state-of-the-art in semi-supervised classification, however their capacity for deriving useful discriminative features in a completely unsupervised fashion for classification in difficult real-world data sets, where adequate manifold separation is required has not been adequately explored. Most methods rely on defining a pipeline of deriving features via generative modeling and then applying clustering algorithms, separating the modeling and discriminative processes. We propose a deep hierarchical generative model which uses a mixture of discrete and continuous distributions to learn to effectively separate the different data manifolds and is trainable end-to-end. We show that by specifying the form of the discrete variable distribution we are imposing a specific structure on the model's latent representations. We test our model's discriminative performance on the task of CLL diagnosis against baselines from the field of computational FC, as well as the Variational Autoencoder literature.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Unsupervised classification via deep generative modeling with controllable feature learning evaluated in a difficult real world task</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">variational inference, vae, variational autoencoders, generative modeling, representation learning, classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkERSm-0-">
      <h4>
        <a href="https://openreview.net/forum?id=SkERSm-0-">
          Preliminary theoretical troubleshooting in Variational Autoencoder
        </a>
        
          <a href="https://openreview.net/pdf?id=SkERSm-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=liushiqi%40stu.xjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liushiqi@stu.xjtu.edu.cn">Shiqi Liu</a>, <a href="https://openreview.net/profile?email=dymeng%40mail.xjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dymeng@mail.xjtu.edu.cn">Qian Zhao</a>, <a href="https://openreview.net/profile?email=timmy.zhaoqian%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="timmy.zhaoqian@gmail.com">Xiangyong Cao</a>, <a href="https://openreview.net/profile?email=460376821%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="460376821@qq.com">Deyu Meng</a>, <a href="https://openreview.net/profile?email=1030884089%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="1030884089@qq.com">Zilu Ma</a>, <a href="https://openreview.net/profile?email=602077855%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="602077855@qq.com">Tao Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 27 Mar 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkERSm-0--details-535" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkERSm-0--details-535"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">What would be learned by variational autoencoder(VAE) and what influence the disentanglement of VAE? This paper tries to preliminarily address VAE's intrinsic dimension, real factor, disentanglement and indicator issues theoretically in the idealistic situation and implementation issue practically through noise modeling perspective in the realistic case.  On intrinsic dimension issue, due to information conservation, the idealistic VAE learns and only learns intrinsic factor dimension. Besides, suggested by mutual information separation property, the constraint induced by Gaussian prior to the VAE objective encourages the information sparsity in dimension. On disentanglement issue,   subsequently, inspired by information conservation theorem the clarification on disentanglement in this paper is made. On real factor issue, due to factor equivalence, the idealistic VAE possibly learns any factor set in the equivalence class.  On indicator issue, the behavior of current disentanglement metric is discussed, and several performance indicators regarding the disentanglement and generating influence are subsequently raised to evaluate the performance of VAE model and to supervise the used factors. On implementation issue, the experiments under noise modeling and constraints empirically testify the theoretical analysis and also show their own characteristic in pursuing disentanglement.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper tries to preliminarily address the disentanglement theoretically in the idealistic situation and practically through noise modelling perspective in the realistic case.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">variational autoencoder, information theory, noise modelling, representation learning, generative model, disentanglement</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1kj4ACp-">
      <h4>
        <a href="https://openreview.net/forum?id=r1kj4ACp-">
          Understanding Deep Learning Generalization by Maximum Entropy
        </a>
        
          <a href="https://openreview.net/pdf?id=r1kj4ACp-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhenggh%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhenggh@mail.ustc.edu.cn">Guanhua Zheng</a>, <a href="https://openreview.net/profile?email=jtsang%40bjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jtsang@bjtu.edu.cn">Jitao Sang</a>, <a href="https://openreview.net/profile?email=csxu%40nlpr.ia.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="csxu@nlpr.ia.ac.cn">Changsheng Xu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1kj4ACp--details-745" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1kj4ACp--details-745"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning achieves remarkable generalization capability with overwhelming number of model parameters. Theoretical understanding of deep learning generalization receives recent attention yet remains not fully explored. This paper attempts to provide an alternative understanding from the perspective of maximum entropy. We first derive two feature conditions that softmax regression strictly apply maximum entropy principle. DNN is then regarded as approximating the feature conditions with multilayer feature learning, and proved to be a recursive solution towards maximum entropy principle. The connection between DNN and maximum entropy well explains why typical designs such as shortcut and regularization improves model generalization, and provides instructions for future model development.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove that DNN is a recursively approximated solution to the maximum entropy principle.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">generalization, maximum entropy, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1X4DWWRb">
      <h4>
        <a href="https://openreview.net/forum?id=B1X4DWWRb">
          Learning Weighted Representations for Generalization Across Designs
        </a>
        
          <a href="https://openreview.net/pdf?id=B1X4DWWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=fredrikj%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fredrikj@mit.edu">Fredrik D. Johansson</a>, <a href="https://openreview.net/profile?email=kallus%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kallus@cornell.edu">Nathan Kallus</a>, <a href="https://openreview.net/profile?email=urish22%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="urish22@gmail.com">Uri Shalit</a>, <a href="https://openreview.net/profile?email=dsontag%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dsontag@csail.mit.edu">David Sontag</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1X4DWWRb-details-619" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1X4DWWRb-details-619"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Distributional shift, causal effects, domain adaptation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ4IhxZAb">
      <h4>
        <a href="https://openreview.net/forum?id=HJ4IhxZAb">
          Meta-Learning Transferable Active Learning Policies by Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ4IhxZAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=k.pang%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="k.pang@ed.ac.uk">Kunkun Pang</a>, <a href="https://openreview.net/profile?email=mingzhi.dong.13%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingzhi.dong.13@ucl.ac.uk">Mingzhi Dong</a>, <a href="https://openreview.net/profile?email=t.hospedales%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="t.hospedales@ed.ac.uk">Timothy Hospedales</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ4IhxZAb-details-265" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ4IhxZAb-details-265"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Active learning (AL) aims to enable training high performance classifiers with low annotation cost by predicting which subset of unlabelled instances would be most beneficial to label. The importance of AL has motivated extensive research, proposing a wide variety of manually designed AL algorithms with diverse theoretical and intuitive motivations. In contrast to this body of research, we propose to treat active learning algorithm design as a meta-learning problem and learn the best criterion from data. We model an active learning algorithm as a deep neural network that inputs the base learner state and the unlabelled point set and predicts the best point to annotate next. Training this active query policy network with reinforcement learning, produces the best non-myopic policy for a given dataset. The key challenge in achieving a general solution to AL then becomes that of learner generalisation, particularly across heterogeneous datasets. We propose a multi-task dataset-embedding approach that allows dataset-agnostic active learners to be trained. Our evaluation shows that AL algorithms trained in this way can directly generalize across diverse problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Active Learning, Deep Reinforcement Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SktLlGbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=SktLlGbRZ">
          CyCADA: Cycle-Consistent Adversarial Domain Adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=SktLlGbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jhoffman%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jhoffman@eecs.berkeley.edu">Judy Hoffman</a>, <a href="https://openreview.net/profile?email=etzeng%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="etzeng@eecs.berkeley.edu">Eric Tzeng</a>, <a href="https://openreview.net/profile?email=taesung_park%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="taesung_park@berkeley.edu">Taesung Park</a>, <a href="https://openreview.net/profile?email=junyanz%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junyanz@berkeley.edu">Jun-Yan Zhu</a>, <a href="https://openreview.net/profile?email=isola%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="isola@eecs.berkeley.edu">Phillip Isola</a>, <a href="https://openreview.net/profile?email=saenko%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saenko@bu.edu">Kate Saenko</a>, <a href="https://openreview.net/profile?email=efros%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="efros@eecs.berkeley.edu">Alyosha Efros</a>, <a href="https://openreview.net/profile?email=trevor%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="trevor@eecs.berkeley.edu">Trevor Darrell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SktLlGbRZ-details-182" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SktLlGbRZ-details-182"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Domain adaptation is critical for success in new, unseen environments.
      Adversarial adaptation models applied in feature spaces discover domain invariant representations, but are difficult to visualize and sometimes fail to capture pixel-level and low-level domain shifts.
      Recent work has shown that generative adversarial networks combined with cycle-consistency constraints are surprisingly effective at  mapping images between domains, even without the use of aligned image pairs.
      We propose a novel discriminatively-trained Cycle-Consistent Adversarial Domain Adaptation model.
      CyCADA adapts representations at both the pixel-level and feature-level, enforces cycle-consistency while leveraging a task loss, and does not require aligned pairs.  Our model can be applied in a variety of visual recognition and prediction settings.
      We show new state-of-the-art results across multiple adaptation tasks, including digit classification and semantic segmentation of road scenes demonstrating transfer from synthetic to real world domains.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An unsupervised domain adaptation approach which adapts at both the pixel and feature levels</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">domain adaptation, unsupervised learning, classification, semantic segmentation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyhRVm-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=SyhRVm-Rb">
          Automatic Goal Generation for Reinforcement Learning Agents
        </a>
        
          <a href="https://openreview.net/pdf?id=SyhRVm-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dheld%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dheld@andrew.cmu.edu">David Held</a>, <a href="https://openreview.net/profile?email=young.geng%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="young.geng@berkeley.edu">Xinyang Geng</a>, <a href="https://openreview.net/profile?email=florensa%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="florensa@berkeley.edu">Carlos Florensa</a>, <a href="https://openreview.net/profile?email=pabbeel%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@berkeley.edu">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>23 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyhRVm-Rb-details-521" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyhRVm-Rb-details-521"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement learning (RL) is a powerful technique to train an agent to perform a task.  However, an agent that is trained using RL is only capable of achieving the single task that is specified via its reward function.   Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks, such as navigating to varying positions in a room or moving objects to varying locations.  Instead, we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing in its environment.  We use a generator network to propose tasks for the agent to try to achieve, each task being specified as reaching a certain parametrized subset of the state-space.  The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent.  Our method thus automatically produces a curriculum of tasks for the agent to learn.  We show that, by using this framework, an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment (Videos and code available at: https://sites.google.com/view/goalgeneration4rl). Our method can also learn to achieve tasks with sparse rewards, which pose significant challenges for traditional RL methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We efficiently solve multi-task problems with an automatic curriculum generation algorithm based on a generative model that tracks the learning agent's performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Multi-task Learning, Curriculum Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryj0790hb">
      <h4>
        <a href="https://openreview.net/forum?id=ryj0790hb">
          Incremental Learning through Deep Adaptation
        </a>
        
          <a href="https://openreview.net/pdf?id=ryj0790hb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amir.rosenfeld%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amir.rosenfeld@gmail.com">Amir Rosenfeld</a>, John K. Tsotsos
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryj0790hb-details-20" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryj0790hb-details-20"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Given an existing trained neural network, it is often desirable to learn new capabilities without hindering performance of those already learned. Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added task, typically as many as the original network. We propose a method called Deep Adaptation Networks (DAN) that constrains newly learned filters to be linear combinations of existing ones. DANs preserve performance on the original task, require a fraction (typically 13%) of the number of parameters compared to standard fine-tuning procedures and converge in less cycles of training to a comparable or better level of performance. When coupled with standard network quantization techniques, we further reduce the parameter cost to around 3% of the original with negligible or no loss in accuracy. The learned architecture can be controlled to switch between various learned representations, enabling a single network to solve a task from multiple different domains. We conduct extensive experiments showing the effectiveness of our method on a range of image classification tasks and explore different aspects of its behavior.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An alternative to transfer learning that learns faster, requires much less parameters (3-13 %), usually achieves better results and precisely preserves performance on old tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Transfer Learning, Learning without forgetting, Multitask Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1DPFCyA-">
      <h4>
        <a href="https://openreview.net/forum?id=r1DPFCyA-">
          Discriminative k-shot learning using probabilistic models
        </a>
        
          <a href="https://openreview.net/pdf?id=r1DPFCyA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=msb55%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="msb55@cam.ac.uk">Matthias Bauer</a>, <a href="https://openreview.net/profile?email=mrojascarulla%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mrojascarulla@gmail.com">Mateo Rojas-Carulla</a>, <a href="https://openreview.net/profile?email=kuba.swiatkowski%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kuba.swiatkowski@gmail.com">Jakub Bartłomiej Świątkowski</a>, <a href="https://openreview.net/profile?email=bs%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tuebingen.mpg.de">Bernhard Schölkopf</a>, <a href="https://openreview.net/profile?email=ret26%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ret26@cam.ac.uk">Richard E. Turner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1DPFCyA--details-639" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1DPFCyA--details-639"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces a probabilistic framework for k-shot image classification. The goal is to generalise from an initial large-scale classification task to a separate task comprising new  classes and small numbers of examples. The new approach not only leverages the feature-based representation learned by a neural network from the initial task (representational transfer), but also information about the classes (concept transfer). The concept information is encapsulated in a probabilistic model for the final layer weights of the neural network which acts as a prior for probabilistic k-shot learning. We show that even a simple probabilistic model achieves state-of-the-art on a standard k-shot learning dataset by a large margin. Moreover, it is able to accurately model uncertainty, leading to well calibrated classifiers, and is easily extensible and flexible, unlike many recent approaches to k-shot learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper introduces a probabilistic framework for k-shot image classification that achieves state-of-the-art results</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">discriminative k-shot learning, probabilistic inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeZRGbRW">
      <h4>
        <a href="https://openreview.net/forum?id=rkeZRGbRW">
          Variance Regularizing Adversarial Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rkeZRGbRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=karanraj.grewal%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="karanraj.grewal@mail.utoronto.ca">Karan Grewal</a>, <a href="https://openreview.net/profile?email=erroneus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="erroneus@gmail.com">R Devon Hjelm</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkeZRGbRW-details-103" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeZRGbRW-details-103"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study how, in generative adversarial networks, variance in the discriminator's output affects the generator's ability to learn the data distribution. In particular, we contrast the results from various well-known techniques for training GANs when the discriminator is near-optimal and updated multiple times per update to the generator. As an alternative, we propose an additional method to train GANs by explicitly modeling the discriminator's output as a bi-modal Gaussian distribution over the real/fake indicator variables. In order to do this, we train the Gaussian classifier to match the target bi-modal distribution implicitly through meta-adversarial training. We observe that our new method, when trained together with a strong discriminator, provides meaningful, non-vanishing gradients.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce meta-adversarial learning, a new technique to regularize GANs, and propose a training method by explicitly controlling the discriminator's output distribution.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Generative Adversarial Network, Integral Probability Metric, Meta-Adversarial Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1BO9M-0Z">
      <h4>
        <a href="https://openreview.net/forum?id=H1BO9M-0Z">
          Lifelong Word Embedding via Meta-Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=H1BO9M-0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hxu48%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hxu48@uic.edu">Hu Xu</a>, <a href="https://openreview.net/profile?email=liub%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liub@uic.edu">Bing Liu</a>, <a href="https://openreview.net/profile?email=lshu3%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lshu3@uic.edu">Lei Shu</a>, <a href="https://openreview.net/profile?email=psyu%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="psyu@uic.edu">Philip S. Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1BO9M-0Z-details-302" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1BO9M-0Z-details-302"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning high-quality word embeddings is of significant importance in achieving better performance in many down-stream learning tasks. On one hand, traditional word embeddings are trained on a large scale corpus for general-purpose tasks, which are often sub-optimal for many domain-specific tasks. On the other hand, many domain-specific tasks do not have a large enough domain corpus to obtain high-quality embeddings. We observe that domains are not isolated and a small domain corpus can leverage the learned knowledge from many past domains to augment that corpus in order to generate high-quality embeddings. In this paper, we formulate the learning of word embeddings as a lifelong learning process. Given knowledge learned from many previous domains and a small new domain corpus, the proposed method can effectively generate new domain embeddings by leveraging a simple but effective algorithm and a meta-learner, where the meta-learner is able to provide word context similarity information at the domain-level. Experimental results demonstrate that the proposed method can effectively learn new domain embeddings from a small corpus and past domain knowledges\footnote{We will release the code after final revisions.}. We also demonstrate that general-purpose embeddings trained from a large scale corpus are sub-optimal in domain-specific tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">learning better domain embeddings via lifelong learning and meta-learning</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Lifelong learning, meta learning, word embedding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJB7fkWR-">
      <h4>
        <a href="https://openreview.net/forum?id=BJB7fkWR-">
          Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games
        </a>
        
          <a href="https://openreview.net/pdf?id=BJB7fkWR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=d.ratcliffe%40qmul.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.ratcliffe@qmul.ac.uk">Dino S. Ratcliffe</a>, <a href="https://openreview.net/profile?email=lciti%40essex.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="lciti@essex.ac.uk">Luca Citi</a>, <a href="https://openreview.net/profile?email=sam.devlin%40york.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sam.devlin@york.ac.uk">Sam Devlin</a>, <a href="https://openreview.net/profile?email=udo%40essex.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="udo@essex.ac.uk">Udo Kruschwitz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJB7fkWR--details-586" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJB7fkWR--details-586"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many deep reinforcement learning approaches use graphical state representations,
      this means visually distinct games that share the same underlying structure cannot
      effectively share knowledge. This paper outlines a new approach for learning
      underlying game state embeddings irrespective of the visual rendering of the game
      state. We utilise approaches from multi-task learning and domain adaption in
      order to place visually distinct game states on a shared embedding manifold. We
      present our results in the context of deep reinforcement learning agents.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">An approach to learning a shared embedding space between visually distinct games.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning, Domain Adaptation, Adversarial Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1suU-bAW">
      <h4>
        <a href="https://openreview.net/forum?id=B1suU-bAW">
          Learning Covariate-Specific Embeddings with Tensor Decompositions
        </a>
        
          <a href="https://openreview.net/pdf?id=B1suU-bAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kjtian%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kjtian@stanford.edu">Kevin Tian</a>, <a href="https://openreview.net/profile?email=tengz%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tengz@stanford.edu">Teng Zhang</a>, <a href="https://openreview.net/profile?email=jamesz%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamesz@stanford.edu">James Zou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1suU-bAW-details-542" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1suU-bAW-details-542"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Word embedding is a useful approach to capture co-occurrence structures in a large corpus of text. In addition to the text data itself, we often have additional covariates associated with individual documents in the corpus---e.g. the demographic of the author, time and venue of publication, etc.---and we would like the embedding to naturally capture the information of the covariates. In this paper, we propose a new tensor decomposition model for word embeddings with covariates. Our model jointly learns a \emph{base} embedding for all the words as well as a weighted diagonal transformation to model how each covariate modifies the base embedding. To obtain the specific embedding for a particular author or venue, for example, we can then simply multiply the base embedding by the transformation matrix associated with that time or venue. The main advantages of our approach is data efficiency and interpretability of the covariate transformation matrix. Our experiments demonstrate that our joint model learns substantially better embeddings conditioned on each covariate compared to the standard approach of learning a separate embedding for each covariate using only the relevant subset of data. Furthermore, our model encourages the embeddings to be ``topic-aligned'' in the sense that the dimensions have specific independent meanings. This allows our covariate-specific embeddings to be compared by topic, enabling downstream differential analysis. We empirically evaluate the benefits of our algorithm on several datasets, and demonstrate how it can be used to address many natural questions about the effects of covariates.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using the same embedding across covariates doesn't make sense, we show that a tensor decomposition algorithm learns sparse covariate-specific embeddings and naturally separable topics jointly and data-efficiently.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Word embedding, tensor decomposition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S16FPMgRZ">
      <h4>
        <a href="https://openreview.net/forum?id=S16FPMgRZ">
          Tensor Contraction &amp; Regression Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=S16FPMgRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jean.kossaifi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jean.kossaifi@gmail.com">Jean Kossaifi</a>, <a href="https://openreview.net/profile?email=zlipton%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlipton@cmu.edu">Zack Chase Lipton</a>, <a href="https://openreview.net/profile?email=arankhan%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arankhan@amazon.com">Aran Khanna</a>, <a href="https://openreview.net/profile?email=tfurlanello%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tfurlanello@gmail.com">Tommaso Furlanello</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Anima Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S16FPMgRZ-details-876" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S16FPMgRZ-details-876"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolution neural networks typically consist of many convolutional layers followed by several fully-connected layers.  While convolutional layers map between high-order activation tensors, the fully-connected layers operate on flattened activation vectors.  Despite its success, this approach has notable drawbacks. Flattening discards the multi-dimensional structure of the activations, and the fully-connected layers require a large number of parameters. 
      We present two new techniques to address these problems.  First, we introduce tensor contraction layers which can replace the ordinary fully-connected layers in a neural network. Second, we introduce tensor regression layers, which express the output of a neural network as a low-rank multi-linear mapping from a high-order activation tensor to the softmax layer.  Both the contraction and regression weights are learned end-to-end by backpropagation. By imposing low rank on both, we use significantly fewer parameters.  Experiments on the ImageNet dataset show that applied to the popular VGG and ResNet architectures, our methods significantly reduce the number of parameters in the fully connected layers (about 65% space savings) while negligibly impacting accuracy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose tensor contraction and low-rank tensor regression layers to preserve and leverage the multi-linear structure throughout the network, resulting in huge space savings with little to no impact on performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">tensor contraction, tensor regression, network compression, deep neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkGZuJb0b">
      <h4>
        <a href="https://openreview.net/forum?id=rkGZuJb0b">
          Compact Neural Networks based on the Multiscale Entanglement Renormalization Ansatz
        </a>
        
          <a href="https://openreview.net/pdf?id=rkGZuJb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=andrew.hallam.10%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrew.hallam.10@ucl.ac.uk">Andrew Hallam</a>, <a href="https://openreview.net/profile?email=edward.grant.16%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="edward.grant.16@ucl.ac.uk">Edward Grant</a>, <a href="https://openreview.net/profile?email=vstojevic%40gtn.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="vstojevic@gtn.ai">Vid Stojevic</a>, <a href="https://openreview.net/profile?email=s.severini%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.severini@ucl.ac.uk">Simone Severini</a>, <a href="https://openreview.net/profile?email=andrew.green%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrew.green@ucl.ac.uk">Andrew G. Green</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkGZuJb0b-details-397" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkGZuJb0b-details-397"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The goal of this paper is to demonstrate a method for tensorizing neural networks based upon an efficient way of approximating scale invariant quantum states, the Multi-scale Entanglement Renormalization Ansatz (MERA). We employ MERA as a replacement for linear layers in a neural network and test this implementation on the CIFAR-10 dataset. The proposed method outperforms factorization using tensor trains, providing greater compression for the same level of accuracy and greater accuracy for the same level of compression. We demonstrate MERA-layers with 3900 times fewer parameters and a reduction in accuracy of less than 1% compared to the equivalent fully connected layers.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We replace the fully connected layers of a neural network with the multi-scale entanglement renormalization ansatz, a type of quantum operation which describes long range correlations. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Networks, Tensor Networks, Tensor Trains</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1bgpzZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=B1bgpzZAZ">
          ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions
        </a>
        
          <a href="https://openreview.net/pdf?id=B1bgpzZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sohamp%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="sohamp@cse.iitm.ac.in">Soham Parikh</a>, <a href="https://openreview.net/profile?email=ananyasb%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="ananyasb@cse.iitm.ac.in">Ananya Sai</a>, <a href="https://openreview.net/profile?email=preksha%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="preksha@cse.iitm.ac.in">Preksha Nema</a>, <a href="https://openreview.net/profile?email=miteshk%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="miteshk@cse.iitm.ac.in">Mitesh M Khapra</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1bgpzZAZ-details-887" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1bgpzZAZ-details-887"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given \{\textit{passage, question}\} pair and select one of the $n$ given options. The current state of the art model for this task first computes a query-aware representation for the passage and then \textit{selects} the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of \textit{elimination} and \textit{selection}. Specifically, a human would first try to eliminate the most irrelevant option and then read the document again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose \textit{ElimiNet}, a neural network based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the \{\textit{document, question}\} pair and if so it tries to make the document representation orthogonal to this eliminatedd option (akin to ignoring portions of the document corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the document representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the 13 question types in this dataset. Further we show that taking an ensemble of our \textit{elimination-selection} based method with a \textit{selection} based method gives us an improvement of 7\% (relative) over the best reported performance on this dataset.    
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A model combining elimination and selection for answering multiple choice questions</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reading Comprehension, Answering Multiple Choice Questions</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryF-cQ6T-">
      <h4>
        <a href="https://openreview.net/forum?id=ryF-cQ6T-">
          Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures
        </a>
        
          <a href="https://openreview.net/pdf?id=ryF-cQ6T-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dingliu_thu%40126.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dingliu_thu@126.com">Ding Liu</a>, <a href="https://openreview.net/profile?email=shi-ju.ran%40icfo.eu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shi-ju.ran@icfo.eu">Shi-Ju Ran</a>, <a href="https://openreview.net/profile?email=peter.wittek%40icfo.eu" class="profile-link" data-toggle="tooltip" data-placement="top" title="peter.wittek@icfo.eu">Peter Wittek</a>, <a href="https://openreview.net/profile?email=pengcheng12%40mails.ucas.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="pengcheng12@mails.ucas.ac.cn">Cheng Peng</a>, <a href="https://openreview.net/profile?email=raulbzga%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raulbzga@gmail.com">Raul Blázquez García</a>, <a href="https://openreview.net/profile?email=gsu%40ucas.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="gsu@ucas.ac.cn">Gang Su</a>, <a href="https://openreview.net/profile?email=maciej.lewenstein%40icfo.eu" class="profile-link" data-toggle="tooltip" data-placement="top" title="maciej.lewenstein@icfo.eu">Maciej Lewenstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryF-cQ6T--details-897" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryF-cQ6T--details-897"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention. In particular, tensor networks (TNs) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning. Previous results used one-dimensional TNs in image recognition, showing limited scalability and a request of high bond dimension. In this work, we train two-dimensional hierarchical TNs to solve image recognition problems, using a training algorithm derived from the multipartite entanglement renormalization ansatz (MERA). This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning. While keeping the TN unitary in the training phase, TN states can be defined, which optimally encodes each class of the images into a quantum many-body state. We study the quantum features of the TN states, including quantum entanglement and fidelity. We suggest these quantities could be novel properties that characterize the image classes, as well as the machine learning tasks. Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">quantum machine learning, tensor network, quantum information</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyHmGyZCZ">
      <h4>
        <a href="https://openreview.net/forum?id=HyHmGyZCZ">
          Comparison of Paragram and GloVe Results for Similarity Benchmarks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyHmGyZCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jakub.dutkiewicz%40put.poznan.pl" class="profile-link" data-toggle="tooltip" data-placement="top" title="jakub.dutkiewicz@put.poznan.pl">Jakub Dutkiewicz</a>, <a href="https://openreview.net/profile?email=czeslaw.jedrzejek%40put.poznan.pl" class="profile-link" data-toggle="tooltip" data-placement="top" title="czeslaw.jedrzejek@put.poznan.pl">Czesław Jędrzejek</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyHmGyZCZ-details-425" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyHmGyZCZ-details-425"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Distributional Semantics Models(DSM) derive word space from linguistic items
      in context. Meaning is obtained by defining a distance measure between vectors
      corresponding to lexical entities. Such vectors present several problems. This
      work concentrates on quality of word embeddings, improvement of word embedding
      vectors, applicability of a novel similarity metric used ‘on top’ of the
      word embeddings. In this paper we provide comparison between two methods
      for post process improvements to the baseline DSM vectors. The counter-fitting
      method which enforces antonymy and synonymy constraints into the Paragram
      vector space representations recently showed improvement in the vectors’ capability
      for judging semantic similarity. The second method is our novel RESM
      method applied to GloVe baseline vectors. By applying the hubness reduction
      method, implementing relational knowledge into the model by retrofitting synonyms
      and providing a new ranking similarity definition RESM that gives maximum
      weight to the top vector component values we equal the results for the ESL
      and TOEFL sets in comparison with our calculations using the Paragram and Paragram
      + Counter-fitting methods. For SIMLEX-999 gold standard since we cannot
      use the RESM the results using GloVe and PPDB are significantly worse compared
      to Paragram. Apparently, counter-fitting corrects hubness. The Paragram
      or our cosine retrofitting method are state-of-the-art results for the SIMLEX-999
      gold standard. They are 0.2 better for SIMLEX-999 than word2vec with sense
      de-conflation (that was announced to be state-of the-art method for less reliable
      gold standards). Apparently relational knowledge and counter-fitting is more important
      for judging semantic similarity than sense determination for words. It is to
      be mentioned, though that Paragram hyperparameters are fitted to SIMLEX-999
      results. The lesson is that many corrections to word embeddings are necessary
      and methods with more parameters and hyperparameters perform better.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Paper provides a description of a procedure to enhance word vector space model with an evaluation of Paragram and GloVe models for Similarity Benchmarks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">language models, vector spaces, word embedding, similarity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlhPMWAW">
      <h4>
        <a href="https://openreview.net/forum?id=SJlhPMWAW">
          GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders
        </a>
        
          <a href="https://openreview.net/pdf?id=SJlhPMWAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=simonovm%40imagine.enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="simonovm@imagine.enpc.fr">Martin Simonovsky</a>, <a href="https://openreview.net/profile?email=nikos.komodakis%40enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikos.komodakis@enpc.fr">Nikos Komodakis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJlhPMWAW-details-548" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlhPMWAW-details-548"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning on graphs has become a popular research topic with many applications. However, past work has concentrated on learning graph embedding tasks only, which is in contrast with advances in generative models for images and text. Is it possible to transfer this progress to the domain of graphs? We propose to sidestep hurdles associated with linearization of such discrete structures by having a decoder output a probabilistic fully-connected graph of a predefined maximum size directly at once. Our method is formulated as a variational autoencoder. We evaluate on the challenging task of conditional molecule generation. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We demonstate an autoencoder for graphs.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">graph, generative model, autoencoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1fcY-Z0-">
      <h4>
        <a href="https://openreview.net/forum?id=S1fcY-Z0-">
          Bayesian Hypernetworks
        </a>
        
          <a href="https://openreview.net/pdf?id=S1fcY-Z0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=david.scott.krueger%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.scott.krueger@gmail.com">David Krueger</a>, <a href="https://openreview.net/profile?email=chin-wei.huang%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="chin-wei.huang@umontreal.ca">Chin-Wei Huang</a>, <a href="https://openreview.net/profile?email=riashat.islam%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="riashat.islam@mail.mcgill.ca">Riashat Islam</a>, <a href="https://openreview.net/profile?email=turnerry%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="turnerry@iro.umontreal.ca">Ryan Turner</a>, <a href="https://openreview.net/profile?email=allac%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="allac@elementai.com">Alexandre Lacoste</a>, <a href="https://openreview.net/profile?email=aaron.courville%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaron.courville@gmail.com">Aaron Courville</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1fcY-Z0--details-481" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1fcY-Z0--details-481"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks. A Bayesian hypernetwork, h, is a neural network which learns to transform a simple noise distribution, p(e) = N(0,I), to a distribution q(t) := q(h(e)) over the parameters t of another neural network (the ``primary network). We train q with variational inference, using an invertible h to enable efficient estimation of the variational lower bound on the posterior p(t | D) via sampling. In contrast to most methods for Bayesian deep learning, Bayesian hypernets can represent a complex multimodal approximate posterior with correlations between parameters, while enabling cheap iid sampling of q(t).  In practice, Bayesian hypernets provide a better defense against adversarial examples than dropout, and also exhibit competitive performance on a suite of tasks which evaluate model uncertainty, including regularization, active learning, and anomaly detection.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">variational inference, bayesian inference, deep networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkqV-XZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=SkqV-XZRZ">
          Variational Bi-LSTMs
        </a>
        
          <a href="https://openreview.net/pdf?id=SkqV-XZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=s.shabanian%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.shabanian@gmail.com">Samira Shabanian</a>, <a href="https://openreview.net/profile?email=devansharpit%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="devansharpit@gmail.com">Devansh Arpit</a>, <a href="https://openreview.net/profile?email=adam.trischler%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.trischler@microsoft.com">Adam Trischler</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkqV-XZRZ-details-469" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkqV-XZRZ-details-469"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks like long short-term memory (LSTM) are important architectures for sequential prediction tasks. LSTMs (and RNNs in general) model sequences along the forward time direction. Bidirectional LSTMs (Bi-LSTMs), which model sequences along both forward and backward directions, generally perform better at such tasks because they capture a richer representation of the data. In the training of Bi-LSTMs, the forward and backward paths are learned independently. We propose a variant of the Bi-LSTM architecture, which we call Variational Bi-LSTM, that creates a dependence between the two paths (during training, but which may be omitted during inference). Our model acts as a regularizer and encourages the two networks to inform each other in making their respective predictions using distinct information. We perform ablation studies to better understand the different components of our model and evaluate the method on various benchmarks, showing state-of-the-art performance.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk6qQGWRb">
      <h4>
        <a href="https://openreview.net/forum?id=Bk6qQGWRb">
          Efficient Exploration through Bayesian   Deep Q-Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk6qQGWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=kazizzad%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kazizzad@uci.edu">Kamyar Azizzadenesheli</a>, <a href="https://openreview.net/profile?email=ebrun%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ebrun@cs.stanford.edu">Emma Brunskill</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Animashree Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk6qQGWRb-details-704" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk6qQGWRb-details-704"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose Bayesian Deep Q-Network  (BDQN), a  practical Thompson sampling based Reinforcement Learning (RL) Algorithm. Thompson sampling allows for targeted exploration in high dimensions through posterior sampling but is usually computationally expensive. We address this limitation by introducing uncertainty only at the output layer of the network through a Bayesian Linear Regression (BLR) model, which can be trained with fast closed-form updates and its samples can be drawn efficiently through the Gaussian distribution. We apply our method to a wide range of Atari Arcade Learning Environments. Since BDQN carries out more efficient exploration, it is able to reach higher rewards substantially faster than a key baseline, DDQN.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using Bayesian regression to estimate the posterior over Q-functions and deploy Thompson Sampling as a targeted exploration strategy with efficient trade-off the exploration and exploitation</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep RL, Thompson Sampling, Posterior update</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By-IifZRW">
      <h4>
        <a href="https://openreview.net/forum?id=By-IifZRW">
          Gaussian Process Neurons
        </a>
        
          <a href="https://openreview.net/pdf?id=By-IifZRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=surban%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="surban@tum.de">Sebastian Urban</a>, <a href="https://openreview.net/profile?email=smagt%40brml.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="smagt@brml.org">Patrick van der Smagt</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By-IifZRW-details-765" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By-IifZRW-details-765"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a method to learn stochastic activation functions for use in probabilistic neural networks.
      First, we develop a framework to embed stochastic activation functions based on Gaussian processes in probabilistic neural networks.
      Second, we analytically derive expressions for the propagation of means and covariances in such a network, thus allowing for an efficient implementation and training without the need for sampling.
      Third, we show how to apply variational Bayesian inference to regularize and efficiently train this model.
      The resulting model can deal with uncertain inputs and implicitly provides an estimate of the confidence of its predictions.
      Like a conventional neural network it can scale to datasets of arbitrary size and be extended with convolutional and recurrent connections, if desired.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We model the activation function of each neuron as a Gaussian Process and learn it alongside the weight with Variational Inference.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">gaussian process neuron activation function stochastic transfer function learning variational bayes probabilistic</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJlrSmbAZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJlrSmbAZ">
          Bayesian Uncertainty Estimation for Batch Normalized Deep Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=BJlrSmbAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=teye%40kth.se" class="profile-link" data-toggle="tooltip" data-placement="top" title="teye@kth.se">Mattias Teye</a>, <a href="https://openreview.net/profile?email=azizpour%40kth.se" class="profile-link" data-toggle="tooltip" data-placement="top" title="azizpour@kth.se">Hossein Azizpour</a>, <a href="https://openreview.net/profile?email=ksmith%40kth.se" class="profile-link" data-toggle="tooltip" data-placement="top" title="ksmith@kth.se">Kevin Smith</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJlrSmbAZ-details-738" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJlrSmbAZ-details-738"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks have led to a series of breakthroughs, dramatically improving the state-of-the-art in many domains. The techniques driving these advances, however, lack a formal method to account for model uncertainty. While the Bayesian approach to learning provides a solid theoretical framework to handle uncertainty, inference in Bayesian-inspired deep neural networks is difficult. In this paper, we provide a practical approach to Bayesian learning that relies on a regularization technique found in nearly every modern network, batch normalization. We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models, and we demonstrate how this finding allows us to make useful estimates of the model uncertainty. Using our approach, it is possible to make meaningful uncertainty estimates using conventional architectures without modifying the network or the training procedure. Our approach is thoroughly validated in a series of empirical experiments on different tasks and using various measures, showing it to outperform baselines on a majority of datasets with strong statistical significance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models, and we demonstrate how this finding allows us to make useful estimates of the model uncertainty in conventional networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">uncertainty estimation, deep learning, Bayesian learning, batch normalization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SknC0bW0-">
      <h4>
        <a href="https://openreview.net/forum?id=SknC0bW0-">
          Continuous-fidelity Bayesian Optimization with Knowledge Gradient
        </a>
        
          <a href="https://openreview.net/pdf?id=SknC0bW0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jw926%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jw926@cornell.edu">Jian Wu</a>, <a href="https://openreview.net/profile?email=pf98%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pf98@cornell.edu">Peter I. Frazier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SknC0bW0--details-341" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SknC0bW0--details-341"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While Bayesian optimization (BO) has achieved great success in optimizing expensive-to-evaluate black-box functions, especially tuning hyperparameters of neural networks, methods such as random search (Li et al., 2016) and multi-fidelity BO (e.g. Klein et al. (2017)) that exploit cheap approximations, e.g. training on a smaller training data or with fewer iterations, can outperform standard BO approaches that use only full-fidelity observations. In this paper, we propose a novel Bayesian optimization algorithm, the continuous-fidelity knowledge gradient (cfKG) method, that can be used when fidelity is controlled by one or more continuous settings such as training data size and the number of training iterations. cfKG characterizes the value of the information gained by sampling a point at a given fidelity, choosing to sample at the point and fidelity with the largest value per unit cost. Furthermore, cfKG can be generalized, following Wu et al. (2017), to settings where derivatives are available in the optimization process, e.g. large-scale kernel learning, and where more than one point can be evaluated simultaneously. Numerical experiments show that cfKG outperforms state-of-art algorithms when optimizing synthetic functions, tuning convolutional neural networks (CNNs) on CIFAR-10 and SVHN, and in large-scale kernel learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a Bayes-optimal Bayesian optimization algorithm for hyperparameter tuning by exploiting cheap approximations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Continuous fidelity, Bayesian optimization, fast, knowledge gradient, hyperparameter optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk8R_JWRW">
      <h4>
        <a href="https://openreview.net/forum?id=rk8R_JWRW">
          Gating out sensory noise in a spike-based Long Short-Term Memory network
        </a>
        
          <a href="https://openreview.net/pdf?id=rk8R_JWRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=d.zambrano%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.zambrano@cwi.nl">Davide Zambrano</a>, <a href="https://openreview.net/profile?email=isabella.pozzi%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="isabella.pozzi@cwi.nl">Isabella Pozzi</a>, <a href="https://openreview.net/profile?email=roeland.nusselder%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="roeland.nusselder@gmail.com">Roeland Nusselder</a>, <a href="https://openreview.net/profile?email=s.m.bohte%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.m.bohte@cwi.nl">Sander Bohte</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk8R_JWRW-details-724" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk8R_JWRW-details-724"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Spiking neural networks are being investigated both as biologically plausible models of neural computation and also as a potentially more efficient type of neural network. While convolutional spiking neural networks have been demonstrated to achieve near state-of-the-art performance, only one solution has been proposed to convert gated recurrent neural networks, so far.
      Recurrent neural networks in the form of networks of gating memory cells have been central in state-of-the-art solutions in problem domains that involve sequence recognition or generation. Here, we design an analog gated LSTM cell where its neurons can be substituted for efficient stochastic spiking neurons. These adaptive spiking neurons implement an adaptive form of sigma-delta coding to convert internally computed analog activation values to spike-trains. For such neurons, we approximate the effective activation function, which resembles a sigmoid. We show how analog neurons with such activation functions can be used to create an analog LSTM cell; networks of these cells can then be trained with standard backpropagation. We train these LSTM networks on a noisy and noiseless version of the original sequence prediction task from Hochreiter &amp; Schmidhuber (1997), and also on a noisy and noiseless version of a classical working memory reinforcement learning task, the T-Maze. Substituting the analog neurons for corresponding adaptive spiking neurons, we then show that almost all resulting spiking neural network equivalents correctly compute the original tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value"> We demonstrate a gated recurrent asynchronous spiking neural network that corresponds to an LSTM unit.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">spiking neural networks, LSTM, recurrent neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyxCqGbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=SyxCqGbRZ">
          Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SyxCqGbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jfutoma14%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfutoma14@gmail.com">Joseph Futoma</a>, <a href="https://openreview.net/profile?email=anthony.lin%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anthony.lin@duke.edu">Anthony Lin</a>, <a href="https://openreview.net/profile?email=mark.sendak%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mark.sendak@duke.edu">Mark Sendak</a>, <a href="https://openreview.net/profile?email=armando.bedoya%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="armando.bedoya@duke.edu">Armando Bedoya</a>, <a href="https://openreview.net/profile?email=meredith.edwards%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="meredith.edwards@duke.edu">Meredith Clement</a>, <a href="https://openreview.net/profile?email=cara.obrien%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cara.obrien@duke.edu">Cara O'Brien</a>, <a href="https://openreview.net/profile?email=kheller%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kheller@gmail.com">Katherine Heller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyxCqGbRZ-details-75" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyxCqGbRZ-details-75"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Sepsis is a life-threatening complication from infection and a leading cause of mortality in hospitals.  While early detection of sepsis improves patient outcomes, there is little consensus on exact treatment guidelines, and treating septic patients remains an open  problem.  In this work we present a new deep reinforcement learning method that we use to learn optimal personalized treatment policies for septic patients. We model patient continuous-valued physiological time series using multi-output Gaussian processes, a probabilistic model that easily handles missing values and irregularly spaced observation times while maintaining estimates of uncertainty. The Gaussian process is directly tied to a deep recurrent Q-network that learns clinically interpretable treatment policies, and both models are learned together end-to-end.  We evaluate our approach on a heterogeneous dataset of septic spanning 15 months from our university health system, and find that our learned policy could reduce patient mortality by as much as 8.2\% from an overall baseline mortality rate of 13.3\%.  Our algorithm could be used to make treatment recommendations to physicians as part of a decision support tool, and the framework readily applies to other reinforcement learning problems that rely on sparsely sampled and frequently missing multivariate time series data.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We combine Multi-output Gaussian processes with deep recurrent Q-networks to learn optimal treatments for sepsis and show improved performance over standard deep reinforcement learning methods,</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Healthcare, Gaussian Process, Deep Reinforcement Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkTBjG-AZ">
      <h4>
        <a href="https://openreview.net/forum?id=rkTBjG-AZ">
          DeepArchitect: Automatically Designing and Training Deep Architectures
        </a>
        
          <a href="https://openreview.net/pdf?id=rkTBjG-AZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=negrinho%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="negrinho@cs.cmu.edu">Renato Negrinho</a>, <a href="https://openreview.net/profile?email=ggordon%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ggordon@cs.cmu.edu">Geoff Gordon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkTBjG-AZ-details-587" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkTBjG-AZ-details-587"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In deep learning, performance is strongly affected by the choice of architecture
      and hyperparameters. While there has been extensive work on automatic hyperpa-
      rameter optimization for simple spaces, complex spaces such as the space of deep
      architectures remain largely unexplored. As a result, the choice of architecture is
      done manually by the human expert through a slow trial and error process guided
      mainly by intuition. In this paper we describe a framework for automatically
      designing and training deep models. We propose an extensible and modular lan-
      guage that allows the human expert to compactly represent complex search spaces
      over architectures and their hyperparameters. The resulting search spaces are tree-
      structured and therefore easy to traverse. Models can be automatically compiled to
      computational graphs once values for all hyperparameters have been chosen. We
      can leverage the structure of the search space to introduce different model search
      algorithms, such as random search, Monte Carlo tree search (MCTS), and sequen-
      tial model-based optimization (SMBO). We present experiments comparing the
      different algorithms on CIFAR-10 and show that MCTS and SMBO outperform
      random search. We also present experiments on MNIST, showing that the same
      search space achieves near state-of-the-art performance with a few samples. These
      experiments show that our framework can be used effectively for model discov-
      ery, as it is possible to describe expressive search spaces and discover competitive
      models without much effort from the human expert. Code for our framework and
      experiments has been made publicly available</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe a modular and composable language for describing expressive search spaces over architectures and simple model search algorithms applied to these search spaces. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">architecture search, deep learning, hyperparameter tuning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyBbjW-RW">
      <h4>
        <a href="https://openreview.net/forum?id=HyBbjW-RW">
          Open Loop Hyperparameter Optimization and Determinantal Point Processes
        </a>
        
          <a href="https://openreview.net/pdf?id=HyBbjW-RW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jessed%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jessed@cs.cmu.edu">Jesse Dodge</a>, <a href="https://openreview.net/profile?email=jamieson%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamieson@cs.washington.edu">Kevin Jamieson</a>, <a href="https://openreview.net/profile?email=nasmith%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nasmith@cs.washington.edu">Noah A. Smith</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyBbjW-RW-details-860" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyBbjW-RW-details-860"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Driven by the need for parallelizable hyperparameter optimization methods, this paper studies \emph{open loop} search methods: sequences that are predetermined and can be generated before a single configuration is evaluated. Examples include grid search, uniform random search, low discrepancy sequences, and other sampling distributions.
      In particular, we propose the use of $k$-determinantal point processes in  hyperparameter optimization via random search. Compared to conventional uniform random search where hyperparameter settings are sampled independently, a $k$-DPP promotes diversity.  We describe an approach that transforms hyperparameter search spaces for efficient use with a $k$-DPP. In addition, we introduce a novel Metropolis-Hastings algorithm which can sample from $k$-DPPs defined over spaces with a mixture of discrete and continuous dimensions. Our experiments show significant benefits over uniform random search  in realistic scenarios with a limited budget for training supervised learners, whether in serial or parallel.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Driven by the need for parallelizable, open-loop hyperparameter optimization methods, we propose the use of $k$-determinantal point processes in  hyperparameter optimization via random search.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hyperparameter optimization, random search, determinantal point processes, low discrepancy sequences</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1Nyf7W0Z">
      <h4>
        <a href="https://openreview.net/forum?id=H1Nyf7W0Z">
          Alpha-divergence bridges maximum likelihood and reinforcement learning in neural sequence generation
        </a>
        
          <a href="https://openreview.net/pdf?id=H1Nyf7W0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sotetsu.koyamada%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sotetsu.koyamada@gmail.com">Sotetsu Koyamada</a>, Yuta Kikuchi, Atsunori Kanemura, Shin-ichi Maeda, Shin Ishii
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1Nyf7W0Z-details-511" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1Nyf7W0Z-details-511"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural sequence generation is commonly approached by using maximum- likelihood (ML) estimation or reinforcement learning (RL). However, it is known that they have their own shortcomings; ML presents training/testing discrepancy, whereas RL suffers from sample inefficiency. We point out that it is difficult to resolve all of the shortcomings simultaneously because of a tradeoff between ML and RL. In order to counteract these problems, we propose an objective function for sequence generation using α-divergence, which leads to an ML-RL integrated method that exploits better parts of ML and RL. We demonstrate that the proposed objective function generalizes ML and RL objective functions because it includes both as its special cases (ML corresponds to α → 0 and RL to α → 1). We provide a proposition stating that the difference between the RL objective function and the proposed one monotonically decreases with increasing α. Experimental results on machine translation tasks show that minimizing the proposed objective function achieves better sequence generation performance than ML-based methods.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Propose new objective function for neural sequence generation which integrates ML-based and RL-based objective functions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural network, reinforcement learning, natural language processing, machine translation, alpha-divergence</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryk77mbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=ryk77mbRZ">
          Noise-Based Regularizers for Recurrent Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ryk77mbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=abd2141%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abd2141@columbia.edu">Adji B. Dieng</a>, <a href="https://openreview.net/profile?email=altosaar%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="altosaar@princeton.edu">Jaan Altosaar</a>, <a href="https://openreview.net/profile?email=rajeshr%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rajeshr@cs.princeton.edu">Rajesh Ranganath</a>, <a href="https://openreview.net/profile?email=david.blei%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.blei@columbia.edu">David M. Blei</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryk77mbRZ-details-354" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryk77mbRZ-details-354"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recurrent neural networks (RNNs) are powerful models for sequential data. They can approximate arbitrary computations, and have been used successfully in domains such as text and speech. However, the flexibility of RNNs makes them susceptible to overfitting and regularization is important. We develop a noise-based regularization method for RNNs. The idea is simple and easy to implement: we inject noise in the hidden units of the RNN and then maximize the original RNN's likelihood averaged over the injected noise. On a language modeling benchmark, our method achieves better performance than the deterministic RNN and the variational dropout.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1vccClCb">
      <h4>
        <a href="https://openreview.net/forum?id=r1vccClCb">
          Neighbor-encoder
        </a>
        
          <a href="https://openreview.net/pdf?id=r1vccClCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=myeh003%40ucr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="myeh003@ucr.edu">Chin-Chia Michael Yeh</a>, <a href="https://openreview.net/profile?email=yzhu015%40ucr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzhu015@ucr.edu">Yan Zhu</a>, <a href="https://openreview.net/profile?email=epapalex%40cs.ucr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="epapalex@cs.ucr.edu">Evangelos E. Papalexakis</a>, <a href="https://openreview.net/profile?email=mueen%40unm.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mueen@unm.edu">Abdullah Mueen</a>, <a href="https://openreview.net/profile?email=eamonn%40cs.ucr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eamonn@cs.ucr.edu">Eamonn Keogh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1vccClCb-details-129" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1vccClCb-details-129"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised learning, representation learning, autoencoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkYMnLxRW">
      <h4>
        <a href="https://openreview.net/forum?id=SkYMnLxRW">
          Weighted Transformer Network for Machine Translation
        </a>
        
          <a href="https://openreview.net/pdf?id=SkYMnLxRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=karim.mmm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karim.mmm@gmail.com">Karim Ahmed</a>, <a href="https://openreview.net/profile?email=keskar.nitish%40u.northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="keskar.nitish@u.northwestern.edu">Nitish Shirish Keskar</a>, <a href="https://openreview.net/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkYMnLxRW-details-161" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkYMnLxRW-details-161"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">State-of-the-art results on neural machine translation often use attentional sequence-to-sequence models with some form of convolution or recursion. Vaswani et. al. (2017) propose a new architecture that avoids recurrence and convolution completely. Instead, it uses only self-attention and feed-forward layers. While the proposed architecture achieves state-of-the-art results on several machine translation tasks, it requires a large number of parameters and training iterations to converge. We propose Weighted Transformer, a Transformer with modified attention layers, that not only outperforms the baseline network in BLEU score but also converges 15-40% faster. Specifically, we replace the multi-head attention by multiple self-attention branches that the model learns to combine during the training process. Our model improves the state-of-the-art performance by 0.5 BLEU points on the WMT 2014 English-to-German translation task and by 0.4 on the English-to-French translation task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using branched attention with learned combination weights outperforms the baseline transformer for machine translation tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">transformer, branching, attention, machine translation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJBiunlAW">
      <h4>
        <a href="https://openreview.net/forum?id=rJBiunlAW">
          Training RNNs as Fast as CNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=rJBiunlAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tao%40asapp.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tao@asapp.com">Tao Lei</a>, <a href="https://openreview.net/profile?email=yzhang87%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzhang87@csail.mit.edu">Yu Zhang</a>, <a href="https://openreview.net/profile?email=yoav%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoav@cs.cornell.edu">Yoav Artzi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJBiunlAW-details-641" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJBiunlAW-details-641"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Common recurrent neural network architectures scale poorly due to the intrinsic difficulty in parallelizing their state computations. In this work, we propose the Simple Recurrent Unit (SRU) architecture, a recurrent unit that simplifies the computation and exposes more parallelism. In SRU, the majority of computation for each step is independent of the recurrence and can be easily parallelized. SRU is as fast as a convolutional layer and 5-10x faster than an optimized LSTM implementation. We study SRUs on a wide range of applications,  including classification, question answering, language modeling, translation and speech recognition. Our experiments demonstrate the effectiveness of SRU and the trade-off it enables between speed and performance. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">recurrent neural networks, natural language processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJOQ7MgAW">
      <h4>
        <a href="https://openreview.net/forum?id=HJOQ7MgAW">
          Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum
        </a>
        
          <a href="https://openreview.net/pdf?id=HJOQ7MgAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=omerlevy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="omerlevy@gmail.com">Omer Levy</a>, <a href="https://openreview.net/profile?email=kentonl%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kentonl@cs.washington.edu">Kenton Lee</a>, <a href="https://openreview.net/profile?email=nfitz%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nfitz@cs.washington.edu">Nicholas FitzGerald</a>, <a href="https://openreview.net/profile?email=lsz%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsz@cs.washington.edu">Luke Zettlemoyer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJOQ7MgAW-details-811" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJOQ7MgAW-details-811"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Long short-term memory networks (LSTMs) were introduced to combat vanishing gradients in simple recurrent neural networks (S-RNNs) by augmenting them with additive recurrent connections controlled by gates. We present an alternate view to explain the success of LSTMs: the gates themselves are powerful recurrent models that provide more representational power than previously appreciated. We do this by showing that the LSTM's gates can be decoupled from the embedded S-RNN, producing a restricted class of RNNs where the main recurrence computes an element-wise weighted sum of context-independent functions of the inputs. Experiments on a range of challenging NLP problems demonstrate that the simplified gate-based models work substantially better than S-RNNs, and often just as well as the original LSTMs, strongly suggesting that the gates are doing much more in practice than just alleviating vanishing gradients.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Gates do all the heavy lifting in LSTMs by computing element-wise weighted sums, and removing the internal simple RNN does not degrade model performance.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkffVjUaW">
      <h4>
        <a href="https://openreview.net/forum?id=SkffVjUaW">
          Building effective deep neural networks one feature at a time
        </a>
        
          <a href="https://openreview.net/pdf?id=SkffVjUaW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mundt%40fias.uni-frankfurt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mundt@fias.uni-frankfurt.de">Martin Mundt</a>, <a href="https://openreview.net/profile?email=weis%40ccc.cs.uni-frankfurt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="weis@ccc.cs.uni-frankfurt.de">Tobias Weis</a>, <a href="https://openreview.net/profile?email=kishore.konda%40insofe.edu.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="kishore.konda@insofe.edu.in">Kishore Konda</a>, <a href="https://openreview.net/profile?email=ramesh%40fias.uni-frankfurt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramesh@fias.uni-frankfurt.de">Visvanathan Ramesh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkffVjUaW-details-424" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkffVjUaW-details-424"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Successful training of convolutional neural networks is often associated with suffi-
      ciently deep architectures composed of high amounts of features. These networks
      typically rely on a variety of regularization and pruning techniques to converge
      to less redundant states. We introduce a novel bottom-up approach to expand
      representations in fixed-depth architectures. These architectures start from just a
      single feature per layer and greedily increase width of individual layers to attain
      effective representational capacities needed for a specific task. While network
      growth can rely on a family of metrics, we propose a computationally efficient
      version based on feature time evolution and demonstrate its potency in determin-
      ing feature importance and a networks’ effective capacity. We demonstrate how
      automatically expanded architectures converge to similar topologies that benefit
      from lesser amount of parameters or improved accuracy and exhibit systematic
      correspondence in representational complexity with the specified task. In contrast
      to conventional design patterns with a typical monotonic increase in the amount of
      features with increased depth, we observe that CNNs perform better when there is
      more learnable parameters in intermediate, with falloffs to earlier and later layers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A bottom-up algorithm that expands CNNs starting with one feature per layer to architectures with sufficient representational capacity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">convolution neural networks, architecture search, meta-learning, representational capacity</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJmAXkgCb">
      <h4>
        <a href="https://openreview.net/forum?id=SJmAXkgCb">
          DNN Feature Map Compression using Learned Representation over GF(2)
        </a>
        
          <a href="https://openreview.net/pdf?id=SJmAXkgCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=denis.gudovskiy%40us.panasonic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="denis.gudovskiy@us.panasonic.com">Denis A. Gudovskiy</a>, <a href="https://openreview.net/profile?email=alec.hodgkinson%40us.panasonic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alec.hodgkinson@us.panasonic.com">Alec Hodgkinson</a>, <a href="https://openreview.net/profile?email=luca.rigazio%40us.panasonic.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="luca.rigazio@us.panasonic.com">Luca Rigazio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJmAXkgCb-details-913" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJmAXkgCb-details-913"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we introduce a method to compress intermediate feature maps of deep neural networks (DNNs) to decrease memory storage and bandwidth requirements during inference. Unlike previous works, the proposed method is based on converting fixed-point activations into vectors over the smallest GF(2) finite field followed by nonlinear dimensionality reduction (NDR) layers embedded into a DNN. Such an end-to-end learned representation finds more compact feature maps by exploiting quantization redundancies within the fixed-point activations along the channel or spatial dimensions. We apply the proposed network architecture to the tasks of ImageNet classification and PASCAL VOC object detection. Compared to prior approaches, the conducted experiments show a factor of 2 decrease in memory requirements with minor degradation in accuracy while adding only bitwise computations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Feature map compression method that converts quantized activations into binary vectors followed by nonlinear dimensionality reduction layers embedded into a DNN</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">feature map, representation, compression, quantization, finite-field</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJn0sLgRb">
      <h4>
        <a href="https://openreview.net/forum?id=SJn0sLgRb">
          Data Augmentation by Pairing Samples for Images Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=SJn0sLgRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=inouehrs%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="inouehrs@jp.ibm.com">Hiroshi Inoue</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>25 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJn0sLgRb-details-208" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJn0sLgRb-details-208"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Data augmentation, Image classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy3fJXbA-">
      <h4>
        <a href="https://openreview.net/forum?id=Sy3fJXbA-">
          Connectivity Learning in Multi-Branch Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy3fJXbA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=karim.mmm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karim.mmm@gmail.com">Karim Ahmed</a>, <a href="https://openreview.net/profile?email=lt%40dartmouth.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lt@dartmouth.edu">Lorenzo Torresani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy3fJXbA--details-304" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy3fJXbA--details-304"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While much of the work in the design of convolutional networks over the last five years has revolved around the empirical investigation of the importance of depth, filter sizes, and number of feature channels, recent studies have shown that  branching, i.e., splitting the computation along parallel but distinct threads and then aggregating their outputs, represents a new promising dimension for significant improvements in performance. To combat the complexity of design choices in multi-branch architectures, prior work has adopted simple strategies, such as a fixed branching factor, the same input being fed to all parallel branches, and an additive combination of the outputs produced by all branches at aggregation points. 
      
      In this work we remove these predefined choices and propose an algorithm to learn the connections between branches in the network. Instead of being chosen a priori by the human designer, the multi-branch connectivity is learned simultaneously with the weights of the network by optimizing a single loss function defined with respect to the end task. We demonstrate our approach on the problem of multi-class image classification using four different datasets where it yields consistently higher accuracy compared to the state-of-the-art ``ResNeXt'' multi-branch network given the same learning capacity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In this paper we introduced an algorithm to learn the connectivity of deep multi-branch networks. The approach is evaluated on image categorization where it consistently yields accuracy gains over state-of-the-art models that use fixed connectivity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">connectivity learning, multi-branch networks, image categorization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJoXrxZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJoXrxZAZ">
          HybridNet: A Hybrid Neural Architecture to Speed-up Autoregressive  Models
        </a>
        
          <a href="https://openreview.net/pdf?id=rJoXrxZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhouyanqi%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhouyanqi@baidu.com">Yanqi Zhou</a>, <a href="https://openreview.net/profile?email=pingwei01%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pingwei01@baidu.com">Wei Ping</a>, <a href="https://openreview.net/profile?email=sercanarik%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sercanarik@baidu.com">Sercan Arik</a>, <a href="https://openreview.net/profile?email=pengkainan%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pengkainan@baidu.com">Kainan Peng</a>, <a href="https://openreview.net/profile?email=gregdiamos%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gregdiamos@baidu.com">Greg Diamos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJoXrxZAZ-details-605" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJoXrxZAZ-details-605"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces HybridNet, a hybrid neural network to speed-up autoregressive
      models for raw audio waveform generation. As an example, we propose
      a hybrid model that combines an autoregressive network named WaveNet and a
      conventional LSTM model to address speech synthesis. Instead of generating
      one sample per time-step, the proposed HybridNet generates multiple samples per
      time-step by exploiting the long-term memory utilization property of LSTMs. In
      the evaluation, when applied to text-to-speech, HybridNet yields state-of-art performance.
      HybridNet achieves a 3.83 subjective 5-scale mean opinion score on
      US English, largely outperforming the same size WaveNet in terms of naturalness
      and provide 2x speed up at inference.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">It is a hybrid neural architecture to speed-up autoregressive model. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">neural architecture, inference time reduction, hybrid model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1NHaMW0b">
      <h4>
        <a href="https://openreview.net/forum?id=S1NHaMW0b">
          ShakeDrop regularization
        </a>
        
          <a href="https://openreview.net/pdf?id=S1NHaMW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yamada%40m.cs.osakafu-u.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="yamada@m.cs.osakafu-u.ac.jp">Yoshihiro Yamada</a>, <a href="https://openreview.net/profile?email=masa%40cs.osakafu-u.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="masa@cs.osakafu-u.ac.jp">Masakazu Iwamura</a>, <a href="https://openreview.net/profile?email=kise%40cs.osakafu-u.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="kise@cs.osakafu-u.ac.jp">Koichi Kise</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1NHaMW0b-details-317" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1NHaMW0b-details-317"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper proposes a powerful regularization method named \textit{ShakeDrop regularization}.
      ShakeDrop is inspired by Shake-Shake regularization that decreases error rates by disturbing learning.
      While Shake-Shake can be applied to only ResNeXt which has multiple branches, ShakeDrop can be applied to not only ResNeXt but also ResNet, Wide ResNet and PyramidNet in a memory efficient way.
      Important and interesting feature of ShakeDrop is that it strongly disturbs learning by multiplying even a negative factor to the output of a convolutional layer in the forward training pass.
      The effectiveness of ShakeDrop is confirmed by experiments on CIFAR-10/100 and Tiny ImageNet datasets.
      </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ6iJmWCW">
      <h4>
        <a href="https://openreview.net/forum?id=rJ6iJmWCW">
          POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ6iJmWCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=prannayk%40iitk.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="prannayk@iitk.ac.in">Prannay Khosla</a>, <a href="https://openreview.net/profile?email=pjyothi%40cse.iitb.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="pjyothi@cse.iitb.ac.in">Preethi Jyothi</a>, <a href="https://openreview.net/profile?email=vinaypn%40cse.iitk.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinaypn@cse.iitk.ac.in">Vinay P. Namboodiri</a>, <a href="https://openreview.net/profile?email=msrinivasan%40nvidia.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="msrinivasan@nvidia.com">Mukundhan Srinivasan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ6iJmWCW-details-637" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ6iJmWCW-details-637"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose the generation of accented speech using generative adversarial
      networks. Through this work we make two main contributions a) The
      ability to condition latent representations while generating realistic speech samples
      b) The ability to efficiently generate long speech samples by using a novel
      latent variable transformation module that is trained using policy gradients. Previous
      methods are limited in being able to generate only relatively short samples
      or are not very efficient at generating long samples. The generated speech samples
      are validated through a number of various evaluation measures viz, a WGAN
      critic loss and through subjective scores on user evaluations against competitive
      speech synthesis baselines and detailed ablation analysis of the proposed model.
      The evaluations demonstrate that the model generates realistic long speech samples
      conditioned on accent efficiently.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">speech, generation, accent, gan, adversarial, reinforcement, memory, lstm, policy, gradients, human</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1cKvl-Rb">
      <h4>
        <a href="https://openreview.net/forum?id=H1cKvl-Rb">
          UCB EXPLORATION VIA Q-ENSEMBLES
        </a>
        
          <a href="https://openreview.net/pdf?id=H1cKvl-Rb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=richardchen%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="richardchen@openai.com">Richard Y. Chen</a>, <a href="https://openreview.net/profile?email=szymon%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="szymon@openai.com">Szymon Sidor</a>, <a href="https://openreview.net/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>, <a href="https://openreview.net/profile?email=joschu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joschu@openai.com">John Schulman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1cKvl-Rb-details-679" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1cKvl-Rb-details-679"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We show how an ensemble of $Q^*$-functions can be leveraged for more effective exploration in deep reinforcement learning. We build on well established algorithms from the bandit setting, and adapt them to the $Q$-learning setting. We propose an exploration strategy based on upper-confidence bounds (UCB). Our experiments show significant gains on the Atari benchmark. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Adapting UCB exploration to ensemble Q-learning improves over prior methods such as Double DQN, A3C+ on Atari benchmark</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning, Q-learning, ensemble method, upper confidence bound</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B16yEqkCZ">
      <h4>
        <a href="https://openreview.net/forum?id=B16yEqkCZ">
          Avoiding Catastrophic States with Intrinsic Fear
        </a>
        
          <a href="https://openreview.net/pdf?id=B16yEqkCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zlipton%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlipton@cmu.edu">Zachary C. Lipton</a>, <a href="https://openreview.net/profile?email=kazizzad%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kazizzad@uci.edu">Kamyar Azizzadenesheli</a>, <a href="https://openreview.net/profile?email=abkumar%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abkumar@ucsd.edu">Abhishek Kumar</a>, <a href="https://openreview.net/profile?email=lihongli.cs%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lihongli.cs@gmail.com">Lihong Li</a>, <a href="https://openreview.net/profile?email=jfgao%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfgao@microsoft.com">Jianfeng Gao</a>, <a href="https://openreview.net/profile?email=l.deng%40ieee.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="l.deng@ieee.org">Li Deng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B16yEqkCZ-details-453" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B16yEqkCZ-details-453"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many practical reinforcement learning problems contain catastrophic states that the optimal policy visits infrequently or never. Even on toy problems, deep reinforcement learners periodically revisit these states, once they are forgotten under a new policy. In this paper, we introduce intrinsic fear, a learned reward shaping that accelerates deep reinforcement learning and guards oscillating policies against periodic catastrophes. Our approach incorporates a second model trained via supervised learning to predict the probability of imminent catastrophe. This score acts as a penalty on the Q-learning objective. Our theoretical analysis demonstrates that the perturbed objective yields the same average return under strong assumptions and an $\epsilon$-close average return under weaker assumptions. Our analysis also shows robustness to classification errors. Equipped with intrinsic fear, our DQNs solve the toy environments and improve on the Atari games Seaquest, Asteroids, and Freeway.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Shape reward with intrinsic motivation to avoid catastrophic states and mitigate catastrophic forgetting.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, safe exploration, dqn</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ7d0fW0b">
      <h4>
        <a href="https://openreview.net/forum?id=BJ7d0fW0b">
          Faster Reinforcement Learning with Expert State Sequences
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ7d0fW0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaoxiao.guo%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoxiao.guo@ibm.com">Xiaoxiao Guo</a>, <a href="https://openreview.net/profile?email=shiyu.chang%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiyu.chang@ibm.com">Shiyu Chang</a>, <a href="https://openreview.net/profile?email=yum%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yum@us.ibm.com">Mo Yu</a>, Miao Liu, Gerald Tesauro
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ7d0fW0b-details-937" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ7d0fW0b-details-937"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Imitation learning relies on expert demonstrations. Existing approaches often re- quire that the complete demonstration data, including sequences of actions and states are available. In this paper, we consider a realistic and more difficult sce- nario where a reinforcement learning agent only has access to the state sequences of an expert, while the expert actions are not available. Inferring the unseen ex- pert actions in a stochastic environment is challenging and usually infeasible when combined with a large state space. We propose a novel policy learning method which only utilizes the expert state sequences without inferring the unseen ac- tions. Specifically, our agent first learns to extract useful sub-goal information from the state sequences of the expert and then utilizes the extracted sub-goal information to factorize the action value estimate over state-action pairs and sub- goals. The extracted sub-goals are also used to synthesize guidance rewards in the policy learning. We evaluate our agent on five Doom tasks. Our empirical results show that the proposed method significantly outperforms the conventional DQN method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Imitation Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkpRBFxRb">
      <h4>
        <a href="https://openreview.net/forum?id=HkpRBFxRb">
          Learning to Mix n-Step Returns: Generalizing Lambda-Returns for Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HkpRBFxRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sahil%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="sahil@cse.iitm.ac.in">Sahil Sharma</a>, <a href="https://openreview.net/profile?email=girishraguvir%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="girishraguvir@gmail.com">Girish Raguvir J *</a>, <a href="https://openreview.net/profile?email=sriramesh4%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sriramesh4@gmail.com">Srivatsan Ramesh *</a>, <a href="https://openreview.net/profile?email=ravi%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="ravi@cse.iitm.ac.in">Balaraman Ravindran</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkpRBFxRb-details-331" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkpRBFxRb-details-331"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement Learning (RL) can model complex behavior policies for goal-directed sequential decision making tasks. A hallmark of RL algorithms is Temporal Difference (TD) learning: value function for the current state is moved towards a bootstrapped target that is estimated using the next state's value function. lambda-returns define the target of the RL agent as a weighted combination of rewards estimated by using multiple many-step look-aheads. Although mathematically tractable, the use of  exponentially decaying weighting of n-step returns based targets in lambda-returns is a rather ad-hoc design choice. Our major contribution  is that we propose a generalization of lambda-returns called Confidence-based Autodidactic Returns (CAR), wherein the RL agent learns the weighting of the n-step returns in an end-to-end manner. In contrast to lambda-returns wherein the RL agent is restricted to use an exponentially decaying weighting scheme, CAR allows the agent to learn to decide how much it wants to weigh the n-step returns based targets. Our experiments, in addition to showing the efficacy of CAR, also empirically demonstrate that using sophisticated weighted mixtures of multi-step returns (like CAR and lambda-returns) considerably outperforms the use of n-step returns. We perform our experiments on the  Asynchronous Advantage Actor Critic (A3C) algorithm in the Atari 2600 domain.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel way to generalize lambda-returns by allowing the RL agent to decide how much it wants to weigh each of the n-step returns.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Lambda-Returns</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyunpgbR-">
      <h4>
        <a href="https://openreview.net/forum?id=HyunpgbR-">
          Structured Exploration via Hierarchical Variational Policy Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyunpgbR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=stephan%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephan@caltech.edu">Stephan Zheng</a>, <a href="https://openreview.net/profile?email=yyue%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyue@caltech.edu">Yisong Yue</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyunpgbR--details-408" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyunpgbR--details-408"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement learning in environments with large state-action spaces is challenging, as exploration can be highly inefficient. Even if the dynamics are simple, the optimal policy can be combinatorially hard to discover. In this work, we propose a hierarchical approach to structured exploration to improve the sample efficiency of on-policy exploration in large state-action spaces. The key idea is to model a stochastic policy as a hierarchical latent variable model, which can learn low-dimensional structure in the state-action space, and to define exploration by sampling from the low-dimensional latent space. This approach enables lower sample complexity, while preserving policy expressivity. In order to make learning tractable, we derive a joint learning and exploration strategy by combining hierarchical variational inference with actor-critic learning. The benefits of our learning approach are that 1) it is principled, 2) simple to implement, 3) easily scalable to settings with many actions and 4) easily composable with existing deep learning approaches. We demonstrate the effectiveness of our approach on learning a deep centralized multi-agent policy, as multi-agent environments naturally have an exponentially large state-action space. In this setting, the latent hierarchy implements a form of multi-agent coordination during exploration and execution (MACE). We demonstrate empirically that MACE can more efficiently learn optimal policies in challenging multi-agent games with a large number (~20) of agents, compared to conventional baselines. Moreover, we show that our hierarchical structure leads to meaningful agent coordination.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Make deep reinforcement learning in large state-action spaces more efficient using structured exploration with deep hierarchical policies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Reinforcement Learning, Structured Variational Inference, Multi-agent Coordination, Multi-agent Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJvWjcgAZ">
      <h4>
        <a href="https://openreview.net/forum?id=BJvWjcgAZ">
          Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update
        </a>
        
          <a href="https://openreview.net/pdf?id=BJvWjcgAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sy9424%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sy9424@kaist.ac.kr">Su Young Lee</a>, <a href="https://openreview.net/profile?email=si_choi%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="si_choi@kaist.ac.kr">Sungik Choi</a>, <a href="https://openreview.net/profile?email=schung%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="schung@kaist.ac.kr">Sae-Young Chung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJvWjcgAZ-details-944" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJvWjcgAZ-details-944"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose Episodic Backward Update - a new algorithm to boost the performance of a deep reinforcement learning agent by fast reward propagation. In contrast to the conventional use of the replay memory with uniform random sampling, our agent samples a whole episode and successively propagates the value of a state into its previous states. Our computationally efficient recursive algorithm allows sparse and delayed rewards to propagate effectively throughout the sampled episode. We evaluate our algorithm on 2D MNIST Maze Environment and 49 games of the Atari 2600 Environment and show that our agent improves sample efficiency with a competitive computational cost.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose Episodic Backward Update, a novel deep reinforcement learning algorithm which samples transitions episode by episode and updates values recursively in a backward manner to achieve fast and stable learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Reinforcement Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy_MK3lAZ">
      <h4>
        <a href="https://openreview.net/forum?id=Sy_MK3lAZ">
          PARAMETRIZED DEEP Q-NETWORKS LEARNING: PLAYING ONLINE BATTLE ARENA WITH DISCRETE-CONTINUOUS HYBRID ACTION SPACE
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy_MK3lAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jcxiong%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jcxiong@tencent.com">Jiechao Xiong</a>, <a href="https://openreview.net/profile?email=drwang%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="drwang@tencent.com">Qing Wang</a>, <a href="https://openreview.net/profile?email=pythonsun%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pythonsun@tencent.com">Zhuoran Yang</a>, <a href="https://openreview.net/profile?email=zakzheng%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zakzheng@tencent.com">Peng Sun</a>, <a href="https://openreview.net/profile?email=lxhan%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxhan@tencent.com">Yang Zheng</a>, <a href="https://openreview.net/profile?email=haobofu%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haobofu@tencent.com">Lei Han</a>, <a href="https://openreview.net/profile?email=tongzhang%40tongzhang-ml.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="tongzhang@tongzhang-ml.org">Haobo Fu</a>, <a href="https://openreview.net/profile?email=ji.liu.uwisc%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ji.liu.uwisc@gmail.com">Xiangru Lian</a>, Carson Eisenach, Haichuan Yang, Emmanuel Ekwedike, Bei Peng, Haoyue Gao, Tong Zhang, Ji Liu, Han Liu
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy_MK3lAZ-details-285" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy_MK3lAZ-details-285"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Most existing deep reinforcement learning (DRL) frameworks consider action spaces that are either
      discrete or continuous space. Motivated by the project of design Game AI for King of Glory
      (KOG), one the world’s most popular mobile game, we consider the scenario with the discrete-continuous
      hybrid action space. To directly apply existing DLR frameworks, existing approaches
      either approximate the hybrid space by a discrete set or relaxing it into a continuous set, which is
      usually less efficient and robust. In this paper, we propose a parametrized deep Q-network (P-DQN)
      for the hybrid action space without approximation or relaxation. Our algorithm combines DQN and
      DDPG and can be viewed as an extension of the DQN to hybrid actions. The empirical study on the
      game KOG validates the efficiency and effectiveness of our method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A DQN and DDPG hybrid algorithm is proposed to deal with the discrete-continuous hybrid action space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep reinforcement learning, Hybrid action space, DQN, DDPG</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1GDXzb0b">
      <h4>
        <a href="https://openreview.net/forum?id=S1GDXzb0b">
          Model-based imitation learning from state trajectories
        </a>
        
          <a href="https://openreview.net/pdf?id=S1GDXzb0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=subhajit%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="subhajit@jp.ibm.com">Subhajit Chaudhury</a>, <a href="https://openreview.net/profile?email=daiki%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daiki@jp.ibm.com">Daiki Kimura</a>, <a href="https://openreview.net/profile?email=inouet%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="inouet@jp.ibm.com">Tadanobu Inoue</a>, <a href="https://openreview.net/profile?email=ryuki%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryuki@jp.ibm.com">Ryuki Tachibana</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1GDXzb0b-details-559" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1GDXzb0b-details-559"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Imitation learning from demonstrations usually relies on learning a policy from trajectories of optimal states and actions. However, in real life expert demonstrations, often the action information is missing and only state trajectories are available. We present a model-based imitation learning method that can learn environment-specific optimal actions only from expert state trajectories. Our proposed method starts with a model-free reinforcement learning algorithm with a heuristic reward signal to sample environment dynamics, which is then used to train the state-transition probability. Subsequently, we learn the optimal actions from expert state trajectories by supervised learning, while back-propagating the error gradients through the modeled environment dynamics. Experimental evaluations show that our proposed method successfully achieves performance similar to (state, action) trajectory-based traditional imitation learning methods even in the absence of action information, with much fewer iterations compared to conventional model-free reinforcement learning methods. We also demonstrate that our method can learn to act from only video demonstrations of expert agent for simple games and can learn to achieve desired performance in less number of iterations.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Learning to imitate an expert in the absence of optimal actions learning a dynamics model while exploring the environment.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Model based reinforcement learning, Imitation learning, dynamics model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyDAQl-AW">
      <h4>
        <a href="https://openreview.net/forum?id=HyDAQl-AW">
          Time Limits in Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=HyDAQl-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=f.pardo%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="f.pardo@imperial.ac.uk">Fabio Pardo</a>, <a href="https://openreview.net/profile?email=a.tavakoli%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.tavakoli@imperial.ac.uk">Arash Tavakoli</a>, <a href="https://openreview.net/profile?email=v.levdik%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="v.levdik@imperial.ac.uk">Vitaly Levdik</a>, <a href="https://openreview.net/profile?email=p.kormushev%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="p.kormushev@imperial.ac.uk">Petar Kormushev</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyDAQl-AW-details-928" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyDAQl-AW-details-928"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In reinforcement learning, it is common to let an agent interact with its environment for a fixed amount of time before resetting the environment and repeating the process in a series of episodes. The task that the agent has to learn can either be to maximize its performance over (i) that fixed amount of time, or (ii) an indefinite period where the time limit is only used during training. In this paper, we investigate theoretically how time limits could effectively be handled in each of the two cases. In the first one, we argue that the terminations due to time limits are in fact part of the environment, and propose to include a notion of the remaining time as part of the agent's input. In the second case, the time limits are not part of the environment and are only used to facilitate learning. We argue that such terminations should not be treated as environmental ones and propose a method, specific to value-based algorithms, that incorporates this insight by continuing to bootstrap at the end of each partial episode. To illustrate the significance of our proposals, we perform several experiments on a range of environments from simple few-state transition graphs to complex control tasks, including novel and standard benchmark domains. Our results show that the proposed methods improve the performance and stability of existing reinforcement learning algorithms.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We consider the problem of learning optimal policies in time-limited and time-unlimited domains using time-limited interactions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, Markov decision processes, deep learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkc_hGb0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rkc_hGb0Z">
          A dynamic game approach to training robust deep policies
        </a>
        
          <a href="https://openreview.net/pdf?id=rkc_hGb0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=opo140030%40utdallas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="opo140030@utdallas.edu">Olalekan Ogunmolu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkc_hGb0Z-details-32" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkc_hGb0Z-details-32"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a method for evaluating the sensitivity of deep reinforcement learning (RL) policies. We also formulate a zero-sum dynamic game for designing robust deep reinforcement learning policies. Our approach mitigates the brittleness of policies when agents are trained in a simulated environment and are later exposed to the real world where it is hazardous to employ RL policies. This framework for training deep RL policies involve a zero-sum  dynamic game against an adversarial agent, where the goal is to drive the system dynamics to a saddle region. Using a variant of the guided policy search algorithm, our agent learns to adopt robust policies that require less samples for learning the dynamics and performs better than the GPS algorithm. Without loss of generality, we demonstrate that deep RL policies trained in this fashion will be maximally robust to a ``worst" possible adversarial disturbances.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper demonstrates how H-infinity control theory can help better design robust deep policies for robot motor taks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">game-theory, reinforcement-learning, guided-policy-search, dynamic-programming</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkvDssyRb">
      <h4>
        <a href="https://openreview.net/forum?id=rkvDssyRb">
          Multi-Advisor Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rkvDssyRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=romain.laroche%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="romain.laroche@gmail.com">Romain Laroche</a>, <a href="https://openreview.net/profile?email=mehdi.fatemi%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mehdi.fatemi@microsoft.com">Mehdi Fatemi</a>, <a href="https://openreview.net/profile?email=joshua.romoff%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="joshua.romoff@mail.mcgill.ca">Joshua Romoff</a>, <a href="https://openreview.net/profile?email=havansei%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="havansei@microsoft.com">Harm van Seijen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkvDssyRb-details-291" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkvDssyRb-details-291"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider tackling a single-agent RL problem by distributing it to $n$ learners. These learners, called advisors, endeavour to solve the problem from a different focus. Their advice, taking the form of action values, is then communicated to an aggregator, which is in control of the system. We show that the local planning method for the advisors is critical and that none of the ones found in the literature is flawless: the \textit{egocentric} planning overestimates values of states where the other advisors disagree, and the \textit{agnostic} planning is inefficient around danger zones. We introduce a novel approach called \textit{empathic} and discuss its theoretical aspects. We empirically examine and validate our theoretical findings on a fruit collection task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We consider tackling a single-agent RL problem by distributing it to $n$ learners.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJIgf7bAZ">
      <h4>
        <a href="https://openreview.net/forum?id=rJIgf7bAZ">
          An inference-based policy gradient method for learning options
        </a>
        
          <a href="https://openreview.net/pdf?id=rJIgf7bAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=matthew.smith5%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.smith5@mail.mcgill.ca">Matthew J. A. Smith</a>, <a href="https://openreview.net/profile?email=herke.vanhoof%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="herke.vanhoof@mail.mcgill.ca">Herke van Hoof</a>, <a href="https://openreview.net/profile?email=jpineau%40cs.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpineau@cs.mcgill.ca">Joelle Pineau</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJIgf7bAZ-details-436" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJIgf7bAZ-details-436"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In the pursuit of increasingly intelligent learning systems, abstraction plays a vital role in enabling sophisticated decisions to be made in complex environments. The options framework provides formalism for such abstraction over sequences of decisions.  However most models require that options be given a priori, presumably specified by hand, which is neither efficient, nor scalable. Indeed, it is preferable to learn options directly from interaction with the environment. Despite several efforts, this remains a difficult problem: many approaches require access to a model of the environmental dynamics, and inferred options are often not interpretable, which limits our ability to explain the system behavior for verification or debugging purposes.  In this work we develop a novel policy gradient method for the automatic learning of policies with options.  This algorithm uses inference methods to simultaneously improve all of the options available to an agent, and thus can be employed in an off-policy manner, without observing option labels. Experimental results show that the options learned can be interpreted. Further, we find that the method presented here is more sample efficient than existing methods, leading to faster and more stable learning of policies with options.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We develop a novel policy gradient method for the automatic learning of policies with options using a differentiable inference step.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, hierarchy, options, inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk-ofQZRb">
      <h4>
        <a href="https://openreview.net/forum?id=Bk-ofQZRb">
          TD Learning with Constrained Gradients
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk-ofQZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ishand%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ishand@cs.utexas.edu">Ishan Durugkar</a>, <a href="https://openreview.net/profile?email=pstone%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pstone@cs.utexas.edu">Peter Stone</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk-ofQZRb-details-272" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk-ofQZRb-details-272"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Temporal Difference Learning with function approximation is known to be unstable. Previous work like \citet{sutton2009fast} and \citet{sutton2009convergent} has presented alternative objectives that are stable to minimize. However, in practice, TD-learning with neural networks requires various tricks like using a target network that updates slowly \citep{mnih2015human}. In this work we propose a constraint on the TD update that minimizes change to the target values. This constraint can be applied to the gradients of any TD objective, and can be easily applied to nonlinear function approximation. We validate this update by applying our technique to deep Q-learning, and training without a target network. We also show that adding this constraint on Baird's counterexample keeps Q-learning from diverging.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We show that adding a constraint to TD updates stabilizes learning and allows Deep Q-learning without a target network</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, TD Learning, DQN</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyF7Erp6W">
      <h4>
        <a href="https://openreview.net/forum?id=SyF7Erp6W">
          Learning to play slot cars and Atari 2600 games in just minutes
        </a>
        
          <a href="https://openreview.net/pdf?id=SyF7Erp6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lionel.cordesses%40renault.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lionel.cordesses@renault.com">Lionel Cordesses</a>, <a href="https://openreview.net/profile?email=omar.bentahar%40renault.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="omar.bentahar@renault.com">Omar Bentahar</a>, <a href="https://openreview.net/profile?email=ju.page%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ju.page@hotmail.com">Julien Page</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyF7Erp6W-details-798" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyF7Erp6W-details-798"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Machine learning algorithms for controlling devices will need to learn quickly, with few trials. Such a goal can be attained with concepts borrowed from continental philosophy and formalized using tools from the mathematical theory of categories. Illustrations of this approach are presented on a cyberphysical system: the slot car game, and also on Atari 2600 games.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Continental-philosophy-inspired approach to learn with few data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Artificial Intelligence, Signal processing, Philosophy, Analogy, ALE, Slot Car</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ3fy0k0Z">
      <h4>
        <a href="https://openreview.net/forum?id=rJ3fy0k0Z">
          Deterministic Policy Imitation Gradient Algorithm
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ3fy0k0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=fumihiro.fs.sasaki%40nts.ricoh.co.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="fumihiro.fs.sasaki@nts.ricoh.co.jp">Fumihiro Sasaki</a>, <a href="https://openreview.net/profile?email=atsuo.kawaguchi%40nts.ricoh.co.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="atsuo.kawaguchi@nts.ricoh.co.jp">Atsuo Kawaguchi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ3fy0k0Z-details-38" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ3fy0k0Z-details-38"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The goal of imitation learning (IL) is to enable a learner to imitate an expert’s behavior given the expert’s demonstrations. Recently, generative adversarial imitation learning (GAIL) has successfully achieved it even on complex continuous control tasks. However, GAIL requires a huge number of interactions with environment during training. We believe that IL algorithm could be more applicable to the real-world environments if the number of interactions could be reduced. To this end, we propose a model free, off-policy IL algorithm for continuous control. The keys of our algorithm are two folds: 1) adopting deterministic policy that allows us to derive a novel type of policy gradient which we call deterministic policy imitation gradient (DPIG), 2) introducing a function which we call state screening function (SSF) to avoid noisy policy updates with states that are not typical of those appeared on the expert’s demonstrations. Experimental results show that our algorithm can achieve the goal of IL with at least tens of times less interactions than GAIL on a variety of continuous control tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a model free imitation learning algorithm that is able to reduce number of interactions with environment in comparison with state-of-the-art imitation learning algorithm namely GAIL.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Imitation Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1mSWUxR-">
      <h4>
        <a href="https://openreview.net/forum?id=B1mSWUxR-">
          Softmax Q-Distribution Estimation for Structured Prediction: A Theoretical Interpretation for RAML
        </a>
        
          <a href="https://openreview.net/pdf?id=B1mSWUxR-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xuezhem%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuezhem@cs.cmu.edu">Xuezhe Ma</a>, <a href="https://openreview.net/profile?email=pcyin%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pcyin@cs.cmu.edu">Pengcheng Yin</a>, <a href="https://openreview.net/profile?email=liujingzhou%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liujingzhou@cs.cmu.edu">Jingzhou Liu</a>, <a href="https://openreview.net/profile?email=gneubig%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gneubig@cs.cmu.edu">Graham Neubig</a>, <a href="https://openreview.net/profile?email=hovy%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hovy@cs.cmu.edu">Eduard Hovy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1mSWUxR--details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1mSWUxR--details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reward augmented maximum likelihood (RAML), a simple and effective learning framework to directly optimize towards the reward function in structured prediction tasks, has led to a number of impressive empirical successes. RAML incorporates task-specific reward by performing maximum-likelihood updates on candidate outputs sampled according to an exponentiated payoff distribution, which gives higher probabilities to candidates that are close to the reference output. While RAML is notable for its simplicity, efficiency, and its impressive empirical successes, the theoretical properties of RAML, especially the behavior of the exponentiated payoff distribution, has not been examined thoroughly. In this work, we introduce softmax Q-distribution estimation, a novel theoretical interpretation of RAML, which reveals the relation between RAML and Bayesian decision theory. The softmax Q-distribution can be regarded as a smooth approximation of the Bayes decision boundary, and the Bayes decision rule is achieved by decoding with this Q-distribution. We further show that RAML is equivalent to approximately estimating the softmax Q-distribution, with the temperature $\tau$ controlling approximation error. We perform two experiments, one on synthetic data of multi-class classification and one on real data of image captioning, to demonstrate the relationship between RAML and the proposed softmax Q-distribution estimation, verifying our theoretical analysis. Additional experiments on three structured prediction tasks with rewards defined on sequential (named entity recognition), tree-based (dependency parsing) and irregular (machine translation) structures show notable improvements over maximum likelihood baselines.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">structured prediction, RAML, theory, Bayes decision rule, reward function</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk3b2qxCW">
      <h4>
        <a href="https://openreview.net/forum?id=rk3b2qxCW">
          Policy Gradient For Multidimensional Action Spaces: Action Sampling and Entropy Bonus
        </a>
        
          <a href="https://openreview.net/pdf?id=rk3b2qxCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=quan.hovuong%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="quan.hovuong@gmail.com">Vuong Ho Quan</a>, <a href="https://openreview.net/profile?email=yiming.zhang%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiming.zhang@nyu.edu">Yiming Zhang</a>, <a href="https://openreview.net/profile?email=kenny.song%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kenny.song@nyu.edu">Kenny Song</a>, <a href="https://openreview.net/profile?email=xygong%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xygong@mit.edu">Xiao-Yue Gong</a>, <a href="https://openreview.net/profile?email=keithwross%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="keithwross@nyu.edu">Keith W. Ross</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk3b2qxCW-details-279" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk3b2qxCW-details-279"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In recent years deep reinforcement learning has been shown to be adept at solving sequential decision processes with high-dimensional state spaces such as in the Atari games. Many reinforcement learning problems, however, involve high-dimensional discrete action spaces as well as high-dimensional state spaces. In this paper, we develop a novel policy gradient methodology for the case of large multidimensional discrete action spaces. We propose two approaches for creating parameterized policies: LSTM parameterization and a Modified MDP (MMDP) giving rise to Feed-Forward Network (FFN) parameterization. Both of these approaches provide expressive models to which backpropagation can be applied for training. We then consider entropy bonus, which is typically added to the reward function to enhance exploration. In the case of high-dimensional action spaces, calculating the entropy and the gradient of the entropy requires enumerating all the actions in the action space and running forward and backpropagation for each action, which may be computationally infeasible. We develop several novel unbiased estimators for the entropy bonus and its gradient. Finally, we test our algorithms on two environments: a multi-hunter multi-rabbit grid game and a multi-agent multi-arm bandit problem.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">policy parameterizations and unbiased policy entropy estimators for MDP with large multidimensional discrete action space</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, policy gradient, multidimensional action space, entropy bonus, entropy regularization, discrete action space</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyPMT6gAb">
      <h4>
        <a href="https://openreview.net/forum?id=SyPMT6gAb">
          Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization
        </a>
        
          <a href="https://openreview.net/pdf?id=SyPMT6gAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hwu340%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hwu340@gatech.edu">Hang Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyPMT6gAb-details-311" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyPMT6gAb-details-311"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Off-policy learning, the task of evaluating and improving policies using historic data collected from a logging policy, is important because on-policy evaluation is usually expensive and has adverse impacts. One of the major challenge of off-policy learning is to derive counterfactual estimators that also has low variance and thus low generalization error. 
      In this work, inspired by learning bounds for importance sampling problems, we present a new counterfactual learning principle for off-policy learning with bandit feedbacks.Our method regularizes the generalization error by minimizing the distribution divergence between the logging policy and the new policy, and removes the need for iterating through all training samples to compute sample variance regularization in prior work. With neural network policies, our end-to-end training algorithms using variational divergence minimization showed significant improvement over conventional baseline algorithms and is also consistent with our theoretical results.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">For off-policy learning with bandit feedbacks, we propose a new variance regularized counterfactual learning algorithm, which has both theoretical foundations and superior empirical performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Counterfactual Inference, Off-Policy Learning, Variance Regularization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By5ugjyCb">
      <h4>
        <a href="https://openreview.net/forum?id=By5ugjyCb">
          PACT: Parameterized Clipping Activation for Quantized Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=By5ugjyCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=choij%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="choij@us.ibm.com">Jungwook Choi</a>, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang, Vijayalakshmi Srinivasan, Kailash Gopalakrishnan
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By5ugjyCb-details-842" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By5ugjyCb-details-842"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning algorithms achieve high classification accuracy at the expense of significant computation cost. To address this cost, a number of quantization schemeshave been proposed - but most of these techniques focused on quantizing weights, which are relatively smaller in size compared to activations. This paper proposes a novel quantization scheme for activations during training - that enables neural networks to work well with ultra low precision weights and activations without any significant accuracy degradation.  This technique, PArameterized Clipping acTi-vation (PACT), uses an activation clipping parameter α that is optimized duringtraining to find the right quantization scale. PACT allows quantizing activations toarbitrary bit precisions, while achieving much better accuracy relative to publishedstate-of-the-art quantization schemes. We show, for the first time, that both weights and activations can be quantized to 4-bits of precision while still achieving accuracy comparable to full precision networks across a range of popular models and datasets. We also show that exploiting these reduced-precision computational units in hardware can enable a super-linear improvement in inferencing performance dueto a significant reduction in the area of accelerator compute engines coupled with the ability to retain the quantized model and activation data in on-chip memories.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new way of quantizing activation of Deep Neural Network via parameterized clipping which optimizes the quantization scale via stochastic gradient descent.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, quantized deep neural network, activation quantization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJDV5YxCW">
      <h4>
        <a href="https://openreview.net/forum?id=HJDV5YxCW">
          Heterogeneous Bitwidth Binarization in Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HJDV5YxCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jwfromm%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwfromm@uw.edu">Josh Fromm</a>, <a href="https://openreview.net/profile?email=matthaip%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthaip@microsoft.com">Matthai Philipose</a>, <a href="https://openreview.net/profile?email=shwetak%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shwetak@cs.washington.edu">Shwetak Patel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJDV5YxCW-details-899" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJDV5YxCW-details-899"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent work has shown that performing inference with fast, very-low-bitwidth
      (e.g., 1 to 2 bits) representations of values in models can yield surprisingly accurate
      results. However, although 2-bit approximated networks have been shown to
      be quite accurate, 1 bit approximations, which are twice as fast, have restrictively
      low accuracy. We propose a method to train models whose weights are a mixture
      of bitwidths, that allows us to more finely tune the accuracy/speed trade-off. We
      present the “middle-out” criterion for determining the bitwidth for each value, and
      show how to integrate it into training models with a desired mixture of bitwidths.
      We evaluate several architectures and binarization techniques on the ImageNet
      dataset. We show that our heterogeneous bitwidth approximation achieves superlinear
      scaling of accuracy with bitwidth. Using an average of only 1.4 bits, we are
      able to outperform state-of-the-art 2-bit architectures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce fractional bitwidth approximation and show it has significant advantages.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Computer Vision, Approximation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgf6Z-0W">
      <h4>
        <a href="https://openreview.net/forum?id=SJgf6Z-0W">
          Predicting Multiple Actions for Stochastic Continuous Control
        </a>
        
          <a href="https://openreview.net/pdf?id=SJgf6Z-0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sanjeev.kumar%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjeev.kumar@in.tum.de">Sanjeev Kumar</a>, <a href="https://openreview.net/profile?email=christian.rupprecht%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="christian.rupprecht@in.tum.de">Christian Rupprecht</a>, <a href="https://openreview.net/profile?email=tombari%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="tombari@in.tum.de">Federico Tombari</a>, <a href="https://openreview.net/profile?email=hager%40cs.tum.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hager@cs.tum.edu">Gregory D. Hager</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJgf6Z-0W-details-433" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgf6Z-0W-details-433"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a new approach to estimate continuous actions using actor-critic algorithms for reinforcement learning problems. Policy gradient methods usually predict one continuous action estimate or parameters of a presumed distribution (most commonly Gaussian) for any given state which might not be optimal as it may not capture the complete description of the target distribution. Our approach instead predicts M actions with the policy network (actor) and then uniformly sample one action during training as well as testing at each state. This allows the agent to learn a simple stochastic policy that has an easy to compute expected return. In all experiments, this facilitates better exploration of the state space during training and converges to a better policy. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a novel reinforcement learning algorithm, that predicts multiple actions and samples from them.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, DDPG, Multiple Action Prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1BRfhiab">
      <h4>
        <a href="https://openreview.net/forum?id=r1BRfhiab">
          The Principle of Logit Separation
        </a>
        
          <a href="https://openreview.net/pdf?id=r1BRfhiab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cruvadom%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cruvadom@gmail.com">Gil Keren</a>, <a href="https://openreview.net/profile?email=sivan.sabato%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sivan.sabato@gmail.com">Sivan Sabato</a>, <a href="https://openreview.net/profile?email=bjoern.schuller%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="bjoern.schuller@imperial.ac.uk">Björn Schuller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1BRfhiab-details-841" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1BRfhiab-details-841"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We consider neural network training, in applications in which there are many possible classes, but at test-time, the task is to identify only whether the given example belongs to a specific class, which can be different in different applications of the classifier. For instance, this is the case in an image search engine. We consider the Single Logit Classification (SLC) task: training the network so that at test-time, it would be possible to accurately identify if the example belongs to a given class, based only on the output logit for this class. 
      We propose a natural principle, the Principle of Logit Separation, as a guideline for choosing and designing losses suitable for the SLC. 
      We show that the cross-entropy loss function is not aligned with the Principle of Logit Separation. In contrast, there are known loss functions, as well as novel batch loss functions that we propose, which are aligned with this principle. In total, we study seven loss functions. 
      Our experiments show that indeed in almost all cases, losses that are aligned with Principle of Logit Separation obtain a 20%-35% relative performance improvement in the SLC task, compared to losses that are not aligned with it. We therefore conclude that the Principle of Logit Separation sheds light on an important property of the most common loss functions used by neural network classifiers. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJD8YjCpW">
      <h4>
        <a href="https://openreview.net/forum?id=SJD8YjCpW">
          Balanced and Deterministic Weight-sharing Helps Network Performance
        </a>
        
          <a href="https://openreview.net/pdf?id=SJD8YjCpW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=oscar.chang%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="oscar.chang@columbia.edu">Oscar Chang</a>, <a href="https://openreview.net/profile?email=hod.lipson%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hod.lipson@columbia.edu">Hod Lipson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJD8YjCpW-details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJD8YjCpW-details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Weight-sharing plays a significant role in the success of many deep neural networks, by increasing memory efficiency and incorporating useful inductive priors about the problem into the network. But understanding how weight-sharing can be used effectively in general is a topic that has not been studied extensively. Chen et al. (2015) proposed HashedNets, which augments a multi-layer perceptron with a hash table, as a method for neural network compression. We generalize this method into a framework (ArbNets) that allows for efficient arbitrary weight-sharing, and use it to study the role of weight-sharing in neural networks. We show that common neural networks can be expressed as ArbNets with different hash functions. We also present two novel hash functions, the Dirichlet hash and the Neighborhood hash, and use them to demonstrate experimentally that balanced and deterministic weight-sharing helps with the performance of a neural network.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Studied the role of weight sharing in neural networks using hash functions, found that a balanced and deterministic hash function helps network performance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Weight-sharing, Weight sharing, Weight tying, neural networks, entropy, hash function, hash table, balance, sparse, sparsity, hashednets</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByL48G-AW">
      <h4>
        <a href="https://openreview.net/forum?id=ByL48G-AW">
          Simple Nearest Neighbor Policy Method for Continuous Control Tasks
        </a>
        
          <a href="https://openreview.net/pdf?id=ByL48G-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mansimov%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mansimov@cs.nyu.edu">Elman Mansimov</a>, <a href="https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByL48G-AW-details-431" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByL48G-AW-details-431"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We design a new policy, called a nearest neighbor policy, that does not require any optimization for simple, low-dimensional continuous control tasks. As this policy does not require any optimization, it allows us to investigate the underlying difficulty of a task without being distracted by optimization difficulty of a learning algorithm. We propose two variants, one that retrieves an entire trajectory based on a pair of initial and goal states, and the other retrieving a partial trajectory based on a pair of current and goal states. We test the proposed policies on five widely-used benchmark continuous control tasks with a sparse reward: Reacher, Half Cheetah, Double Pendulum, Cart Pole and Mountain Car. We observe that the majority (the first four) of these tasks, which have been considered difficult, are easily solved by the proposed policies with high success rates, indicating that reported difficulties of them may have likely been due to the optimization difficulty. Our work suggests that it is necessary to evaluate any sophisticated policy learning algorithm on more challenging problems in order to truly assess the advances from them.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">nearest neighbor, reinforcement learning, policy, continuous control</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkw-jlb0W">
      <h4>
        <a href="https://openreview.net/forum?id=rkw-jlb0W">
          Deep Lipschitz networks and Dudley GANs
        </a>
        
          <a href="https://openreview.net/pdf?id=rkw-jlb0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ehsan.abbasnejad%40adelaide.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="ehsan.abbasnejad@adelaide.edu.au">Ehsan Abbasnejad</a>, <a href="https://openreview.net/profile?email=javen.shi%40adelaide.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="javen.shi@adelaide.edu.au">Javen Shi</a>, <a href="https://openreview.net/profile?email=anton.vandenhengel%40adelaide.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="anton.vandenhengel@adelaide.edu.au">Anton van den Hengel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkw-jlb0W-details-688" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkw-jlb0W-details-688"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generative adversarial networks (GANs) have enjoyed great success, however often suffer instability during training which motivates many attempts to resolve this issue. Theoretical explanation for the cause of instability is provided in Wasserstein GAN (WGAN), and wasserstein distance is proposed to stablize the training. Though WGAN is indeed more stable than previous GANs, it takes much more iterations and time to train. This is because the ways to ensure Lipschitz condition in WGAN (such as weight-clipping) significantly limit the capacity of the network. In this paper, we argue that it is beneficial to ensure Lipschitz condition as well as maintain sufficient capacity and expressiveness of the network. To facilitate this, we develop both theoretical and practical building blocks, using which one can construct different neural networks using a large range of metrics, as well as ensure Lipschitz condition and sufficient capacity of the networks. Using the proposed building blocks, and a special choice of a metric called Dudley metric, we propose Dudley GAN that outperforms the state of the arts in both convergence and sample quality. We discover a natural link between Dudley GAN (and its extension) and empirical risk minimization, which gives rise to generalization analysis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, Lipschitz neural network</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJtChcgAW">
      <h4>
        <a href="https://openreview.net/forum?id=SJtChcgAW">
          Cheap DNN Pruning with Performance Guarantees 
        </a>
        
          <a href="https://openreview.net/pdf?id=SJtChcgAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=konstantinos.pitas%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="konstantinos.pitas@epfl.ch">Konstantinos Pitas</a>, <a href="https://openreview.net/profile?email=mike.davies%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mike.davies@ed.ac.uk">Mike Davies</a>, <a href="https://openreview.net/profile?email=pierre.vandergheynst%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="pierre.vandergheynst@epfl.ch">Pierre Vandergheynst</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJtChcgAW-details-673" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJtChcgAW-details-673"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent DNN pruning algorithms have succeeded in reducing the number of parameters in fully connected layers often with little or no drop in classification accuracy. However most of the existing pruning schemes either have to be applied during training or require a costly retraining procedure after pruning to regain classification accuracy. In this paper we propose a cheap pruning algorithm based on difference of convex (DC) optimisation. We also provide theoretical analysis for the growth in the Generalisation Error (GE) of the new pruned network. Our method can be used with any convex regulariser and allows for a controlled degradation in classification accuracy while being orders of magnitude faster than competing approaches. Experiments on common feedforward neural networks show that for sparsity levels above 90% our method achieves 10% higher classification accuracy compared to Hard Thresholding.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A fast pruning algorithm for fully connected DNN layers with theoretical analysis of degradation in Generalisation Error.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">pruning, generalisation error, DC optimisation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy-tszZRZ">
      <h4>
        <a href="https://openreview.net/forum?id=Sy-tszZRZ">
          Bounding and Counting Linear Regions of Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy-tszZRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tserra%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tserra@gmail.com">Thiago Serra</a>, <a href="https://openreview.net/profile?email=ctjandra%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ctjandra@andrew.cmu.edu">Christian Tjandraatmadja</a>, <a href="https://openreview.net/profile?email=srikumar.ramalingam%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="srikumar.ramalingam@gmail.com">Srikumar Ramalingam</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy-tszZRZ-details-473" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy-tszZRZ-details-473"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we study the representational power of deep neural networks (DNN) that belong to the family of piecewise-linear (PWL) functions, based on PWL activation units such as rectifier or maxout. We investigate the complexity of such networks by studying the number of linear regions of the PWL function. Typically, a PWL function from a DNN can be seen as a large family of linear functions acting on millions of such regions. We directly build upon the work of Mont´ufar et al. (2014), Mont´ufar (2017), and Raghu et al. (2017) by refining the upper and lower bounds on the number of linear regions for rectified and maxout networks. In addition to achieving tighter bounds, we also develop a novel method to perform exact numeration or counting of the number of linear regions with a mixed-integer linear formulation that maps the input space to output. We use this new capability to visualize how the number of linear regions change while training DNNs.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We empirically count the number of linear regions of rectifier networks and refine upper and lower bounds.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">rectifier networks, maxout networks, piecewise linear functions, linear regions, mixed-integer programming</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1l8sz-AW">
      <h4>
        <a href="https://openreview.net/forum?id=H1l8sz-AW">
          Improving generalization by regularizing in $L^2$ function space
        </a>
        
          <a href="https://openreview.net/pdf?id=H1l8sz-AW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aarrii%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aarrii@seas.upenn.edu">Ari S Benjamin</a>, Konrad Kording
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1l8sz-AW-details-157" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1l8sz-AW-details-157"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning rules for neural networks necessarily include some form of regularization. Most regularization techniques are conceptualized and implemented in the space of parameters. However, it is also possible to regularize in the space of functions. Here, we propose to measure networks in an $L^2$ Hilbert space, and test a learning rule that regularizes the distance a network can travel through $L^2$-space each update.  This approach is inspired by the slow movement of gradient descent through parameter space as well as by the natural gradient, which can be derived from a regularization term upon functional change. The resulting learning rule, which we call Hilbert-constrained gradient descent (HCGD), is thus closely related to the natural gradient but regularizes a different and more calculable metric over the space of functions. Experiments show that the HCGD is efficient and leads to considerably better generalization. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">It's important to consider optimization in function space, not just parameter space. We introduce a learning rule that reduces distance traveled in function space, just like SGD limits distance traveled in parameter space.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">natural gradient, generalization, optimization, function space, Hilbert</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry831QWAb">
      <h4>
        <a href="https://openreview.net/forum?id=ry831QWAb">
          BLOCK-NORMALIZED GRADIENT METHOD: AN EMPIRICAL STUDY FOR TRAINING DEEP NEURAL NETWORK
        </a>
        
          <a href="https://openreview.net/pdf?id=ry831QWAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=weiyu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="weiyu@cs.cmu.edu">Adams Wei Yu</a>, <a href="https://openreview.net/profile?email=huanglei%40nlsde.buaa.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="huanglei@nlsde.buaa.edu.cn">Lei Huang</a>, <a href="https://openreview.net/profile?email=qihang-lin%40uiowa.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qihang-lin@uiowa.edu">Qihang Lin</a>, <a href="https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>, <a href="https://openreview.net/profile?email=jgc%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgc@cs.cmu.edu">Jaime Carbonell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry831QWAb-details-67" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry831QWAb-details-67"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a generic and simple strategy for utilizing stochastic gradient information in optimization. The technique essentially contains two consecutive steps in each iteration: 1) computing and normalizing each block (layer) of the mini-batch stochastic gradient; 2) selecting appropriate step size to update the decision variable (parameter) towards the negative of the block-normalized gradient. We conduct extensive empirical studies on various non-convex neural network optimization problems, including multilayer perceptron, convolution neural networks and recurrent neural networks. The results indicate the block-normalized gradient can help accelerate the training of neural networks.  In particular,
      we observe that the normalized gradient methods having constant step size with occasionally decay, such as SGD with momentum, have better performance in the deep convolution neural networks, while those with adaptive step sizes, such as Adam, perform better in recurrent neural networks. Besides, we also observe this line of methods can lead to solutions with better generalization properties, which is confirmed by the performance improvement over strong baselines. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1pri9vTZ">
      <h4>
        <a href="https://openreview.net/forum?id=H1pri9vTZ">
          Deep Function Machines: Generalized Neural Networks for Topological Layer Expression
        </a>
        
          <a href="https://openreview.net/pdf?id=H1pri9vTZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wguss%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wguss@cs.cmu.edu">William H. Guss</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1pri9vTZ-details-254" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1pri9vTZ-details-254"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper we propose a generalization of deep neural networks called deep function machines (DFMs). DFMs act on vector spaces of arbitrary (possibly infinite) dimension and we show that a family of DFMs are invariant to the dimension of input data; that is, the parameterization of the model does not directly hinge on the quality of the input  (eg. high resolution images). Using this generalization we provide a new theory of universal approximation of bounded non-linear operators between function spaces. We then suggest that DFMs provide an expressive framework for designing new neural network layer types with topological considerations in mind. Finally, we introduce a novel architecture, RippLeNet, for resolution invariant computer vision, which empirically achieves state of the art invariance.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning theory, infinite neural networks, topology</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJma2bZCW">
      <h4>
        <a href="https://openreview.net/forum?id=rJma2bZCW">
          Three factors influencing minima in SGD
        </a>
        
          <a href="https://openreview.net/pdf?id=rJma2bZCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=staszek.jastrzebski%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="staszek.jastrzebski@gmail.com">Stanisław Jastrzębski</a>, <a href="https://openreview.net/profile?email=zakenton%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zakenton@gmail.com">Zac Kenton</a>, <a href="https://openreview.net/profile?email=devansh.arpit%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="devansh.arpit@umontreal.ca">Devansh Arpit</a>, <a href="https://openreview.net/profile?email=ballas.n%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ballas.n@gmail.com">Nicolas Ballas</a>, <a href="https://openreview.net/profile?email=asja.fischer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="asja.fischer@gmail.com">Asja Fischer</a>, <a href="https://openreview.net/profile?email=a.storkey%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.storkey@ed.ac.uk">Amos Storkey</a>, <a href="https://openreview.net/profile?email=yoshua.umontreal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.umontreal@gmail.com">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJma2bZCW-details-209" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJma2bZCW-details-209"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the statistical properties of the endpoint of stochastic gradient descent (SGD). We approximate SGD as a stochastic differential equation (SDE) and consider its Boltzmann Gibbs equilibrium distribution under the assumption of isotropic variance in loss gradients.. Through this analysis, we find that three factors – learning rate, batch size and the variance of the loss gradients – control the trade-off between the depth and width of the minima found by SGD, with wider minima favoured by a higher ratio of learning rate to batch size. In the equilibrium distribution only the ratio of learning rate to batch size appears, implying that it’s invariant under a simultaneous rescaling of each by the same amount. 
      We experimentally show how learning rate and batch size affect SGD from two perspectives: the endpoint of SGD and the dynamics that lead up to it. For the endpoint, the experiments suggest the endpoint of SGD is similar under simultaneous rescaling of batch size and learning rate, and also that a higher ratio leads to flatter minima, both findings are consistent with our theoretical analysis. We note experimentally that the dynamics also seem to be similar under the same rescaling of learning rate and batch size, which we explore showing that one can exchange batch size and learning rate in a cyclical learning rate schedule. Next, we illustrate how noise affects memorization, showing that high noise levels lead to better generalization. Finally, we find experimentally that the similarity under simultaneous rescaling of learning rate and batch size breaks down if the learning rate gets too large or the batch size gets too small.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Three factors (batch size, learning rate, gradient noise) change in predictable way the properties (e.g. sharpness) of minima found by SGD.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">SGD, Deep Learning, Generalization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk3mjYRp-">
      <h4>
        <a href="https://openreview.net/forum?id=rk3mjYRp-">
          Diffusing Policies : Towards Wasserstein Policy Gradient Flows
        </a>
        
          <a href="https://openreview.net/pdf?id=rk3mjYRp-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=phr17%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="phr17@imperial.ac.uk">Pierre H. Richemond</a>, <a href="https://openreview.net/profile?email=b.maginnis%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="b.maginnis@imperial.ac.uk">Brendan Maginnis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk3mjYRp--details-295" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk3mjYRp--details-295"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Policy gradients methods often achieve better performance when the change in policy is limited to a small Kullback-Leibler divergence. We derive policy gradients where the change in policy is limited to a small Wasserstein distance (or trust region). This is done in the discrete and continuous multi-armed bandit settings with entropy regularisation. We show that in the small steps limit with respect to the Wasserstein distance $W_2$, policy dynamics are governed by the heat equation, following the Jordan-Kinderlehrer-Otto result. This means that policies undergo diffusion and advection, concentrating near actions with high reward. This helps elucidate the nature of convergence in the probability matching setup, and provides justification for empirical practices such as Gaussian policy priors and additive gradient noise.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Linking Wasserstein-trust region entropic policy gradients, and the heat equation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Optimal transport, policy gradients, entropy regularization, reinforcement learning, heat equation, Wasserstein, JKO, gradient flows</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxjwgbRZ">
      <h4>
        <a href="https://openreview.net/forum?id=HyxjwgbRZ">
          Convergence rate of sign stochastic gradient descent for non-convex functions
        </a>
        
          <a href="https://openreview.net/pdf?id=HyxjwgbRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bernstein%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bernstein@caltech.edu">Jeremy Bernstein</a>, <a href="https://openreview.net/profile?email=kazizzad%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kazizzad@uci.edu">Kamyar Azizzadenesheli</a>, <a href="https://openreview.net/profile?email=yuxiangw%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuxiangw@cs.cmu.edu">Yu-Xiang Wang</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Anima Anandkumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyxjwgbRZ-details-594" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxjwgbRZ-details-594"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The sign stochastic gradient descent method (signSGD) utilizes only the sign of the stochastic gradient in its updates. Since signSGD carries out one-bit quantization of the gradients, it is extremely practical for distributed optimization where gradients need to be aggregated from different processors. For the first time, we establish convergence rates for signSGD on general non-convex functions under transparent conditions. We show that the rate of signSGD to reach first-order critical points matches that of SGD in terms of number of stochastic gradient calls, up to roughly a linear factor in the dimension. We carry out simple experiments to explore the behaviour of sign gradient descent (without the stochasticity) close to saddle points and show that it often helps completely avoid them without using either stochasticity or curvature information.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove a non-convex convergence rate for the sign stochastic gradient method. The algorithm has links to algorithms like Adam and Rprop, as well as gradient quantisation schemes used in distributed machine learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">sign, stochastic, gradient, non-convex, optimization, gradient, quantization, convergence, rate</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1uvH_gC-">
      <h4>
        <a href="https://openreview.net/forum?id=B1uvH_gC-">
          Parametric Manifold Learning Via Sparse Multidimensional Scaling
        </a>
        
          <a href="https://openreview.net/pdf?id=B1uvH_gC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=paigautam%40cs.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="paigautam@cs.technion.ac.il">Gautam Pai</a>, <a href="https://openreview.net/profile?email=ronen%40ef.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronen@ef.technion.ac.il">Ronen Talmon</a>, <a href="https://openreview.net/profile?email=ron%40cs.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="ron@cs.technion.ac.il">Ron Kimmel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1uvH_gC--details-671" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1uvH_gC--details-671"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a metric-learning framework for computing distance-preserving maps that generate low-dimensional embeddings for a certain class of manifolds. We employ Siamese networks to solve the problem of least squares multidimensional scaling for generating mappings that preserve geodesic distances on the manifold. In contrast to previous parametric manifold learning methods we show a substantial reduction in training effort enabled by the computation of geodesic distances in a farthest point sampling strategy. Additionally, the use of a network to model the distance-preserving map reduces the complexity of the multidimensional scaling problem and leads to an improved non-local generalization of the manifold compared to analogous non-parametric counterparts. We demonstrate our claims on point-cloud data and on image manifolds and show a numerical analysis of our technique to facilitate a greater understanding of the representational power of neural networks in modeling manifold data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Parametric Manifold Learning with Neural Networks in a Geometric Framework </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Manifold Learning, Non-linear Dimensionality Reduction, Neural Networks, Unsupervised Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk0pHeZAW">
      <h4>
        <a href="https://openreview.net/forum?id=Sk0pHeZAW">
          Sparse Regularized Deep Neural Networks For Efficient Embedded Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk0pHeZAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jb4e14%40soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jb4e14@soton.ac.uk">Jia Bi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk0pHeZAW-details-956" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk0pHeZAW-details-956"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning is becoming more widespread in its application due to its power in solving complex classification problems. However, deep learning models often require large memory and energy consumption, which may prevent them from being deployed effectively on embedded platforms, limiting their applications. This work addresses the problem by proposing methods {\em Weight Reduction Quantisation} for compressing the memory footprint of the models, including reducing the number of weights and the number of bits to store each weight. Beside, applying with sparsity-inducing regularization, our work focuses on speeding up stochastic variance reduced gradients (SVRG) optimization on non-convex problem. Our method that mini-batch SVRG with $\ell$1 regularization on non-convex problem has faster and smoother convergence rates than SGD by using adaptive learning rates. Experimental evaluation of our approach uses MNIST and CIFAR-10 datasets on LeNet-300-100 and LeNet-5 models, showing our approach can reduce the memory requirements both in the convolutional and fully connected layers by up to 60$\times$ without affecting their test accuracy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Compression of Deep neural networks deployed on embedded device. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Sparse representation, Compression Deep Learning Models, L1 regularisation, Optimisation.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1ISxGZRb">
      <h4>
        <a href="https://openreview.net/forum?id=r1ISxGZRb">
          Generation and Consolidation of Recollections for Efficient Deep Lifelong Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=r1ISxGZRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mdriemer%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mdriemer@us.ibm.com">Matt Riemer</a>, <a href="https://openreview.net/profile?email=franceschini%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="franceschini@us.ibm.com">Michele Franceschini</a>, <a href="https://openreview.net/profile?email=tklinger%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tklinger@us.ibm.com">and Tim Klinger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1ISxGZRb-details-487" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1ISxGZRb-details-487"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep lifelong learning systems need to efficiently manage resources to scale to large numbers of experiences and non-stationary goals. In this paper, we explore the relationship between lossy compression and the resource constrained lifelong learning problem of function transferability. We demonstrate that lossy episodic experience storage can enable efficient function transferability between different architectures and algorithms at a fraction of the storage cost of lossless storage. This is achieved by introducing a generative knowledge distillation strategy that does not store any full training examples. As an important extension of this idea, we show that lossy recollections stabilize deep networks much better than lossless sampling in resource constrained settings of lifelong learning while avoiding catastrophic forgetting. For this setting, we propose a novel dual purpose recollection buffer used to both stabilize the recollection generator itself and an accompanying reasoning model. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S14EogZAZ">
      <h4>
        <a href="https://openreview.net/forum?id=S14EogZAZ">
          Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=S14EogZAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wenbinli%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenbinli@mpi-inf.mpg.de">Wenbin Li</a>, <a href="https://openreview.net/profile?email=bohg%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bohg@stanford.edu">Jeannette Bohg</a>, <a href="https://openreview.net/profile?email=mfritz%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mfritz@mpi-inf.mpg.de">Mario Fritz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S14EogZAZ-details-781" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S14EogZAZ-details-781"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Understanding physical phenomena is a key component of human intelligence and enables physical interaction with previously unseen environments. In this paper, we study how an artificial agent can autonomously acquire this intuition through interaction with the environment. We created a synthetic block stacking environment with physics simulation in which the agent can learn a policy end-to-end through trial and error. Thereby, we bypass to explicitly model physical knowledge within the policy. We are specifically interested in tasks that require the agent to reach a given goal state that may be different for every new trial. To this end, we propose a deep reinforcement learning framework that learns policies which are parametrized by a goal. We validated the model on a toy example navigating in a grid world with different target positions and in a block stacking task with different target structures of the final tower. In contrast to prior work, our policies show better generalization across different goals.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJssAZ-0-">
      <h4>
        <a href="https://openreview.net/forum?id=rJssAZ-0-">
          TRL: Discriminative Hints for Scalable Reverse Curriculum Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rJssAZ-0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jere.wang%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jere.wang@sjtu.edu.cn">Chen Wang</a>, <a href="https://openreview.net/profile?email=cxy_1997%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxy_1997@sjtu.edu.cn">Xiangyu Chen</a>, <a href="https://openreview.net/profile?email=h_e_r_o%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="h_e_r_o@sjtu.edu.cn">Zelin Ye</a>, <a href="https://openreview.net/profile?email=faldict%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="faldict@sjtu.edu.cn">Jialu Wang</a>, <a href="https://openreview.net/profile?email=sjtu_caiziruo%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjtu_caiziruo@sjtu.edu.cn">Ziruo Cai</a>, <a href="https://openreview.net/profile?email=sg717%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sg717@cam.ac.uk">Shixiang Gu</a>, <a href="https://openreview.net/profile?email=lucewu%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lucewu@sjtu.edu.cn">Cewu Lu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJssAZ-0--details-449" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJssAZ-0--details-449"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep reinforcement learning algorithms have proven successful in a variety of domains. However, tasks with sparse rewards remain challenging when the state space is large. Goal-oriented tasks are among the most typical problems in this domain, where a reward can only be received when the final goal is accomplished. In this work, we propose a potential solution to such problems with the introduction of an experience-based tendency reward mechanism, which provides the agent with additional hints based on a discriminative learning on past experiences during an automated reverse curriculum. This mechanism not only provides dense additional learning signals on what states lead to success, but also allows the agent to retain only this tendency reward instead of the whole histories of experience during multi-phase curriculum learning. We extensively study the advantages of our method on the standard sparse reward domains like Maze and Super Mario Bros and show that our method performs more efficiently and robustly than prior approaches in tasks with long time horizons and large state space. In addition, we demonstrate that using an optional keyframe scheme with very small quantity of key states, our approach can solve difficult robot manipulation challenges directly from perception and sparse rewards.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose Tendency RL to efficiently solve goal-oriented tasks with large state space using automated curriculum learning and discriminative shaping reward, which has the potential to tackle robot manipulation tasks with perception.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, deep reinforcement learning, robotics, perception</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkeC_J-R-">
      <h4>
        <a href="https://openreview.net/forum?id=BkeC_J-R-">
          Combination of Supervised and Reinforcement Learning For Vision-Based Autonomous Control
        </a>
        
          <a href="https://openreview.net/pdf?id=BkeC_J-R-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=d.kangin%40exeter.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.kangin@exeter.ac.uk">Dmitry Kangin</a>, <a href="https://openreview.net/profile?email=n.pugeault%40exeter.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="n.pugeault@exeter.ac.uk">Nicolas Pugeault</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkeC_J-R--details-759" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkeC_J-R--details-759"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> Reinforcement learning methods have recently achieved impressive results on a wide range of control problems. However, especially with complex inputs, they still require an extensive amount of training data in order to converge to a meaningful solution. This limitation largely prohibits  their usage for complex input spaces such as video signals, and it is still impossible to use it for a number of complex problems in a real world environments, including many of those for video based control. Supervised learning, on the contrary, is capable of learning on a relatively small number of samples, however it does not take into account reward-based control policies and is not capable to provide independent control policies.  In this article we propose a model-free control method, which uses a combination of reinforcement and supervised learning for autonomous control and paves the way towards policy based control in real world environments. We use SpeedDreams/TORCS video game to demonstrate that our approach requires much less samples (hundreds of thousands against millions or tens of millions) comparing to the state-of-the-art reinforcement learning techniques on similar data, and at the same time overcomes both supervised and reinforcement learning approaches in terms of quality. Additionally, we demonstrate the applicability of the method to MuJoCo control problems. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The new combination of reinforcement and supervised learning, dramatically decreasing the number of required samples for training on video</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement learning, deep learning, autonomous control</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HktXuGb0-">
      <h4>
        <a href="https://openreview.net/forum?id=HktXuGb0-">
          Reward Estimation via State Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=HktXuGb0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=daiki%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daiki@jp.ibm.com">Daiki Kimura</a>, <a href="https://openreview.net/profile?email=subhajit%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="subhajit@jp.ibm.com">Subhajit Chaudhury</a>, <a href="https://openreview.net/profile?email=ryuki%40jp.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryuki@jp.ibm.com">Ryuki Tachibana</a>, <a href="https://openreview.net/profile?email=sakya%40leapmind.io" class="profile-link" data-toggle="tooltip" data-placement="top" title="sakya@leapmind.io">Sakyasingha Dasgupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HktXuGb0--details-165" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HktXuGb0--details-165"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement learning typically requires carefully designed reward functions in order to learn the desired behavior. We present a novel reward estimation method that is based on a finite sample of optimal state trajectories from expert demon- strations and can be used for guiding an agent to mimic the expert behavior. The optimal state trajectories are used to learn a generative or predictive model of the “good” states distribution. The reward signal is computed by a function of the difference between the actual next state acquired by the agent and the predicted next state given by the learned generative or predictive model. With this inferred reward function, we perform standard reinforcement learning in the inner loop to guide the agent to learn the given task. Experimental evaluations across a range of tasks demonstrate that the proposed method produces superior performance compared to standard reinforcement learning with both complete or sparse hand engineered rewards. Furthermore, we show that our method successfully enables an agent to learn good actions directly from expert player video of games such as the Super Mario Bros and Flappy Bird.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Reward Estimation from Game Videos</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reinforcement learning, inverse reinforcement learning, imitation learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgVaG-Ab">
      <h4>
        <a href="https://openreview.net/forum?id=BJgVaG-Ab">
          AUTOMATA GUIDED HIERARCHICAL REINFORCEMENT LEARNING FOR ZERO-SHOT SKILL COMPOSITION
        </a>
        
          <a href="https://openreview.net/pdf?id=BJgVaG-Ab" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xli87%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xli87@bu.edu">Xiao Li</a>, <a href="https://openreview.net/profile?email=yaoma%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaoma@bu.edu">Yao Ma</a>, <a href="https://openreview.net/profile?email=cbelta%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbelta@bu.edu">Calin Belta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJgVaG-Ab-details-819" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgVaG-Ab-details-819"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">An obstacle that prevents the wide adoption of (deep) reinforcement learning (RL) in control systems is its need for a large number of interactions with the environment in order to master a skill. The learned skill usually generalizes poorly across domains and re-training is often necessary when presented with a new task. We present a framework that combines techniques in \textit{formal methods} with \textit{hierarchical reinforcement learning} (HRL). The set of techniques we provide allows for the convenient specification of tasks with logical expressions, learns hierarchical policies (meta-controller and low-level controllers) with well-defined intrinsic rewards using any RL methods and is able to construct new skills from existing ones without additional learning. We evaluate the proposed methods in a simple grid world simulation as well as simulation on a Baxter robot. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Combine temporal logic with hierarchical reinforcement learning for skill composition</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Hierarchical reinforcement learning, temporal logic, skill composition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJFOptp6Z">
      <h4>
        <a href="https://openreview.net/forum?id=rJFOptp6Z">
          Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification
        </a>
        
          <a href="https://openreview.net/pdf?id=rJFOptp6Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chongwang.nlpr%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongwang.nlpr@gmail.com">Chong Wang</a>, <a href="https://openreview.net/profile?email=xipeng.lan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xipeng.lan@gmail.com">Xipeng Lan</a>, <a href="https://openreview.net/profile?email=caveman1984%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="caveman1984@gmail.com">Yangang Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJFOptp6Z-details-892" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJFOptp6Z-details-892"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Knowledge distillation is a potential solution for model compression. The idea is to make a small student network imitate the target of a large teacher network, then the student network can be competitive to the teacher one. Most previous studies focus on model distillation in the classification task, where they propose different architectures and initializations for the student network. However, only the classification task is not enough, and other related tasks such as regression and retrieval are barely considered. To solve the problem, in this paper, we take face recognition as a breaking point and propose model distillation with knowledge transfer from face classification to alignment and verification. By selecting appropriate initializations and targets in the knowledge transfer, the distillation can be easier in non-classification tasks. Experiments on the CelebA and CASIA-WebFace datasets demonstrate that the student network can be competitive to the teacher one in alignment and verification, and even surpasses the teacher network under specific compression rates. In addition, to achieve stronger knowledge transfer, we also use a common initialization trick to improve the distillation performance of classification. Evaluations on the CASIA-Webface and large-scale MS-Celeb-1M datasets show the effectiveness of this simple trick.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We take face recognition as a breaking point and propose model distillation with knowledge transfer from face classification to alignment and verification</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">distill, transfer, classification, alignment, verification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sktm4zWRb">
      <h4>
        <a href="https://openreview.net/forum?id=Sktm4zWRb">
          Soft Value Iteration Networks for Planetary Rover Path Planning
        </a>
        
          <a href="https://openreview.net/pdf?id=Sktm4zWRb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mpflueger%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mpflueger@gmail.com">Max Pflueger</a>, <a href="https://openreview.net/profile?email=aliahga%40jpl.nasa.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="aliahga@jpl.nasa.gov">Ali Agha</a>, <a href="https://openreview.net/profile?email=gaurav%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gaurav@usc.edu">Gaurav S. Sukhatme</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sktm4zWRb-details-744" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sktm4zWRb-details-744"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Value iteration networks are an approximation of the value iteration (VI) algorithm implemented with convolutional neural networks to make VI fully differentiable. In this work, we study these networks in the context of robot motion planning, with a focus on applications to planetary rovers. The key challenging task in learning-based motion planning is to learn a transformation from terrain observations to a suitable navigation reward function. In order to deal with complex terrain observations and policy learning, we propose a value iteration recurrence, referred to as the soft value iteration network (SVIN). SVIN is designed to produce more effective training gradients through the value iteration network. It relies on a soft policy model, where the policy is represented with a probability distribution over all possible actions, rather than a deterministic policy that returns only the best action. We demonstrate the effectiveness of the proposed method in robot motion planning scenarios. In particular, we study the application of SVIN to very challenging problems in planetary rover navigation and present early training results on data gathered by the  Curiosity rover that is currently operating on Mars.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose an improvement to value iteration networks, with applications to planetary rover path planning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">value iteration networks, robotics, space robotics, imitation learning, convolutional neural networks, path planning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1xDcSR6W">
      <h4>
        <a href="https://openreview.net/forum?id=S1xDcSR6W">
          Hybed: Hyperbolic Neural Graph Embedding
        </a>
        
          <a href="https://openreview.net/pdf?id=S1xDcSR6W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=benjamin.chamberlain%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="benjamin.chamberlain@gmail.com">Benjamin Paul Chamberlain</a>, <a href="https://openreview.net/profile?email=james.clough%40kcl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.clough@kcl.ac.uk">James R Clough</a>, <a href="https://openreview.net/profile?email=m.deisenroth%40imperial.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.deisenroth@imperial.ac.uk">Marc Peter Deisenroth</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1xDcSR6W-details-189" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1xDcSR6W-details-189"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural embeddings have been used with great success in Natural Language Processing (NLP) where they provide compact representations that encapsulate word similarity and attain state-of-the-art performance in a range of linguistic tasks. The success of neural embeddings has prompted significant amounts of research into applications in domains other than language. One such domain is graph-structured data, where embeddings of vertices can be learned that encapsulate vertex similarity and improve performance on tasks including edge prediction and vertex labelling. For both NLP and graph-based tasks, embeddings in high-dimensional Euclidean spaces have been learned.
      However, recent work has shown that the appropriate isometric space for embedding complex networks is not the flat Euclidean space, but a negatively curved hyperbolic space. We present a new concept that exploits these recent insights and propose learning neural embeddings of graphs in hyperbolic space. We provide experimental evidence that hyperbolic embeddings significantly outperform Euclidean embeddings on vertex classification tasks for several real-world public datasets. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We learn neural embeddings of graphs in hyperbolic instead of Euclidean space</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">embeddings, hyperbolic space, neural networks, geometry</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJd0EAy0b">
      <h4>
        <a href="https://openreview.net/forum?id=SJd0EAy0b">
          Generalized Graph Embedding Models
        </a>
        
          <a href="https://openreview.net/pdf?id=SJd0EAy0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=qliu%40uestc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="qliu@uestc.edu.cn">Qiao Liu</a>, <a href="https://openreview.net/profile?email=yangxhui%40uestc.std.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangxhui@uestc.std.edu.cn">Xiaohui Yang</a>, <a href="https://openreview.net/profile?email=rwan%40uestc.std.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="rwan@uestc.std.edu.cn">Rui Wan</a>, <a href="https://openreview.net/profile?email=tusz11%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="tusz11@mails.tsinghua.edu.cn">Shouzhong Tu</a>, <a href="https://openreview.net/profile?email=wuzufeng%40uestc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuzufeng@uestc.edu.cn">Zufeng Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJd0EAy0b-details-621" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJd0EAy0b-details-621"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Many types of relations in physical, biological, social and information systems can be modeled as homogeneous or heterogeneous concept graphs. Hence, learning from and with graph embeddings has drawn a great deal of research interest recently, but only ad hoc solutions have been obtained this far. In this paper, we conjecture that the one-shot supervised learning mechanism is a bottleneck in improving the performance of the graph embedding learning algorithms, and propose to extend this by introducing a multi-shot unsupervised learning framework. Empirical results on several real-world data set show that the proposed model consistently and significantly outperforms existing state-of-the-art approaches on knowledge base completion and graph based multi-label classification tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Generalized Graph Embedding Models</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, knowledge graphs, relational inference, link prediction, multi-label classification, knowledge base completion</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1viikbCW">
      <h4>
        <a href="https://openreview.net/forum?id=S1viikbCW">
          TCAV: Relative concept importance testing with Linear Concept Activation Vectors
        </a>
        
          <a href="https://openreview.net/pdf?id=S1viikbCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=beenkim%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="beenkim@google.com">Been Kim</a>, <a href="https://openreview.net/profile?email=viegas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="viegas@google.com">Justin Gilmer</a>, <a href="https://openreview.net/profile?email=wattenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wattenberg@google.com">Martin Wattenberg</a>, <a href="https://openreview.net/profile?email=gilmer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gilmer@google.com">Fernanda Viégas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1viikbCW-details-66" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1viikbCW-details-66"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Despite neural network’s high performance, the lack of interpretability has been the main bottleneck for its safe usage in practice. In domains with high stakes (e.g., medical diagnosis), gaining insights into the network is critical for gaining trust and being adopted. One of the ways to improve interpretability of a NN is to explain the importance of a particular concept (e.g., gender) in prediction. This is useful for explaining reasoning behind the networks’ predictions, and for revealing any biases the network may have. This work aims to provide quantitative answers to \textit{the relative importance of concepts of interest} via concept activation vectors (CAV). In particular, this framework enables non-machine learning experts to express concepts of interests and  test hypotheses using examples (e.g., a set of pictures that illustrate  the concept). We show that CAV can be learned given a relatively small set of examples. Testing with CAV, for example, can answer whether a particular concept (e.g., gender) is more important in predicting a given class (e.g., doctor) than other set of concepts. Interpreting with CAV does not require any retraining or modification of the network. We show that many levels of meaningful concepts are learned (e.g., color, texture, objects, a person’s occupation), and we present CAV’s \textit{empirical deepdream} — where we maximize an activation using a set of example pictures. We show how various insights can be gained from the relative importance testing with CAV.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This work aims to provide quantitative answers to the relative importance of concepts of interest via concept activation vectors (CAV). In particular, this framework enables non-machine learning experts to express concepts of interest and test hypotheses using examples (e.g., a set of pictures that illustrate  the concept). We show that CAV can be learned given a relatively small set of examples. Hypothesis testing with CAV can answer whether a particular concept (e.g., gender) is more important in predicting a given class (e.g., doctor) than other sets of concepts. Interpreting networks with CAV does not require any retraining or modification of the network. </span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryZ3KCy0W">
      <h4>
        <a href="https://openreview.net/forum?id=ryZ3KCy0W">
          Link Weight Prediction with Node Embeddings
        </a>
        
          <a href="https://openreview.net/pdf?id=ryZ3KCy0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yuchen.hou%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuchen.hou@wsu.edu">Yuchen Hou</a>, <a href="https://openreview.net/profile?email=holder%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="holder@wsu.edu">Lawrence B. Holder</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryZ3KCy0W-details-109" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryZ3KCy0W-details-109"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Application of deep learning has been successful in various domains such as im-
      age recognition, speech recognition and natural language processing. However,
      the research on its application in graph mining is still in an early stage. Here we
      present the first generic deep learning approach to the graph link weight prediction
      problem based on node embeddings. We evaluate this approach with three differ-
      ent node embedding techniques experimentally and compare its performance with
      two state-of-the-art non deep learning baseline approaches. Our experiment re-
      sults suggest that this deep learning approach outperforms the baselines by up to
      70% depending on the dataset and embedding technique applied. This approach
      shows that deep learning can be successfully applied to link weight prediction to
      improve prediction accuracy.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJhxcGZCW">
      <h4>
        <a href="https://openreview.net/forum?id=BJhxcGZCW">
          Generative Discovery of Relational Medical Entity Pairs
        </a>
        
          <a href="https://openreview.net/pdf?id=BJhxcGZCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=czhang99%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="czhang99@uic.edu">Chenwei Zhang</a>, <a href="https://openreview.net/profile?email=yaliangli%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaliangli@baidu.com">Yaliang Li</a>, <a href="https://openreview.net/profile?email=nandu%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nandu@baidu.com">Nan Du</a>, <a href="https://openreview.net/profile?email=davidwfan%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidwfan@tencent.com">Wei Fan</a>, <a href="https://openreview.net/profile?email=psyu%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="psyu@uic.edu">Philip S. Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJhxcGZCW-details-140" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJhxcGZCW-details-140"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Online healthcare services can provide the general public with ubiquitous access to medical knowledge and reduce the information access cost for both individuals and societies. To promote these benefits, it is desired to effectively expand the scale of high-quality yet novel relational medical entity pairs that embody rich medical knowledge in a structured form. To fulfill this goal, we introduce a generative model called Conditional Relationship Variational Autoencoder (CRVAE), which can discover meaningful and novel relational medical entity pairs without the requirement of additional external knowledge. Rather than discriminatively identifying the relationship between two given medical entities in a free-text corpus, we directly model and understand medical relationships from diversely expressed medical entity pairs. The proposed model introduces the generative modeling capacity of variational autoencoder to entity pairs, and has the ability to discover new relational medical entity pairs solely based on the existing entity pairs. Beside entity pairs, relationship-enhanced entity representations are obtained as another appealing benefit of the proposed method. Both quantitative and qualitative evaluations on real-world medical datasets demonstrate the effectiveness of the proposed method in generating relational medical entity pairs that are meaningful and novel.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Generatively discover meaningful, novel entity pairs with a certain medical relationship by purely learning from the existing meaningful entity pairs, without the requirement of additional text corpus for discriminative extraction.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Knowledge Discovery, Generative Modeling, Medical, Entity Pair</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryA-jdlA-">
      <h4>
        <a href="https://openreview.net/forum?id=ryA-jdlA-">
          A closer look at the word analogy problem
        </a>
        
          <a href="https://openreview.net/pdf?id=ryA-jdlA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=siddharthkumar%40upwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="siddharthkumar@upwork.com">Siddharth Krishna Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryA-jdlA--details-858" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryA-jdlA--details-858"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Although word analogy problems have become a standard tool for evaluating word vectors, little is known about why word vectors are so good at solving these problems. In this paper, I attempt to further our understanding of the subject, by developing a simple, but highly accurate generative approach to solve the word analogy problem for the case when all terms involved in the problem are nouns. My results demonstrate the ambiguities associated with learning the relationship between a word pair, and the role of the training dataset in determining the relationship which gets most highlighted. Furthermore, my results show that the ability of a model to accurately solve the word analogy problem may not be indicative of a model’s ability to learn the relationship between a word pair the way a human does.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Simple generative approach to solve the word analogy problem which yields insights into word relationships, and the problems with estimating them</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">word2vec, glove, word analogy, word relationships, word vectors</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkF2D7g0b">
      <h4>
        <a href="https://openreview.net/forum?id=SkF2D7g0b">
          Exploring the Space of Black-box Attacks on Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkF2D7g0b" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=abhagoji%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhagoji@princeton.edu">Arjun Nitin Bhagoji</a>, <a href="https://openreview.net/profile?email=_w%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="_w@eecs.berkeley.edu">Warren He</a>, <a href="https://openreview.net/profile?email=lxbosky%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxbosky@gmail.com">Bo Li</a>, <a href="https://openreview.net/profile?email=dawnsong%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong@gmail.com">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkF2D7g0b-details-302" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkF2D7g0b-details-302"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Existing black-box attacks on deep neural networks (DNNs) so far have largely focused on transferability, where an adversarial instance generated for a locally trained model can “transfer” to attack other learning models. In this paper, we propose novel Gradient Estimation black-box attacks for adversaries with query access to the target model’s class probabilities, which do not rely on transferability. We also propose strategies to decouple the number of queries required to generate each adversarial sample from the dimensionality of the input. An iterative variant of our attack achieves close to 100% adversarial success rates for both targeted and untargeted attacks on DNNs. We carry out extensive experiments for a thorough comparative evaluation of black-box attacks and show that the proposed Gradient Estimation attacks outperform all transferability based black-box attacks we tested on both MNIST and CIFAR-10 datasets, achieving adversarial success rates similar to well known, state-of-the-art white-box attacks. We also apply the Gradient Estimation attacks successfully against a real-world content moderation classiﬁer hosted by Clarifai. Furthermore, we evaluate black-box attacks against state-of-the-art defenses. We show that the Gradient Estimation attacks are very effective even against these defenses.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Query-based black-box attacks on deep neural networks with adversarial success rates matching white-box attacks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adversarial machine learning, black-box attacks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1RF3ExCb">
      <h4>
        <a href="https://openreview.net/forum?id=r1RF3ExCb">
          Transformation Autoregressive Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1RF3ExCb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joliva%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="joliva@cs.cmu.edu">Junier Oliva</a>, <a href="https://openreview.net/profile?email=akdubey%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="akdubey@cs.cmu.edu">Avinava Dubey</a>, <a href="https://openreview.net/profile?email=bapoczos%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bapoczos@cs.cmu.edu">Barnabás Póczos</a>, <a href="https://openreview.net/profile?email=epxing%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="epxing@cs.cmu.edu">Eric P. Xing</a>, <a href="https://openreview.net/profile?email=schneide%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="schneide@cs.cmu.edu">Jeff Schneider</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1RF3ExCb-details-767" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1RF3ExCb-details-767"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The fundamental task of general density estimation has been of keen interest to machine learning. Recent advances in density estimation have either: a) proposed using a flexible model to estimate the conditional factors of the chain rule; or b) used flexible, non-linear transformations of variables of a simple base distribution. Instead, this work jointly leverages transformations of variables and autoregressive conditional models, and proposes novel methods for both. We provide a deeper understanding of our models, showing a considerable improvement with our methods through a comprehensive study over both real world and synthetic data. Moreover, we illustrate the use of our models in outlier detection and image modeling task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">density estimation, autoregressive models, RNNs</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkONG0xAW">
      <h4>
        <a href="https://openreview.net/forum?id=rkONG0xAW">
          Recursive Binary Neural Network Learning Model  with 2-bit/weight Storage Requirement
        </a>
        
          <a href="https://openreview.net/pdf?id=rkONG0xAW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tg2569%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tg2569@columbia.edu">Tianchan Guan</a>, <a href="https://openreview.net/profile?email=xyzeng%40fudan.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xyzeng@fudan.edu">Xiaoyang Zeng</a>, <a href="https://openreview.net/profile?email=ms4415%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ms4415@columbia.edu">Mingoo Seok</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkONG0xAW-details-156" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkONG0xAW-details-156"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper presents a storage-efficient learning model titled Recursive Binary Neural Networks for embedded and mobile devices having a limited amount of on-chip data storage such as hundreds of kilo-Bytes. The main idea of the proposed model is to recursively recycle data storage of weights (parameters) during training. This enables a device with a given storage constraint to train and instantiate a neural network classifier with a larger number of weights on a chip, achieving better classification accuracy. Such efficient use of on-chip storage reduces off-chip storage accesses, improving energy-efficiency and speed of training. We verified the proposed training model with deep and convolutional neural network classifiers on the MNIST and voice activity detection benchmarks. For the deep neural network, our model achieves data storage requirement of as low as 2 bits/weight, whereas the conventional binary neural network learning models require data storage of 8 to 32 bits/weight. With the same amount of data storage, our model can train a bigger network having more weights, achieving 1% less test error than the conventional binary neural network learning model. To achieve the similar classification error, the conventional binary neural network model requires 4× more data storage for weights than our proposed model. For the convolution neural network classifier, the proposed model achieves 2.4% less test error for the same on-chip storage or 6× storage savings to achieve the similar accuracy.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a learning model enabling DNN to learn with only 2 bit/weight, which is especially useful for on-device learning</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJIA6ZWC-">
      <h4>
        <a href="https://openreview.net/forum?id=SJIA6ZWC-">
          Stochastic Hyperparameter Optimization through Hypernetworks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJIA6ZWC-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=lorraine%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lorraine@cs.toronto.edu">Jonathan Lorraine</a>, <a href="https://openreview.net/profile?email=duvenaud%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="duvenaud@cs.toronto.edu">David Duvenaud</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJIA6ZWC--details-790" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJIA6ZWC--details-790"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Machine learning models are usually tuned by nesting optimization of model weights inside the optimization of hyperparameters.  We give a method to collapse this nested optimization into joint stochastic optimization of both weights and hyperparameters.  Our method trains a neural network to output approximately optimal weights as a function of hyperparameters.  We show that our method converges to locally optimal weights and hyperparameters for sufficiently large hypernets.  We compare this method to standard hyperparameter optimization strategies and demonstrate its effectiveness for tuning thousands of hyperparameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We train a neural network to output approximately optimal weights as a function of hyperparameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hypernetworks, hyperparameter optimization, metalearning, neural networks, Bayesian optimization, game theory, optimization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByW5yxgA-">
      <h4>
        <a href="https://openreview.net/forum?id=ByW5yxgA-">
          Multiscale Hidden Markov Models For Covariance Prediction
        </a>
        
          <a href="https://openreview.net/pdf?id=ByW5yxgA-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=joao%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="joao@cis.upenn.edu">João Sedoc</a>, <a href="https://openreview.net/profile?email=jsr6q%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsr6q@virginia.edu">Jordan Rodu</a>, <a href="https://openreview.net/profile?email=dean%40foster.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="dean@foster.net">Dean Foster</a>, <a href="https://openreview.net/profile?email=ungar%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ungar@cis.upenn.edu">Lyle Ungar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ByW5yxgA--details-772" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByW5yxgA--details-772"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper presents a novel variant of hierarchical hidden Markov models (HMMs), the multiscale hidden Markov model (MSHMM), and an associated spectral estimation and prediction scheme that is consistent, finds global optima, and is computationally efficient. Our MSHMM is a generative model of multiple HMMs evolving at different rates where the observation is a result of the additive emissions of the HMMs. While estimation is relatively straightforward, prediction for the MSHMM poses a unique challenge, which we address in this paper.  Further, we show that spectral estimation of the MSHMM outperforms standard  methods of predicting the asset covariance of stock prices, a widely addressed problem that is multiscale, non-stationary, and requires processing huge amounts of data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multiscale models, hidden Markov model, covariance prediction</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1uOhfb0W">
      <h4>
        <a href="https://openreview.net/forum?id=r1uOhfb0W">
          Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning
        </a>
        
          <a href="https://openreview.net/pdf?id=r1uOhfb0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhangyic17%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangyic17@mails.tsinghua.edu.cn">Yichi Zhang</a>, <a href="https://openreview.net/profile?email=ozj%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ozj@tsinghua.edu.cn">Zhijian Ou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1uOhfb0W-details-863" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1uOhfb0W-details-863"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">An ensemble of neural networks is known to be more robust and accurate than an individual network, however usually with linearly-increased cost in both training and testing. 
      In this work, we propose a two-stage method to learn Sparse Structured Ensembles (SSEs) for neural networks.
      In the first stage, we run SG-MCMC with group sparse priors to draw an ensemble of samples from the posterior distribution of network parameters. In the second stage, we apply weight-pruning to each sampled network and then perform retraining over the remained connections.
      In this way of learning SSEs with SG-MCMC and pruning, we not only achieve high prediction accuracy since SG-MCMC enhances exploration of the model-parameter space, but also reduce memory and computation cost significantly in both training and testing of NN ensembles.
      This is thoroughly evaluated in the experiments of learning SSE ensembles of both FNNs and LSTMs.
      For example, in LSTM based language modeling (LM), we obtain 21\% relative reduction in LM perplexity by learning a SSE of 4 large LSTM models, which has only 30\% of model parameters and 70\% of computations in total, as compared to the baseline large LSTM LM.
      To the best of our knowledge, this work represents the first methodology and empirical study of integrating SG-MCMC, group sparse prior and network pruning together for learning NN ensembles.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Propose a novel method by integrating SG-MCMC sampling, group sparse prior and network pruning to learn Sparse Structured Ensemble (SSE) with improved performance and significantly reduced cost than traditional methods. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">ensemble learning, SG-MCMC, group sparse prior, network pruning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJJ0w--0W">
      <h4>
        <a href="https://openreview.net/forum?id=HJJ0w--0W">
          Long-term Forecasting using Tensor-Train RNNs
        </a>
        
          <a href="https://openreview.net/pdf?id=HJJ0w--0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rose%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rose@caltech.edu">Rose Yu</a>, <a href="https://openreview.net/profile?email=stephan%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephan@caltech.edu">Stephan Zheng</a>, <a href="https://openreview.net/profile?email=anima%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anima@caltech.edu">Anima Anandkumar</a>, <a href="https://openreview.net/profile?email=yyue%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyue@caltech.edu">Yisong Yue</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJJ0w--0W-details-212" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJJ0w--0W-details-212"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present Tensor-Train RNN (TT-RNN), a novel family of neural sequence architectures for multivariate forecasting in environments with nonlinear dynamics. Long-term forecasting in such systems is highly challenging, since there exist long-term temporal dependencies, higher-order correlations and sensitivity to error propagation. Our proposed tensor recurrent architecture addresses these issues by learning the nonlinear dynamics directly using higher order moments and high-order state transition functions. Furthermore, we decompose the higher-order structure using the tensor-train (TT) decomposition to reduce the number of parameters while preserving the model performance. We theoretically establish the approximation properties of Tensor-Train RNNs for general sequence inputs, and such guarantees are not available for usual RNNs. We also demonstrate significant long-term prediction improvements over general RNN and LSTM architectures on a range of simulated environments with nonlinear dynamics, as well on real-world climate and traffic data.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Accurate forecasting over very long time horizons using tensor-train RNNs</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">RNNs, time series forecasting, nonlinear dynamics, tensor-train</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skx5txzb0W">
      <h4>
        <a href="https://openreview.net/forum?id=Skx5txzb0W">
          A Boo(n) for Evaluating Architecture Performance
        </a>
        
          <a href="https://openreview.net/pdf?id=Skx5txzb0W" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ondrej%40bajgar.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="ondrej@bajgar.org">Ondrej Bajgar</a>, <a href="https://openreview.net/profile?email=rudolf_kadlec%40cz.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rudolf_kadlec@cz.ibm.com">Rudolf Kadlec</a>, <a href="https://openreview.net/profile?email=jankle%40cz.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jankle@cz.ibm.com">and Jan Kleindienst</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 23 Jul 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skx5txzb0W-details-655" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skx5txzb0W-details-655"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We point out important problems with the common practice of using the best single model performance for comparing deep learning architectures, and we propose a method that corrects these flaws. Each time a model is trained, one gets a different result due to random factors in the training process, which include random parameter initialization and random data shuffling. Reporting the best single model performance does not appropriately address this stochasticity. We propose a normalized expected best-out-of-n performance (Boo_n) as a way to correct these problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We point out important problems with the common practice of using the best single model performance for comparing deep learning architectures, and we propose a method that corrects these flaws.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">evaluation, methodology</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkwAEQbAb">
      <h4>
        <a href="https://openreview.net/forum?id=SkwAEQbAb">
          A novel method to determine the number of latent dimensions with SVD
        </a>
        
          <a href="https://openreview.net/pdf?id=SkwAEQbAb" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=asana.neishabouri%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="asana.neishabouri@polymtl.ca">Asana Neishabouri</a>, <a href="https://openreview.net/profile?email=michel.desmarais%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="michel.desmarais@polymtl.ca">Michel Desmarais</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkwAEQbAb-details-571" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkwAEQbAb-details-571"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Determining the number of latent dimensions is a ubiquitous problem in machine
      learning. In this study, we introduce a novel method that relies on SVD to discover
      the number of latent dimensions. The general principle behind the method is to
      compare the curve of singular values of the SVD decomposition of a data set with
      the randomized data set curve. The inferred number of latent dimensions corresponds
      to the crossing point of the two curves. To evaluate our methodology, we
      compare it with competing methods such as Kaisers eigenvalue-greater-than-one
      rule (K1), Parallel Analysis (PA), Velicers MAP test (Minimum Average Partial).
      We also compare our method with the Silhouette Width (SW) technique which is
      used in different clustering methods to determine the optimal number of clusters.
      The result on synthetic data shows that the Parallel Analysis and our method have
      similar results and more accurate than the other methods, and that our methods is
      slightly better result than the Parallel Analysis method for the sparse data sets.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In this study, we introduce a novel method that relies on SVD to discover the number of latent dimensions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">SVD, Latent Dimensions, Dimension Reductions, Machine Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ5C67-C-">
      <h4>
        <a href="https://openreview.net/forum?id=rJ5C67-C-">
          Hyperedge2vec: Distributed Representations for Hyperedges
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ5C67-C-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sharm170%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sharm170@umn.edu">Ankit Sharma</a>, <a href="https://openreview.net/profile?email=srjoty%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="srjoty@ntu.edu.sg">Shafiq Joty</a>, <a href="https://openreview.net/profile?email=himanshukharkwal765%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="himanshukharkwal765@gmail.com">Himanshu Kharkwal</a>, <a href="https://openreview.net/profile?email=srivasta%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srivasta@umn.edu">Jaideep Srivastava</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ5C67-C--details-42" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ5C67-C--details-42"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Data structured in form of overlapping or non-overlapping sets is found in a variety of domains, sometimes explicitly but often subtly. For example, teams, which are of prime importance in social science studies are \enquote{sets of individuals}; \enquote{item sets} in pattern mining are sets; and for various types of analysis in language studies a sentence can be considered as a \enquote{set or bag of words}. Although building models and inference algorithms for structured data has been an important task in the fields of machine learning and statistics, research on \enquote{set-like} data still remains less explored. Relationships between pairs of elements can be modeled as edges in a graph. However, modeling relationships that involve all members of a set, a hyperedge is a more natural representation for the set. In this work, we focus on the problem of embedding hyperedges in a hypergraph (a network of overlapping sets) to a low dimensional vector space. We propose a probabilistic deep-learning based method as well as a tensor-based algebraic model, both of which capture the hypergraph structure in a principled manner without loosing set-level information. Our central focus is to highlight the connection between hypergraphs (topology), tensors (algebra) and probabilistic models. We present a number of interesting baselines, some of which adapt existing node-level embedding models to the hyperedge-level, as well as sequence based language techniques which are adapted for set structured hypergraph topology. The performance is evaluated with a network of social groups and a network of word phrases. Our experiments show that accuracy wise our methods perform similar to those of baselines which are not designed for hypergraphs. Moreover, our tensor based method is quiet efficient as compared to deep-learning based auto-encoder method. We therefore, argue that we have proposed more general methods which are suited for hypergraphs (and therefore also for graphs) while maintaining accuracy and efficiency. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hypergraph, representation learning, tensors</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ry5wc1bCW">
      <h4>
        <a href="https://openreview.net/forum?id=ry5wc1bCW">
          Causal Generative Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=ry5wc1bCW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=olivier.goudet%40lri.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="olivier.goudet@lri.fr">Olivier Goudet</a>, <a href="https://openreview.net/profile?email=diviyan.kalainathan%40lri.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="diviyan.kalainathan@lri.fr">Diviyan Kalainathan</a>, <a href="https://openreview.net/profile?email=dlp%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlp@fb.com">David Lopez-Paz</a>, <a href="https://openreview.net/profile?email=philippe.caillou%40lri.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="philippe.caillou@lri.fr">Philippe Caillou</a>, <a href="https://openreview.net/profile?email=isabelle.guyon%40chalearn.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="isabelle.guyon@chalearn.org">Isabelle Guyon</a>, <a href="https://openreview.net/profile?email=michele.sebag%40lri.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="michele.sebag@lri.fr">Michèle Sebag</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Feb 2018 (modified: 16 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>2 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ry5wc1bCW-details-253" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ry5wc1bCW-details-253"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce CGNN, a framework to learn functional causal models as generative neural networks. These networks are trained using backpropagation to minimize the maximum mean discrepancy to the observed data. Unlike previous approaches, CGNN leverages both conditional independences and distributional asymmetries to seamlessly discover bivariate and multivariate 
       causal structures, with or without hidden variables. CGNN does not only estimate the causal structure, but a full and differentiable generative model of the data. Throughout an extensive variety of experiments, we illustrate the competitive  esults of CGNN w.r.t state-of-the-art alternatives in observational causal discovery on both simulated and real data, in the tasks of cause-effect inference, v-structure identification, and multivariate causal discovery. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Discover the structure of functional causal models with generative neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Causal structure discovery, Generative neural networks, Cause-effect pair problem, Functional causal model, Maximum Mean Discrepancy, Structural Equation Models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
</ul>
</div>
    <div role="tabpanel" class="tab-pane fade  " id="withdrawn-papers">
      
    <ul class="list-unstyled submissions-list">
    <li class="note " data-id="H1x5K0mSnQ">
      <h4>
        <a href="https://openreview.net/forum?id=H1x5K0mSnQ">
          Few-Shot Learning with Simplex
        </a>
        
          <a href="https://openreview.net/pdf?id=H1x5K0mSnQ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=bwzhang%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="bwzhang@sjtu.edu.cn">Bowen Zhang</a>, <a href="https://openreview.net/profile?email=xf-zh14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xf-zh14@mails.tsinghua.edu.cn">Xifan Zhang</a>, <a href="https://openreview.net/profile?email=chengfan85%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chengfan85@gmail.com">Fan Cheng</a>, <a href="https://openreview.net/profile?email=zhaodeli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaodeli@gmail.com">Deli Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">30 Oct 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1x5K0mSnQ-details-838" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1x5K0mSnQ-details-838"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning has made remarkable achievement in many fields. However, learning
      the parameters of neural networks usually demands a large amount of labeled
      data. The algorithms of deep learning, therefore, encounter difficulties when applied
      to supervised learning where only little data are available. This specific task
      is called few-shot learning. To address it, we propose a novel algorithm for fewshot
      learning using discrete geometry, in the sense that the samples in a class are
      modeled as a reduced simplex. The volume of the simplex is used for the measurement
      of class scatter. During testing, combined with the test sample and the
      points in the class, a new simplex is formed. Then the similarity between the test
      sample and the class can be quantized with the ratio of volumes of the new simplex
      to the original class simplex. Moreover, we present an approach to constructing
      simplices using local regions of feature maps yielded by convolutional neural networks.
      Experiments on Omniglot and miniImageNet verify the effectiveness of
      our simplex algorithm on few-shot learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simplex-based geometric method is proposed to cope with few-shot learning problems.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">One-shot learning, few-shot learning, deep learning, simplex</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lzcXfknm">
      <h4>
        <a href="https://openreview.net/forum?id=H1lzcXfknm">
          Tracking Loss: Converting Object Detector to Robust Visual Tracker
        </a>
        
          <a href="https://openreview.net/pdf?id=H1lzcXfknm" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhenb.yan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhenb.yan@gmail.com">Zhenbin Yan</a>, <a href="https://openreview.net/profile?email=jimmy.sj.ren%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jimmy.sj.ren@gmail.com">Jimmy Ren</a>, <a href="https://openreview.net/profile?email=issliao%40cityu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="issliao@cityu.edu.hk">Stephen Shaoyi Liao</a>, <a href="https://openreview.net/profile?email=kayang6-c%40my.cityu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="kayang6-c@my.cityu.edu.hk">Kai Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">25 Oct 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1lzcXfknm-details-606" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lzcXfknm-details-606"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we find that by designing a novel loss function entitled, ''tracking loss'', Convolutional Neural Network (CNN) based object detectors can be successfully converted to well-performed visual trackers without any extra computational cost. This property is preferable to visual tracking where annotated video sequences for training are always absent, because rich features learned by detectors from still images could be utilized by dynamic trackers. It also avoids extra machinery such as feature engineering and feature aggregation proposed in previous studies. Tracking loss achieves this property by exploiting the internal structure of feature maps within the detection network and treating different feature points discriminatively. Such structure allows us to simultaneously consider discrimination quality and bounding box accuracy which is found to be crucial to the success. We also propose a network compression method to accelerate tracking speed without performance reduction. That also verifies tracking loss will remain highly effective even if the network is drastically compressed. Furthermore, if we employ a carefully designed tracking loss ensemble, the tracker would be much more robust and accurate. Evaluation results show that our trackers (including the ensemble tracker and two baseline trackers), outperform all state-of-the-art methods on VOT 2016 Challenge in terms of Expected Average Overlap (EAO) and robustness. We will make the code publicly available.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We successfully convert a popular detector RPN to a well-performed tracker from the viewpoint of loss function.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Object detection, Visual Tracking, Loss function, Region Proposal Network, Network compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1g-gk5EuQ">
      <h4>
        <a href="https://openreview.net/forum?id=H1g-gk5EuQ">
          Large Margin Neural Language Models
        </a>
        
          <a href="https://openreview.net/pdf?id=H1g-gk5EuQ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=huangjiaji%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huangjiaji@baidu.com">Jiaji Huang</a>, <a href="https://openreview.net/profile?email=liyi17%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liyi17@baidu.com">Yi Li</a>, <a href="https://openreview.net/profile?email=pingwei01%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pingwei01@baidu.com">Wei Ping</a>, <a href="https://openreview.net/profile?email=sanjeevsatheesh%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjeevsatheesh@baidu.com">Sanjeev Satheesh</a>, <a href="https://openreview.net/profile?email=gregdiamos%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gregdiamos@baidu.com">Gregory Diamos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">11 Sep 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1g-gk5EuQ-details-714" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1g-gk5EuQ-details-714"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural language models (NLMs) are generative, and they model the distribution of grammatical sentences. Trained on huge corpus, NLMs are pushing the limit of modeling accuracy. Besides, they have also been applied to supervised learning tasks that decode text, e.g., automatic speech recognition (ASR). By re-scoring the n-best list, NLM can select grammatically more correct candidate among the list, and significantly reduce word/char error rate. However, the generative nature of NLM may not guarantee a discrimination between “good” and “bad” (in a task-specific sense) sentences, resulting in suboptimal performance. This work proposes an approach to adapt a generative NLM to a discriminative one. Different from the commonly used maximum likelihood objective, the proposed method aims at enlarging the margin between the “good” and “bad” sentences. It is trained end-to-end and can be widely applied to tasks that involve the re-scoring of the decoded text. Significant gains are observed in both ASR and statistical machine translation (SMT) tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Enhance the language model for supervised learning task </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Language Model, discriminative model</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1eT9VMgOX">
      <h4>
        <a href="https://openreview.net/forum?id=B1eT9VMgOX">
          Clustering with Deep Learning: Taxonomy and New Methods
        </a>
        
          <a href="https://openreview.net/pdf?id=B1eT9VMgOX" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=elie.aljalbout%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="elie.aljalbout@tum.de">Elie Aljalbout</a>, <a href="https://openreview.net/profile?email=vladimir.golkov%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="vladimir.golkov@tum.de">Vladimir Golkov</a>, <a href="https://openreview.net/profile?email=yawar.siddiqui%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="yawar.siddiqui@tum.de">Yawar Siddiqui</a>, <a href="https://openreview.net/profile?email=cremers%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="cremers@tum.de">Daniel Cremers</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">07 Sep 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1eT9VMgOX-details-590" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1eT9VMgOX-details-590"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Clustering is a fundamental machine learning method. The quality of its results is dependent on the data distribution. For this reason, deep neural networks can be used for learning better representations of the data. In this paper, we propose a systematic taxonomy for clustering with deep learning, in addition to a review of methods from the field. Based on our taxonomy, creating new methods is more straightforward. We also propose a new approach which is built on the taxonomy and surpasses some of the limitations of some previous work. Our experimental evaluation on image datasets shows that the method approaches state-of-the-art clustering quality, and performs better in some cases.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Unifying framework to perform clustering using deep neural networks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">clustering, deep learning, neural networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxSG1Z3IX">
      <h4>
        <a href="https://openreview.net/forum?id=HyxSG1Z3IX">
          Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation
        </a>
        
          <a href="https://openreview.net/pdf?id=HyxSG1Z3IX" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pascaltuan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pascaltuan@gmail.com">Yi-Lin Tuan</a>, <a href="https://openreview.net/profile?email=hungyilee%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="hungyilee@ntu.edu.tw">Hung-yi Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">23 Aug 2018 (modified: 23 Aug 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyxSG1Z3IX-details-105" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxSG1Z3IX-details-105"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">conditional sequence generation, generative adversarial network, REINFORCE, dialogue generation</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgYEQ9h4m">
      <h4>
        <a href="https://openreview.net/forum?id=SkgYEQ9h4m">
          Convolutional Mesh Autoencoders for 3D Face Representation
        </a>
        
          <a href="https://openreview.net/pdf?id=SkgYEQ9h4m" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=anurag.ranjan%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="anurag.ranjan@tue.mpg.de">Anurag Ranjan</a>, <a href="https://openreview.net/profile?email=timo.bolkart%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="timo.bolkart@tuebingen.mpg.de">Timo Bolkart</a>, <a href="https://openreview.net/profile?email=black%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="black@tuebingen.mpg.de">Michael J. Black</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">30 Jul 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkgYEQ9h4m-details-927" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgYEQ9h4m-details-927"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Convolutional neural networks (CNNs) have achieved state of the art performance on recognizing and representing audio, images, videos and 3D volumes; that is, domains where the input can be characterized by a regular graph structure. 
      However, generalizing CNNs to irregular domains like 3D meshes is challenging. Additionally, training data for 3D meshes is often limited. In this work, we generalize convolutional autoencoders to mesh surfaces. We perform spectral decomposition of meshes and apply convolutions directly in frequency space. In addition, we use max pooling and introduce upsampling within the network to represent meshes in a low dimensional space. We construct a complex dataset of 20,466 high resolution meshes with extreme facial expressions and encode it using our Convolutional Mesh Autoencoder. Despite limited training data, our method outperforms state-of-the-art PCA models of faces with 50% lower error,  while using 75% fewer parameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Convolutional autoencoders generalized to mesh surfaces for encoding and reconstructing extreme 3D facial expressions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">meshes, convolutions, faces, autoencoder</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1e4p1mLfQ">
      <h4>
        <a href="https://openreview.net/forum?id=r1e4p1mLfQ">
          DENSELY CONNECTED RECURRENT NEURAL NETWORK FOR SEQUENCE-TO-SEQUENCE LEARNING
        </a>
        
          <a href="https://openreview.net/pdf?id=r1e4p1mLfQ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Fei Tian
      </div>
      
      <div class="note-meta-info">
        <span class="date">01 Jul 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1e4p1mLfQ-details-295" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1e4p1mLfQ-details-295"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep neural networks based sequence-to-sequence learning has achieved remarkable progress in applications like machine translation and text summarization. However, sequence-to-sequence models suffer from severe inefficiency in training process, requiring huge amount of training time as well as memory usage. In this work, inspired by densely connected layers in modern convolutional neural network, we introduce densely connected sequence-to-sequence learning mechanism to tackle this challenge. In this mechanism, multiple layers of representations from stacked recurrent neural networks are concatenated to enhance feature reuse. Furthermore, a densely connected attention model is elaborately leveraged to improve information flow with more efficient parameter usage via multi-branch structure and local sparsity. We show that such a densely connected mechanism significantly reduces training time and memory usage for sequence-to-sequence learning. In particular, in WMT-14 English-French translation task with a subset of 12M training data, it takes half of training time and model parameters to achieve similar BLEU as typical stacked LSTM models.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BypdvewVM">
      <h4>
        <a href="https://openreview.net/forum?id=BypdvewVM">
          Assessing the scalability of biologically-motivated deep learning algorithms and architectures
        </a>
        
          <a href="https://openreview.net/pdf?id=BypdvewVM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">13 Jan 2018 (modified: 16 Jun 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BypdvewVM-details-406" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BypdvewVM-details-406"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The backpropagation of error algorithm (BP) is often said to be impossible to implement in a real brain. The recent success of deep networks in machine learning and AI, however, has inspired a number of proposals for understanding how the brain might learn across multiple layers, and hence how it might implement or approximate BP. As of yet, none of these proposals have been rigorously evaluated on tasks where BP-guided deep learning has proved critical, or in architectures more structured than simple fully-connected networks. Here we present the first results on scaling up a biologically motivated model of deep learning to datasets which need deep networks with  appropriate architectures to achieve good performance. We present results on CIFAR-10 and ImageNet.  For CIFAR-10 we show that our algorithm, a straightforward, weight-transport-free variant of difference target-propagation (DTP) modified to remove backpropagation from the penultimate layer, is competitive with BP in training deep networks with locally defined receptive fields that have untied weights.  For ImageNet we find that both DTP and our algorithm perform significantly worse than BP, opening questions about whether different architectures or algorithms are required to scale these approaches. Our results and implementation details help establish baselines for biologically motivated deep learning schemes going forward.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Benchmarks for biologically plausible learning algorithms on complex datasets and architectures</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">target propagation, biologically-plausible learning, benchmark, neuroscience</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkeK5B9LyQ">
      <h4>
        <a href="https://openreview.net/forum?id=SkeK5B9LyQ">
          A Neural-Symbolic Approach to Natural Language Tasks
        </a>
        
          <a href="https://openreview.net/pdf?id=SkeK5B9LyQ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=idfree%40ufl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="idfree@ufl.edu">Qiuyuan Huang</a>, <a href="https://openreview.net/profile?email=psmo%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="psmo@microsoft.com">Paul Smolensky</a>, <a href="https://openreview.net/profile?email=xiaohe%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaohe@microsoft.com">Xiaodong He</a>, <a href="https://openreview.net/profile?email=deng629%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="deng629@gmail.com">Li Deng</a>, <a href="https://openreview.net/profile?email=dpwu%40ufl.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dpwu@ufl.edu">Dapeng Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 May 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkeK5B9LyQ-details-972" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkeK5B9LyQ-details-972"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning (DL) has in recent years been widely used in natural
      language processing (NLP) applications due to its superior
      performance. However, while natural languages are rich in
      grammatical structure, DL has not been able to explicitly
      represent and enforce such structures. This paper proposes a new
      architecture to bridge this gap by exploiting tensor product
      representations (TPR), a structured neural-symbolic framework
      developed in cognitive science over the past 20 years, with the
      aim of integrating DL with explicit language structures and rules.
      We call it the Tensor Product Generation Network
      (TPGN), and apply it to image captioning. The key
      ideas of TPGN are: 1) unsupervised learning of
      role-unbinding vectors of words via a TPR-based deep neural
      network, and 2) integration of TPR with typical DL architectures
      including Long Short-Term Memory (LSTM) models. The novelty of our
      approach lies in its ability to generate a sentence and extract
      partial grammatical structure of the sentence by using
      role-unbinding vectors, which are obtained in an unsupervised
      manner. Experimental results demonstrate the effectiveness of the
      proposed approach.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This paper is intended to develop a tensor product representation approach for deep-learning-based natural language processinig applications.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, tensor product representation, LSTM, image captioning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgINf1G1m">
      <h4>
        <a href="https://openreview.net/forum?id=rkgINf1G1m">
          Softmax Supervision with Isotropic Normalization
        </a>
        
          <a href="https://openreview.net/pdf?id=rkgINf1G1m" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tigerzhaoyue%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tigerzhaoyue@outlook.com">Yue Zhao</a>, <a href="https://openreview.net/profile?email=zhaodeli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaodeli@gmail.com">Deli Zhao</a>, <a href="https://openreview.net/profile?email=zhangbo%40xiaomi.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangbo@xiaomi.com">Shaohua Wan</a>, <a href="https://openreview.net/profile?email=wanshaohua%40xiaomi.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanshaohua@xiaomi.com">Bo Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">23 May 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkgINf1G1m-details-786" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgINf1G1m-details-786"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The softmax function is widely used to train deep neural networks for multi-class classification. Despite its outstanding performance in classification tasks, the features derived from the supervision of softmax are usually sub-optimal in some scenarios where Euclidean distances apply in feature spaces. To address this issue, we propose a new loss, dubbed the isotropic loss, in the sense that the overall distribution of data points is regularized to approach the isotropic normal one. Combined with the vanilla softmax, we formalize a novel criterion called the isotropic softmax, or isomax for short, for supervised learning of deep neural networks. By virtue of the isomax, the intra-class features are penalized by the isotropic loss while inter-class distances are well kept by the original softmax loss. Moreover, the isomax loss does not require any additional modifications to the network, mini-batches or the training process. Extensive experiments on classification and clustering are performed to demonstrate the superiority and robustness of the isomax loss.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The discriminative capability of softmax for learning feature vectors of objects is effectively enhanced by virture of isotropic normalization on global distribution of data points.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">softmax, center loss, triplet loss, convolution neural network, supervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryQz_ZfHz">
      <h4>
        <a href="https://openreview.net/forum?id=ryQz_ZfHz">
          Neural Variational Sparse Topic Model
        </a>
        
          <a href="https://openreview.net/pdf?id=ryQz_ZfHz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">21 Jan 2018 (modified: 13 May 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryQz_ZfHz-details-310" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryQz_ZfHz-details-310"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Effectively inferring discriminative and coherent latent topics of short texts is a critical task for many real world applications. Nevertheless, the task has been proven to be a great challenge for traditional topic models due to the data sparsity problem induced by the characteristics of short texts. Moreover, the complex inference algorithm also become a bottleneck for these traditional models to rapidly explore variations. In this paper, we propose a novel model called Neural Variational Sparse Topic Model (NVSTM) based on a sparsity-enhanced topic model named Sparse Topical Coding (STC). In the model, the auxiliary word embeddings are utilized to improve the generation of representations. The Variational Autoencoder (VAE) approach is applied to inference the model efficiently, which makes the model easy to explore extensions for its black-box inference process. Experimental results onWeb Snippets, 20Newsgroups, BBC and Biomedical datasets show the effectiveness and efficiency of the model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">a neural sparsity-enhanced topic model based on VAE</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Variational Autoencoder, Sparse Topical Coding, Neural Variational Inference</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJ1ZxXbAM">
      <h4>
        <a href="https://openreview.net/forum?id=HJ1ZxXbAM">
          DEEPCAST : UNIVERSAL TIME-SERIES FORECASTER
        </a>
        
          <a href="https://openreview.net/pdf?id=HJ1ZxXbAM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nlaptev%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nlaptev@stanford.edu">Nikolay Laptev</a>, <a href="https://openreview.net/profile?email=joyjfy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joyjfy@gmail.com">Jiafan Yu</a>, <a href="https://openreview.net/profile?email=ramr%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramr@stanford.edu">Ram Rajagopal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">10 May 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJ1ZxXbAM-details-608" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJ1ZxXbAM-details-608"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reliable and accurate time-series forecasting is critical in many fields including energy, finance, and manufacturing. Many time-series tasks, however, suffer from a limited amount of training data (i.e., the cold start problem) resulting in poor forecasting performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through CNNs’ ability to learn rich mid-level image representations. However, no prior work exists on general transfer learning for time-series forecasting. In this paper, motivated by recent success of transfer learning in CNN model and image-related tasks, we for the first time show how time-series representations learned with Long Short Term Memory (LSTM) on large-scale datasets can be efficiently transferred to other time-series forecasting tasks with limited amount of training data. We also validate that despite differences in time-series statistics and tasks in the datasets, the transferred representation leads to significantly improved forecasting results outperforming majority of the best time-series methods on the public M3 and other datasets. Our online universal forecasting tool, DeepCast, will leverage transfer learning to provide accurate forecasts for a diverse set of time series where classical methods were computationally infeasible or inapplicable due to short training history.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJHOuiqaf">
      <h4>
        <a href="https://openreview.net/forum?id=rJHOuiqaf">
          MINE: Mutual Information Neural Estimation
        </a>
        
          <a href="https://openreview.net/pdf?id=rJHOuiqaf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ishmael.belghazi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ishmael.belghazi@gmail.com">Mohamed Ishmael Belghazi</a>, <a href="https://openreview.net/profile?email=rajsai24%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rajsai24@gmail.com">Sai Rajeswar</a>, <a href="https://openreview.net/profile?email=aristidebaratin%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aristidebaratin@hotmail.com">Aristide Baratin</a>, <a href="https://openreview.net/profile?email=eronous%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eronous@gmail.com">Devon Hjelm</a>, <a href="https://openreview.net/profile?email=aaron.courville%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaron.courville@gmail.com">Aaron Courville</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">05 May 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJHOuiqaf-details-812" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJHOuiqaf-details-812"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper presents a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size. MINE is  back-propable and we prove that it is strongly consistent. We illustrate a handful of applications in which MINE is succesfully applied  to enhance the property of generative models in both unsupervised and supervised settings. We apply our framework to estimate the information bottleneck, and apply it in tasks related to supervised classification problems. Our results  demonstrate substantial added flexibility and improvement in these settings.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A scalable in sample size and dimensions mutual information estimator.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Neural Networks, Information Theory, Generative models, GAN, Adversarial</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1RPJf5Tz">
      <h4>
        <a href="https://openreview.net/forum?id=H1RPJf5Tz">
          Curiosity-driven Exploration by Bootstrapping Features
        </a>
        
          <a href="https://openreview.net/pdf?id=H1RPJf5Tz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=h.l.edwards%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="h.l.edwards@sms.ed.ac.uk">Harri Edwards</a>, <a href="https://openreview.net/profile?email=yburda%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yburda@gmail.com">Yuri Burda</a>, <a href="https://openreview.net/profile?email=a.storkey%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.storkey@ed.ac.uk">Amos Storkey</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">05 May 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1RPJf5Tz-details-866" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1RPJf5Tz-details-866"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce CBF, an exploration method that works in the absence of rewards or end of episode signal. CBF is based on intrinsic reward derived from the error of a dynamics model operating in feature space. It was inspired by (Pathak et al., 2017), is easy to implement, and can achieve results such as passing four levels of Super Mario Bros, navigating VizDoom mazes and passing two levels of SpaceInvaders. We investigated the effect of combining the method with several auxiliary tasks, but find inconsistent improvements over the CBF baseline.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A simple intrinsic motivation method using forward dynamics model error in feature space of the policy.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">exploration, intrinsic motivation, reinforcement learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkq4mpM5f">
      <h4>
        <a href="https://openreview.net/forum?id=Hkq4mpM5f">
          Embedding Deep Networks into Visual Explanations
        </a>
        
          <a href="https://openreview.net/pdf?id=Hkq4mpM5f" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=qiz%40oregonstate.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiz@oregonstate.edu">Zhongang Qi</a>, <a href="https://openreview.net/profile?email=lif%40eecs.oregonstate.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lif@eecs.oregonstate.edu">Fuxin Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">24 Mar 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hkq4mpM5f-details-594" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkq4mpM5f-details-594"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a novel explanation module to explain the predictions made by a deep network. Explanation module works by embedding a high-dimensional deep network layer nonlinearly into a low-dimensional explanation space while retaining faithfulness, so that the original deep learning predictions can be constructed from the few concepts extracted by the explanation module. We then visualize such concepts for human to learn about the high-level concepts that deep learning is using to make decisions. We propose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for learning the embedding to the explanation space. SRAE aims to reconstruct part of the original feature space while retaining faithfulness. A visualization system is then introduced for human understanding of features in the explanation space. The proposed method is applied to explain CNN models in image classification tasks, and several novel metrics are introduced to evaluate the performance of explanations quantitatively without human involvement. Experiments show that the proposed approach could generate better explanations of the mechanisms CNN use for making predictions.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyW0afxKM">
      <h4>
        <a href="https://openreview.net/forum?id=HyW0afxKM">
          Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner
        </a>
        
          <a href="https://openreview.net/pdf?id=HyW0afxKM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nicolas.duminy%40telecom-bretagne.eu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nicolas.duminy@telecom-bretagne.eu">Nicolas Duminy</a>, <a href="https://openreview.net/profile?email=nguyensmai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nguyensmai@gmail.com">Sao Mai Nguyen</a>, <a href="https://openreview.net/profile?email=dominique.duhaut%40univ-ubs.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="dominique.duhaut@univ-ubs.fr">Dominique Duhaut</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">09 Mar 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyW0afxKM-details-366" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyW0afxKM-details-366"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose an active learning algorithmic architecture, capable of organizing its learning process in order to achieve a field of complex tasks by learning sequences of primitive motor policies : Socially Guided Intrinsic Motivation with Procedure Babbling (SGIM-PB). The learner can generalize over its experience to continuously learn new outcomes, by choosing actively what and how to learn guided by empirical measures of its own progress. In this paper, we are considering the learning of a set of interrelated complex outcomes hierarchically organized.
      
      We introduce a new framework called "procedures", which enables the autonomous discovery of how to combine previously learned skills in order to learn increasingly more complex motor policies (combinations of primitive motor policies). Our architecture can actively decide which outcome to focus on and which exploration strategy to apply. Those strategies could be autonomous exploration, or active social guidance, where it relies on the expertise of a human teacher providing demonstrations at the learner's request. We show on a simulated environment that our new architecture is capable of tackling the learning of complex motor policies, to adapt the complexity of its policies to the task at hand. We also show that our "procedures" increases the agent's capability to learn complex tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper describes a strategic intrinsically motivated learning algorithm which tackles the learning of complex motor policies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">developmental robotics, intrinsic motivation, strategic learning, complex motor policies</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Symlf87uG">
      <h4>
        <a href="https://openreview.net/forum?id=Symlf87uG">
          Semi-supervised Regression with Generative Adversarial Networks for End to End Learning in Autonomous Driving
        </a>
        
          <a href="https://openreview.net/pdf?id=Symlf87uG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mehdi.rezagholizadeh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mehdi.rezagholizadeh@gmail.com">Mehdi Rezagholizadeh</a>, <a href="https://openreview.net/profile?email=md.akmal.haidar%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="md.akmal.haidar@huawei.com">Md Akmal Haidar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">28 Feb 2018 (modified: 28 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Symlf87uG-details-369" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Symlf87uG-details-369"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This research concerns solving the semi-supervised learning problem with generative adversarial networks for regression. In contrast to classification, where only a limited number of distinct classes is given, the regression task is defined as predicting continuous labels for a given dataset. Semi-supervised learning is of vital importance for the applications where a small number of labeled samples is available, or labeling samples is difficult or expensive to collect. A case in point is autonomous driving in which obtaining sufficient labeled samples covering all driving conditions is costly. In this context, we can take advantage of semi-supervised learning techniques with groundbreaking generative models, such as generative adversarial networks. However, almost all proposed GAN-based semi-supervised techniques in the literature are focused on solving the classification problem. Hence, developing a GAN-based semi-supervised method for the regression task is still an open problem. In this work, two different architectures will be proposed to address this problem. In summary, our introduced method is able to predict continuous labels for a training dataset which has only a limited number of labeled samples. Moreover, the application of this technique for solving the end-to-end task in autonomous driving will be presented.  
      We performed several experiments over a publicly available driving dataset to evaluate our proposed method, and the results are very promising. The results show that our approach generates images with high quality, gives smaller label prediction error and leads to a more stable training compared with the state-of-the-art Improved GAN technique~\citep{ImprovedGAN2016}.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, Regression, SSL, Autonomous Driving</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJQhyvYwG">
      <h4>
        <a href="https://openreview.net/forum?id=HJQhyvYwG">
          DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension
        </a>
        
          <a href="https://openreview.net/pdf?id=HJQhyvYwG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=amrita.saha87%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amrita.saha87@gmail.com">Amrita Saha</a>, <a href="https://openreview.net/profile?email=rahul.a.r%40in.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rahul.a.r@in.ibm.com">Rahul Aralikatte</a>, <a href="https://openreview.net/profile?email=miteshk%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="miteshk@cse.iitm.ac.in">Mitesh M. Khapra</a>, <a href="https://openreview.net/profile?email=kartsank%40in.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kartsank@in.ibm.com">Karthik Sankaranarayanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">20 Feb 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJQhyvYwG-details-534" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJQhyvYwG-details-534"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in language understanding beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie - one from Wikipedia and the other from IMDb - written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize corresponding answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different level of plot detail, narration style, vocabulary, etc., answering questions from the second version requires deeper language understanding and incorporating background knowledge not available in the given text. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor performance (F1 score of 37.42% on DuoRC v/s 86% on SQuAD dataset). This opens up several interesting research avenues wherein DuoRC could complement other Reading Comprehension style datasets to explore novel neural approaches for studying language understanding.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose DuoRC, a novel dataset for Reading Comprehension (RC) containing 186,089 human-generated QA pairs created from a collection of 7680 pairs of parallel movie plots and introduce a RC task of reading one version of the plot and answering questions created from the other version; thus by design, requiring complex reasoning and deeper language understanding to overcome the poor lexical overlap between the plot and the question.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">reading comprehension, question answering</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkv76ilDz">
      <h4>
        <a href="https://openreview.net/forum?id=Bkv76ilDz">
          Discrete Wasserstein Generative Adversarial Networks (DWGAN)
        </a>
        
          <a href="https://openreview.net/pdf?id=Bkv76ilDz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rfatho2%40uic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rfatho2@uic.edu">Rizal Fathony</a>, <a href="https://openreview.net/profile?email=naveen.goela%40technicolor.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="naveen.goela@technicolor.com">Naveen Goela</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">14 Feb 2018 (modified: 14 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bkv76ilDz-details-861" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkv76ilDz-details-861"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Generating complex discrete distributions remains as one of the challenging problems in machine learning. Existing techniques for generating complex distributions with high degrees of freedom depend on standard generative models like Generative Adversarial Networks (GAN), Wasserstein GAN, and associated variations. Such models are based on an optimization involving the distance between two continuous distributions. We introduce a Discrete Wasserstein GAN (DWGAN) model which is based on a dual formulation of the Wasserstein distance between two discrete distributions. We derive a novel training algorithm and corresponding network architecture based on the formulation. Experimental results are provided for both synthetic discrete data, and real discretized data from MNIST handwritten digits.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a Discrete Wasserstein GAN (DWGAN) model which is based on a dual formulation of the Wasserstein distance between two discrete distributions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">GAN, wasserstein distance, discrete probability distribution</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJTCsqMUf">
      <h4>
        <a href="https://openreview.net/forum?id=SJTCsqMUf">
          Deep contextualized word representations
        </a>
        
          <a href="https://openreview.net/pdf?id=SJTCsqMUf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=matthewp%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthewp@allenai.org">Matthew E Peters</a>, <a href="https://openreview.net/profile?email=markn%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="markn@allenai.org">Mark Neumann</a>, <a href="https://openreview.net/profile?email=mohiti%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohiti@allenai.org">Mohit Iyyer</a>, <a href="https://openreview.net/profile?email=mattg%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="mattg@allenai.org">Matt Gardner</a>, <a href="https://openreview.net/profile?email=csquared%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="csquared@cs.washington.edu">Christopher Clark</a>, <a href="https://openreview.net/profile?email=kentonl%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kentonl@cs.washington.edu">Kenton Lee</a>, <a href="https://openreview.net/profile?email=lsz%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsz@cs.washington.edu">Luke Zettlemoyer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Feb 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJTCsqMUf-details-667" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJTCsqMUf-details-667"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy).  Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis.  We also present an analysis showing that exposing the deep internals of the pretrained network is crucial, allowing downstream models to mix different types of semi-supervision signals.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We introduce a new type of deep contextualized word representation that significantly improves the state of the art for a range of challenging NLP tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">representation learning, contextualized word embeddings</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1NKuC6SG">
      <h4>
        <a href="https://openreview.net/forum?id=B1NKuC6SG">
          Language Style Transfer from Non-Parallel Text with Arbitrary Styles
        </a>
        
          <a href="https://openreview.net/pdf?id=B1NKuC6SG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhaoyp1%40shanghaitech.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaoyp1@shanghaitech.edu.cn">Yanpeng Zhao</a>, <a href="https://openreview.net/profile?email=victoriabi%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="victoriabi@tencent.com">Victoria W. Bi</a>, <a href="https://openreview.net/profile?email=thisisjcykcd%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thisisjcykcd@gmail.com">Deng Cai</a>, <a href="https://openreview.net/profile?email=kieranliu%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kieranliu@tencent.com">Xiaojiang Liu</a>, <a href="https://openreview.net/profile?email=tukw%40shanghaitech.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="tukw@shanghaitech.edu.cn">Kewei Tu</a>, <a href="https://openreview.net/profile?email=shumingshi%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shumingshi@tencent.com">Shuming Shi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">30 Jan 2018 (modified: 01 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1NKuC6SG-details-509" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1NKuC6SG-details-509"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">style transfer, text generation, non-parallel data</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJWu8i18G">
      <h4>
        <a href="https://openreview.net/forum?id=HJWu8i18G">
          title
        </a>
        
          <a href="https://openreview.net/pdf?id=HJWu8i18G" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        authors
      </div>
      
      <div class="note-meta-info">
        <span class="date">01 Feb 2018 (modified: 01 Feb 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJWu8i18G-details-432" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJWu8i18G-details-432"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">abstract</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1cT3NTBM">
      <h4>
        <a href="https://openreview.net/forum?id=H1cT3NTBM">
          Learning Audio Features for Singer Identification and Embedding
        </a>
        
          <a href="https://openreview.net/pdf?id=H1cT3NTBM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chw160%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chw160@ucsd.edu">Cheng-i Wang</a>, <a href="https://openreview.net/profile?email=gtzan%E2%80%8B%40cs%E2%80%8B.uvic%E2%80%8B.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gtzan​@cs​.uvic​.ca">George Tzanetakis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">30 Jan 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1cT3NTBM-details-164" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1cT3NTBM-details-164"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">There has been an increasing use of neural networks for music information retrieval tasks. In this paper, we empirically investigate different ways of improving the performance of convolutional neural networks (CNNs) on spectral audio features. More specifically, we explore three aspects of CNN design: depth of the network, the use of residual blocks along with the use of grouped convolution, and global aggregation over time. The application context is singer classification and singing performance embedding and we believe the conclusions extend to other types of music analysis using convolutional neural networks. The results show that global time aggregation helps to improve the performance of CNNs the most. Another contribution of this paper is the release of a singing recording dataset that can be used for training and evaluation. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using deep learning techniques on singing voice related tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">convolution neural networks, attention, music information retrieval</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJsb_xTSM">
      <h4>
        <a href="https://openreview.net/forum?id=SJsb_xTSM">
          Multitask learning of Multilingual Sentence Representations
        </a>
        
          <a href="https://openreview.net/pdf?id=SJsb_xTSM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=singlak%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="singlak@usc.edu">Karan Singla</a>, <a href="https://openreview.net/profile?email=dogancan%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dogancan@usc.edu">Dogan Can</a>, <a href="https://openreview.net/profile?email=shri%40ee.usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shri@ee.usc.edu">Shrikanth Narayanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">30 Jan 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJsb_xTSM-details-327" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJsb_xTSM-details-327"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a novel multi-task training approach to learning multilingual distributed representations of text. Our system learns word and sentence embeddings jointly by training a multilingual skip-gram model together with a cross-lingual sentence similarity model. We construct sentence embeddings by processing word embeddings with an LSTM and by taking an average of the outputs. Our architecture can transparently use both monolingual and sentence aligned bilingual corpora to learn multilingual embeddings, thus covering a vocabulary significantly larger than the vocabulary of the bilingual corpora alone. Our model shows competitive performance in a standard cross-lingual document classification task. We also show the effectiveness of our method in a low-resource scenario.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We jointly train a multilingual skip-gram model and a cross-lingual sentence similarity model to learn high quality multilingual text embeddings that perform well in the low resource scenario.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multilingual, embedding, representation learning, multi-task learning, low resource</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryEJWe2HM">
      <h4>
        <a href="https://openreview.net/forum?id=ryEJWe2HM">
          Melody Generation for Pop Music via Word Representation of Musical Properties
        </a>
        
          <a href="https://openreview.net/pdf?id=ryEJWe2HM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=andrew%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrew@mi.t.u-tokyo.ac.jp">Andrew Shin</a>, <a href="https://openreview.net/profile?email=crestel%40ircam.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="crestel@ircam.fr">Leopold Crestel</a>, <a href="https://openreview.net/profile?email=kato%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="kato@mi.t.u-tokyo.ac.jp">Hiroharu Kato</a>, <a href="https://openreview.net/profile?email=k-saito%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="k-saito@mi.t.u-tokyo.ac.jp">Kuniaki Saito</a>, <a href="https://openreview.net/profile?email=ohnishi%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="ohnishi@mi.t.u-tokyo.ac.jp">Katsunori Ohnishi</a>, <a href="https://openreview.net/profile?email=yamaguchi%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="yamaguchi@mi.t.u-tokyo.ac.jp">Masataka Yamaguchi</a>, <a href="https://openreview.net/profile?email=nakawaki.ici%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nakawaki.ici@gmail.com">Masahiro Nakawaki</a>, <a href="https://openreview.net/profile?email=ushiku%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="ushiku@mi.t.u-tokyo.ac.jp">Yoshitaka Ushiku</a>, <a href="https://openreview.net/profile?email=harada%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="harada@mi.t.u-tokyo.ac.jp">Tatsuya Harada</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">29 Jan 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryEJWe2HM-details-995" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryEJWe2HM-details-995"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Automatic melody generation for pop music has been a long-time aspiration for
      both AI researchers and musicians. However, learning to generate euphonious
      melody has turned out to be highly challenging due to a number of factors. Representation
      of multivariate property of notes has been one of the primary challenges.
      It is also difficult to remain in the permissible spectrum of musical variety, outside
      of which would be perceived as a plain random play without auditory pleasantness.
      Observing the conventional structure of pop music poses further challenges.
      In this paper, we propose to represent each note and its properties as a unique
      ‘word,’ thus lessening the prospect of misalignments between the properties, as
      well as reducing the complexity of learning. We also enforce regularization policies
      on the range of notes, thus encouraging the generated melody to stay close
      to what humans would find easy to follow. Furthermore, we generate melody
      conditioned on song part information, thus replicating the overall structure of a
      full song. Experimental results demonstrate that our model can generate auditorily
      pleasant songs that are more indistinguishable from human-written ones than
      previous models.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel model to represent notes and their properties, which can enhance the automatic melody generation.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">music, lstm, gan, generation, rnn, hmm</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryOBB6g-M">
      <h4>
        <a href="https://openreview.net/forum?id=ryOBB6g-M">
          Spatial Variational Auto-Encoding via Matrix-Variate Normal Distributions
        </a>
        
          <a href="https://openreview.net/pdf?id=ryOBB6g-M" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zwang6%40eecs.wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zwang6@eecs.wsu.edu">Zhengyang Wang</a>, <a href="https://openreview.net/profile?email=hao.yuan%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hao.yuan@wsu.edu">Hao Yuan</a>, <a href="https://openreview.net/profile?email=sji%40eecs.wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sji@eecs.wsu.edu">Shuiwang Ji</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryOBB6g-M-details-807" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryOBB6g-M-details-807"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The key idea of variational auto-encoders (VAEs) resembles that of traditional auto-encoder models in which spatial information is supposed to be explicitly encoded in the latent space. However, the latent variables in VAEs are vectors, which can be interpreted as multiple feature maps of size 1x1. Such representations can only convey spatial information implicitly when coupled with powerful decoders. In this work, we propose spatial VAEs that use feature maps of larger size as latent variables to explicitly capture spatial information. This is achieved by allowing the latent variables to be sampled from matrix-variate normal (MVN) distributions whose parameters are computed from the encoder network. To increase dependencies among locations on latent feature maps and reduce the number of parameters, we further propose spatial VAEs via low-rank MVN distributions. Experimental results show that the proposed spatial VAEs outperform original VAEs in capturing rich structural and spatial information.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Variational auto-encoder, unsupervised learning, image generation, spatial information, matrix-variate normal distribution</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkNzJ4m0-">
      <h4>
        <a href="https://openreview.net/forum?id=rkNzJ4m0-">
          Overview on Reinforcement Learning for Robotics
        </a>
        
          <a href="https://openreview.net/pdf?id=rkNzJ4m0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">29 Oct 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkNzJ4m0--details-334" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkNzJ4m0--details-334"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Reinforcement Learning(RL) offers robotics tasks a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors.[1]
      Reinforcement Learning is an branch of Machine Learning inspired by behaviorist psychology[wiki- Reinforcemenr Learning], concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.
      The basic idea of Reinforcement Learning is to obtain a policy that extract more reward from the environment by picking actions given a state.
      By policy, we mean a decision maker (Agent) that decide on an action based on some parameterized rules given an input observation of environment (State). The policy can be a set of weight that linearly combine the features in a state or different structured Neural Network. The environment in Reinforcement Learning context provide the agent a new state and reward immediately after the agent takes a specific action.
      From a more broad view, the Machine Learning method was mainly three folds. The Supervised Learning, Semi-supervised Learning and Unsupervised Learning. The supervised learning network was trained given a dataset including the observation data and the corresponding categorization. The latter was given a dataset that no classification is label to the observation data. For reinforcement Learning, it is more close to supervised learning, while its label is obtained by exploring the environment and get feedback (reward, r) from it. The RL algorithm marks the policy that generates the highest score as the training target and make small change of its parameters (or weights, θ) towards that policy until the policy converge.
      In this report, we mainly focus on the methods of Reinforcement Learning methods for robotics.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Reinforcement Learning, Robotics</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1D4bs1Wz">
      <h4>
        <a href="https://openreview.net/forum?id=r1D4bs1Wz">
          Dense Transformer Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=r1D4bs1Wz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jun.li3%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jun.li3@wsu.edu">Jun Li</a>, <a href="https://openreview.net/profile?email=yongjun.chen%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yongjun.chen@wsu.edu">Yongjun Chen</a>, <a href="https://openreview.net/profile?email=lei.cai%40wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lei.cai@wsu.edu">Lei Cai</a>, <a href="https://openreview.net/profile?email=davidson%40cs.ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidson@cs.ucdavis.edu">Ian Davidson</a>, <a href="https://openreview.net/profile?email=sji%40eecs.wsu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sji@eecs.wsu.edu">Shuiwang Ji</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">02 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1D4bs1Wz-details-614" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1D4bs1Wz-details-614"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The key idea of current deep learning methods for dense prediction
      is to apply a model on a regular patch centered on each pixel to
      make pixel-wise predictions. These methods are limited in the sense
      that the patches are determined by network architecture instead of
      learned from data. In this work, we propose the dense transformer
      networks, which can learn the shapes and sizes of patches from data.
      The dense transformer networks employ an encoder-decoder
      architecture, and a pair of dense transformer modules are inserted
      into each of the encoder and decoder paths. The novelty of this work
      is that we provide technical solutions for learning the shapes and
      sizes of patches from data and efficiently restoring the spatial
      correspondence required for dense prediction. The proposed dense
      transformer modules are differentiable, thus the entire network can
      be trained. We apply the proposed networks on natural and biological
      image segmentation tasks and show superior performance is achieved
      in comparison to baseline methods.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJ8lbVAfz">
      <h4>
        <a href="https://openreview.net/forum?id=BJ8lbVAfz">
          Self-Organization adds application robustness to deep learners
        </a>
        
          <a href="https://openreview.net/pdf?id=BJ8lbVAfz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hartono%40ieee.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="hartono@ieee.org">Pitoyo Hartono</a>, <a href="https://openreview.net/profile?email=tt%40cs.dal.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tt@cs.dal.edu">Thomas Trappenberg</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">25 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJ8lbVAfz-details-578" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJ8lbVAfz-details-578"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">While self-organizing principles have motivated much of early learning models, such principles have rarely been included in deep learning architectures. Indeed, from a supervised learning perspective it seems that topographic constraints are rather decremental to optimal performance. Here we study a network model that incorporates self-organizing maps into a supervised network and show how gradient learning results in a form of a self-organizing learning rule. Moreover, we show that such a model is robust in the sense of its application to a variety of  areas, which is believed to be a hallmark of biological learning systems. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">integration of self-organization and supervised learning in a hierarchical neural network</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">supervised learning, unsupervised learning, self-organization, internal representation, topological structure</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ8X2VT7M">
      <h4>
        <a href="https://openreview.net/forum?id=rJ8X2VT7M">
          Information Theoretic Co-Training
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ8X2VT7M" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mcallester%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcallester@ttic.edu">David McAllester</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">06 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ8X2VT7M-details-333" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ8X2VT7M-details-333"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper introduces an information theoretic co-training objective for unsupervised learning.  We consider the problem of predicting the future. Rather than predict future sensations (image pixels or sound waves) we predict ``hypotheses'' to be confirmed by future sensations. More formally, we assume a population distribution on pairs $(x,y)$ where we can think of $x$ as a past sensation and $y$ as a future sensation. We train both a predictor model $P_\Phi(z|x)$ and a confirmation model $P_\Psi(z|y)$ where we view $z$ as hypotheses (when predicted) or facts (when confirmed). For a population distribution on pairs $(x,y)$ we focus on the problem of measuring the mutual information between $x$ and $y$. By the data processing inequality this mutual information is at least as large as the mutual information between $x$ and $z$ under the distribution on triples $(x,z,y)$ defined by the confirmation model $P_\Psi(z|y)$. The information theoretic training objective for $P_\Phi(z|x)$ and $P_\Psi(z|y)$ can be viewed as a form of co-training where we want the prediction from $x$ to match the confirmation from $y$. We give experiments on applications to learning phonetics on the TIMIT dataset.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Presents an information theoretic training objective for co-training and demonstrates its power in unsupervised learning of phonetics.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">co-training, phonetics, unsupervised learning, mutual information</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BysrYlP0-">
      <h4>
        <a href="https://openreview.net/forum?id=BysrYlP0-">
          Placeholder 
        </a>
        
          <a href="https://openreview.net/pdf?id=BysrYlP0-" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=chongyangtao%40163.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongyangtao@163.com">Chongyang Tao</a>, <a href="https://openreview.net/profile?email=63388%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="63388@qq.com">Shen Gao</a>, <a href="https://openreview.net/profile?email=shangmy%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="shangmy@pku.edu.cn">Mingyue Shang</a>, <a href="https://openreview.net/profile?email=ruiyan%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruiyan@pku.edu.cn">Rui Yan</a>, <a href="https://openreview.net/profile?email=zhaody%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaody@pku.edu.cn">Dongyan Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">01 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BysrYlP0--details-270" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BysrYlP0--details-270"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Placeholder </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Dialog Systems, Language Generation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rko6pIcRZ">
      <h4>
        <a href="https://openreview.net/forum?id=rko6pIcRZ">
          The Multilinear Structure of ReLU Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rko6pIcRZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tlaurent%40lmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tlaurent@lmu.edu">Thomas Laurent</a>, <a href="https://openreview.net/profile?email=james.vonbrecht%40csulb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.vonbrecht@csulb.edu">James von Brecht</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">04 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rko6pIcRZ-details-11" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rko6pIcRZ-details-11"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the loss surface of neural networks that involve only rectified linear unit (ReLU) nonlinearities from a theoretical point-of-view. Any such network defines a piecewise multilinear form in parameter space. As a consequence, optima of such networks generically occur in non-differentiable regions of parameter space and so any understanding of such networks must carefully take into account their non-smooth nature. We then proceed to leverage this multilinear structure in an analysis of a neural network with one hidden-layer. Under the assumption of linearly separable data, the piecewise bilinear structure of the loss allows us to provide an explicit  description of all  critical points.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyyHX4gZM">
      <h4>
        <a href="https://openreview.net/forum?id=HyyHX4gZM">
          Towards Quantum Inspired Convolution Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=HyyHX4gZM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=dg1%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dg1@nyu.edu">Davi Geiger</a>, <a href="https://openreview.net/profile?email=kedem%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kedem@nyu.edu">Zvi Kedem</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">02 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyyHX4gZM-details-825" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyyHX4gZM-details-825"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep Convolution Neural Networks (CNNs), rooted by the pioneer work of  \cite{Hinton1986,LeCun1985,Alex2012}, and summarized in \cite{LeCunBengioHinton2015},   have been shown to be very useful in a variety of fields.  The  state-of-the art CNN machines such as image rest net \cite{He_2016_CVPR} are described by real value inputs and kernel convolutions followed by the local and  non-linear rectified linear outputs.  Understanding the role of these layers, the accuracy and limitations of them,  as well as making them more efficient (fewer parameters)  are all ongoing research questions. 
       
       Inspired in quantum theory, we propose the use of complex value kernel functions, followed by the local non-linear  absolute (modulus) operator square. We argue that an advantage of quantum inspired complex kernels is robustness to realistic unpredictable scenarios (such as clutter noise,  data deformations). We study a concrete problem of shape detection and show that when multiple overlapping shapes are deformed and/or clutter noise is added, a convolution layer with quantum inspired complex kernels outperforms the statistical/classical kernel counterpart and a "Bayesian shape estimator" . The superior performance is due to the quantum phenomena of interference, not present in classical CNNs.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A quantum inspired kernel for convolution network, exhibiting interference phenomena,  can be very useful (and compared it with real value  counterpart).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">quantum technique, convolution networks, shape detection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BykJlIAbM">
      <h4>
        <a href="https://openreview.net/forum?id=BykJlIAbM">
          A cluster-to-cluster framework for neural machine translation
        </a>
        
          <a href="https://openreview.net/pdf?id=BykJlIAbM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">13 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BykJlIAbM-details-868" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BykJlIAbM-details-868"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The quality of a machine translation system depends largely on the availability of sizable parallel corpora. For the recently popular Neural Machine Translation (NMT) framework, data sparsity problem can become even more severe. With large amount of tunable parameters, the NMT model may overfit to the existing language pairs while failing to understand the general diversity in language. In this paper, we advocate to broadcast every sentence pair as two groups of similar sentences to incorporate more diversity in language expressions, which we name as parallel cluster. Then we define a more general cluster-to-cluster correspondence score and train our model to maximize this score. Since direct maximization is difficult, we derive its lower-bound as our surrogate objective, which is found to generalize point-point Maximum Likelihood Estimation (MLE) and point-to-cluster Reward Augmented Maximum Likelihood (RAML) algorithms as special cases. Based on this novel objective function, we delineate four potential systems to realize our cluster-to-cluster framework and test their performances in three recognized translation tasks, each task with forward and reverse translation directions. In each of the six experiments, our proposed four parallel systems have consistently proved to outperform the MLE baseline, RL (Reinforcement Learning) and RAML systems significantly. Finally, we have performed case study to empirically analyze the strength of the cluster-to-cluster NMT framework. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We invent a novel cluster-to-cluster framework for NMT training, which can better understand the both source and target language diversity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Natural Language Processing, Machine Translation, Deep Learning, Data Augmentation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1PaPUsXM">
      <h4>
        <a href="https://openreview.net/forum?id=r1PaPUsXM">
          Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic Interpretation of Deep Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=r1PaPUsXM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">04 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1PaPUsXM-details-753" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1PaPUsXM-details-753"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper gives a rigorous analysis of trained Generalized Hamming Networks (GHN) proposed by Fan (2017) and discloses an interesting finding about GHNs, i.e. stacked convolution layers in a GHN is equivalent to a single yet wide convolution layer. The revealed equivalence, on the theoretical side, can be regarded as a constructive manifestation of the universal approximation theorem Cybenko (1989); Hornik (1991). In practice, it has profound and multi-fold implications. For network visualization, the constructed deep epitomes at each layer provide a visualization of network internal representation that does not rely on the input data. Moreover, deep epitomes allows the direct extraction of features in just one step, without resorting to regularized optimizations used in existing visualization tools.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">bridge the gap in soft computing</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, CNN, fuzzy logic, generalized hamming distance</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r16u6i_Xz">
      <h4>
        <a href="https://openreview.net/forum?id=r16u6i_Xz">
          Interactive Boosting of Neural Networks for Small-sample Image Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=r16u6i_Xz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xiaoxulilut%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoxulilut@gmail.com">Xiaoxu Li</a>, <a href="https://openreview.net/profile?email=dlchanglut%40hotmai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlchanglut@hotmai.com">Dongliang Chang</a>, <a href="https://openreview.net/profile?email=zt%40es.aau.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="zt@es.aau.dk">Zheng-Hua Tan</a>, <a href="https://openreview.net/profile?email=mazhanyu%40bupt.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="mazhanyu@bupt.edu.cn">Zhanyu Ma</a>, <a href="https://openreview.net/profile?email=guojun%40bupt.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="guojun@bupt.edu.cn">Jun Guo</a>, <a href="https://openreview.net/profile?email=caoj%40lut.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="caoj@lut.cn">Jie Cao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">02 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r16u6i_Xz-details-703" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r16u6i_Xz-details-703"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Neural networks have recently shown excellent performance on numerous classi- fication tasks. These networks often have a large number of parameters and thus require much data to train. When the number of training data points is small, however, a network with high flexibility will quickly overfit the training data, resulting in a large model variance and a poor generalization performance. To address this problem, we propose a new ensemble learning method called InterBoost for small-sample image classification. In the training phase, InterBoost first randomly generates two complementary datasets to train two base networks of the same structure, separately, and then next two complementary datasets for further training the networks are generated through interaction (or information sharing) between the two base networks trained previously. This interactive training process continues iteratively until a stop criterion is met. In the testing phase, the outputs of the two networks are combined to obtain one final score for classification. Detailed analysis of the method is provided for an in-depth understanding of its mechanism.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">In the paper, we proposed an ensemble method called InterBoost for training neural networks for small-sample classification. The method has better generalization performance than other ensemble methods, and reduces variances significantly.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">ensemble learning, neural network, small-sample, overfitting, variance</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyB9Np6WG">
      <h4>
        <a href="https://openreview.net/forum?id=HyB9Np6WG">
          Tensor-Based Preposition Representation
        </a>
        
          <a href="https://openreview.net/pdf?id=HyB9Np6WG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hgong6%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hgong6@illinois.edu">Hongyu Gong</a>, <a href="https://openreview.net/profile?email=pramodv%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pramodv@illinois.edu">Suma Bhat</a>, <a href="https://openreview.net/profile?email=spbhat2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="spbhat2@illinois.edu">Pramod Viswanath</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">13 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HyB9Np6WG-details-735" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyB9Np6WG-details-735"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Prepositions are among the most frequent words. Good prepositional representation  is of great syntactic and semantic interest  in computational linguistics. Existing methods on preposition representation either treat prepositions as content words (e.g., word2vec and GloVe) or depend heavily on external linguistic resources including syntactic parsing, training task and dataset-specific representations. In this paper we use word-triple counts (one of the words is a preposition) to  capture the preposition's interaction with its head and children. Prepositional  embeddings are derived via tensor decompositions on a large unlabeled corpus.  We reveal a new geometry involving Hadamard products and empirically demonstrate its utility in paraphrasing of phrasal verbs. Furthermore, our prepositional  embeddings are used as simple features to two challenging downstream tasks: preposition selection and prepositional attachment disambiguation. We achieve comparable to or better results than state of the art on  multiple standardized datasets.  </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">This work is about tensor-based method for preposition representation training.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">word representation, unsupervised learning, computational linguistics</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1G6uM0WG">
      <h4>
        <a href="https://openreview.net/forum?id=B1G6uM0WG">
          Tactical Decision Making for Lane Changing with Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B1G6uM0WG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=mmukadam3%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mmukadam3@gatech.edu">Mustafa Mukadam</a>, <a href="https://openreview.net/profile?email=acosgun%40hra.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="acosgun@hra.com">Akansel Cosgun</a>, <a href="https://openreview.net/profile?email=anakhaei%40hra.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anakhaei@hra.com">Alireza Nakhaei</a>, <a href="https://openreview.net/profile?email=kfujimura%40hra.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kfujimura@hra.com">Kikuo Fujimura</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">13 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1G6uM0WG-details-536" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1G6uM0WG-details-536"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we consider the problem of autonomous lane changing for self driving vehicles in a multi-lane, multi-agent setting. We present a framework that demonstrates a more structured and data efficient alternative to end-to-end complete policy learning on problems where the high-level policy is hard to formulate using traditional optimization or rule based methods but well designed low-level controllers are available. Our framework uses deep reinforcement learning solely to obtain a high-level policy for tactical decision making, while still maintaining a tight integration with the low-level controller, thus getting the best of both worlds. We accomplish this with Q-masking, a technique with which we are able to incorporate prior knowledge, constraints, and information from a low-level controller, directly in to the learning process thereby simplifying the reward function and making learning faster and data efficient. We provide preliminary results in a simulator and show our approach to be more efficient than a greedy baseline, and more successful and safer than human driving.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A framework that provides a policy for autonomous lane changing by learning to make high-level tactical decisions with deep reinforcement learning, and maintaining a tight integration with a low-level controller to take low-level actions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">autonomous lane changing, decision making, deep reinforcement learning, q-learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1-IBSgMz">
      <h4>
        <a href="https://openreview.net/forum?id=H1-IBSgMz">
           A Matrix Approximation View of NCE that Justifies Self-Normalization
        </a>
        
          <a href="https://openreview.net/pdf?id=H1-IBSgMz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jacob.goldberger%40biu.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="jacob.goldberger@biu.ac.il">Jacob Goldberger</a>, <a href="https://openreview.net/profile?email=oren%40melamuds.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oren@melamuds.com">Oren Melamud</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">15 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1-IBSgMz-details-942" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1-IBSgMz-details-942"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Self-normalizing discriminative models approximate the normalized probability of a class without having to compute the partition function. This property is useful to computationally-intensive neural network classifiers, as the cost of computing the partition function grows linearly with the number of classes and may become prohibitive. In particular, since neural language models may deal with up to millions of classes, their self-normalization properties received notable attention. Several
      recent studies empirically found that language models, trained using Noise Contrastive Estimation (NCE), exhibit self-normalization, but could not explain why. In this study, we provide a theoretical justification to this property by viewing
      NCE as a low-rank matrix approximation. Our empirical investigation compares NCE to the alternative explicit approach for self-normalizing language models. It also uncovers a surprising negative correlation between self-normalization and
      perplexity, as well as some regularity in the observed errors that may potentially be used for improving self-normalization algorithms in the future.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We prove that NCE is self-normalized and demonstrate it on datasets</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">language modeling, NCE, self-normalization</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rknJHfXBz">
      <h4>
        <a href="https://openreview.net/forum?id=rknJHfXBz">
          Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text
        </a>
        
          <a href="https://openreview.net/pdf?id=rknJHfXBz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">22 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rknJHfXBz-details-954" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rknJHfXBz-details-954"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recently, deep neural network models have shown promising opportunities for many natural language processing (NLP) tasks. In practice, the number of parameters of deep neural models is often significantly larger than the size of the training set, and its generalization behavior cannot be explained by the classic generalization theory. In this paper, with extensive experiments, we empirically investigate the model capacity and generalization of neural models for text. The experiments show that deep neural models can find patterns better than brute-force memorization. Therefore, a large-capacity model with early-stopping stochastic gradient descent (SGD) as implicit regularizer seems to be the best choice, as it has better generalization ability and higher convergence speed.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Text, Empirical Investigation, Model Capacity, Generalization Ability, Neural Networks, Deep Learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJjADecmf">
      <h4>
        <a href="https://openreview.net/forum?id=SJjADecmf">
          Detecting Anomalies in Communication Packet Streams based on  Generative Adversarial Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=SJjADecmf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJjADecmf-details-809" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJjADecmf-details-809"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The fault diagnosis in a modern communication system is traditionally supposed to be difficult, or even impractical for a purely data-driven machine learning approach, for it is a humanmade system of intensive knowledge. A few labeled raw packet streams extracted from fault archive can hardly be sufficient to deduce the intricate logic of underlying protocols. In this paper, we supplement these limited samples with two inexhaustible data sources: the unlabeled records probed from a system in service, and the labeled data simulated in an emulation environment. To transfer their inherent knowledge to the target domain, we construct a directed information flow graph, whose nodes are neural network components consisting of two generators, three discriminators and one classifier, and whose every forward path represents a pair of adversarial optimization goals, in accord with the semi-supervised and transfer learning demands. The multi-headed network can be trained in an alternative approach, at each iteration of which we select one target to update the weights along the path upstream, and refresh the residual layer-wisely to all outputs downstream. The actual results show that it can achieve comparable accuracy on classifying Transmission Control Protocol (TCP) streams without deliberate expert features. The solution has relieved operation engineers from massive works of understanding and maintaining rules, and provided a quick solution independent of specific protocols.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">semi-supervised and transfer learning on packet flow classification, via a system of cooperative or adversarial neural blocks</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Anomaly Detection, Fault diagnosis, Generative Adversarial Networks, Network Operation, TCP/IP</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SywMS6ZfM">
      <h4>
        <a href="https://openreview.net/forum?id=SywMS6ZfM">
          Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection
        </a>
        
          <a href="https://openreview.net/pdf?id=SywMS6ZfM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=hschang%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hschang@cs.umass.edu">Haw-Shiuan Chang</a>, <a href="https://openreview.net/profile?email=wang-zy14%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wang-zy14@mails.tsinghua.edu.cn">ZiYun Wang</a>, <a href="https://openreview.net/profile?email=luke%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="luke@cs.umass.edu">Luke Vilnis</a>, <a href="https://openreview.net/profile?email=mccallum%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mccallum@cs.umass.edu">Andrew McCallum</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SywMS6ZfM-details-288" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SywMS6ZfM-details-288"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Modeling hypernymy, such as poodle is-a dog, is an important generalization aid to many NLP tasks, such as entailment, relation extraction, and question answering. Supervised learning from labeled hypernym sources, such as WordNet, limit the coverage of these models, which can be addressed by learning hypernyms from unlabeled text.  Existing unsupervised methods either do not scale to large vocabularies or yield unacceptably poor accuracy.  This paper introduces {\it distributional inclusion vector embedding (DIVE)}, a simple-to-implement unsupervised method of hypernym discovery via per-word non-negative vector embeddings which preserve the inclusion property of word contexts. In experimental evaluations more comprehensive than any previous literature of which we are aware---evaluating on 11 datasets using multiple existing as well as newly proposed scoring functions---we find that our method provides up to double the precision of previous unsupervised methods, and the highest average performance, using a much more compact word representation, and yielding many new state-of-the-art results. In addition, the meaning of each dimension in DIVE is interpretable, which leads to a novel approach on word sense disambiguation as another promising application of DIVE.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a novel unsupervised word embedding which preserves the inclusion property in the context distribution and achieve state-of-the-art results on unsupervised hypernymy detection</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">unsupervised word embedding, unsupervised hypernym detection, distributional inclusion hypothesis, non-negative matrix factorization, word sense disambiguation, hypernym scoring functions</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="By03VlJGG">
      <h4>
        <a href="https://openreview.net/forum?id=By03VlJGG">
          Embedding Multimodal Relational Data
        </a>
        
          <a href="https://openreview.net/pdf?id=By03VlJGG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=pezeshkp%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pezeshkp@uci.edu">Pouya Pezeshkpour</a>, <a href="https://openreview.net/profile?email=liyanc%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liyanc@uci.edu">Liyan Chen</a>, <a href="https://openreview.net/profile?email=sameer%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sameer@uci.edu">Sameer Singh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">14 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#By03VlJGG-details-390" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="By03VlJGG-details-390"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Representing entities and relations in an embedding space is a well-studied approach for machine learning on relational data. Existing approaches however primarily focus on simple link structure between a finite set of entities, ignoring the variety of data types that are often used in relational databases, such as text, images, and numerical values. In our approach, we propose a multimodal embedding using different neural encoders for this variety of data, and combine with existing models to learn embeddings of the entities. We extend existing datasets to create two novel benchmarks, YAGO-10-plus and MovieLens-100k-plus, that contain additional relations such as textual descriptions and images of the original entities. We demonstrate that our model utilizes the additional information effectively to provide further gains in accuracy. Moreover, we test our learned multimodal embeddings by using them to predict missing multimodal attributes. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Extending relational modeling to support multimodal data using neural encoders.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">multimodal, knowledge base, relational modeling, embedding, link prediction, neural network encoders</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJPO7JMyG">
      <h4>
        <a href="https://openreview.net/forum?id=SJPO7JMyG">
          Automatic Measurement on Etched Structure in Semiconductor Using Deep Learning Approach
        </a>
        
          <a href="https://openreview.net/pdf?id=SJPO7JMyG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">09 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJPO7JMyG-details-804" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJPO7JMyG-details-804"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The fabrication of semiconductor involves etching process to remove selected areas from wafers. However, the measurement of etched structure in micro-graph heavily relies on time-consuming manual routines. Traditional image processing usually demands on large number of annotated data and the performance is still poor. We treat this challenge as segmentation problem and use deep learning approach to detect masks of objects in etched structure of wafer. Then, we use simple image processing to carry out automatic measurement on the objects. We attempt Generative Adversarial Network (GAN) to generate more data to overcome the problem of very limited dataset. We download 10 SEM (Scanning Electron Microscope) images of 4 types from Internet, based on which we carry out our experiments. Our deep learning based method demonstrates superiority over image processing approach with  mean accuracy reaching over 96% for the measurements, compared with the ground truth. To the best of our knowledge, it is the first time that deep learning has been applied in semiconductor industry for automatic measurement.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Using deep learning method to carry out automatic measurement of SEM images in semiconductor industry</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, segmentation, automatic measurement, semiconductor, Scanning Electron Microscope</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1zRea1Mf">
      <h4>
        <a href="https://openreview.net/forum?id=H1zRea1Mf">
          pix2code: Generating Code from a Graphical User Interface Screenshot
        </a>
        
          <a href="https://openreview.net/pdf?id=H1zRea1Mf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">14 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1zRea1Mf-details-570" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1zRea1Mf-details-570"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Transforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">CNN and LSTM to generate markup-like code describing graphical user interface images.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">computer vision, scene understanding, text processing</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r11QyBLAZ">
      <h4>
        <a href="https://openreview.net/forum?id=r11QyBLAZ">
          Word Mover's Embedding: From Word2Vec to Document Embedding
        </a>
        
          <a href="https://openreview.net/pdf?id=r11QyBLAZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wuli%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuli@us.ibm.com">Lingfei Wu</a>, <a href="https://openreview.net/profile?email=eyan%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eyan@cs.cmu.edu">Ian En-Hsu Yen</a>, <a href="https://openreview.net/profile?email=fxu02%40email.wm.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fxu02@email.wm.edu">Fangli Xu</a>, <a href="https://openreview.net/profile?email=avinash.bala%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avinash.bala@us.ibm.com">Avinash Balakrishnan</a>, <a href="https://openreview.net/profile?email=pin-yu.chen%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pin-yu.chen@ibm.com">Pin-Yu Chen</a>, <a href="https://openreview.net/profile?email=pradeepr%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pradeepr@cs.cmu.edu">Pradeep Ravikumar</a>, <a href="https://openreview.net/profile?email=witbrock%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="witbrock@us.ibm.com">Michael J. Witbrock</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">01 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r11QyBLAZ-details-731" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r11QyBLAZ-details-731"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Learning effective text representations is a key foundation for numerous machine learning and NLP applications. While the celebrated Word2Vec technique yields semantically rich word representations, it is less clear whether sentence or document representations should be built upon word representations or from scratch. Recent work has demonstrated that a distance measure between documents called \emph{Word Mover's Distance} (WMD) that aligns semantically similar words, yields unprecedented KNN classification accuracy. However, WMD is very expensive to compute, and is harder to apply beyond simple KNN than feature embeddings. In this paper, we propose the \emph{Word Mover's Embedding } (WME), a novel approach to building an unsupervised document (sentence) embedding from pre-trained word embeddings. Our technique extends the theory of \emph{Random Features} to show convergence of the inner product between WMEs to a positive-definite kernel that can be interpreted as a soft version of (inverse) WMD. The proposed embedding is more efficient and flexible than WMD in many situations. As an example, WME with a simple linear classifier reduces the computational cost of WMD-based KNN \emph{from cubic to linear} in document length and \emph{from quadratic to linear} in number of samples, while simultaneously improving accuracy. In experiments on 9 benchmark text classification datasets and 22 textual similarity tasks the proposed technique consistently matches or outperforms state-of-the-art techniques, with significantly higher accuracy on problems of short length.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A novel approach to building an unsupervised document (sentence) embeddings from pre-trainedword embeddings</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Word2Vec, Word Mover's Distance, Document Embedding</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sk62KZYRW">
      <h4>
        <a href="https://openreview.net/forum?id=Sk62KZYRW">
          Confidence Scoring Using Whitebox Meta-models with Linear Classifier Probes
        </a>
        
          <a href="https://openreview.net/pdf?id=Sk62KZYRW" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tongfei%40cs.jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tongfei@cs.jhu.edu">Tongfei Chen</a>, <a href="https://openreview.net/profile?email=jiri%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiri@us.ibm.com">Jiří Navrátil</a>, <a href="https://openreview.net/profile?email=viyengar%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="viyengar@us.ibm.com">Vijay Iyengar</a>, <a href="https://openreview.net/profile?email=karthikeyan.shanmugam2%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karthikeyan.shanmugam2@ibm.com">Karthikeyan Shanmugam</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sk62KZYRW-details-952" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sk62KZYRW-details-952"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a confidence scoring mechanism for multi-layer neural networks based on a paradigm of a base model and a meta-model. The confidence score is learned by the meta-model using features derived from the base model – a deep neural network considered a whitebox. As features, we investigate linear classifier probes inserted between the various layers of the base model and trained using each layer’s intermediate activations. Experiments show that this approach outperforms various baselines in a filtering task, i.e., task of rejecting samples with low confidence. Experimental results are presented using CIFAR-10 and CIFAR-100 dataset with and without added noise exploring various aspects of the method.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">confidence scoring, meta-model, linear classifier probes</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkSZyinVG">
      <h4>
        <a href="https://openreview.net/forum?id=HkSZyinVG">
          Improved Learning in Convolutional Neural Networks with Shifted Exponential Linear Units (ShELUs)
        </a>
        
          <a href="https://openreview.net/pdf?id=HkSZyinVG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">17 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkSZyinVG-details-514" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkSZyinVG-details-514"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The Exponential Linear Unit (ELU) has been proven to speed up learning and improve the classification performance over activation functions such as ReLU and Leaky ReLU for convolutional neural networks. The reasons behind the improved behavior are that ELU reduces the bias shift, it saturates for large negative inputs and it is continuously differentiable. However, it remains open whether ELU has the optimal shape and we address the quest for a superior activation function.
      We use a new formulation to tune a piecewise linear activation function during training, to investigate the above question, and learn the shape of the locally optimal activation function. With this tuned activation function, the classification performance is improved and the resulting, learned activation function shows to be ELU-shaped irrespective if it is initialized as a RELU, LReLU or ELU. Interestingly, the learned activation function does not exactly pass through the origin indicating that a shifted ELU-shaped activation function is preferable. This observation leads us to introduce the Shifted Exponential Linear Unit (ShELU) as a new activation function.
      Experiments on Cifar-100 show that the classification performance is further improved when using the ShELU activation function in comparison with ELU. The improvement is achieved when learning an individual bias shift for each neuron.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B11bwYgfM">
      <h4>
        <a href="https://openreview.net/forum?id=B11bwYgfM">
          Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=B11bwYgfM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=yum%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yum@us.ibm.com">Mo Yu</a>, <a href="https://openreview.net/profile?email=xiaoxiao.guo%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoxiao.guo@ibm.com">Xiaoxiao Guo</a>, <a href="https://openreview.net/profile?email=jinfengyi.ustc%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinfengyi.ustc@gmail.com">Jinfeng Yi</a>, Shiyu Chang, Saloni Potdar, Gerald Tesauro, Haoyu Wang, Bowen Zhou
      </div>
      
      <div class="note-meta-info">
        <span class="date">15 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B11bwYgfM-details-904" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B11bwYgfM-details-904"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We investigate task clustering for deep learning-based multi-task and few-shot learning in the settings with large numbers of diverse tasks. Our method measures task similarities using cross-task transfer performance matrix. Although this matrix provides us critical information regarding similarities between tasks, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. Moreover, when the number of tasks is large, generating the full transfer performance matrix can be very time consuming. To overcome these limitations, we propose a novel task clustering algorithm to estimate the similarity matrix based on the theory of matrix completion. The proposed algorithm can work on partially-observed similarity matrices based on only sampled task-pairs with reliable scores, ensuring its efficiency and robustness. Our theoretical analysis shows that under mild assumptions, the reconstructed matrix perfectly matches the underlying “true” similarity matrix with an overwhelming probability. The final task partition is computed by applying an efficient spectral clustering algorithm to the recovered matrix. Our results show that the new task clustering method can discover task clusters that benefit both multi-task learning and few-shot learning setups for sentiment classification and dialog intent classification tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a matrix-completion based task clustering algorithm for deep multi-task and few-shot learning in the settings with large numbers of diverse tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">task clustering, matrix completion, multi-task learning, few-shot learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1Azqvy1G">
      <h4>
        <a href="https://openreview.net/forum?id=S1Azqvy1G">
          Pseudo sequence based deep neural network compression
        </a>
        
          <a href="https://openreview.net/pdf?id=S1Azqvy1G" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">08 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#S1Azqvy1G-details-334" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1Azqvy1G-details-334"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Along with the performance increase of the neural network, both the number of layers and the number of parameters in each layer are becoming larger and larger. Therefore, there are more and more works trying to compress the neural network efficiently while keeping the performance. However, all of them have not taken the similarity among the kernels into consideration. In this paper, we try to organize the kernels in different channels into a frame and encode the frames using block-based video coding methods. First, we try to reshape the weights in different channels into a pseudo sequence. Second, after obtaining all the frames in the videos, we will convert the weight into the PCA domain to obtain a more compact representation. Then both the intra prediction and the inter prediction will be performed in the PCA domain to achieve better performance. Finally, the uniform quantization and entropy coding will be used to encode the residue blocks. The experimental results show that we can achieve $58$ times compression for the classical VGG-16 model. Not only with very high compression ratio, the proposed method can also provide the benefits of getting a better balance between the bits per weight and the error in more precise granularity by adjusting the quantization parameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkktYCkZf">
      <h4>
        <a href="https://openreview.net/forum?id=BkktYCkZf">
          Per-Weight Class-Based Learning Rates via Analytical Continuation
        </a>
        
          <a href="https://openreview.net/pdf?id=BkktYCkZf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=migo007%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="migo007@gmail.com">Michael Rotman</a>, <a href="https://openreview.net/profile?email=wolf%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wolf@fb.com">Lior Wolf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">02 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkktYCkZf-details-53" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkktYCkZf-details-53"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We study the problem of training deep fully connected neural networks. Despite much progress in the design of activation functions, novel normalization techniques, and various skip-connection techniques, such networks remain challenging to train due to vanishing or exploding gradients. Our method is based on employing a different class-dependent learning rate to each network weight. Since the learning rates are hyperparameters and not part of the network, we perform an analytical continuation of the network, and create a generalized network. Following this reparameterization, the set of per-class per-weight learning rates are being manipulated during the training iterations. Our results show that the new algorithm leads to improved classification accuracy for both classical and modern activation functions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">adaptive learning rates, analytical continuation, fully connected networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkTQ8UckG">
      <h4>
        <a href="https://openreview.net/forum?id=BkTQ8UckG">
          VSE++: Improving Visual-Semantic Embeddings with Hard Negatives
        </a>
        
          <a href="https://openreview.net/pdf?id=BkTQ8UckG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=faghri%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="faghri@cs.toronto.edu">Fartash Faghri</a>, <a href="https://openreview.net/profile?email=fleet%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fleet@cs.toronto.edu">David J. Fleet</a>, <a href="https://openreview.net/profile?email=rkiros%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rkiros@cs.toronto.edu">Jamie Ryan Kiros</a>, <a href="https://openreview.net/profile?email=fidler%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fidler@cs.toronto.edu">Sanja Fidler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>1 Reply</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkTQ8UckG-details-576" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkTQ8UckG-details-576"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a new technique for learning visual-semantic embeddings for cross-modal retrieval.  Inspired by the use of hard negatives in structured prediction, and ranking loss functions used in retrieval, we introduce a simple change to common loss functions used to learn multi-modal embeddings.  That, combined with fine-tuning and the use of augmented data, yields significant gains in retrieval performance.  We showcase our approach, dubbed VSE++, on the MS-COCO and Flickr30K datasets, using ablation studies and comparisons with existing methods.  On MS-COCO our approach outperforms state-of-the-art methods by 8.8% in caption retrieval, and 11.3% in image retrieval (based on R@1).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A new loss based on relatively hard negatives that achieves state-of-the-art performance in image-caption retrieval.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Joint embeddings, Hard Negatives, Visual-semantic embeddings, Cross-modal retrieval, Ranking</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJtPtdqQG">
      <h4>
        <a href="https://openreview.net/forum?id=HJtPtdqQG">
          Dynamically Learning the Learning Rates:  Online Hyperparameter Optimization
        </a>
        
          <a href="https://openreview.net/pdf?id=HJtPtdqQG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tsarkar%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsarkar@mit.edu">Tuhin Sarkar</a>, <a href="https://openreview.net/profile?email=animakumar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="animakumar@gmail.com">Anima Anandkumar</a>, <a href="https://openreview.net/profile?email=leodirac%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="leodirac@amazon.com">Leo Dirac</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJtPtdqQG-details-247" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJtPtdqQG-details-247"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Hyperparameter tuning is arguably the most important ingredient for obtaining state of art performance in deep networks.  We focus on hyperparameters  that are related to the optimization algorithm, e.g.  learning rates, which have a large impact on the training speed and the resulting accuracy. Typically, fixed learning rate schedules are employed during training. We propose Hyperdyn a dynamic hyperparameter optimization method that selects new learning rates on the fly at the end of each epoch. Our explore-exploit   framework  combines Bayesian optimization (BO) with a rejection strategy, based on a simple probabilistic wait and watch test.   We obtain state of  art accuracy results on CIFAR and Imagenet datasets, but with significantly faster training, when compared with the best manually tuned networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Bayesian optimization based online hyperparameter optimization.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hyperparameters, optimization, SGD, Adam, Bayesian</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rk1J969Xz">
      <h4>
        <a href="https://openreview.net/forum?id=rk1J969Xz">
          MULTI-MODAL GEOLOCATION ESTIMATION USING DEEP NEURAL NETWORKS
        </a>
        
          <a href="https://openreview.net/pdf?id=rk1J969Xz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=jesse.johns%40pnnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="jesse.johns@pnnl.gov">Jesse Johns</a>, <a href="https://openreview.net/profile?email=jeremiah.rounds%40pnnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeremiah.rounds@pnnl.gov">Jeremiah Rounds</a>, <a href="https://openreview.net/profile?email=michael.j.henry%40pnnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.j.henry@pnnl.gov">Michael Henry</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">04 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rk1J969Xz-details-383" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rk1J969Xz-details-383"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Estimating the location where an image was taken based solely on the contents of the image is a challenging task, even for humans, as properly labeling an image in such a fashion relies heavily on contextual information, and is not as simple as identifying  a single object in the image. Thus any methods which attempt to do so must somehow account for these complexities, and no single model to date is completely capable of addressing all challenges. This work contributes to the state of research in image geolocation inferencing by introducing a novel global meshing strategy, outlining a variety of training procedures to overcome the considerable data limitations when training these models, and demonstrating how incorporating additional information can be used to improve the overall performance of a geolocation inference model. In this work, it is shown that Delaunay triangles are an effective type of mesh for geolocation in relatively low volume scenarios when compared to results from state of the art models which use quad trees and an order of magnitude more training data.  In addition, the time of posting, learned user albuming, and other meta data are easily incorporated to improve geolocation by up to 11% for country-level (750 km) locality accuracy to 3% for city-level (25 km) localities.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">A global geolocation inferencing strategy with novel meshing strategy and demonstrating incorporating additional information can be used to improve the overall performance of a geolocation inference model.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep neural networks, geolocation, inception, long-short term memory networks, social media applications</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkBCjzp7G">
      <h4>
        <a href="https://openreview.net/forum?id=BkBCjzp7G">
          Accelerating Convolutional Neural Networks using Iterative Two-Pass Decomposition
        </a>
        
          <a href="https://openreview.net/pdf?id=BkBCjzp7G" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=weishianglin1993%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weishianglin1993@gmail.com">Wei-Shiang Lin</a>, <a href="https://openreview.net/profile?email=wuhoward2002%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuhoward2002@gmail.com">Hao-Ning Wu</a>, <a href="https://openreview.net/profile?email=cthuang%40cs.nthu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="cthuang@cs.nthu.edu.tw">Chih-Tsun Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">05 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkBCjzp7G-details-564" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkBCjzp7G-details-564"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present the iterative two-pass decomposition flow to accelerate existing convolutional neural networks (CNNs).  The proposed rank selection algorithm can effectively determine the proper ranks of the target convolutional layers for the low rank approximation. Our two-pass CP-decomposition helps prevent from the instability problem. The iterative flow makes the decomposition of the deeper networks systematic. The experiment results shows that VGG16 can be accelerated with a 6.2x measured speedup while the accuracy drop remains only 1.2%.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We present the iterative two-pass CP decomposition flow to effectively accelerate existing convolutional neural networks (CNNs).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Convolutional Neural Networks, CNN, CP Decomposition, Low Rank Approximation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJ1os4eHf">
      <h4>
        <a href="https://openreview.net/forum?id=rJ1os4eHf">
          Adaptive Weight Sparsity for Training Deep Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=rJ1os4eHf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=michael%40cerebras.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael@cerebras.net">Michael James</a>, <a href="https://openreview.net/profile?email=jacklindsey%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jacklindsey@stanford.edu">Jack Lindsey</a>, <a href="https://openreview.net/profile?email=ilya%40cerebras.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilya@cerebras.net">Ilya Sharapov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">20 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rJ1os4eHf-details-300" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJ1os4eHf-details-300"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We introduce adaptive weight sparsity, an algorithm that allows a neural network to learn a sparse connection pattern during training. We demonstrate that the proposed algorithm shows performance benefits across a wide variety of tasks and network structures, improving state-of-the-art results for recurrent networks of comparable size. We show that adaptive weight sparsity outperforms traditional pruning-based approaches to learning sparse configurations on convolutional and recurrent networks.  We offer insights into the algorithm's behavior, demonstrating that training-time adaptivity is crucial to the success of the method and uncovering an interpretable evolution toward small-world network structures.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, sparsity, adaptive methods</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJWpQCa7z">
      <h4>
        <a href="https://openreview.net/forum?id=HJWpQCa7z">
          Deep Net Triage: Assessing The Criticality of Network Layers by Structural Compression
        </a>
        
          <a href="https://openreview.net/pdf?id=HJWpQCa7z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=tsnowak%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsnowak@umich.edu">Theodore S. Nowak</a>, <a href="https://openreview.net/profile?email=jjcorso%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjcorso@umich.edu">Jason J. Corso</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">06 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJWpQCa7z-details-42" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJWpQCa7z-details-42"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep network compression seeks to reduce the number of parameters in the network while maintaining a certain level of performance.  Deep network distillation seeks to train a smaller network that matches soft-max performance of a larger network.  While both regimes have led to impressive performance for their respective goals, neither provide insight into the importance of a given layer in the original model, which is useful if we are to improve our understanding of these highly parameterized models.  In this paper, we present the concept of deep net triage, which individually assesses small blocks of convolution layers to understand their collective contribution to the overall performance, which we call \emph{criticality}.  We call it triage because we assess this criticality by answering the question: what is the impact to the health of the overall network if we compress a block of layers into a single layer.
      We propose a suite of triage methods and compare them on problem spaces of varying complexity.  We ultimately show that, across these problem spaces, deep net triage is able to indicate the of relative importance of different layers.  Surprisingly, our local structural compression technique also leads to an improvement in overall accuracy when the final model is fine-tuned globally.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We seek to understand learned representations in compressed networks via an experimental regime we call deep net triage</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Compression, Deep Learning, Parent-Teacher Networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryOegkTXf">
      <h4>
        <a href="https://openreview.net/forum?id=ryOegkTXf">
          Deep Active Learning over the Long Tail
        </a>
        
          <a href="https://openreview.net/pdf?id=ryOegkTXf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">05 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryOegkTXf-details-510" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryOegkTXf-details-510"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">This paper is concerned with pool-based active learning for deep neural networks. Motivated by coreset dataset compression ideas, we present a novel active learning algorithm that queries consecutive points from the pool using farthest-first traversals in the space of neural activation over a representation layer. We show consistent and overwhelming improvement in sample complexity over passive learning (random sampling) for three datasets: MNIST, Cifar-10, and Cifar-100. In addition, our algorithm outperforms the traditional uncertainty sampling technique (obtained using softmax activations), and we identify cases where uncertainty sampling is only slightly better than random sampling.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Active Learning, Deep Learning, Coreset, Deep Representation, Compression</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sy3nGCYXz">
      <h4>
        <a href="https://openreview.net/forum?id=Sy3nGCYXz">
          THE LOCAL DIMENSION OF DEEP MANIFOLD
        </a>
        
          <a href="https://openreview.net/pdf?id=Sy3nGCYXz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zmx%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zmx@hust.edu.cn">Mengxiao Zhang</a>, <a href="https://openreview.net/profile?email=u201514497%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="u201514497@hust.edu.cn">Wangquan Wu</a>, <a href="https://openreview.net/profile?email=hhxjzyr%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="hhxjzyr@hust.edu.cn">Yanren Zhang</a>, <a href="https://openreview.net/profile?email=brooklet60%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="brooklet60@hust.edu.cn">Kun He</a>, <a href="https://openreview.net/profile?email=ydtydr%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ydtydr@sjtu.edu.cn">Tao Yu</a>, <a href="https://openreview.net/profile?email=longhuan%40cs.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="longhuan@cs.sjtu.edu.cn">Huan Long</a>, <a href="https://openreview.net/profile?email=jeh%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeh@cs.cornell.edu">John E. Hopcroft</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Sy3nGCYXz-details-481" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sy3nGCYXz-details-481"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Based on our observation that there exists a dramatic drop for the singular values of the fully connected layers or a single feature map of the convolutional layer, and that the dimension of the concatenated feature vector almost equals the summation of the dimension on each feature map, we propose a singular value decomposition (SVD) based approach to estimate the dimension of the deep manifolds for a typical convolutional neural network VGG19. We choose three categories from the ImageNet, namely Persian Cat, Container Ship and Volcano, and determine the local dimension of the deep manifolds of the deep layers through the tangent space of a target image. Through several augmentation methods, we found that the Gaussian noise method is closer to the intrinsic dimension, as by adding random noise to an image we are moving in an arbitrary dimension, and when the rank of the feature matrix of the augmented images does not increase we are very close
      to the local dimension of the manifold. We also estimate the dimension of the deep manifold based on the tangent space for each of the maxpooling layers. Our results show that the dimensions of different categories are close to each other and decline quickly along the convolutional layers and fully connected layers. Furthermore, we show that the dimensions decline quickly inside the Conv5 layer. Our work provides new insights for the intrinsic structure of deep neural networks and helps unveiling the inner organization of the black box of deep neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose a SVD based method to explore the local dimension of activation manifold in deep neural networks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">activation manifold, dimension, deep neural network, singular value decomposition</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkh-agjMG">
      <h4>
        <a href="https://openreview.net/forum?id=rkh-agjMG">
          Learning to Imagine Manipulation Goals for Robot Task Planning
        </a>
        
          <a href="https://openreview.net/pdf?id=rkh-agjMG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=cpaxton%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cpaxton@jhu.edu">Chris Paxton</a>, <a href="https://openreview.net/profile?email=kkatyal2%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kkatyal2@jhu.edu">Kapil Katyal</a>, <a href="https://openreview.net/profile?email=christian.rupprecht%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="christian.rupprecht@in.tum.de">Christian Rupprecht</a>, <a href="https://openreview.net/profile?email=arora%40cs.jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="arora@cs.jhu.edu">Raman Arora</a>, <a href="https://openreview.net/profile?email=hager%40cs.jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hager@cs.jhu.edu">Gregory D Hager</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">23 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkh-agjMG-details-150" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkh-agjMG-details-150"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Prospection is an important part of how humans come up with new task plans, but has not been explored in depth in robotics. Predicting multiple task-level is a challenging problem that involves capturing both task semantics and continuous variability over the state of the world. Ideally, we would combine the ability of machine learning to leverage big data for learning the semantics of a task, while using techniques from task planning to reliably generalize to new environment. In this work, we propose a method for learning a model encoding just such a representation for task planning. We learn a neural net that encodes the k most likely outcomes from high level actions from a given world. Our approach creates comprehensible task plans that allow us to predict changes to the environment many time steps into the future. We demonstrate this approach via application to a stacking task in a cluttered environment, where the robot must select between different colored blocks while avoiding obstacles, in order to perform a task. We also show results on a simple navigation task. Our algorithm generates realistic image and pose predictions at multiple points in a given task.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We describe an architecture for generating diverse hypotheses for intermediate goals during robotic manipulation tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep learning, planning, prediction, generative models</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skvin0GWM">
      <h4>
        <a href="https://openreview.net/forum?id=Skvin0GWM">
          Human-like Clustering with Deep Convolutional Neural Networks
        </a>
        
          <a href="https://openreview.net/pdf?id=Skvin0GWM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=aliborji%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aliborji@gmail.com">Ali Borji</a>, <a href="https://openreview.net/profile?email=adundar%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="adundar@purdue.edu">Aysegul Dundar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">04 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Skvin0GWM-details-601" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skvin0GWM-details-601"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Classification and clustering have been studied separately in machine learning and computer vision. Inspired by the recent success of deep learning models in solving various vision problems (e.g., object recognition, semantic segmentation) and the fact that humans serve as the gold standard in assessing clustering algorithms, here, we advocate for a unified treatment of the two problems and suggest that hierarchical frameworks that progressively build complex patterns on top of the simpler ones (e.g., convolutional neural networks) offer a promising solution. We do not dwell much on the learning mechanisms in these frameworks as they are still a matter of debate, with respect to biological constraints. Instead, we emphasize on the compositionality of the real world structures and objects. In particular, we show that CNNs, trained end to end using back propagation with noisy labels, are able to cluster data points belonging to several overlapping shapes, and do so much better than the state of the art algorithms. The main takeaway lesson from our study is that mechanisms of human vision, particularly the hierarchal organization of the visual ventral stream should be taken into account in clustering algorithms (e.g., for learning representations in an unsupervised manner or with minimum supervision) to reach human level clustering performance. This, by no means, suggests that other methods do not hold merits. For example, methods relying on pairwise affinities (e.g., spectral clustering) have been very successful in many cases but still fail in some cases (e.g., overlapping clusters).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Human-like Clustering with CNNs</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Cluttering, deep learning, human learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1wN2f2-G">
      <h4>
        <a href="https://openreview.net/forum?id=B1wN2f2-G">
          Attribute-aware Collaborative Filtering: Survey and Classification
        </a>
        
          <a href="https://openreview.net/pdf?id=B1wN2f2-G" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=b02902023%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="b02902023@ntu.edu.tw">Wen-Hao Chen</a>, <a href="https://openreview.net/profile?email=chinchi%40iis.sinica.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="chinchi@iis.sinica.edu.tw">Chin-Chi Hsu</a>, <a href="https://openreview.net/profile?email=miyen%40iis.sinica.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="miyen@iis.sinica.edu.tw">Mi-Yen Yeh</a>, <a href="https://openreview.net/profile?email=sdlin%40csie.ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="sdlin@csie.ntu.edu.tw">Shou-De Lin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">11 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1wN2f2-G-details-557" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1wN2f2-G-details-557"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Attribute-aware CF models aims at rating prediction given not only the historical rating from users to items, but also the information associated with users (e.g. age),  items (e.g. price),  or even ratings (e.g. rating time).   This paper surveys
      works in the past decade developing attribute-aware CF systems, and discovered that mathematically they can be classified into four different categories.  We provide the readers not only the high level mathematical interpretation of the existing
      works in this area but also the mathematical insight for each category of models. Finally we provide our preliminary experiment results comparing the effectiveness of the major works in each category.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJyy3a0Ez">
      <h4>
        <a href="https://openreview.net/forum?id=BJyy3a0Ez">
          Continuous Propagation: Layer-Parallel Training
        </a>
        
          <a href="https://openreview.net/pdf?id=BJyy3a0Ez" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=michae%40cerebras.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="michae@cerebras.net">Michael James</a>, <a href="https://openreview.net/profile?email=devansharpit%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="devansharpit@gmail.com">Devansh Arpit</a>, <a href="https://openreview.net/profile?email=herman%40cerebras.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="herman@cerebras.net">Herman Sahota</a>, <a href="https://openreview.net/profile?email=ilya%40cerebras.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilya@cerebras.net">Ilya Sharapov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">19 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BJyy3a0Ez-details-115" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJyy3a0Ez-details-115"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Continuous propagation is a parallel technique for training deep neural networks with batch size one at full utilization of a multiprocessor system. It enables spatially distributed computations on emerging deep learning hardware accelerators that do not impose programming limitations of contemporary GPUs. The algorithm achieves model parallelism along the depth of a deep network. The method is based on the continuous representation of the optimization process and enables sustained gradient generation during all phases of computation. We demonstrate that in addition to its increased concurrency, continuous propagation improves the convergence rate of state of the art methods while matching their accuracy. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Model parallelism, Learning theory</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byni8NLHf">
      <h4>
        <a href="https://openreview.net/forum?id=Byni8NLHf">
          Learning Topics using Semantic Locality
        </a>
        
          <a href="https://openreview.net/pdf?id=Byni8NLHf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zzhao37%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zzhao37@syr.edu">Ziyi Zhao</a>, <a href="https://openreview.net/profile?email=kpugdeet%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kpugdeet@syr.edu">Krittaphat Pugdeethosapol</a>, <a href="https://openreview.net/profile?email=shlin%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shlin@syr.edu">Sheng Lin</a>, <a href="https://openreview.net/profile?email=zli89%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zli89@syr.edu">Zhe Li</a>, <a href="https://openreview.net/profile?email=ywang393%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywang393@syr.edu">Yanzhi Wang</a>, <a href="https://openreview.net/profile?email=qiqiu%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiqiu@syr.edu">Qinru Qiu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">25 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Byni8NLHf-details-437" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byni8NLHf-details-437"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The topic modeling discovers the latent topic probability of given the text documents. To generate the more meaningful topic that better represents the given document, we proposed a universal method which can be used in the data preprocessing stage. The method consists of three steps. First, it generates the word/word-pair from every single document. Second, it applies a two way parallel TF-IDF algorithm to word/word-pair for semantic filtering. Third, it uses the k-means algorithm to merge the word pairs that have the similar semantic meaning.
      
      Experiments are carried out on the Open Movie Database (OMDb), Reuters Dataset and 20NewsGroup Dataset and use the mean Average Precision score as the evaluation metric. Comparing our results with other state-of-the-art topic models, such as Latent Dirichlet allocation and traditional Restricted Boltzmann Machines. Our proposed data preprocessing can improve the generated topic accuracy by up to 12.99\%. How the number of clusters and the number of word pairs should be adjusted for different type of text document is also discussed.
      </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We proposed a universal method which can be used in the data preprocessing stage to generate the more meaningful topic that better represents the given document</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylfg-DNM">
      <h4>
        <a href="https://openreview.net/forum?id=rylfg-DNM">
          Anticipatory Asynchronous Advantage Actor-Critic (A4C): The power of Anticipation in Deep Reinforcement Learning
        </a>
        
          <a href="https://openreview.net/pdf?id=rylfg-DNM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=xun.luan%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xun.luan@rice.edu">Xun Luan</a>, <a href="https://openreview.net/profile?email=trm3%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="trm3@rice.edu">Tharun Medini</a>, <a href="https://openreview.net/profile?email=anshumali%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anshumali@rice.edu">Anshumali Shrivastava</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">13 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rylfg-DNM-details-296" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylfg-DNM-details-296"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose to extend existing deep reinforcement learning  (Deep RL) algorithms by allowing them to additionally choose sequences of actions as a part of their policy.  This modification forces the network to anticipate the reward of action sequences, which, as we show, improves the exploration leading to better convergence. Our proposal is simple, flexible, and can be easily incorporated into any Deep RL framework. We show the power of our scheme by consistently outperforming the state-of-the-art GA3C algorithm on several popular Atari Games.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Anticipation improves convergence of deep reinforcement learning.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">deep reinforcement learning, A3C, deep learning, Atari games</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkpqdGDeM">
      <h4>
        <a href="https://openreview.net/forum?id=rkpqdGDeM">
          Sparse Deep Scattering Croisé Network
        </a>
        
          <a href="https://openreview.net/pdf?id=rkpqdGDeM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=rom.cosentino%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rom.cosentino@gmail.com">Romain Cosentino</a>, <a href="https://openreview.net/profile?email=randallbalestriero%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="randallbalestriero@gmail.com">Randall Balestriero</a>, <a href="https://openreview.net/profile?email=ankitpatel715%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ankitpatel715@gmail.com">Richard Baraniuk</a>, <a href="https://openreview.net/profile?email=baraniuk%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="baraniuk@gmail.com">Ankit Patel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>1 Reply</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkpqdGDeM-details-261" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkpqdGDeM-details-261"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this work, we propose the Sparse Deep Scattering Croisé Network (SDCSN) a novel architecture based on the Deep Scattering Network (DSN). The DSN is achieved by cascading  wavelet transform convolutions with a complex modulus and a time-invariant operator. We extend this work by first,
      crossing multiple wavelet family transforms to increase the feature diversity while avoiding any learning. Thus providing a more informative latent representation and benefit from the development of highly specialized wavelet filters over the last decades. Beside, by combining all the different wavelet representations, we reduce the amount of prior information needed regarding the signals at hand.
      Secondly, we develop an optimal thresholding strategy for over-complete filter banks that regularizes the network and controls instabilities such as inherent non-stationary noise in the signal. Our systematic and principled solution sparsifies the latent representation of the network by acting as a local mask distinguishing between activity and noise. Thus, we propose to enhance the DSN by increasing the variance of the scattering coefficients representation as well as improve its robustness with respect to non-stationary noise.
      We show that our new approach is more robust and outperforms the DSN on a bird detection task.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We propose to enhance the Deep Scattering Network  in order to improve control and stability of any given machine learning pipeline by proposing a continuous wavelet thresholding scheme</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Scattering Network, Continuous Wavelet Thresholding, Sparse Activations, Time-frequency represenation, Multi-Family, Wavelets, Convolutional Network, Bird Detection</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hy-lXyDWG">
      <h4>
        <a href="https://openreview.net/forum?id=Hy-lXyDWG">
          Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing
        </a>
        
          <a href="https://openreview.net/pdf?id=Hy-lXyDWG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sarwar%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sarwar@purdue.edu">Syed Shakib Sarwar</a>, <a href="https://openreview.net/profile?email=aankit%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aankit@purdue.edu">Aayush Ankit</a>, <a href="https://openreview.net/profile?email=kaushik%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaushik@purdue.edu">Kaushik Roy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">07 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Hy-lXyDWG-details-629" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hy-lXyDWG-details-629"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep convolutional neural network (DCNN) based supervised learning is a widely practiced approach for large-scale image classification.  However, retraining these large networks to accommodate new, previously unseen data demands high computational time and energy requirements. Also, previously seen training samples may not be available at the time of retraining. We propose an efficient training methodology and incrementally growing a DCNN to allow new classes to be learned while sharing part of the base network. Our proposed methodology is inspired by transfer learning techniques, although it does not forget previously learned classes. An updated network for learning new set of classes is formed using previously learned convolutional layers (shared from initial part of base network) with addition of few newly added convolutional kernels included in the later layers of the network. We evaluated the proposed scheme on several recognition applications. The classification accuracy achieved by our approach is comparable to the regular incremental learning approach (where networks are updated with new training samples only, without any network sharing).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">The paper is about a new energy-efficient methodology for Incremental learning</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep learning, Incremental learning, energy-efficient learning, supervised learning</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bk9nkMa4G">
      <h4>
        <a href="https://openreview.net/forum?id=Bk9nkMa4G">
          Bayesian Embeddings for Long-Tailed Datasets
        </a>
        
          <a href="https://openreview.net/pdf?id=Bk9nkMa4G" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=victor.fragoso%40mail.wvu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="victor.fragoso@mail.wvu.edu">Victor Fragoso</a>, <a href="https://openreview.net/profile?email=deva%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="deva@andrew.cmu.edu">Deva Ramanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">18 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#Bk9nkMa4G-details-993" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bk9nkMa4G-details-993"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">The statistics of the real visual world presents a long-tailed distribution: a few classes have significantly more training instances than the remaining classes in a dataset. This is because the real visual world has a few classes that are common while others are rare. Unfortunately, the performance of a convolutional neural network is typically unsatisfactory when trained using a long-tailed dataset. To alleviate this issue, we propose a method that discriminatively learns an embedding in which a simple Bayesian classifier can balance the class-priors to generalize well for rare classes. To this end, the proposed approach uses a Gaussian mixture model to factor out class-likelihoods and class-priors in a long-tailed dataset. The proposed method is simple and easy-to-implement in existing deep learning frameworks. Experiments on publicly available datasets show that the proposed approach improves the performance on classes with few training instances, while maintaining a comparable performance to the state-of-the-art on classes with abundant training examples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Approach to improve classification accuracy on classes in the tail.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Long-tail datasets, Imbalanced datasets</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkeR2JURZ">
      <h4>
        <a href="https://openreview.net/forum?id=SkeR2JURZ">
          Distributed Restarting NewtonCG Method for Large-Scale Empirical Risk Minimization
        </a>
        
          <a href="https://openreview.net/pdf?id=SkeR2JURZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=maj314%40lehigh.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="maj314@lehigh.edu">Majid Jahani</a>, <a href="https://openreview.net/profile?email=xih314%40lehigh.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xih314@lehigh.edu">Xi He</a>, <a href="https://openreview.net/profile?email=chm514%40lehigh.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chm514@lehigh.edu">Chenxin Ma</a>, <a href="https://openreview.net/profile?email=dheevatsa.mudigere%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dheevatsa.mudigere@intel.com">Dheevatsa Mudigere</a>, <a href="https://openreview.net/profile?email=aryanm%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aryanm@seas.upenn.edu">Aryan Mokhtari</a>, <a href="https://openreview.net/profile?email=aribeiro%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aribeiro@seas.upenn.edu">Alejandro Ribeiro</a>, <a href="https://openreview.net/profile?email=martin.taki%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.taki@gmail.com">Martin Takac</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">31 Oct 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SkeR2JURZ-details-166" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkeR2JURZ-details-166"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose a distributed damped Newton method in which sample size is gradually increasing to quickly obtain a solution whose empirical loss is under satisfactory statistical accuracy. Our proposed method is multistage in which the solution of one stage serves as a warm start for the next stage which contains more samples (including the samples in the previous stage). This overall multistage algorithm reduce the number of passes over data. Moreover, our algorithm in nature is easy to be distributed and shares the strong scaling property indicating that acceleration is always expected by using more computing nodes. Various iteration complexity results regarding descent direction computation and stopping criteria are analyzed under convex setting. Our results of experiments illustrate that the proposed algorithm can outperform other comparable methods for training machine learning tasks including neural networks.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1O0xvz-z">
      <h4>
        <a href="https://openreview.net/forum?id=r1O0xvz-z">
          Deep Hyperspherical Defense against Adversarial Perturbations
        </a>
        
          <a href="https://openreview.net/pdf?id=r1O0xvz-z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=wyliu%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wyliu@gatech.edu">Weiyang Liu</a>, <a href="https://openreview.net/profile?email=liuzhen1994%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuzhen1994@gatech.edu">Zhen Liu</a>, <a href="https://openreview.net/profile?email=zchen451%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zchen451@gatech.edu">Zhehui Chen</a>, <a href="https://openreview.net/profile?email=bohr.dai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bohr.dai@gmail.com">Bo Dai</a>, <a href="https://openreview.net/profile?email=tourzhao%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tourzhao@gatech.edu">Tuo Zhao</a>, <a href="https://openreview.net/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">04 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1O0xvz-z-details-165" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1O0xvz-z-details-165"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Recent studies show that deep neural networks are extremely vulnerable to adversarial examples which are semantically indistinguishable from natural data and yet incorrectly classified. These adversarial examples are generated from the natural data by adding a small amount of adversarial perturbation. This paper tackles the adversarial attack problem with hyperspherical defense - a defense strategy that learns neural network over hyperspheres. The hyperspherical defense framework is well motivated by: (i) Learning on hyperspheres gives us bounded output, which may make the geometry of neural networks more smooth; (ii) Learning on hyperspheres could naturally eliminate some adversarial perturbations and reduce the effect of adversarial perturbations; (iii) Representing data on hyperspheres selectively drops some information of the inputs, but these information are shown to be not crucial to visual recognition (based on the fact that hyperspherical neural network performs comparable to or even better than standard neural networks in visual recognition). Furthermore, we introduce the hyperspherical compactness and propose a robust geodesic inference. We also provide theoretical insights about why our hyperspherical defense improves robustness. Last, we validate the superiority of hyperspherical defense with extensive experiments on both white-box and black-box adversarial attacks on multiple datasets.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkbOsNeSM">
      <h4>
        <a href="https://openreview.net/forum?id=BkbOsNeSM">
          FastNorm: Improving Numerical Stability of Deep Network Training with Efficient Normalization
        </a>
        
          <a href="https://openreview.net/pdf?id=BkbOsNeSM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=sadhika%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sadhika@mit.edu">Sadhika Malladi</a>, <a href="https://openreview.net/profile?email=ilya%40cerebras.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilya@cerebras.net">Ilya Sharapov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">20 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#BkbOsNeSM-details-423" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkbOsNeSM-details-423"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We propose a modification to weight normalization techniques that provides the same convergence benefits but requires fewer computational operations. The proposed method, FastNorm, exploits the low-rank properties of weight updates and infers the norms without explicitly calculating them, replacing an $O(n^2)$ computation with an $O(n)$ one for a fully-connected layer.  It improves numerical stability and reduces accuracy variance enabling higher learning rate and offering better convergence.  We report experimental results that illustrate the advantage of the proposed method. </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural networks, Training, Convergence</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1-4BLaQz">
      <h4>
        <a href="https://openreview.net/forum?id=r1-4BLaQz">
          Cluster-based Warm-Start Nets
        </a>
        
          <a href="https://openreview.net/pdf?id=r1-4BLaQz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">06 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#r1-4BLaQz-details-879" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1-4BLaQz-details-879"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Theories in cognitive psychology postulate that humans use similarity as a basis
      for object categorization. However, work in image classification generally as-
      sumes disjoint and equally dissimilar classes to achieve super-human levels of
      performance on certain datasets. In our work, we adapt notions of similarity using
      weak labels over multiple hierarchical levels to boost classification performance.
      Instead of pitting clustering directly against classification, we use a warm-start
      based evaluation to explicitly provide value to a clustering representation by its
      ability to aid classification. We evaluate on CIFAR10 and a fine-grained classifi-
      cation dataset to show improvements in performance with the procedural addition
      of intermediate losses and weak labels based on multiple hierarchy levels. Further-
      more, we show that pretraining AlexNet on hierarchical weak labels in conjunc-
      tion with intermediate losses outperforms a classification baseline by over 17% on
      a subset of Birdsnap dataset. Finally, we show improvement over AlexNet trained
      using ImageNet pre-trained weights as initializations which further supports our 
      claim of the importance of similarity.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Cluster before you classify; using weak labels to improve classification </span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">hierarchical labels, weak labels, pairwise constraints, clustering, classification</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1vOZ8ylG">
      <h4>
        <a href="https://openreview.net/forum?id=B1vOZ8ylG">
          THINK VISUALLY: QUESTION ANSWERING THROUGH VIRTUAL IMAGERY
        </a>
        
          <a href="https://openreview.net/pdf?id=B1vOZ8ylG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ankgoyal%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ankgoyal@umich.edu">Ankit Goyal</a>, <a href="https://openreview.net/profile?email=jianwolf%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianwolf@umich.edu">Jian Wang</a>, <a href="https://openreview.net/profile?email=jiadeng%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiadeng@umich.edu">Jia Deng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">20 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#B1vOZ8ylG-details-753" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1vOZ8ylG-details-753"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we study the problem of visual reasoning in the context of textual question answering. We introduce Dynamic Spatial Memory Networks (DSMN), a new deep network architecture that specializes in answering questions that admit latent visual representations, and learns to generate and reason over such representations. Further, we propose two synthetic benchmarks, HouseQA and ShapeIntersection, to evaluate the visual reasoning capability of textual QA systems. Experimental results validate the effectiveness of our proposed DSMN for visual reasoning tasks.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1TWfmnNf">
      <h4>
        <a href="https://openreview.net/forum?id=H1TWfmnNf">
          Do Convolutional Neural Networks act  as Compositional Nearest Neighbors?
        </a>
        
          <a href="https://openreview.net/pdf?id=H1TWfmnNf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">17 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#H1TWfmnNf-details-846" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1TWfmnNf-details-846"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">We present a simple approach based on pixel-wise nearest neighbors to understand and interpret the functioning of state-of-the-art neural networks for pixel-level tasks. We aim to understand and uncover the synthesis/prediction mechanisms of state-of-the-art convolutional neural networks. To this end, we primarily analyze the synthesis process of generative models and the prediction mechanism of discriminative models. The main hypothesis of this work is that convolutional neural networks for pixel-level tasks learn a fast compositional nearest neighbor synthesis/prediction function. Our experiments on semantic segmentation and image-to-image translation show qualitative and quantitative evidence supporting this hypothesis.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Convolutional Neural Networks behave as Compositional Nearest Neighbors!</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">interpreting convolutional neural networks, nearest neighbors, generative adversarial networks</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryKRRsm0Z">
      <h4>
        <a href="https://openreview.net/forum?id=ryKRRsm0Z">
          Binarized Back-Propagation: Training Binarized Neural Networks with Binarized Gradients
        </a>
        
          <a href="https://openreview.net/pdf?id=ryKRRsm0Z" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=itayhubara%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="itayhubara@gmail.com">Itay Hubara</a>, <a href="https://openreview.net/profile?email=elad.hoffer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="elad.hoffer@gmail.com">Elad Hoffer</a>, <a href="https://openreview.net/profile?email=daniel.soudry%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.soudry@gmail.com">Daniel Soudy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">30 Oct 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#ryKRRsm0Z-details-837" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryKRRsm0Z-details-837"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value"> Binarized Neural networks (BNNs) have been shown to be effective in improving network efficiency during the inference phase, after the network has been trained. However, BNNs only binarize the model parameters and activations during propagations. Therefore, BNNs do not offer significant efficiency improvements during training, since the gradients are still propagated and used with high precision. 
       
       We show there is no inherent difficulty in training BNNs using "Binarized BackPropagation" (BBP), in which we also binarize the gradients. To avoid significant degradation in test accuracy, we simply increase the number of filter maps in a each convolution layer. Using BBP on dedicated hardware can potentially significantly improve the execution efficiency (\emph{e.g.}, reduce dynamic memory footprint, memory bandwidth and computational energy) and speed up the training process with an appropriate hardware support, even after such an increase in network size. Moreover, our method is ideal for distributed learning as it reduces the communication costs significantly (e.g., by ~32). Using this method, we demonstrate a minimal loss in classification accuracy on several datasets and topologies.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Binarized Back-Propagation all you need for completely binarized training is to is to inflate the size of the network</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Neural Network  acceleration, Low Precision neural networks.</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJvq-EcCZ">
      <h4>
        <a href="https://openreview.net/forum?id=SJvq-EcCZ">
          withdraw
        </a>
        
          <a href="https://openreview.net/pdf?id=SJvq-EcCZ" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ll2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ll2@illinois.edu">Liyuan Liu</a>, <a href="https://openreview.net/profile?email=shang7%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shang7@illinois.edu">Jingbo Shang</a>, <a href="https://openreview.net/profile?email=xiaotao2%40illinois.du" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaotao2@illinois.du">Xiaotao Gu</a>, <a href="https://openreview.net/profile?email=xiangren%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiangren@usc.edu">Xiang Ren</a>, <a href="https://openreview.net/profile?email=jianpeng%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianpeng@illinois.edu">Jian Peng</a>, <a href="https://openreview.net/profile?email=hanj%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanj@illinois.edu">Jiawei Han</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">04 Nov 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>0 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SJvq-EcCZ-details-12" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJvq-EcCZ-details-12"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">withdraw</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJFcmshbM">
      <h4>
        <a href="https://openreview.net/forum?id=HJFcmshbM">
          DETECTING ADVERSARIAL PERTURBATIONS WITH SALIENCY
        </a>
        
          <a href="https://openreview.net/pdf?id=HJFcmshbM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=zhangcl16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangcl16@mails.tsinghua.edu.cn">Chiliang Zhang</a>, <a href="https://openreview.net/profile?email=zuochang%40tsinhua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zuochang@tsinhua.edu.cn">Zuochang Ye</a>, <a href="https://openreview.net/profile?email=zhangbo%40xiaomi.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangbo@xiaomi.com">Bo Zhang</a>, <a href="https://openreview.net/profile?email=zhaodeli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaodeli@gmail.com">Deli Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">12 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HJFcmshbM-details-601" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJFcmshbM-details-601"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper we propose novel method for detecting adversarial examples by train-ing a binary classifier with both origin data and saliency data. In the case of image classification model, saliency simply explain how the model make decisions by identifying significant pixels for prediction. Perturbing origin image is essentially perturbing saliency of right output w.r.t. origin image. Our approach shows good performance on detecting adversarial perturbations. We quantitatively evaluate generalization ability of the detector where detector trained with strong adver-saries and its’ saliency perform well on weak adversaries. In addition, we further discuss relationship between solving adversary problem and model interpretation, which helps us understand how convolutional neural networks making wrong de-cisions.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Adversarial Examples, Detection, Saliency, Model Interpretation</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkrqgCWMG">
      <h4>
        <a href="https://openreview.net/forum?id=rkrqgCWMG">
          Withdraw
        </a>
        
          <a href="https://openreview.net/pdf?id=rkrqgCWMG" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=ll2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ll2@illinois.edu">Liyuan Liu</a>, <a href="https://openreview.net/profile?email=shang7%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shang7@illinois.edu">Jingbo Shang</a>, <a href="https://openreview.net/profile?email=xiaotao2%40illinois.du" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaotao2@illinois.du">Xiaotao Gu</a>, <a href="https://openreview.net/profile?email=xiangren%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiangren@usc.edu">Xiang Ren</a>, <a href="https://openreview.net/profile?email=jianpeng%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianpeng@illinois.edu">Jian Peng</a>, <a href="https://openreview.net/profile?email=hanj%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanj@illinois.edu">Jiawei Han</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">16 Dec 2017 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkrqgCWMG-details-888" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkrqgCWMG-details-888"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">withdrawn paper</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkCy2uqQM">
      <h4>
        <a href="https://openreview.net/forum?id=HkCy2uqQM">
          Complex- and Real-Valued Neural Network Architectures
        </a>
        
          <a href="https://openreview.net/pdf?id=HkCy2uqQM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        <a href="https://openreview.net/profile?email=nm819%40york.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="nm819@york.ac.uk">Nils Moenning</a>, <a href="https://openreview.net/profile?email=suresh.manandhar%40york.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="suresh.manandhar@york.ac.uk">Suresh Manandhar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">03 Jan 2018 (modified: 25 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HkCy2uqQM-details-801" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkCy2uqQM-details-801"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Complex-value neural networks are not a new concept, however, the use of real-values has often been favoured over complex-values due to difficulties in training and accuracy of results. Existing literature ignores the number of parameters used. We compared complex- and real-valued neural networks using five activation functions. We found that when real and complex neural networks are compared using simple classification tasks, complex neural networks perform equal to or slightly worse than real-value neural networks. However, when specialised architecture is used, complex-valued neural networks outperform real-valued neural networks. Therefore, complex–valued neural networks should be used when the input data is also complex or it can be meaningfully to the complex plane,  or when the network architecture uses the structure defined by using complex numbers.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Comparison of complex- and real-valued multi-layer perceptron with respect to the number of real-valued parameters.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">complex numbers, complex-valued, neural, network, multi-layer, perceptron, architecture</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rynniUpQM">
      <h4>
        <a href="https://openreview.net/forum?id=rynniUpQM">
          Learning with Mental Imagery
        </a>
        
          <a href="https://openreview.net/pdf?id=rynniUpQM" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">06 Jan 2018 (modified: 12 Jan 2018)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rynniUpQM-details-14" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rynniUpQM-details-14"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">In this paper, we propose deep convolutional generative adversarial networks (DCGAN) that learn to produce a 'mental image' of the input image as internal representation of a certain category of input data distribution.  This mental image is what the DCGAN 'imagines' that the input image might look like under ideal conditions.  The mental image contains a version of the input that is iconic, without any peculiarities that do not contribute to the ideal representation of the input data distribution within a category. A DCGAN learns this association by training an encoder to capture salient features from the original image and a decoder to convert salient features into its associated mental image representation.  Our new approach, which we refer to as a Mental Image DCGAN (MIDCGAN), learns features that are useful for recognizing entire classes of objects, and that this in turn has the benefit of helping single and zero shot recognition.  We demonstrate our approach on object instance recognition and handwritten digit recognition tasks.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">Object instance recognition with adversarial autoencoders was performed with a novel 'mental image' target that is canonical representation of the input image.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value">Deep Learning, Adversarial Networks, Object Instance Recognition, Cognitive AI</span>
          </li>
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyWvxWYQf">
      <h4>
        <a href="https://openreview.net/forum?id=SyWvxWYQf">
          Withdrawn
        </a>
        
          <a href="https://openreview.net/pdf?id=SyWvxWYQf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        withdrawn.
      </div>
      
      <div class="note-meta-info">
        <span class="date">02 Jan 2018</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#SyWvxWYQf-details-439" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyWvxWYQf-details-439"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">withdrawn</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeDJ04Mf">
      <h4>
        <a href="https://openreview.net/forum?id=rkeDJ04Mf">
          HyperNetworks with statistical filtering for defending adversarial examples
        </a>
        
          <a href="https://openreview.net/pdf?id=rkeDJ04Mf" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        Anonymous
      </div>
      
      <div class="note-meta-info">
        <span class="date">18 Dec 2017 (modified: 18 Dec 2017)</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#rkeDJ04Mf-details-152" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeDJ04Mf-details-152"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Deep learning algorithms have been known to be vulnerable to adversarial perturbations in various tasks such as image classification. This problem was addressed by employing several defense methods for detection and rejection of particular types of attacks. However, training and manipulating networks according to particular defense schemes increases computational complexity of the learning algorithms. In this work, we propose a simple yet effective method to improve robustness of convolutional neural networks (CNNs) to adversarial attacks by using data dependent adaptive convolution kernels. To this end, we propose a new type of HyperNetwork in order to employ statistical properties of input data and features for computation of statistical adaptive maps. Then, we filter convolution weights of CNNs with the learned statistical maps to compute dynamic kernels. Thereby, weights and kernels are collectively optimized for learning of image classification models robust to
      adversarial attacks without employment of additional target detection and rejection algorithms.
      We empirically demonstrate that the proposed method enables CNNs to spontaneously defend against different types of attacks, e.g. attacks generated by Gaussian noise, fast gradient sign methods (Goodfellow et al., 2014) and a black-box attack (Narodytska &amp; Kasiviswanathan, 2016).</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value">We modified the CNN using HyperNetworks and observed better robustness against adversarial examples.</span>
          </li>
          
          
          <li>
            <strong class="note-content-field">Withdrawal:</strong>
            <span class="note-content-value">Confirmed</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HksxTdiWz">
      <h4>
        <a href="https://openreview.net/forum?id=HksxTdiWz">
          withdrawn
        </a>
        
          <a href="https://openreview.net/pdf?id=HksxTdiWz" class="pdf-link" title="Download PDF" target="_blank"><img src="./ICLR 2018 Conference _ OpenReview_files/pdf_icon_blue.svg"></a>
        
        </h4>
      
      
      
      <div class="note-authors">
        withdrawn
      </div>
      
      <div class="note-meta-info">
        <span class="date">11 Dec 2017</span>
          <span class="item">ICLR 2018 Conference Withdrawn Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>3 Replies</span>
        
        
      </div>
      
        <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#HksxTdiWz-details-258" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HksxTdiWz-details-258"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value">Paper was withdrawn.</span>
          </li>
          
          
      </ul>
      </div></div>
      
      
      
      
    </li>
</ul>
</div>
</div>
</div></div></div>
      
    </main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="https://openreview.net/about">About OpenReview</a></li>
              <li><a href="https://openreview.net/group?id=OpenReview.net/Support">Hosting a Venue</a></li>
              <li><a href="https://openreview.net/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="https://openreview.net/contact">Contact</a></li>
              <li><a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
              <li><a href="https://codeforscience.org/jobs?job=OpenReview-Developer" target="_blank"><strong>Join the Team</strong></a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="https://openreview.net/terms">Terms of Service</a></li>
              <li><a href="https://openreview.net/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="https://openreview.net/about">About OpenReview</a></li>
              <li><a href="https://openreview.net/group?id=OpenReview.net/Support">Hosting a Venue</a></li>
              <li><a href="https://openreview.net/venues">All Venues</a></li>
              <li><a href="https://codeforscience.org/jobs?job=OpenReview-Developer" target="_blank"><strong>Join the Team</strong></a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="https://openreview.net/contact">Contact</a></li>
              <li><a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
              <li><a href="https://openreview.net/terms">Terms of Service</a></li>
              <li><a href="https://openreview.net/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="https://openreview.net/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email">
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject">
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="./ICLR 2018 Conference _ OpenReview_files/analytics.js.下载"></script><script src="./ICLR 2018 Conference _ OpenReview_files/jquery.min.js.下载"></script>
  <script>window.jQuery || document.write('<script src="/static/js/vendor/jquery-2.2.4.min.js"><\/script>')</script>

  <script src="./ICLR 2018 Conference _ OpenReview_files/vendor.min.js.下载"></script>
  <script src="./ICLR 2018 Conference _ OpenReview_files/templates.min.js.下载"></script>
  <script src="./ICLR 2018 Conference _ OpenReview_files/openreview.min.js.下载"></script>

    <script>window.legacyScripts = false;</script>

    <script>
      
        window.user = {"id":"guest_1565948215550","isGuest":true};
        $(function() {
          var args = {"id":"ICLR.cc/2018/Conference"};
          var group = {"id":"ICLR.cc/2018/Conference","cdate":1518532924300,"ddate":null,"tmdate":1562675385805,"tddate":null,"signatures":["~Super_User1"],"signatories":["ICLR.cc/2018/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2018/Conference"],"members":[],"details":{"writable":false}};
          var document = null;
          var window = null;

          $('#group-container').empty();

          // ------------------------------------
// Advanced venue homepage template
//
// This webfield displays the conference header (#header), the submit button (#invitation),
// and a tabbed interface for viewing various types of notes.
// ------------------------------------

// Constants
var CONFERENCE = 'ICLR.cc/2018/Conference';
var INVITATION = CONFERENCE + '/-/Submission';
var BLIND_INVITATION = CONFERENCE + '/-/Blind_Submission';
var WITHDRAWN_INVITATION = CONFERENCE + '/-/Withdrawn_Submission';

var initialPageLoad = true;

// Main is the entry point to the webfield code and runs everything
function main() {
  Webfield.ui.setup('#group-container', CONFERENCE);  // required

  renderConferenceHeader();

  renderConferenceTabs();

  load().then(renderContent);
}

// Load makes all the API calls needed to get the data to render the page
// It returns a jQuery deferred object: https://api.jquery.com/category/deferred-object/
function load() {
  var notesP = Webfield.api.getSubmissions(BLIND_INVITATION, { pageSize: 1000, details: 'replyCount' });

  var withdrawnNotesP = Webfield.api.getSubmissions(WITHDRAWN_INVITATION, { pageSize: 1000 , noDetails: true});

  var decisionNotesP = Webfield.api.getSubmissions('ICLR.cc/2018/Conference/-/Acceptance_Decision', {
    noDetails: true,
    pageSize: 1000
  });

  return $.when(notesP, withdrawnNotesP, decisionNotesP);
}


// Render functions
function renderConferenceHeader() {
  Webfield.ui.venueHeader({
    title: 'ICLR 2018 Conference Track',
    subtitle: '6th International Conference on Learning Representations',
    location: 'Vancouver Convention Center, Vancouver, BC, Canada',
    date: 'April 30 - May 3, 2018',
    website: 'http://www.iclr.cc'
  });

  Webfield.ui.spinner('#notes');
}

function renderConferenceTabs() {
  var sections = [
    {
      heading: 'Oral Papers',
      id: 'accepted-oral-papers',
    },
    {
      heading: 'Poster Papers',
      id: 'accepted-poster-papers',
    },
    {
      heading: 'Invited to submit to Workshop',
      id: 'workshop-papers',
    },
    {
      heading: 'Rejected Papers',
      id: 'rejected-papers',
    },
    {
      heading: 'Withdrawn Papers',
      id: 'withdrawn-papers',
    }
  ];

  Webfield.ui.tabPanel(sections, {
    container: '#notes',
    hidden: true
  });
}

function renderContent(notes, withdrawnNotes, decisionsNotes) {

  var notesDict = {};
  _.forEach(notes, function(n) {
    notesDict[n.id] = n;
  });

  var oralDecisions = [];
  var posterDecisions = [];
  var rejectDecisions = [];
  var workshopDecisions = [];

  _.forEach(decisionsNotes, function(d) {

    if (_.has(notesDict, d.forum)) {
            if (d.content.decision === 'Accept (Oral)') {
              oralDecisions.push(notesDict[d.forum]);
            } else if (d.content.decision === 'Accept (Poster)') {
              posterDecisions.push(notesDict[d.forum]);
            } else if (d.content.decision === 'Reject') {
              rejectDecisions.push(notesDict[d.forum]);
            } else if (d.content.decision === 'Invite to Workshop Track') {
              workshopDecisions.push(notesDict[d.forum]);
            }    
    }
  });

  var paperDisplayOptions = {
    pdfLink: true,
    replyCount: true,
    showContents: true
  };

  Webfield.ui.searchResults(
    oralDecisions,
    _.assign({}, paperDisplayOptions, {showTags: false, container: '#accepted-oral-papers'})
  );

  Webfield.ui.searchResults(
    posterDecisions,
    _.assign({}, paperDisplayOptions, {showTags: false, container: '#accepted-poster-papers'})
  );

  Webfield.ui.searchResults(
    rejectDecisions,
    _.assign({}, paperDisplayOptions, {showTags: false, container: '#rejected-papers'})
  );

  Webfield.ui.searchResults(
    workshopDecisions,
    _.assign({}, paperDisplayOptions, {showTags: false, container: '#workshop-papers'})
  );

  Webfield.ui.searchResults(
    withdrawnNotes,
    _.assign({}, paperDisplayOptions, {showTags: false, container: '#withdrawn-papers'})
  );



  $('#notes .spinner-container').remove();
  $('.tabs-container').show();

  // Show first available tab
  if (initialPageLoad) {
    $('.tabs-container ul.nav-tabs li a:visible').eq(0).click();
    initialPageLoad = false;
  }
}

// Go!
main();


          
        });
        
    </script>

    <script async="" src="./ICLR 2018 Conference _ OpenReview_files/js"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>